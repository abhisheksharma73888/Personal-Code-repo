(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{100:function(e,n,t){var r=t(101);"string"==typeof r&&(r=[[e.i,r,""]]);var a={hmr:!0,transform:undefined,insertInto:void 0};t(17)(r,a);r.locals&&(e.exports=r.locals)},101:function(e,n,t){(n=t(16)(!1)).push([e.i,".flex-upgrade-content{display:flex;align-items:center}",""]),e.exports=n},116:function(e,n,t){"use strict";var r=t(14),a=t(2),i=t.n(a),o=t(8),l=t(3),s=t(15),c=t(42);let u=class extends a.Component{constructor(e){super(e),this.handleSearch=()=>{this.props.onSearch(this.state.searchTerm)},this.handleBlur=e=>{this.setState({searchTerm:e.target.value},this.handleSearch)},this.handleChange=e=>{this.setState({searchTerm:e.target.value},this.handleSearch)},this.clear=()=>{this.setState({searchTerm:""},this.handleSearch)},this.state={searchTerm:this.props.searchTerm}}componentDidUpdate(e){this.props.searchTerm!==e.searchTerm&&this.setState({searchTerm:this.props.searchTerm})}UNSAFE_componentWillMount(){this.handleSearch=Object(o.debounce)(this.handleSearch,50)}render(){const{placeholderText:e,testID:n,tabIndex:t=0,autoFocus:r,size:a}=this.props,{searchTerm:o}=this.state;return i.a.createElement(c.a,null,i.a.createElement(l.Input,{icon:l.IconFont.Search_New,placeholder:e,value:o,onChange:this.handleChange,onBlur:this.handleBlur,testID:n,className:"search-widget-input",tabIndex:t,onClear:this.clear,autoFocus:r,size:a}))}};u.defaultProps={widthPixels:440,placeholderText:"Search...",searchTerm:"",testID:"search-widget",autoFocus:!1,tabIndex:0,size:l.ComponentSize.Small},u=Object(r.a)([s.a,Object(r.b)("design:paramtypes",[Object])],u),n.a=u},161:function(e,n,t){"use strict";var r=t(2),a=t(6);n.a=class extends r.PureComponent{render(){const{children:e}=this.props;return a.f?null:e}}},214:function(e,n,t){"use strict";t.d(n,"a",(function(){return r})),t.d(n,"b",(function(){return a}));const r={},a=e=>Object.values(r).filter((n=>n.name.toLowerCase().includes(e.toLowerCase()))).sort(((e,n)=>e.name.toLowerCase().localeCompare(n.name.toLowerCase()))),i=t(528);i.keys().forEach((e=>{i(e).default((e=>{if(r.hasOwnProperty(e.id))throw new Error(`Client of type [${e.id}] has already been registered`);r[e.id]=Object.assign({},e)}))}))},2541:function(e,n,t){"use strict";t.r(n),t.d(n,"WriteDataSearchContext",(function(){return w}));var r=t(2),a=t.n(r),i=t(3),o=t(116);var l=()=>{const{searchTerm:e,setSearchTerm:n}=Object(r.useContext)(w);return a.a.createElement(o.a,{placeholderText:"Search data writing methods...",searchTerm:e,size:i.ComponentSize.Large,onSearch:n,autoFocus:!0,testID:"write-data--search"})},s=t(885),c=t(881),u=t(214),d=t(193),m=t(763);var p=()=>{const{searchTerm:e}=Object(r.useContext)(w),n=Object(s.b)(e);return n.length?a.a.createElement("div",{className:"write-data--section","data-testid":"write-data--section file-upload"},a.a.createElement(i.Heading,{element:i.HeadingElement.H2,weight:i.FontWeight.Regular,style:{marginTop:"24px",marginBottom:"4px"}},"File Upload"),a.a.createElement(i.Heading,{element:i.HeadingElement.H5,weight:i.FontWeight.Regular,style:{marginBottom:"24px"}},"Upload line protocol or Annotated CSVs with the click of a button"),a.a.createElement(i.SquareGrid,{cardSize:"170px",gutter:i.ComponentSize.Small},n.map((e=>a.a.createElement(m.a,{key:e.id,id:e.id,name:e.name,image:e.image,url:`${d.h}/${e.id}`}))))):null};var f=()=>{const{searchTerm:e}=Object(r.useContext)(w),n=Object(u.b)(e);return n.length?a.a.createElement("div",{className:"write-data--section","data-testid":"write-data--section client-libraries"},a.a.createElement(i.Heading,{element:i.HeadingElement.H2,weight:i.FontWeight.Regular,style:{marginTop:"24px",marginBottom:"4px"}},"Client Libraries"),a.a.createElement(i.Heading,{element:i.HeadingElement.H5,weight:i.FontWeight.Regular,style:{marginBottom:"24px"}},"Back-end, front-end, and mobile applications"),a.a.createElement(i.SquareGrid,{cardSize:"170px",gutter:i.ComponentSize.Small},n.map((e=>a.a.createElement(m.a,{key:e.id,id:e.id,name:e.name,image:e.logo,url:`${d.c}/${e.id}`}))))):null};var h=()=>{const{searchTerm:e}=Object(r.useContext)(w),n=Object(c.b)(e);return n.length?a.a.createElement("div",{className:"write-data--section","data-testid":"write-data--section telegraf-plugins"},a.a.createElement(i.Heading,{element:i.HeadingElement.H2,weight:i.FontWeight.Regular,style:{marginTop:"24px",marginBottom:"4px"},testID:"sources-telegraf-plugins"},"Telegraf Plugins"),a.a.createElement(i.Heading,{element:i.HeadingElement.H5,weight:i.FontWeight.Regular,style:{marginBottom:"24px"}},"An open-source agent for collecting data and reporting metrics via a vast library of plugins"),a.a.createElement(i.SquareGrid,{cardSize:"170px",gutter:i.ComponentSize.Small},n.map((e=>a.a.createElement(m.a,{key:e.id,id:e.id,name:e.name,image:e.image,style:e.style,url:`${d.t}/${e.id}`}))))):null};var g=()=>{const{searchTerm:e}=Object(r.useContext)(w);return!!Object(s.b)(e).length||!!Object(u.b)(e).length||!!Object(c.b)(e).length?a.a.createElement(a.a.Fragment,null,a.a.createElement(p,null),a.a.createElement(f,null),a.a.createElement(h,null)):a.a.createElement(i.EmptyState,{size:i.ComponentSize.Large},a.a.createElement("h4",null,"Nothing matched ",a.a.createElement("strong",null,`"${e}"`)))},b=t(341),x=t(350),y=t(63);const w=Object(r.createContext)({searchTerm:"",setSearchTerm:()=>{}});n.default=()=>{const[e,n]=Object(r.useState)("");return a.a.createElement(w.Provider,{value:{searchTerm:e,setSearchTerm:n}},a.a.createElement(i.Page,{titleTag:Object(y.a)(["Sources","Load Data"])},a.a.createElement(b.a,null),a.a.createElement(x.a,{activeTab:"sources"},a.a.createElement(l,null),a.a.createElement(g,null))))}},29:function(e,n,t){"use strict";t.d(n,"a",(function(){return r})),t.d(n,"b",(function(){return a})),t.d(n,"c",(function(){return i}));const r=e=>e.me,a=e=>e.me.quartzMe,i=e=>{var n,t;const{quartzMe:r}=e.me,a=null!==(n=null==r?void 0:r.isRegionBeta)&&void 0!==n&&n;return"free"===(null!==(t=null==r?void 0:r.accountType)&&void 0!==t?t:"free")&&!1===a}},341:function(e,n,t){"use strict";var r=t(2),a=t.n(r),i=t(3),o=t(89);n.a=()=>a.a.createElement(i.Page.Header,{fullWidth:!1,testID:"load-data--header"},a.a.createElement(i.Page.Title,{title:"Load Data"}),a.a.createElement(o.a,null))},350:function(e,n,t){"use strict";var r=t(2),a=t.n(r),i=t(4),o=t(42),l=t(14),s=t(184),c=t(3),u=t(24),d=t(15),m=t(161);let p=class extends r.PureComponent{render(){const{activeTab:e,orgID:n,history:t}=this.props,r=e=>{t.push(`/orgs/${n}/load-data/${e}`)},i=[{text:"Sources",id:"sources",cloudExclude:!1,featureFlag:null},{text:"Buckets",id:"buckets",cloudExclude:!1,featureFlag:null},{text:"Telegraf",id:"telegrafs",cloudExclude:!1,featureFlag:null},{text:"Scrapers",id:"scrapers",cloudExclude:!0,featureFlag:null},{text:"API Tokens",id:"tokens",cloudExclude:!1,featureFlag:null}],o=i.find((n=>n.id===e)).text;return a.a.createElement(c.Tabs,{orientation:c.Orientation.Horizontal,size:c.ComponentSize.Large,dropdownBreakpoint:872,dropdownLabel:o},i.map((n=>{let t=a.a.createElement(c.Tabs.Tab,{testID:`${n.id}--tab`,key:n.id,text:n.text,id:n.id,onClick:r,active:n.id===e});return n.cloudExclude&&(t=a.a.createElement(m.a,{key:n.id},t)),n.featureFlag&&(t=a.a.createElement(u.a,{key:n.id,name:n.featureFlag},t)),t})))}};p=Object(l.a)([d.a],p);var f=Object(s.j)(p),h=t(9);const g=e=>("buckets"!==e||!Object(u.c)("fetchAllBuckets"))&&("tokens"!==e||!Object(u.c)("paginatedTokens")),b=Object(i.c)((e=>({orgID:Object(h.a)(e).id})));n.a=b((({activeTab:e,orgID:n,children:t})=>a.a.createElement(c.Page.Contents,{fullWidth:!1,scrollable:g(e),scrollbarSize:c.ComponentSize.Large,autoHideScrollbar:!0},a.a.createElement(c.Tabs.Container,{orientation:c.Orientation.Horizontal,stretchToFitHeight:!0},a.a.createElement(f,{activeTab:e,orgID:n}),a.a.createElement(o.a,null,a.a.createElement(c.Tabs.TabContents,null,t))))))},50:function(e,n,t){"use strict";var r=t(2),a=t.n(r),i=t(4),o=t(19),l=t.n(o),s=t(184),c=t(3),u=t(77),d=t(29);n.a=({size:e=c.ComponentSize.Small,className:n,buttonText:t="Upgrade Now",metric:r})=>{const o=Object(i.e)(d.c),m=l()("upgrade-payg--button",{[`${n}`]:n}),p=Object(s.f)();return a.a.createElement(u.a,null,o&&a.a.createElement(c.Button,{icon:c.IconFont.CrownSolid_New,className:m,size:e,shape:c.ButtonShape.Default,onClick:()=>{r&&r(),p.push("/checkout")},text:t,style:{background:"linear-gradient(45deg, rgb(52, 187, 85) 0%, rgb(0, 163, 255) 100%)"},testID:"cloud-upgrade--button"}))}},528:function(e,n,t){var r={"./Arduino/index.ts":564,"./CSharp/index.ts":561,"./Go/index.ts":562,"./Java/index.ts":556,"./Javascript/index.ts":565,"./Kotlin/index.ts":557,"./PHP/index.ts":558,"./Python/index.ts":559,"./R/index.ts":569,"./Ruby/index.ts":555,"./Scala/index.ts":566,"./Swift/index.ts":560};function a(e){var n=i(e);return t(n)}function i(e){if(!t.o(r,e)){var n=new Error("Cannot find module '"+e+"'");throw n.code="MODULE_NOT_FOUND",n}return r[e]}a.keys=function(){return Object.keys(r)},a.resolve=i,e.exports=a,a.id=528},529:function(e,n,t){e.exports=t.p+"d282b5dc2d.svg"},53:function(e,n,t){"use strict";t.d(n,"a",(function(){return p}));var r=t(2),a=t.n(r),i=t(4),o=t(19),l=t.n(o),s=t(3),c=t(50),u=t(34),d=t(29),m=t(7);const p=({type:e,link:n,className:t,limitText:r})=>a.a.createElement("div",{className:`${t} rate-alert--content__free`},a.a.createElement("span",null,"Oh no! You hit the"," ",a.a.createElement("a",{href:n,className:"rate-alert--docs-link",target:"_blank",rel:"noreferrer"},"series cardinality"===e?"series cardinality":"query write")," ","limit ",null!=r?r:""," and your data stopped writing. Donâ€™t lose important metrics."),a.a.createElement(s.FlexBox,{justifyContent:s.JustifyContent.Center,className:"rate-alert--button"},a.a.createElement(c.a,{className:"upgrade-payg--button__rate-alert",metric:()=>Object(m.a)(`user.limits.${e}.upgrade`)})));n.b=({className:e})=>{const n=Object(i.d)(),t=Object(i.e)(d.c),r=l()("rate-alert--content",{[`${e}`]:e});return t?a.a.createElement(p,{type:"series cardinality",link:"https://docs.influxdata.com/influxdb/v2.0/write-data/best-practices/resolve-high-cardinality/",className:r}):a.a.createElement("div",{className:`${r} rate-alert--content__payg`},a.a.createElement("span",null,"Data in has stopped because you've hit the"," ",a.a.createElement("a",{href:"https://docs.influxdata.com/influxdb/v2.0/write-data/best-practices/resolve-high-cardinality/",className:"rate-alert--docs-link",target:"_blank",rel:"noreferrer"},"series cardinality")," ","limit. Let's get it flowing again."),a.a.createElement(s.FlexBox,{justifyContent:s.JustifyContent.Center,className:"rate-alert--button"},a.a.createElement(s.Button,{className:"rate-alert-overlay-button",color:s.ComponentColor.Primary,size:s.ComponentSize.Small,onClick:()=>{n(Object(u.d)("rate-limit",null,(()=>n(u.b))))},text:"Inspect Series Cardinality"})))}},530:function(e,n,t){e.exports=t.p+"6a035ca694.svg"},531:function(e,n,t){e.exports=t.p+"d831880c7d.svg"},532:function(e,n,t){e.exports=t.p+"5f2c6d9067.svg"},533:function(e,n,t){e.exports=t.p+"ed5875c592.svg"},534:function(e,n,t){e.exports=t.p+"b4105a4388.svg"},535:function(e,n,t){e.exports=t.p+"057f237d97.svg"},536:function(e,n,t){e.exports=t.p+"3dabdf9fea.svg"},537:function(e,n,t){e.exports=t.p+"c99ec09528.svg"},538:function(e,n,t){e.exports=t.p+"586aa8f23c.svg"},539:function(e,n,t){e.exports=t.p+"8c756c1e65.svg"},540:function(e,n,t){e.exports=t.p+"74ba2b9c36.svg"},555:function(e,n,t){"use strict";t.r(n);var r=t(538),a=t.n(r);n.default=e=>e({id:"ruby",name:"Ruby",featureFlag:"client-library--ruby",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-ruby" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Install the Gem\n\n```\ngem install influxdb-client\n```\n',logo:a.a,initialize:"require 'influxdb-client'\n\n# You can generate an API token from the \"API Tokens Tab\" in the UI\ntoken = '<%= token %>'\norg = '<%= org %>'\nbucket = '<%= bucket %>'\n\nclient = InfluxDB2::Client.new('<%= server %>', token,\n  precision: InfluxDB2::WritePrecision::NANOSECOND)\n\n",write:[{title:"Use InfluxDB Line Protocol to write data",code:"write_api = client.create_write_api\n\ndata = 'mem,host=host1 used_percent=23.43234543'\nwrite_api.write(data: data, bucket: bucket, org: org)\n\n"},{title:"Use a Data Point to write data",code:"point = InfluxDB2::Point.new(name: 'mem')\n  .add_tag('host', 'host1')\n  .add_field('used_percent', 23.43234543)\n  .time(Time.now.utc, InfluxDB2::WritePrecision::NANOSECOND)\n\nwrite_api.write(data: point, bucket: bucket, org: org)\n\n"},{title:"Use a Hash to write data",code:"hash = {name: 'h2o',\n  tags: {host: 'aws', region: 'us'},\n  fields: {level: 5, saturation: '99%'},\n  time: Time.now.utc}\n\nwrite_api.write(data: hash, bucket: bucket, org: org)\n\n"},{title:"Use a Batch Sequence to write data",code:"point = InfluxDB2::Point.new(name: 'mem')\n  .add_tag('host', 'host1')\n  .add_field('used_percent', 23.43234543)\n  .time(Time.now.utc, InfluxDB2::WritePrecision::NANOSECOND)\n\nhash = {name: 'h2o',\n  tags: {host: 'aws', region: 'us'},\n  fields: {level: 5, saturation: '99%'},\n  time: Time.now.utc}\n\ndata = 'mem,host=host1 used_percent=23.23234543'\n\nwrite_api.write(data: [point, hash, data], bucket: bucket, org: org)\n\n"}],execute:'query = "<%= query %>"\n\ntables = client.create_query_api.query(query: query, org: org)\ntables.each do |_, table|\n  table.records.each do |record|\n    puts "#{record.time} #{record.measurement}: #{record.field}=#{record.value}"\n  end\nend\n',query:'from(bucket: \\"<%= bucket %>\\") |> range(start: -1h)',dispose:"client.close!\n",executeFull:"require 'influxdb-client'\n\n# You can generate a Token from the \"Tokens Tab\" in the UI\ntoken = '<%= token %>'\norg = '<%= org %>'\n\nclient = InfluxDB2::Client.new('<%= server %>', token,\n  precision: InfluxDB2::WritePrecision::NANOSECOND)\n\nquery = %{<%= query %>}\n\ntables = client.create_query_api.query(query: query, org: org)\ntables.each do |_, table|\n  table.records.each do |record|\n    puts \"#{record.time} #{record.measurement}: #{record.field}=#{record.value}\"\n  end\nend\n\nclient.close!\n"})},556:function(e,n,t){"use strict";t.r(n);var r=t(532),a=t.n(r);n.default=e=>e({id:"java",name:"Java",featureFlag:"client-library--java",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-java" target="_blank" rel="noreferrer">GitHub Repository</a>\n\n##### Add Dependency\n\nBuild with Maven\n\n```\n<dependency>\n  <groupId>com.influxdb</groupId>\n  <artifactId>influxdb-client-java</artifactId>\n  <version>3.1.0</version>\n</dependency>\n```\n\nBuild with Gradle\n\n```\ndependencies {\n  compile "com.influxdb:influxdb-client-java:3.1.0"\n}\n```\n',logo:a.a,initialize:'package example;\n\nimport java.time.Instant;\nimport java.util.List;\n\nimport com.influxdb.annotations.Column;\nimport com.influxdb.annotations.Measurement;\nimport com.influxdb.client.InfluxDBClient;\nimport com.influxdb.client.InfluxDBClientFactory;\nimport com.influxdb.client.WriteApi;\nimport com.influxdb.client.domain.WritePrecision;\nimport com.influxdb.client.write.Point;\nimport com.influxdb.query.FluxTable;\n\npublic class InfluxDB2Example {\n  public static void main(final String[] args) {\n\n    // You can generate an API token from the "API Tokens Tab" in the UI\n    String token = "<%= token %>";\n    String bucket = "<%= bucket %>";\n    String org = "<%= org %>";\n\n    InfluxDBClient client = InfluxDBClientFactory.create("<%= server %>", token.toCharArray());\n  }\n}\n\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'String data = "mem,host=host1 used_percent=23.43234543";\n\nWriteApiBlocking writeApi = client.getWriteApiBlocking();\nwriteApi.writeRecord(bucket, org, WritePrecision.NS, data);\n\n'},{title:"Use a Data Point to write data",code:'Point point = Point\n  .measurement("mem")\n  .addTag("host", "host1")\n  .addField("used_percent", 23.43234543)\n  .time(Instant.now(), WritePrecision.NS);\n\nWriteApiBlocking writeApi = client.getWriteApiBlocking();\nwriteApi.writePoint(bucket, org, point);\n\n'},{title:"Use POJO and corresponding class to write data",code:'Mem mem = new Mem();\nmem.host = "host1";\nmem.used_percent = 23.43234543;\nmem.time = Instant.now();\n\nWriteApiBlocking writeApi = client.getWriteApiBlocking();\nwriteApi.writeRecord(bucket, org, WritePrecision.NS, mem);\n\n\n\n@Measurement(name = "mem")\npublic static class Mem {\n  @Column(tag = true)\n  String host;\n  @Column\n  Double used_percent;\n  @Column(timestamp = true)\n  Instant time;\n}\n\n'}],execute:'String query = "<%= query %>";\nList<FluxTable> tables = client.getQueryApi().query(query, org);\n\nfor (FluxTable table : tables) {\n  for (FluxRecord record : table.getRecords()) {\n    System.out.println(record);\n  }\n}\n',query:'from(bucket: \\"<%= bucket %>\\") |> range(start: -1h)',querySanitize:e=>e.replace(/"/g,'\\"').split("\n").map(((e,n,t)=>{let r;return r=t.length==n+1?'"':'\\n" +',`"${e}${r}`})).join("\n"),executeFull:'package example;\n\nimport java.util.List;\n\nimport com.influxdb.client.InfluxDBClient;\nimport com.influxdb.client.InfluxDBClientFactory;\nimport com.influxdb.query.FluxRecord;\nimport com.influxdb.query.FluxTable;\n\npublic class InfluxDB2Example {\n  public static void main(final String[] args) {\n\n    // You can generate a Token from the "Tokens Tab" in the UI\n    String token = "<%= token %>";\n    String org = "<%= org %>";\n\n    try (InfluxDBClient client = InfluxDBClientFactory.create("<%= server %>", token.toCharArray())) {\n\n      String query = <%= query %>;\n      List<FluxTable> tables = client.getQueryApi().query(query, org);\n\n      for (FluxTable table : tables) {\n        for (FluxRecord record : table.getRecords()) {\n          System.out.println(record);\n        }\n      }\n    }\n  }\n}\n\n',dispose:"client.close();\n"})},557:function(e,n,t){"use strict";t.r(n);var r=t(534),a=t.n(r);n.default=e=>e({id:"kotlin",name:"Kotlin",featureFlag:"client-library--kotlin",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-java/tree/master/client-kotlin" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Add Dependency\n\nBuild with Maven\n\n```\n<dependency>\n  <groupId>com.influxdb</groupId>\n  <artifactId>influxdb-client-kotlin</artifactId>\n  <version>3.1.0</version>\n</dependency>\n```\n\nBuild with Gradle\n\n```\ndependencies {\n  compile "com.influxdb:influxdb-client-kotlin:3.1.0"\n}\n```\n',logo:a.a,initialize:'package example\n\nimport com.influxdb.annotations.Column\nimport com.influxdb.annotations.Measurement\nimport com.influxdb.client.domain.WritePrecision\nimport com.influxdb.client.kotlin.InfluxDBClientKotlinFactory\nimport com.influxdb.client.write.Point\nimport kotlinx.coroutines.flow.collect\nimport kotlinx.coroutines.flow.consumeAsFlow\nimport kotlinx.coroutines.runBlocking\nimport java.time.Instant\n\nfun main() = runBlocking {\n\n    // You can generate an API token from the "API Tokens Tab" in the UI\n    val token = "<%= token %>"\n    val org = "<%= org %>"\n    val bucket = "<%= bucket %>"\n\n    val client = InfluxDBClientKotlinFactory.create("<%= server %>", token.toCharArray(), org, bucket)\n    client.use {\n\n    }\n}\n\n',execute:'val query = """<%= query %>"""\n\n// Result is returned as a stream\nval results = client.getQueryKotlinApi().query(query)\n\nresults\n  .consumeAsFlow()\n  .collect { println("$it") }\n',query:'from(bucket: "<%= bucket %>")\n    |> range(start: -1d)\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'val writeApi = client.getWriteKotlinApi()\n\nval record = "mem,host=host1 used_percent=23.43234543"\nwriteApi.writeRecord(record, WritePrecision.NS)\n'},{title:"Use a Data Point to write data",code:'val point = Point\n  .measurement("mem")\n  .addTag("host", "host1")\n  .addField("used_percent", 23.43234543)\n  .time(Instant.now(), WritePrecision.NS);\n\nwriteApi.writePoint(point)\n'},{title:"Use POJO and corresponding class to write data",code:'val mem = Mem("host1", 23.43234543, Instant.now())\nwriteApi.writeMeasurement(mem, WritePrecision.NS)\n\n\n@Measurement(name = "mem")\ndata class Mem(\n  @Column(tag = true) val host: String,\n  @Column val used_percent: Double,\n  @Column(timestamp = true) val time: Instant\n)\n'}],dispose:"client.close()\n",executeFull:'package example\n\nimport com.influxdb.client.kotlin.InfluxDBClientKotlinFactory\nimport kotlinx.coroutines.flow.collect\nimport kotlinx.coroutines.flow.consumeAsFlow\nimport kotlinx.coroutines.runBlocking\n\nfun main() = runBlocking {\n\n    // You can generate a Token from the "Tokens Tab" in the UI\n    val token = "<%= token %>"\n    val org = "<%= org %>"\n\n    val client = InfluxDBClientKotlinFactory.create("<%= server %>", token.toCharArray(), org)\n    client.use {\n        val query = """<%= query %>"""\n\n        val results = client.getQueryKotlinApi().query(query)\n        results\n          .consumeAsFlow()\n          .collect { println("$it") }\n    }\n}\n\n'})},558:function(e,n,t){"use strict";t.r(n);var r=t(535),a=t.n(r);n.default=e=>e({id:"php",name:"PHP",featureFlag:"client-library--php",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-php" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Install via Composer\n\n```\ncomposer require influxdata/influxdb-client-php\n```\n',logo:a.a,initialize:'use InfluxDB2\\Client;\nuse InfluxDB2\\Model\\WritePrecision;\nuse InfluxDB2\\Point;\n\n# You can generate an API token from the "API Tokens Tab" in the UI\n$token = \'<%= token %>\';\n$org = \'<%= org %>\';\n$bucket = \'<%= bucket %>\';\n\n$client = new Client([\n    "url" => "<%= server %>",\n    "token" => $token,\n]);\n\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'$writeApi = $client->createWriteApi();\n\n$data = "mem,host=host1 used_percent=23.43234543";\n\n$writeApi->write($data, WritePrecision::S, $bucket, $org);\n\n'},{title:"Use a Data Point to write data",code:"$point = Point::measurement('mem')\n  ->addTag('host', 'host1')\n  ->addField('used_percent', 23.43234543)\n  ->time(microtime(true));\n\n$writeApi->write($point, WritePrecision::S, $bucket, $org);\n\n"},{title:"Use Array structure to write data",code:"$dataArray = ['name' => 'cpu',\n  'tags' => ['host' => 'server_nl', 'region' => 'us'],\n  'fields' => ['internal' => 5, 'external' => 6],\n  'time' => microtime(true)];\n\n$writeApi->write($dataArray, WritePrecision::S, $bucket, $org);\n\n"}],execute:'$query = "<%= query %>";\n$tables = $client->createQueryApi()->query($query, $org);\n\nforeach ($tables as $table) {\n    foreach ($table->records as $record) {\n        $time = $record->getTime();\n        $measurement = $record->getMeasurement();\n        $field = $record->getField();\n        $value = $record->getValue();\n        print "$time $measurement: $field=$value\\n";\n    }\n}\n',query:'from(bucket: \\"<%= bucket %>\\") |> range(start: -1h)',dispose:"$client->close();\n",executeFull:'use InfluxDB2\\Client;\n\n# You can generate a Token from the "Tokens Tab" in the UI\n$token = \'<%= token %>\';\n$org = \'<%= org %>\';\n\n$client = new Client([\n    "url" => "<%= server %>",\n    "token" => $token,\n]);\n\n$query = "<%= query %>";\n$tables = $client->createQueryApi()->query($query, $org);\n\nforeach ($tables as $table) {\n    foreach ($table->records as $record) {\n        $time = $record->getTime();\n        $measurement = $record->getMeasurement();\n        $field = $record->getField();\n        $value = $record->getValue();\n        print "$time $measurement: $field=$value\\n";\n    }\n}\n\n$client->close();\n',querySanitize:e=>e.replace(/"/g,'\\"')})},559:function(e,n,t){"use strict";t.r(n);var r=t(536),a=t.n(r);n.default=e=>e({id:"python",name:"Python",featureFlag:"client-library--python",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-python" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Install Package\n\n```\npip install influxdb-client\n```\n',logo:a.a,initialize:'from datetime import datetime\n\nfrom influxdb_client import InfluxDBClient, Point, WritePrecision\nfrom influxdb_client.client.write_api import SYNCHRONOUS\n\n# You can generate an API token from the "API Tokens Tab" in the UI\ntoken = "<%= token %>"\norg = "<%= org %>"\nbucket = "<%= bucket %>"\n\nwith InfluxDBClient(url="<%= server %>", token=token, org=org) as client:\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'write_api = client.write_api(write_options=SYNCHRONOUS)\n\ndata = "mem,host=host1 used_percent=23.43234543"\nwrite_api.write(bucket, org, data)\n\n'},{title:"Use a Data Point to write data",code:'point = Point("mem") \\\n  .tag("host", "host1") \\\n  .field("used_percent", 23.43234543) \\\n  .time(datetime.utcnow(), WritePrecision.NS)\n\nwrite_api.write(bucket, org, point)\n\n'},{title:"Use a Batch Sequence to write data",code:'sequence = ["mem,host=host1 used_percent=23.43234543",\n            "mem,host=host1 available_percent=15.856523"]\nwrite_api.write(bucket, org, sequence)\n\n'}],execute:"query = '<%= query %>'\ntables = client.query_api().query(query, org=org)\nfor table in tables:\n    for record in table.records:\n        print(record)\n",query:'from(bucket: "<%= bucket %>") |> range(start: -1h)',dispose:"client.close()\n",executeFull:'from influxdb_client import InfluxDBClient\n\n# You can generate a Token from the "Tokens Tab" in the UI\ntoken = "<%= token %>"\norg = "<%= org %>"\nbucket = "<%= bucket %>"\n\nwith InfluxDBClient(url="<%= server %>", token=token, org=org) as client:\n    query = """<%= query %>"""\n    tables = client.query_api().query(query, org=org)\n    for table in tables:\n        for record in table.records:\n            print(record)\n'})},560:function(e,n,t){"use strict";t.r(n);var r=t(540),a=t.n(r);n.default=e=>e({id:"swift",name:"Swift",featureFlag:"client-library--swift",description:'For more detailed and up to date information check out the [GitHub Repository](https://github.com/influxdata/influxdb-client-swift/)\n\n##### Install via Swift Package Manager\n\nAdd this line to your `Package.swift`:\n\n```swift\n// swift-tools-version:5.3\nimport PackageDescription\n\nlet package = Package(\n    name: "MyPackage",\n    dependencies: [\n        .package(name: "influxdb-client-swift", url: "https://github.com/influxdata/influxdb-client-swift", from: "0.6.0"),\n    ],\n    targets: [\n        .target(name: "MyModule", dependencies: [\n          .product(name: "InfluxDBSwift", package: "influxdb-client-swift"),\n          // or InfluxDBSwiftApis for management API\n          .product(name: "InfluxDBSwiftApis", package: "influxdb-client-swift")\n        ])\n    ]\n)\n```\n',logo:a.a,initialize:'import Foundation\nimport InfluxDBSwift\n\n@main\nclass Example {\n    static func main() {\n\n        let url = "<%= server %>"\n        let token = "<%= token %>"\n        let bucket = "<%= bucket %>"\n        let org = "<%= org %>"\n\n        let client = InfluxDBClient(url: url, token: token)\n\n    }\n}\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'let recordString = "demo,type=string value=1i"\n\nclient.makeWriteAPI().write(bucket: bucket, org: org, record: recordString) { result, error in\n    // For handle error\n    if let error = error {\n        print("Error:\\n\\n\\(error)")\n    }\n\n    // For Success write\n    if result != nil {\n        print("Successfully written data:\\n\\n\\(recordString)")\n    }\n}\n\n'},{title:"Use a Data Point to write data",code:'let recordPoint = InfluxDBClient\n        .Point("demo")\n        .addTag(key: "type", value: "point-timestamp")\n        .addField(key: "value", value: .int(2))\n        .time(time: .date(Date()))\n\nclient.makeWriteAPI().write(bucket: bucket, org: org, points: [recordPoint]) { result, error in\n    // For handle error\n    if let error = error {\n        print("Error:\\n\\n\\(error)")\n    }\n\n    // For Success write\n    if result != nil {\n        print("Successfully written data:\\n\\n\\([recordPoint])")\n    }\n}\n\n'},{title:"Use Tuple to write data",code:'let recordTuple: InfluxDBClient.Point.Tuple\n        = (measurement: "demo", tags: ["type": "tuple"], fields: ["value": .int(3)], time: nil)\n\nclient.makeWriteAPI().write(bucket: bucket, org: org, tuple: recordTuple) { result, error in\n    // For handle error\n    if let error = error {\n        print("Error:\\n\\n\\(error)")\n    }\n\n    // For Success write\n    if result != nil {\n        print("Successfully written data:\\n\\n\\(recordTuple)")\n    }\n}\n\n'}],execute:'let query = """\n            <%= query %>"""\n\nclient.queryAPI.query(query: query, org: org) { response, error in\n  // Error response\n  if let error = error {\n    print("Error:\\n\\n\\(error)")\n  }\n\n  // Success response\n  if let response = response {\n\n    print("\\nSuccess response...\\n")\n    do {\n      try response.forEach { record in\n        print("\\t\\(record.values["_field"]!): \\(record.values["_value"]!)")\n      }\n    } catch {\n       print("Error:\\n\\n\\(error)")\n    }\n  }\n}\n\n',query:'from(bucket: "<%= bucket %>") |> range(start: -1h)\n',dispose:"client.close()\n",executeFull:'import Foundation\nimport InfluxDBSwift\n\n@main\nclass Example {\n    static func main() {\n\n        let url = "<%= server %>"\n        let token = "<%= token %>"\n        let org = "<%= org %>"\n\n        let client = InfluxDBClient(url: url, token: token)\n\n        let query = """\n                    <%= query %>\n                    """\n\n        client.queryAPI.query(query: query, org: org) { response, error in\n          // Error response\n          if let error = error {\n            print("Error:\\n\\n\\(error)")\n          }\n\n          // Success response\n          if let response = response {\n\n            do {\n              try response.forEach { record in\n                let time = record.values["_time"]!\n                let measurement = record.values["_measurement"]!\n                let field = record.values["_field"]!\n                let value = record.values["_value"]!\n                return print("\\(time) \\(measurement): \\(field)=\\(value)")\n              }\n            } catch {\n               print("Error:\\n\\n\\(error)")\n            }\n          }\n\n          client.close()\n        }\n    }\n}\n'})},561:function(e,n,t){"use strict";t.r(n);var r=t(530),a=t.n(r);n.default=e=>e({id:"csharp",name:"C#",featureFlag:"client-library--csharp",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-csharp" target="_blank" rel="noreferrer">GitHub Repository</a>\n\n##### Install Package\n\nLibrary Manager\n\n```\nInstall-Package InfluxDB.Client\n```\n\n.NET CLI\n\n```\ndotnet add package InfluxDB.Client\n```\n\nPackage Reference\n\n```\n<PackageReference Include="InfluxDB.Client" />\n```\n',logo:a.a,initialize:'using System;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing InfluxDB.Client;\nusing InfluxDB.Client.Api.Domain;\nusing InfluxDB.Client.Core;\nusing InfluxDB.Client.Writes;\n\nnamespace Examples\n{\n  public class Examples\n  {\n    public static async Task Main(string[] args)\n    {\n      // You can generate an API token from the "API Tokens Tab" in the UI\n      const string token = "<%= token %>";\n      const string bucket = "<%= bucket %>";\n      const string org = "<%= org %>";\n\n      using var client = InfluxDBClientFactory.Create("<%= server %>", token);\n    }\n  }\n}\n\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'const string data = "mem,host=host1 used_percent=23.43234543";\nusing (var writeApi = client.GetWriteApi())\n{\n  writeApi.WriteRecord(bucket, org, WritePrecision.Ns, data);\n}\n\n'},{title:"Use a Data Point to write data",code:'var point = PointData\n  .Measurement("mem")\n  .Tag("host", "host1")\n  .Field("used_percent", 23.43234543)\n  .Timestamp(DateTime.UtcNow, WritePrecision.Ns);\n\nusing (var writeApi = client.GetWriteApi())\n{\n  writeApi.WritePoint(bucket, org, point);\n}\n\n'},{title:"Use POCO and corresponding class to write data",code:'var mem = new Mem { Host = "host1", UsedPercent = 23.43234543, Time = DateTime.UtcNow };\n\nusing (var writeApi = client.GetWriteApi())\n{\n  writeApi.WriteMeasurement(bucket, org, WritePrecision.Ns, mem);\n}\n\n\n[Measurement("mem")]\nprivate class Mem\n{\n  [Column("host", IsTag = true)] public string Host { get; set; }\n  [Column("used_percent")] public double? UsedPercent { get; set; }\n  [Column(IsTimestamp = true)] public DateTime Time { get; set; }\n}\n'}],execute:'var query = "<%= query %>";\nvar tables = await client.GetQueryApi().QueryAsync(query, org);\n\nforeach (var record in tables.SelectMany(table => table.Records))\n{\n    Console.WriteLine($"{record}");\n}\n',query:'from(bucket: \\"<%= bucket %>\\") |> range(start: -1h)',querySanitize:e=>e.replace(/"/g,'""'),executeFull:'using System;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing InfluxDB.Client;\n\nnamespace Examples\n{\n  public class Examples\n  {\n    public static async Task Main(string[] args)\n    {\n      // You can generate a Token from the "Tokens Tab" in the UI\n      const string token = "<%= token %>";\n      const string org = "<%= org %>";\n\n      using var client = InfluxDBClientFactory.Create("<%= server %>", token);\n\n      const string query = @"\n      <%= query %>\n      ";\n\n      var tables = await client.GetQueryApi().QueryAsync(query, org);\n\n      foreach (var record in tables.SelectMany(table => table.Records))\n      {\n        Console.WriteLine($"{record}");\n      }\n    }\n  }\n}\n\n'})},562:function(e,n,t){"use strict";t.r(n);var r=t(531),a=t.n(r);n.default=e=>e({id:"go",name:"GO",featureFlag:"client-library--go",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-go" target="_blank" rel="noreferrer">GitHub Repository</a>\n',logo:a.a,initialize:'package main\n\nimport (\n  "context"\n  "fmt"\n  "time"\n\n   "github.com/influxdata/influxdb-client-go/v2"\n)\n\nfunc main() {\n  // Create a client\n  // You can generate an API Token from the "API Tokens Tab" in the UI\n  client := influxdb2.NewClient("<%= server %>", "<%= token %>")\n  // always close client at the end\n  defer client.Close()\n}\n\n',write:[{title:"Use InfluxDB Line Protocol to write data",code:'// get non-blocking write client\nwriteAPI := client.WriteAPI("<%= org %>", "<%= bucket %>")\n\n// write line protocol\nwriteAPI.WriteRecord(fmt.Sprintf("stat,unit=temperature avg=%f,max=%f", 23.5, 45.0))\n// Flush writes\nwriteAPI.Flush()\n\n'},{title:"Use a Data Point to write data",code:'// get non-blocking write client\nwriteAPI := client.WriteAPI("<%= org %>", "<%= bucket %>")\n\np := influxdb2.NewPoint("stat",\n  map[string]string{"unit": "temperature"},\n  map[string]interface{}{"avg": 24.5, "max": 45},\n  time.Now())\n// write point asynchronously\nwriteAPI.WritePoint(p)\n// create point using fluent style\np = influxdb2.NewPointWithMeasurement("stat").\n  AddTag("unit", "temperature").\n  AddField("avg", 23.2).\n  AddField("max", 45).\n  SetTime(time.Now())\n// write point asynchronously\nwriteAPI.WritePoint(p)\n// Flush writes\nwriteAPI.Flush()\n\n'}],execute:'// Get query client\nqueryAPI := client.QueryAPI("<%= org %>")\n\nquery := `<%= query %>`\n\n// get QueryTableResult\nresult, err := queryAPI.Query(context.Background(), query)\nif err != nil {\n  panic(err)\n}\n\n// Iterate over query response\nfor result.Next() {\n  // Notice when group key has changed\n  if result.TableChanged() {\n    fmt.Printf("table: %s\\n", result.TableMetadata().String())\n  }\n  // Access data\n  fmt.Printf("value: %v\\n", result.Record().Value())\n}\n// check for an error\nif result.Err() != nil {\n  fmt.Printf("query parsing error: %\\n", result.Err().Error())\n}\n\n',query:'from(bucket:"<%= bucket %>")|> range(start: -1h) |> filter(fn: (r) => r._measurement == "stat")',executeFull:'package main\n\nimport (\n  "context"\n  "fmt"\n\n  "github.com/influxdata/influxdb-client-go/v2"\n)\n\nfunc main() {\n  // Create a client\n  // You can generate a Token from the "Tokens Tab" in the UI\n  client := influxdb2.NewClient("<%= server %>", "<%= token %>")\n  // always close client at the end\n  defer client.Close()\n\n  // Get query client\n  queryAPI := client.QueryAPI("<%= org %>")\n\n  query := `<%= query %>`\n  // get QueryTableResult\n  result, err := queryAPI.Query(context.Background(), query)\n  if err != nil {\n    panic(err)\n  }\n\n  // Iterate over query response\n  for result.Next() {\n    // Notice when group key has changed\n    if result.TableChanged() {\n      fmt.Printf("table: %s\\n", result.TableMetadata().String())\n    }\n    // Access data\n    fmt.Printf("value: %v\\n", result.Record().Value())\n  }\n  // check for an error\n  if result.Err() != nil {\n    fmt.Printf("query parsing error: %\\n", result.Err().Error())\n  }\n}\n\n'})},564:function(e,n,t){"use strict";t.r(n);var r=t(529),a=t.n(r);n.default=e=>e({id:"arduino",name:"Arduino",featureFlag:"client-library--arduino",description:'For more detailed and up to date information check out the <a href="https://github.com/tobiasschuerg/InfluxDB-Client-for-Arduino" target="_blank" rel="noreferrer">GitHub Repository</a>\n\n##### Install Library\n\nLibrary Manager\n\n```\n1. Open the Arduino IDE and click to the "Sketch" menu and then Include Library > Manage Libraries.\n2. Type \'influxdb\' in the search box\n3. Install the \'InfluxDBClient for Arduino\' library\n```\n\nManual Installation\n\n```\n1. cd <arduino-sketch-location>/library.\n2. git clone https://github.com/tobiasschuerg/InfluxDB-Client-for-Arduino\n3. Restart the Arduino IDE\n```\n',logo:a.a,initialize:'#if defined(ESP32)\n#include <WiFiMulti.h>\nWiFiMulti wifiMulti;\n#define DEVICE "ESP32"\n#elif defined(ESP8266)\n#include <ESP8266WiFiMulti.h>\nESP8266WiFiMulti wifiMulti;\n#define DEVICE "ESP8266"\n#endif\n\n#include <InfluxDbClient.h>\n#include <InfluxDbCloud.h>\n\n// WiFi AP SSID\n#define WIFI_SSID "SSID"\n// WiFi password\n#define WIFI_PASSWORD "PASSWORD"\n// InfluxDB v2 server url, e.g. https://eu-central-1-1.aws.cloud2.influxdata.com (Use: InfluxDB UI -> Load Data -> Client Libraries)\n#define INFLUXDB_URL "<%= server %>"\n// InfluxDB v2 server or cloud API token (Use: InfluxDB UI -> Data -> API Tokens -> <select token>)\n#define INFLUXDB_TOKEN "<%= token %>"\n// InfluxDB v2 organization id (Use: InfluxDB UI -> User -> About -> Common Ids )\n#define INFLUXDB_ORG "<%= org %>"\n// InfluxDB v2 bucket name (Use: InfluxDB UI ->  Data -> Buckets)\n#define INFLUXDB_BUCKET "<%= bucket %>"\n\n// Set timezone string according to https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html\n// Examples:\n//  Pacific Time: "PST8PDT"\n//  Eastern: "EST5EDT"\n//  Japanesse: "JST-9"\n//  Central Europe: "CET-1CEST,M3.5.0,M10.5.0/3"\n#define TZ_INFO "CET-1CEST,M3.5.0,M10.5.0/3"\n\n// InfluxDB client instance with preconfigured InfluxCloud certificate\nInfluxDBClient client(INFLUXDB_URL, INFLUXDB_ORG, INFLUXDB_BUCKET, INFLUXDB_TOKEN, InfluxDbCloud2CACert);\n\n// Data point\nPoint sensor("wifi_status");\n\nvoid setup() {\n  Serial.begin(115200);\n\n  // Setup wifi\n  WiFi.mode(WIFI_STA);\n  wifiMulti.addAP(WIFI_SSID, WIFI_PASSWORD);\n\n  Serial.print("Connecting to wifi");\n  while (wifiMulti.run() != WL_CONNECTED) {\n    Serial.print(".");\n    delay(100);\n  }\n  Serial.println();\n\n  // Add tags\n  sensor.addTag("device", DEVICE);\n  sensor.addTag("SSID", WiFi.SSID());\n\n  // Accurate time is necessary for certificate validation and writing in batches\n  // For the fastest time sync find NTP servers in your area: https://www.pool.ntp.org/zone/\n  // Syncing progress and the time will be printed to Serial.\n  timeSync(TZ_INFO, "pool.ntp.org", "time.nis.gov");\n\n  // Check server connection\n  if (client.validateConnection()) {\n    Serial.print("Connected to InfluxDB: ");\n    Serial.println(client.getServerUrl());\n  } else {\n    Serial.print("InfluxDB connection failed: ");\n    Serial.println(client.getLastErrorMessage());\n  }\n}\n\n',write:'void loop() {\n  // Clear fields for reusing the point. Tags will remain untouched\n  sensor.clearFields();\n\n  // Store measured value into point\n  // Report RSSI of currently connected network\n  sensor.addField("rssi", WiFi.RSSI());\n\n  // Print what are we exactly writing\n  Serial.print("Writing: ");\n  Serial.println(sensor.toLineProtocol());\n\n  // Check WiFi connection and reconnect if needed\n  if (wifiMulti.run() != WL_CONNECTED) {\n    Serial.println("Wifi connection lost");\n  }\n\n  // Write point\n  if (!client.writePoint(sensor)) {\n    Serial.print("InfluxDB write failed: ");\n    Serial.println(client.getLastErrorMessage());\n  }\n\n  Serial.println("Wait 10s");\n  delay(10000);\n}\n\n',execute:'void loop() {\n  // Construct a Flux query\n  // Query will find the worst RSSI for last hour for each connected WiFi network with this device\n  String query = "<%= query %>";\n\n  // Print composed query\n  Serial.print("Querying with: ");\n  Serial.println(query);\n\n  // Print ouput header\n  Serial.print("==========");\n  // Send query to the server and get result\n  FluxQueryResult result = client.query(query);\n\n  // Iterate over rows. Even there is just one row, next() must be called at least once.\n  while (result.next()) {\n    // Get converted value for flux result column \'SSID\'\n    String ssid = result.getValueByName("SSID").getString();\n    Serial.print("SSID \'");\n    Serial.print(ssid);\n\n    Serial.print("\' with RSSI ");\n    // Get converted value for flux result column \'_value\' where there is RSSI value\n    long value = result.getValueByName("_value").getLong();\n    Serial.print(value);\n\n    // Get converted value for the _time column\n    FluxDateTime time = result.getValueByName("_time").getDateTime();\n\n    // Format date-time for printing\n    // Format string according to http://www.cplusplus.com/reference/ctime/strftime/\n    String timeStr = time.format("%F %T");\n\n    Serial.print(" at ");\n    Serial.print(timeStr);\n\n    Serial.println();\n  }\n\n  // Check if there was an error\n  if(result.getError() != "") {\n    Serial.print("Query result error: ");\n    Serial.println(result.getError());\n  }\n\n  // Close the result\n  result.close();\n\n  Serial.println("Wait 10s");\n  delay(10000);\n}\n\n',query:'from(bucket: \\"<%= bucket %>\\") \\\n    |> range(start: -1h) \\\n    |> filter(fn: (r) => r._measurement == \\"wifi_status\\" and r._field == \\"rssi\\") \\\n    |> min()',querySanitize:e=>e.replace(/"/g,'\\"').split("\n").map(((e,n,t)=>{let r;return r=t.length==n+1?"":" \\",`${e}${r}`})).join("\n"),executeFull:'\nInfluxDBClient client("<%= server %>", "<%= org %>", "<%= bucket %>", "<%= token %>", InfluxDbCloud2CACert);\n\nvoid loop {\n\n  // Construct a Flux query\n  String query = "<%= query %>";\n\n  // Print composed query\n  Serial.print("Querying with: ");\n  Serial.println(query);\n\n  // Send query to the server and get result\n  FluxQueryResult result = client.query(query);\n\n  // Iterate over rows. Even there is just one row, next() must be called at least once.\n  while (result.next()) {\n    // If there is a new table definition\n    if(result.hasTableChanged()) {\n      // Print table metadata\n      Serial.println();\n      for (String col: result.getColumnsName()) {\n        Serial.printf("%10s ", col.c_str());\n      }\n      Serial.println();\n      for (String typ: result.getColumnsDatatype()) {\n        Serial.printf("%10s ", typ.c_str());\n      }\n      Serial.println();\n    }\n    // Print raw, String, value\n    // converted value is retrieved using function FluxValue::getTYPE,\n    // where, depending on the column type,  TYPE can be Long, UnsignedLong, String, Bool, Double or DateTime,\n    for (FluxValue val: result.getValues()) {\n      Serial.printf("%10s ", val.getRawValue().c_str());\n    }\n    Serial.println();\n  }\n\n  // Check if there was an error\n  if(result.getError() != "") {\n    Serial.print("Query result error: ");\n    Serial.println(result.getError());\n  }\n\n  // Close the result\n  result.close();\n\n  delay(15000);\n}'})},565:function(e,n,t){"use strict";t.r(n);var r=t(533),a=t.n(r);n.default=e=>e({id:"javascript-node",name:"JavaScript/Node.js",featureFlag:"client-library--javascript",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-js" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Install via NPM\n\n```\nnpm i @influxdata/influxdb-client\n```\n',logo:a.a,initialize:"const {InfluxDB} = require('@influxdata/influxdb-client')\n\n// You can generate an API token from the \"API Tokens Tab\" in the UI\nconst token = '<%= token %>'\nconst org = '<%= org %>'\nconst bucket = '<%= bucket %>'\n\nconst client = new InfluxDB({url: '<%= server %>', token: token})\n\n",write:"const {Point} = require('@influxdata/influxdb-client')\nconst writeApi = client.getWriteApi(org, bucket)\nwriteApi.useDefaultTags({host: 'host1'})\n\nconst point = new Point('mem').floatField('used_percent', 23.43234543)\nwriteApi.writePoint(point)\n\nwriteApi\n    .close()\n    .then(() => {\n        console.log('FINISHED')\n    })\n    .catch(e => {\n        console.error(e)\n        console.log('Finished ERROR')\n    })\n",execute:"const queryApi = client.getQueryApi(org)\n\nconst query = `<%= query %>`\nqueryApi.queryRows(query, {\n  next(row, tableMeta) {\n    const o = tableMeta.toObject(row)\n    console.log(`${o._time} ${o._measurement}: ${o._field}=${o._value}`)\n  },\n  error(error) {\n    console.error(error)\n    console.log('Finished ERROR')\n  },\n  complete() {\n    console.log('Finished SUCCESS')\n  },\n})\n\n",query:'from(bucket: "<%= bucket %>") |> range(start: -1h)',executeFull:"const {InfluxDB} = require('@influxdata/influxdb-client')\n\n// You can generate a Token from the \"Tokens Tab\" in the UI\nconst token = '<%= token %>'\nconst org = '<%= org %>'\n\nconst client = new InfluxDB({url: '<%= server %>', token: token})\n\nconst queryApi = client.getQueryApi(org)\n\nconst query = `<%= query %>`\nqueryApi.queryRows(query, {\n  next(row, tableMeta) {\n    const o = tableMeta.toObject(row)\n    console.log(`${o._time} ${o._measurement}: ${o._field}=${o._value}`)\n  },\n  error(error) {\n    console.error(error)\n    console.log('Finished ERROR')\n  },\n  complete() {\n    console.log('Finished SUCCESS')\n  },\n})\n"})},566:function(e,n,t){"use strict";t.r(n);var r=t(539),a=t.n(r);n.default=e=>e({id:"scala",name:"Scala",featureFlag:"client-library--scala",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-java/tree/master/client-scala" target="_blank"  rel="noreferrer">GitHub Repository</a>\n\n##### Add Dependency\n\nBuild with sbt\n\n```\nlibraryDependencies += "com.influxdb" % "influxdb-client-scala" % "3.1.0"\n```\n\nBuild with Maven\n\n```\n<dependency>\n  <groupId>com.influxdb</groupId>\n  <artifactId>influxdb-client-scala</artifactId>\n  <version>3.1.0</version>\n</dependency>\n```\n\nBuild with Gradle\n\n```\ndependencies {\n  compile "com.influxdb:influxdb-client-scala:3.1.0"\n}\n```\n',logo:a.a,initialize:'package example\n\nimport akka.actor.ActorSystem\nimport akka.stream.scaladsl.Sink\nimport com.influxdb.client.scala.InfluxDBClientScalaFactory\nimport com.influxdb.query.FluxRecord\n\nimport scala.concurrent.Await\nimport scala.concurrent.duration.Duration\n\nobject InfluxDB2ScalaExample {\n\n  implicit val system: ActorSystem = ActorSystem("it-tests")\n\n  def main(args: Array[String]): Unit = {\n\n    // You can generate an API token from the "API Tokens Tab" in the UI\n    val token = "<%= token %>"\n    val org = "<%= org %>"\n\n    val client = InfluxDBClientScalaFactory.create("<%= server %>", token.toCharArray, org)\n  }\n}\n\n',execute:'val query = """<%= query %>"""\n\n// Result is returned as a stream\nval results = client.getQueryScalaApi().query(query)\n\nval sink = results\n  // print results\n  .runWith(Sink.foreach[FluxRecord](it => println(s"$it")\n  ))\n\n// wait to finish\nAwait.result(sink, Duration.Inf)\n\nclient.close()\nsystem.terminate()\n\n',query:'from(bucket: "<%= bucket %>")\n    |> range(start: -1d)\n',dispose:"client.close()\n",executeFull:'package example\n\nimport akka.actor.ActorSystem\nimport akka.stream.scaladsl.Sink\nimport com.influxdb.client.scala.InfluxDBClientScalaFactory\nimport com.influxdb.query.FluxRecord\n\nimport scala.concurrent.Await\nimport scala.concurrent.duration.Duration\n\nobject InfluxDB2ScalaExample {\n\n  implicit val system: ActorSystem = ActorSystem("it-tests")\n\n  def main(args: Array[String]): Unit = {\n\n    // You can generate a Token from the "Tokens Tab" in the UI\n    val token = "<%= token %>"\n    val org = "<%= org %>"\n\n    val client = InfluxDBClientScalaFactory.create("<%= server %>", token.toCharArray, org)\n\n    val query = """<%= query %>"""\n\n    // Result is returned as a stream\n    val results = client.getQueryScalaApi().query(query)\n\n    val sink = results\n      // print results\n      .runWith(Sink.foreach[FluxRecord](it => println(s"$it")\n      ))\n\n    // wait to finish\n    Await.result(sink, Duration.Inf)\n\n    client.close()\n    system.terminate()\n  }\n}\n\n'})},569:function(e,n,t){"use strict";t.r(n);var r=t(537),a=t.n(r);n.default=e=>e({id:"r",name:"R",featureFlag:"client-library--r",description:'For more detailed and up to date information check out the <a href="https://github.com/influxdata/influxdb-client-r" target="_blank" rel="noreferrer">GitHub Repository</a>\n\n##### Install Package\n\nReleased version published on CRAN\n\n```R\ninstall.packages("influxdbclient")\n```\n\nLatest development version\n\n```R\n# install.packages("remotes")\nremotes::install_github("influxdata/influxdb-client-r")\n```\n',logo:a.a,initialize:'library("influxdbclient")\n\n# You can generate an API token from the "API Tokens Tab" in the UI\ntoken = "<%= token %>"\n\nclient <- InfluxDBClient$new(url = "<%= server %>",\n    token = token,\n    org = "<%= org %>")\n',write:'data <- data.frame(\n    name = replicate(2, "sensors"),\n    sensor_id = c("LM101", "LM102"),\n    temperature = c(71.4, 67.3),\n    humidity = c(47, 59),\n    time = c(Sys.time(),Sys.time())\n)\n\nclient$write(data,bucket = "<%= bucket %>", precision = "ms",\n    measurementCol = "name",\n    tagCols = c("sensor_id"),\n    fieldCols = c("temperature", "humidity"),\n    timeCol = "time")\n\n',execute:"tables <- client$query('<%= query %>')\ntables\n\n",query:'from(bucket: "<%= bucket %>") |> range(start: -1h)'})},63:function(e,n,t){"use strict";t.d(n,"a",(function(){return o}));var r=t(9),a=t(124),i=t(6);const o=e=>{const n=Object(a.a)().getState(),t=Object(r.a)(n),o=i.f?"InfluxDB Cloud":"InfluxDB";return(t&&t.name?[...e,Object(r.a)(n).name,o]:[...e,o]).join(" | ")}},763:function(e,n,t){"use strict";var r=t(2),a=t.n(r),i=t(4),o=t(184),l=t(3),s=t(9),c=t(316),u=t.n(c),d=t(193);t(991);const m=a.a.lazy((()=>t.e(362).then(t.bind(null,1281))));n.a=({id:e,name:n,url:t,image:c,style:p,selected:f,onClick:h,testID:g})=>{const b=Object(o.f)(),x=Object(i.e)(s.a);let y=a.a.createElement("img",{src:u.a});const w=p||{};return c&&(y=a.a.createElement(r.Suspense,{fallback:"Loading..."},a.a.createElement(m,{image:c,style:w,alt:n}))),h?a.a.createElement(l.SquareGrid.Card,{key:e},a.a.createElement(l.SelectableCard,{id:e,formName:"load-data-cards",label:n,selected:f,onClick:h,testID:g,fontSize:l.ComponentSize.ExtraSmall,className:"write-data--item"},a.a.createElement("div",{className:"write-data--item-thumb"},y))):a.a.createElement(l.SquareGrid.Card,{key:e},a.a.createElement(l.SelectableCard,{id:e,formName:"load-data-cards",label:n,testID:`load-data-item ${e}`,selected:!1,onClick:()=>{b.push(`/${d.m}/${x.id}/load-data/${t}`)},fontSize:l.ComponentSize.ExtraSmall,className:"write-data--item"},a.a.createElement("div",{className:"write-data--item-thumb"},y)))}},77:function(e,n,t){"use strict";var r=t(2),a=t(6);n.a=class extends r.PureComponent{render(){const{children:e}=this.props;return a.f?e:null}}},885:function(e,n,t){"use strict";t.d(n,"a",(function(){return l})),t.d(n,"b",(function(){return s}));var r=t(989),a=t.n(r),i=t(990),o=t.n(i);const l=[{id:"annotated_csv",name:"Flux Annotated CSV",image:a.a,markdown:'For more detailed and up to date information check out the <a href="https://docs.influxdata.com/influxdb/v2.0/write-data/developer-tools/csv/#csv-annotations" target="_blank" rel="noreferrer">Annotated CSV Documentation</a>\n\n##### Getting Started\n\nThe Flux Annotated CSV uploader is a simple tool that can be used to upload Flux files downloaded from the UI or exported from the command line tools directly into a bucket.\n\nIf you\'re looking to upload Annotated CSV files into a specific bucket, simply select the bucket you want your data uploaded to and drag & drop your data into the dropzone below.\n'},{id:"csv",name:"CSV Data",image:a.a,markdown:'For more detailed and up to date information check out the [Annotated CSV Documentation](https://docs.influxdata.com/influxdb/v2.0/reference/syntax/annotated-csv/).\n\nFor ingesting custom CSV files into InfluxDB, we recommend you use the [`influx write` command](https://docs.influxdata.com/influxdb/cloud/reference/cli/influx/write/) in the InfluxDB Command Line Interface (CLI).\n\nYou can include [Extended annotated CSV](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/)\nannotations to specify how the data translates into [line protocol](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/).\n\nInclude annotations in the CSV file or inject them using the `--header` flag of\nthe `influx write` command. See the examples below for more details.\n\n##### Example write command\n\n```sh\ninflux write -b <%= bucket %> -f path/to/example.csv\n```\n\n##### example.csv\n\n```csv\n#datatype measurement,tag,double,dateTime:RFC3339\nm,host,used_percent,time\nmem,host1,64.23,2020-01-01T00:00:00Z\nmem,host2,72.01,2020-01-01T00:00:00Z\nmem,host1,62.61,2020-01-01T00:00:10Z\nmem,host2,72.98,2020-01-01T00:00:10Z\nmem,host1,63.40,2020-01-01T00:00:20Z\nmem,host2,73.77,2020-01-01T00:00:20Z\n```\n\n##### Resulting line protocol\n\n```lp\nmem,host=host1 used_percent=64.23 1577836800000000000\nmem,host=host2 used_percent=72.01 1577836800000000000\nmem,host=host1 used_percent=62.61 1577836810000000000\nmem,host=host2 used_percent=72.98 1577836810000000000\nmem,host=host1 used_percent=63.40 1577836820000000000\nmem,host=host2 used_percent=73.77 1577836820000000000\n```\n\n**_Note:_** To test the CSV to line protocol conversion process, use the `influx write dryrun`\ncommand to print the resulting line protocol to stdout rather than write to InfluxDB.\n\n## CSV Annotations\n\nUse **CSV annotations** to specify which element of line protocol each CSV column\nrepresents and how to format the data. CSV annotations are rows at the beginning\nof a CSV file that describe column properties.\n\nThe `influx write` command supports [Extended annotated CSV](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended)\nwhich provides options for specifying how CSV data should be converted into line\nprotocol and how data is formatted.\n\nTo write data to InfluxDB, data must include the following:\n\n- [measurement](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#measurement)\n- [field set](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#field-set)\n- [timestamp](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#timestamp) _(Optional but recommended)_\n- [tag set](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#tag-set) _(Optional)_\n\nUse CSV annotations to specify which of these elements each column represents.\n\n## Inject annotation headers\n\nIf the CSV data you want to write to InfluxDB does not contain the annotations\nrequired to properly convert the data to line protocol, use the `--header` flag\nto inject annotation rows into the CSV data.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/example.csv \\\n  --header "#constant measurement,birds" \\\n  --header "#datatype dataTime:2006-01-02,long,tag"\n```\n\n##### example.csv\n\n```\ndate,sighted,loc\n2020-01-01,12,Boise\n2020-06-01,78,Boise\n2020-01-01,54,Seattle\n2020-06-01,112,Seattle\n2020-01-01,9,Detroit\n2020-06-01,135,Detroit\n```\n\n##### Resulting line protocol\n\n```\nbirds,loc=Boise sighted=12i 1577836800000000000\nbirds,loc=Boise sighted=78i 1590969600000000000\nbirds,loc=Seattle sighted=54i 1577836800000000000\nbirds,loc=Seattle sighted=112i 1590969600000000000\nbirds,loc=Detroit sighted=9i 1577836800000000000\nbirds,loc=Detroit sighted=135i 1590969600000000000\n```\n\n#### Use files to inject headers\n\nThe `influx write` command supports importing multiple files in a single command.\nInclude annotations and header rows in their own file and import them with the write command.\nFiles are read in the order in which they\'re provided.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/headers.csv \\\n  -f path/to/example.csv\n```\n\n##### headers.csv\n\n```\n#constant measurement,birds\n#datatype dataTime:2006-01-02,long,tag\n```\n\n##### example.csv\n\n```\ndate,sighted,loc\n2020-01-01,12,Boise\n2020-06-01,78,Boise\n2020-01-01,54,Seattle\n2020-06-01,112,Seattle\n2020-01-01,9,Detroit\n2020-06-01,135,Detroit\n```\n\n##### Resulting line protocol\n\n```\nbirds,loc=Boise sighted=12i 1577836800000000000\nbirds,loc=Boise sighted=78i 1590969600000000000\nbirds,loc=Seattle sighted=54i 1577836800000000000\nbirds,loc=Seattle sighted=112i 1590969600000000000\nbirds,loc=Detroit sighted=9i 1577836800000000000\nbirds,loc=Detroit sighted=135i 1590969600000000000\n```\n\n## Skip annotation headers\n\nSome CSV data may include header rows that conflict with or lack the annotations\nnecessary to write CSV data to InfluxDB.\nUse the `--skipHeader` flag to specify the **number of rows to skip** at the\nbeginning of the CSV data.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/example.csv \\\n  --skipHeader=2\n```\n\nYou can then inject new header rows to rename columns and provide the necessary annotations.\n\n## Process input as CSV\n\nThe `influx write` command automatically processes files with the `.csv` extension as CSV files.\nIf your CSV file uses a different extension, use the `--format` flat to explicitly\ndeclare the format of the input file.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/example.txt \\\n  --format csv\n```\n\n**_Note:_** The `influx write` command assumes all input files are line protocol unless they\ninclude the `.csv` extension or you declare the `csv`.\n\n## Specify CSV character encoding\n\nThe `influx write` command assumes CSV files contain UTF-8 encoded characters.\nIf your CSV data uses different character encoding, specify the encoding\nwith the `--encoding`.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/example.csv \\\n  --encoding "UTF-16"\n```\n\n## Skip rows with errors\n\nIf a row in your CSV data is missing an\n[element required to write to InfluxDB](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#elements-of-line-protocol)\nor data is incorrectly formatted, when processing the row, the `influx write` command\nreturns an error and cancels the write request.\nTo skip rows with errors, use the `--skipRowOnError` flag.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f path/to/example.csv \\\n  --skipRowOnError\n```\n\n**_Warning:_** Skipped rows are ignored and are not written to InfluxDB.\n\n## Advanced examples\n\n### Define constants\n\nUse the Extended annotated CSV [`#constant` annotation](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#constant)\nto add a column and value to each row in the CSV data.\n\n##### CSV with constants\n\n```\n#constant measurement,example\n#constant tag,source,csv\n#datatype long,dateTime:RFC3339\ncount,time\n1,2020-01-01T00:00:00Z\n4,2020-01-02T00:00:00Z\n9,2020-01-03T00:00:00Z\n18,2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample,source=csv count=1 1577836800000000000\nexample,source=csv count=4 1577923200000000000\nexample,source=csv count=9 1578009600000000000\nexample,source=csv count=18 1578096000000000000\n```\n\n---\n\n### Annotation shorthand\n\nExtended annotated CSV supports [annotation shorthand](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#annotation-shorthand),\nwhich lets you define the **column label**, **datatype**, and **default value** in the column header.\n\n##### CSV with annotation shorthand\n\n```\nm|measurement,count|long|0,time|dateTime:RFC3339\nexample,1,2020-01-01T00:00:00Z\nexample,4,2020-01-02T00:00:00Z\nexample,,2020-01-03T00:00:00Z\nexample,18,2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample count=1 1577836800000000000\nexample count=4 1577923200000000000\nexample count=0 1578009600000000000\nexample count=18 1578096000000000000\n```\n\n#### Replace column header with annotation shorthand\n\nIt\'s possible to replace the column header row in a CSV file with annotation\nshorthand without modifying the CSV file.\nThis lets you define column data types and default values while writing to InfluxDB.\n\nTo replace an existing column header row with annotation shorthand:\n\n1. Use the `--skipHeader` flag to ignore the existing column header row.\n2. Use the `--header` flag to inject a new column header row that uses annotation shorthand.\n\n**_Note:_** `--skipHeader` is the same as `--skipHeader=1`.\n\n```sh\ninflux write -b <%= bucket %> \\\n  -f example.csv \\\n  --skipHeader\n  --header="m|measurement,count|long|0,time|dateTime:RFC3339"\n```\n\n##### Unmodified example.csv\n\n```\nm,count,time\nexample,1,2020-01-01T00:00:00Z\nexample,4,2020-01-02T00:00:00Z\nexample,,2020-01-03T00:00:00Z\nexample,18,2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample count=1i 1577836800000000000\nexample count=4i 1577923200000000000\nexample count=0i 1578009600000000000\nexample count=18i 1578096000000000000\n```\n\n---\n\n### Ignore columns\n\nUse the Extended annotated CSV [`#datatype ignored` annotation](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#ignored)\nto ignore columns when writing CSV data to InfluxDB.\n\n##### CSV data with ignored column\n\n```\n#datatype measurement,long,time,ignored\nm,count,time,foo\nexample,1,2020-01-01T00:00:00Z,bar\nexample,4,2020-01-02T00:00:00Z,bar\nexample,9,2020-01-03T00:00:00Z,baz\nexample,18,2020-01-04T00:00:00Z,baz\n```\n\n##### Resulting line protocol\n\n```\nm count=1i 1577836800000000000\nm count=4i 1577923200000000000\nm count=9i 1578009600000000000\nm count=18i 1578096000000000000\n```\n\n---\n\n### Use alternate numeric formats\n\nIf your CSV data contains numeric values that use a non-default fraction separator (`.`)\nor contain group separators, [define your numeric format](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#double)\nin the `double`, `long`, and `unsignedLong` datatype annotations.\n\n**_Note:_** If your **numeric format separators** include a comma (`,`), wrap the column annotation in double\nquotes (`""`) to prevent the comma from being parsed as a column separator or delimiter.\nYou can also define a custom column separator by injecting the `sep=` header.\n\n##### CSV with non-default float values\n\n```\n#datatype measurement,"double:.,",dateTime:RFC3339\nm,lbs,time\nexample,"1,280.7",2020-01-01T00:00:00Z\nexample,"1,352.5",2020-01-02T00:00:00Z\nexample,"1,862.8",2020-01-03T00:00:00Z\nexample,"2,014.9",2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample lbs=1280.7 1577836800000000000\nexample lbs=1352.5 1577923200000000000\nexample lbs=1862.8 1578009600000000000\nexample lbs=2014.9 1578096000000000000\n```\n\n##### CSV with non-default integer values\n\n```\n#datatype measurement,"long:.,",dateTime:RFC3339\nm,lbs,time\nexample,"1,280.0",2020-01-01T00:00:00Z\nexample,"1,352.0",2020-01-02T00:00:00Z\nexample,"1,862.0",2020-01-03T00:00:00Z\nexample,"2,014.9",2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample lbs=1280i 1577836800000000000\nexample lbs=1352i 1577923200000000000\nexample lbs=1862i 1578009600000000000\nexample lbs=2014i 1578096000000000000\n```\n\n##### CSV with non-default uinteger values\n\n```\n#datatype measurement,"unsignedLong:.,",dateTime:RFC3339\nm,lbs,time\nexample,"1,280.0",2020-01-01T00:00:00Z\nexample,"1,352.0",2020-01-02T00:00:00Z\nexample,"1,862.0",2020-01-03T00:00:00Z\nexample,"2,014.9",2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample lbs=1280u 1577836800000000000\nexample lbs=1352u 1577923200000000000\nexample lbs=1862u 1578009600000000000\nexample lbs=2014u 1578096000000000000\n```\n\n---\n\n### Use alternate boolean format\n\nLine protocol supports only [specific boolean values](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#boolean).\nIf your CSV data contains boolean values that line protocol does not support,\n[define your boolean format](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#boolean)\nin the `boolean` datatype annotation.\n\n##### CSV with non-default boolean values\n\n```\nsep=;\n#datatype measurement,"boolean:y,Y,1:n,N,0",dateTime:RFC3339\nm,verified,time\nexample,y,2020-01-01T00:00:00Z\nexample,n,2020-01-02T00:00:00Z\nexample,1,2020-01-03T00:00:00Z\nexample,N,2020-01-04T00:00:00Z\n```\n\n##### Resulting line protocol\n\n```\nexample verified=true 1577836800000000000\nexample verified=false 1577923200000000000\nexample verified=true 1578009600000000000\nexample verified=false 1578096000000000000\n```\n\n---\n\n### Use different timestamp formats\n\nThe `influx write` command automatically detects **RFC3339** and **number** formatted\ntimestamps when converting CSV to line protocol.\nIf using a different timestamp format, [define your timestamp format](https://docs.influxdata.com/influxdb/cloud/reference/syntax/annotated-csv/extended/#datetime)\nin the `dateTime` datatype annotation.\n\n##### CSV with non-default timestamps\n\n```\n#datatype measurement,dateTime:2006-01-02,field\nm,time,lbs\nexample,2020-01-01,1280.7\nexample,2020-01-02,1352.5\nexample,2020-01-03,1862.8\nexample,2020-01-04,2014.9\n```\n\n##### Resulting line protocol\n\n```\nexample lbs=1280.7 1577836800000000000\nexample lbs=1352.5 1577923200000000000\nexample lbs=1862.8 1578009600000000000\nexample lbs=2014.9 1578096000000000000\n```\n'},{id:"lp",name:"Line Protocol",image:o.a,markdown:'For more detailed and up to date information check out the [Line Protocol Documentation](https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/).\n\n##### Getting Started\n\nThe Line Protocol uploader is a simple tool that can be used to upload files directly to a bucket by uploading a file or writing line protocol directly.\n\nIf you\'re looking to upload Line Protocol files into a specific bucket, simply select the bucket you want your data uploaded to, select the precision of the timestamp your data is set to, and drag & drop your data into the dropzone below. If you\'re interested in manually writing data into your bucket using line protocol, please continue to the section below.\n\n##### Writing Line Protocol\n\nInfluxDB uses line protocol to write data points. It is a text-based format that provides the measurement, tag set, field set, and timestamp of a data point.\n\nSyntax:\n\n```\nmeasurementName,tagKey=tagValue fieldKey="fieldValue" 1465839830100400200\n--------------- --------------- --------------------- -------------------\n       |               |                  |                    |\n  Measurement       Tag set           Field set            Timestamp\n```\n\nExample:\n\n```\nmyMeasurement,tag1=value1,tag2=value2 fieldKey="fieldValue" 1556813561098000000\n```\n\nLines separated by the newline character `\\n` represent a single point in InfluxDB. Line protocol is whitespace sensitive.\n'}],s=e=>l.filter((n=>n.name.toLowerCase().includes(e.toLowerCase()))).sort(((e,n)=>e.name.toLowerCase().localeCompare(n.name.toLowerCase())))},89:function(e,n,t){"use strict";var r=t(2),a=t.n(r),i=t(4),o=t(19),l=t.n(o),s=t(3),c=t(50),u=t(43),d=t(6),m=t(53),p=t(10),f=t(13),h=t(29),g=t(34);t(100);const b={sendNotify:p.c,handleShowOverlay:g.d,handleDismissOverlay:g.b};n.a=Object(i.c)((e=>{const n=Object(u.j)(e);return{status:Object(u.k)(e),resources:n,showUpgrade:Object(h.c)(e)}}),b)((({status:e,alertOnly:n,className:t,resources:i,showUpgrade:o,sendNotify:u,handleShowOverlay:p,handleDismissOverlay:h})=>{const g=()=>{p("write-limit",null,h)};Object(r.useEffect)((()=>{d.f&&"exceeded"===e&&i.includes("write")&&u(o?Object(f.Ud)("",a.a.createElement(m.a,{type:"write",link:"https://docs.influxdata.com/influxdb/v2.0/write-data/best-practices/optimize-writes/",className:"flex-upgrade-content"})):Object(f.Ud)("Data in has stopped because you've hit the query write limit. Let's get it flowing again: ",a.a.createElement(s.Button,{className:"rate-alert-overlay-button",color:s.ComponentColor.Primary,size:s.ComponentSize.Small,onClick:g,text:"Request Write Limit Increase"})))}),[o,e]);const b=l()("rate-alert",{[`${t}`]:t});return d.f&&"exceeded"===e&&i.includes("cardinality")?a.a.createElement(s.FlexBox,{direction:s.FlexDirection.Column,alignItems:s.AlignItems.Center,margin:s.ComponentSize.Large,className:b},a.a.createElement(s.BannerPanel,{size:s.ComponentSize.ExtraSmall,gradient:s.Gradients.PolarExpress,icon:s.IconFont.Cloud,hideMobileIcon:!0,textColor:s.InfluxColors.Yeti},a.a.createElement(m.b,null))):d.f&&!n?a.a.createElement(c.a,{className:"upgrade-payg--button__header"}):null}))},989:function(e,n,t){e.exports=t.p+"c5e11df30f.svg"},990:function(e,n,t){e.exports=t.p+"7c232faa6b.svg"},991:function(e,n,t){var r=t(992);"string"==typeof r&&(r=[[e.i,r,""]]);var a={hmr:!0,transform:undefined,insertInto:void 0};t(17)(r,a);r.locals&&(e.exports=r.locals)},992:function(e,n,t){(n=t(16)(!1)).push([e.i,".write-data--item.cf-selectable-card.cf-selectable-card__xs .cf-selectable-card--label{color:#fff}.write-data--item .cf-selectable-card--children{filter:unset !important}.write-data--item-thumb{position:relative;display:flex;justify-content:center;align-items:center;align-content:center;width:90%;height:90%}.write-data--item-thumb img{max-width:100%;max-height:80px}.write-data--item.cf-selectable-card .cf-selectable-card--children{position:relative}",""]),e.exports=n}}]);
//# sourceMappingURL=42.89c7e17358.js.map