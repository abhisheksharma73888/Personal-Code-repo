(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{2008:function(e,t,n){e.exports=n.p+"0ded195c90.svg"},2009:function(e,t,n){e.exports=n.p+"59a7c64ae2.svg"},2010:function(e,t,n){e.exports=n.p+"c8a5ffd429.svg"},2011:function(e,t,n){e.exports=n.p+"7cfd23c46c.svg"},2012:function(e,t,n){e.exports=n.p+"f0b1424537.svg"},2013:function(e,t,n){e.exports=n.p+"668a77b3cc.svg"},2014:function(e,t,n){e.exports=n.p+"682be7471d.svg"},2015:function(e,t,n){e.exports=n.p+"23b3a029ff.svg"},2016:function(e,t,n){e.exports=n.p+"c5025422d8.svg"},2017:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2018:function(e,t,n){e.exports=n.p+"66b3c62e64.svg"},2019:function(e,t,n){e.exports=n.p+"c788b272da.svg"},2020:function(e,t,n){e.exports=n.p+"21959a1bb5.svg"},2021:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2022:function(e,t,n){e.exports=n.p+"f4eb54ea6d.svg"},2023:function(e,t,n){e.exports=n.p+"a1d5e24cc1.svg"},2024:function(e,t,n){e.exports=n.p+"7aed1b3a51.svg"},2025:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2026:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2027:function(e,t,n){e.exports=n.p+"175098a01b.svg"},2028:function(e,t,n){e.exports=n.p+"38f67e6bee.svg"},2029:function(e,t,n){e.exports=n.p+"096438488d.svg"},2030:function(e,t,n){e.exports=n.p+"096438488d.svg"},2031:function(e,t,n){e.exports=n.p+"884ed986bb.svg"},2032:function(e,t,n){e.exports=n.p+"3e004cc3d0.svg"},2033:function(e,t,n){e.exports=n.p+"d1ea6afe6e.svg"},2034:function(e,t,n){e.exports=n.p+"e4e5aba343.svg"},2035:function(e,t,n){e.exports=n.p+"9f486156be.svg"},2036:function(e,t,n){e.exports=n.p+"58d80338f4.svg"},2037:function(e,t,n){e.exports=n.p+"54f754f1b1.svg"},2038:function(e,t,n){e.exports=n.p+"2dedac00ee.svg"},2039:function(e,t,n){e.exports=n.p+"b1e7bbc2db.svg"},2040:function(e,t,n){e.exports=n.p+"45a59bb23f.svg"},2041:function(e,t,n){e.exports=n.p+"45a59bb23f.svg"},2042:function(e,t,n){e.exports=n.p+"ac851df440.svg"},2043:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2044:function(e,t,n){e.exports=n.p+"8144e25cd4.svg"},2045:function(e,t,n){e.exports=n.p+"2cecf780cf.svg"},2046:function(e,t,n){e.exports=n.p+"2cecf780cf.svg"},2047:function(e,t,n){e.exports=n.p+"14cfaa0fa5.svg"},2048:function(e,t,n){e.exports=n.p+"6588cd86ae.svg"},2049:function(e,t,n){e.exports=n.p+"9d0659f036.svg"},2050:function(e,t,n){e.exports=n.p+"111016e830.svg"},2051:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2052:function(e,t,n){e.exports=n.p+"f0a88e9ba1.svg"},2053:function(e,t,n){e.exports=n.p+"89f49271c1.svg"},2054:function(e,t,n){e.exports=n.p+"89f49271c1.svg"},2055:function(e,t,n){e.exports=n.p+"1f411b102d.svg"},2056:function(e,t,n){e.exports=n.p+"6d99c7671e.svg"},2057:function(e,t,n){e.exports=n.p+"7c08d7e69e.svg"},2058:function(e,t,n){e.exports=n.p+"7c08d7e69e.svg"},2059:function(e,t,n){e.exports=n.p+"7c08d7e69e.svg"},2060:function(e,t,n){e.exports=n.p+"108a283f34.svg"},2061:function(e,t,n){e.exports=n.p+"d2188336d6.svg"},2062:function(e,t,n){e.exports=n.p+"6fbb271634.svg"},2063:function(e,t,n){e.exports=n.p+"175098a01b.svg"},2064:function(e,t,n){e.exports=n.p+"a2543efad8.svg"},2065:function(e,t,n){e.exports=n.p+"614ca6e83a.svg"},2066:function(e,t,n){e.exports=n.p+"45a59bb23f.svg"},2067:function(e,t,n){e.exports=n.p+"53cb3a5f10.svg"},2068:function(e,t,n){e.exports=n.p+"53cb3a5f10.svg"},2069:function(e,t,n){e.exports=n.p+"3e5a1246ef.svg"},2070:function(e,t,n){e.exports=n.p+"53cb3a5f10.svg"},2071:function(e,t,n){e.exports=n.p+"3c5ef5ffee.svg"},2072:function(e,t,n){e.exports=n.p+"0ad25e4b13.svg"},2073:function(e,t,n){e.exports=n.p+"d0ab476331.svg"},2074:function(e,t,n){e.exports=n.p+"d0ab476331.svg"},2075:function(e,t,n){e.exports=n.p+"7735dfc101.svg"},2076:function(e,t,n){e.exports=n.p+"7735dfc101.svg"},2077:function(e,t,n){e.exports=n.p+"d0ab476331.svg"},2078:function(e,t,n){e.exports=n.p+"4496973677.svg"},2079:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2080:function(e,t,n){e.exports=n.p+"51c4fd1ca4.svg"},2081:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2082:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2083:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2084:function(e,t,n){e.exports=n.p+"72514d6e49.svg"},2085:function(e,t,n){e.exports=n.p+"1c13d904a5.svg"},2086:function(e,t,n){e.exports=n.p+"1c13d904a5.svg"},2087:function(e,t,n){e.exports=n.p+"e934e583d4.svg"},2088:function(e,t,n){e.exports=n.p+"f4eb54ea6d.svg"},2089:function(e,t,n){e.exports=n.p+"f4eb54ea6d.svg"},2090:function(e,t,n){e.exports=n.p+"28939e9ec4.svg"},2091:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2092:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2093:function(e,t,n){e.exports=n.p+"f5d7d0f55b.svg"},2094:function(e,t,n){e.exports=n.p+"37d8f470d8.svg"},2095:function(e,t,n){e.exports=n.p+"82ae570387.svg"},2096:function(e,t,n){e.exports=n.p+"fbf149dcc8.svg"},2097:function(e,t,n){e.exports=n.p+"fbf149dcc8.svg"},2098:function(e,t,n){e.exports=n.p+"a67b2229c8.svg"},2099:function(e,t,n){e.exports=n.p+"620134eb80.svg"},2100:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2101:function(e,t,n){e.exports=n.p+"1e99876b35.svg"},2102:function(e,t,n){e.exports=n.p+"2ba9e14599.svg"},2103:function(e,t,n){e.exports=n.p+"d3fc177828.svg"},2104:function(e,t,n){e.exports=n.p+"eda0280db9.svg"},2105:function(e,t,n){e.exports=n.p+"fc8660733b.svg"},2106:function(e,t,n){e.exports=n.p+"17b573894e.svg"},2107:function(e,t,n){e.exports=n.p+"5b0c219f18.svg"},2108:function(e,t,n){e.exports=n.p+"82538a3fed.svg"},2109:function(e,t,n){e.exports=n.p+"361066416c.svg"},2110:function(e,t,n){e.exports=n.p+"9e2d3a1b86.svg"},2111:function(e,t,n){e.exports=n.p+"5077038fa7.svg"},2112:function(e,t,n){e.exports=n.p+"2985235df3.svg"},2113:function(e,t,n){e.exports=n.p+"89c6158164.svg"},2114:function(e,t,n){e.exports=n.p+"dc1b66a141.svg"},2115:function(e,t,n){e.exports=n.p+"36705d208d.svg"},2116:function(e,t,n){e.exports=n.p+"f80a91ba03.svg"},2117:function(e,t,n){e.exports=n.p+"cd591c8aa8.svg"},2118:function(e,t,n){e.exports=n.p+"cd591c8aa8.svg"},2119:function(e,t,n){e.exports=n.p+"42c70b53f0.svg"},2120:function(e,t,n){e.exports=n.p+"8e3e50290e.svg"},2121:function(e,t,n){e.exports=n.p+"ea4e1d80a5.svg"},2122:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2123:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2124:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2125:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2126:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2127:function(e,t,n){e.exports=n.p+"328f7c8f58.svg"},2128:function(e,t,n){e.exports=n.p+"1c28eea713.svg"},2129:function(e,t,n){e.exports=n.p+"4e6a28f518.svg"},2130:function(e,t,n){e.exports=n.p+"4e6a28f518.svg"},2131:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2132:function(e,t,n){e.exports=n.p+"838442d56d.svg"},2133:function(e,t,n){e.exports=n.p+"818d5dd99a.svg"},2134:function(e,t,n){e.exports=n.p+"1f87e13970.svg"},2135:function(e,t,n){e.exports=n.p+"5cb6c5fd31.svg"},2136:function(e,t,n){e.exports=n.p+"838442d56d.svg"},2137:function(e,t,n){e.exports=n.p+"00c1cd41e1.svg"},2138:function(e,t,n){e.exports=n.p+"056151997f.svg"},2139:function(e,t,n){e.exports=n.p+"8e2eb4e81a.svg"},2140:function(e,t,n){e.exports=n.p+"a6ea496e58.svg"},2141:function(e,t,n){e.exports=n.p+"74a6a0b732.svg"},2142:function(e,t,n){e.exports=n.p+"66612c168e.svg"},2143:function(e,t,n){e.exports=n.p+"5e5fe5a981.svg"},2144:function(e,t,n){e.exports=n.p+"9bbd9cb9c8.svg"},2145:function(e,t,n){e.exports=n.p+"9cc0108f08.svg"},2146:function(e,t,n){e.exports=n.p+"c3a4fa94d9.svg"},2147:function(e,t,n){e.exports=n.p+"c3a4fa94d9.svg"},2148:function(e,t,n){e.exports=n.p+"58c83946f6.svg"},2149:function(e,t,n){e.exports=n.p+"58c83946f6.svg"},2150:function(e,t,n){e.exports=n.p+"82538a3fed.svg"},2151:function(e,t,n){e.exports=n.p+"b5dc9994bf.svg"},2152:function(e,t,n){e.exports=n.p+"b1fab729ac.svg"},2153:function(e,t,n){e.exports=n.p+"8b997283fb.svg"},2154:function(e,t,n){e.exports=n.p+"b4acbf00d0.svg"},2155:function(e,t,n){e.exports=n.p+"9b0bcfca5f.svg"},2156:function(e,t,n){e.exports=n.p+"50f28568a0.svg"},2157:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2158:function(e,t,n){e.exports=n.p+"8cded58805.svg"},2159:function(e,t,n){e.exports=n.p+"1cd26fdb60.svg"},2160:function(e,t,n){e.exports=n.p+"4aaff929af.svg"},2161:function(e,t,n){e.exports=n.p+"0f32ad2bfa.svg"},2162:function(e,t,n){e.exports=n.p+"42c9967c69.svg"},2163:function(e,t,n){e.exports=n.p+"1a429df9ec.svg"},2164:function(e,t,n){e.exports=n.p+"8446666eb0.svg"},2165:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2166:function(e,t,n){e.exports=n.p+"1d07589b30.svg"},2167:function(e,t,n){e.exports=n.p+"45a59bb23f.svg"},2168:function(e,t,n){e.exports=n.p+"58696ffaf6.svg"},2169:function(e,t,n){e.exports=n.p+"58696ffaf6.svg"},2170:function(e,t,n){e.exports=n.p+"4ba575f55e.svg"},2171:function(e,t,n){e.exports=n.p+"ac851df440.svg"},2172:function(e,t,n){e.exports=n.p+"af99ebacc0.svg"},2173:function(e,t,n){e.exports=n.p+"99cd4bcb0e.svg"},2174:function(e,t,n){e.exports=n.p+"fa714175dd.svg"},2175:function(e,t,n){e.exports=n.p+"ee8354c1b1.svg"},2176:function(e,t,n){e.exports=n.p+"b5dc9994bf.svg"},2177:function(e,t,n){e.exports=n.p+"09271a32a2.svg"},2178:function(e,t,n){e.exports=n.p+"45a59bb23f.svg"},2179:function(e,t,n){e.exports=n.p+"f11b83d401.svg"},2180:function(e,t,n){e.exports=n.p+"70f2c0d968.svg"},2181:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2182:function(e,t,n){e.exports=n.p+"42ba6a4383.svg"},2183:function(e,t,n){e.exports=n.p+"51c4fd1ca4.svg"},2184:function(e,t,n){e.exports=n.p+"42ab28d0bc.svg"},2185:function(e,t,n){e.exports=n.p+"2ffe2ccff5.svg"},2186:function(e,t,n){e.exports=n.p+"9afaef5b4f.svg"},2187:function(e,t,n){e.exports=n.p+"8e6336e716.svg"},2188:function(e,t,n){e.exports=n.p+"80498d29ec.svg"},2189:function(e,t,n){e.exports=n.p+"9508221c37.svg"},2190:function(e,t,n){e.exports=n.p+"5c23880d6c.svg"},2191:function(e,t,n){e.exports=n.p+"2ffe2ccff5.svg"},2192:function(e,t,n){e.exports=n.p+"b5d0f62d88.svg"},2193:function(e,t,n){e.exports=n.p+"ec1f844187.svg"},2194:function(e,t,n){e.exports=n.p+"b4ed2bd8f1.svg"},2195:function(e,t,n){e.exports=n.p+"ba2b4c974f.svg"},2196:function(e,t,n){e.exports=n.p+"1f16734c1d.svg"},2197:function(e,t,n){e.exports=n.p+"ea4e1d80a5.svg"},2198:function(e,t,n){e.exports=n.p+"ea4e1d80a5.svg"},2199:function(e,t,n){e.exports=n.p+"ea4e1d80a5.svg"},2200:function(e,t,n){e.exports=n.p+"9b75438e96.svg"},2201:function(e,t,n){e.exports=n.p+"bde183ff4d.svg"},2202:function(e,t,n){e.exports=n.p+"d92e2d897a.svg"},2203:function(e,t,n){e.exports=n.p+"f97512804e.svg"},2204:function(e,t,n){e.exports=n.p+"5f7fe9c4b5.svg"},2205:function(e,t,n){e.exports=n.p+"4addfd8db2.svg"},310:function(e,t,n){e.exports=n.p+"340cfcc804.svg"},852:function(e,t,n){"use strict";n.d(t,"a",(function(){return xo})),n.d(t,"b",(function(){return To}));var s=n(2008),a=n.n(s),i=n(2009),o=n.n(i),r=n(2010),c=n.n(r),_=n(2011),l=n.n(_),u=n(2012),d=n.n(u),m=n(2013),p=n.n(m),h=n(2014),g=n.n(h),f=n(2015),b=n.n(f),y=n(2016),v=n.n(y),w=n(2017),k=n.n(w),x=n(2018),T=n.n(x),S=n(2019),q=n.n(S),C=n(2020),I=n.n(C),P=n(2021),A=n.n(P),M=n(2022),D=n.n(M),E=n(2023),O=n.n(E),N=n(2024),R=n.n(N),L=n(2025),z=n.n(L),U=n(2026),F=n.n(U),B=n(2027),j=n.n(B),H=n(2028),W=n.n(H),G=n(2029),Q=n.n(G),K=n(2030),V=n.n(K),X=n(2031),Y=n.n(X),$=n(2032),J=n.n($),Z=n(2033),ee=n.n(Z),te=n(2034),ne=n.n(te),se=n(2035),ae=n.n(se),ie=n(2036),oe=n.n(ie),re=n(2037),ce=n.n(re),_e=n(2038),le=n.n(_e),ue=n(2039),de=n.n(ue),me=n(2040),pe=n.n(me),he=n(2041),ge=n.n(he),fe=n(2042),be=n.n(fe),ye=n(2043),ve=n.n(ye),we=n(2044),ke=n.n(we),xe=n(2045),Te=n.n(xe),Se=n(2046),qe=n.n(Se),Ce=n(2047),Ie=n.n(Ce),Pe=n(2048),Ae=n.n(Pe),Me=n(2049),De=n.n(Me),Ee=n(2050),Oe=n.n(Ee),Ne=n(2051),Re=n.n(Ne),Le=n(2052),ze=n.n(Le),Ue=n(2053),Fe=n.n(Ue),Be=n(2054),je=n.n(Be),He=n(2055),We=n.n(He),Ge=n(2056),Qe=n.n(Ge),Ke=n(2057),Ve=n.n(Ke),Xe=n(2058),Ye=n.n(Xe),$e=n(2059),Je=n.n($e),Ze=n(2060),et=n.n(Ze),tt=n(2061),nt=n.n(tt),st=n(2062),at=n.n(st),it=n(2063),ot=n.n(it),rt=n(2064),ct=n.n(rt),_t=n(2065),lt=n.n(_t),ut=n(2066),dt=n.n(ut),mt=n(2067),pt=n.n(mt),ht=n(2068),gt=n.n(ht),ft=n(2069),bt=n.n(ft),yt=n(2070),vt=n.n(yt),wt=n(2071),kt=n.n(wt),xt=n(2072),Tt=n.n(xt),St=n(2073),qt=n.n(St),Ct=n(2074),It=n.n(Ct),Pt=n(2075),At=n.n(Pt),Mt=n(2076),Dt=n.n(Mt),Et=n(2077),Ot=n.n(Et),Nt=n(2078),Rt=n.n(Nt),Lt=n(2079),zt=n.n(Lt),Ut=n(2080),Ft=n.n(Ut),Bt=n(2081),jt=n.n(Bt),Ht=n(2082),Wt=n.n(Ht),Gt=n(2083),Qt=n.n(Gt),Kt=n(2084),Vt=n.n(Kt),Xt=n(2085),Yt=n.n(Xt),$t=n(2086),Jt=n.n($t),Zt=n(2087),en=n.n(Zt),tn=n(2088),nn=n.n(tn),sn=n(2089),an=n.n(sn),on=n(2090),rn=n.n(on),cn=n(2091),_n=n.n(cn),ln=n(2092),un=n.n(ln),dn=n(2093),mn=n.n(dn),pn=n(2094),hn=n.n(pn),gn=n(2095),fn=n.n(gn),bn=n(2096),yn=n.n(bn),vn=n(2097),wn=n.n(vn),kn=n(2098),xn=n.n(kn),Tn=n(2099),Sn=n.n(Tn),qn=n(2100),Cn=n.n(qn),In=n(2101),Pn=n.n(In),An=n(2102),Mn=n.n(An),Dn=n(2103),En=n.n(Dn),On=n(2104),Nn=n.n(On),Rn=n(2105),Ln=n.n(Rn),zn=n(2106),Un=n.n(zn),Fn=n(2107),Bn=n.n(Fn),jn=n(2108),Hn=n.n(jn),Wn=n(2109),Gn=n.n(Wn),Qn=n(2110),Kn=n.n(Qn),Vn=n(2111),Xn=n.n(Vn),Yn=n(2112),$n=n.n(Yn),Jn=n(2113),Zn=n.n(Jn),es=n(2114),ts=n.n(es),ns=n(2115),ss=n.n(ns),as=n(2116),is=n.n(as),os=n(2117),rs=n.n(os),cs=n(2118),_s=n.n(cs),ls=n(2119),us=n.n(ls),ds=n(2120),ms=n.n(ds),ps=n(2121),hs=n.n(ps),gs=n(2122),fs=n.n(gs),bs=n(2123),ys=n.n(bs),vs=n(2124),ws=n.n(vs),ks=n(2125),xs=n.n(ks),Ts=n(2126),Ss=n.n(Ts),qs=n(2127),Cs=n.n(qs),Is=n(2128),Ps=n.n(Is),As=n(2129),Ms=n.n(As),Ds=n(2130),Es=n.n(Ds),Os=n(2131),Ns=n.n(Os),Rs=n(2132),Ls=n.n(Rs),zs=n(2133),Us=n.n(zs),Fs=n(2134),Bs=n.n(Fs),js=n(2135),Hs=n.n(js),Ws=n(2136),Gs=n.n(Ws),Qs=n(2137),Ks=n.n(Qs),Vs=n(2138),Xs=n.n(Vs),Ys=n(2139),$s=n.n(Ys),Js=n(2140),Zs=n.n(Js),ea=n(2141),ta=n.n(ea),na=n(2142),sa=n.n(na),aa=n(2143),ia=n.n(aa),oa=n(2144),ra=n.n(oa),ca=n(2145),_a=n.n(ca),la=n(2146),ua=n.n(la),da=n(2147),ma=n.n(da),pa=n(2148),ha=n.n(pa),ga=n(2149),fa=n.n(ga),ba=n(2150),ya=n.n(ba),va=n(2151),wa=n.n(va),ka=n(2152),xa=n.n(ka),Ta=n(2153),Sa=n.n(Ta),qa=n(2154),Ca=n.n(qa),Ia=n(2155),Pa=n.n(Ia),Aa=n(2156),Ma=n.n(Aa),Da=n(2157),Ea=n.n(Da),Oa=n(2158),Na=n.n(Oa),Ra=n(2159),La=n.n(Ra),za=n(2160),Ua=n.n(za),Fa=n(2161),Ba=n.n(Fa),ja=n(2162),Ha=n.n(ja),Wa=n(2163),Ga=n.n(Wa),Qa=n(2164),Ka=n.n(Qa),Va=n(2165),Xa=n.n(Va),Ya=n(2166),$a=n.n(Ya),Ja=n(2167),Za=n.n(Ja),ei=n(2168),ti=n.n(ei),ni=n(2169),si=n.n(ni),ai=n(2170),ii=n.n(ai),oi=n(2171),ri=n.n(oi),ci=n(2172),_i=n.n(ci),li=n(2173),ui=n.n(li),di=n(2174),mi=n.n(di),pi=n(2175),hi=n.n(pi),gi=n(2176),fi=n.n(gi),bi=n(2177),yi=n.n(bi),vi=n(2178),wi=n.n(vi),ki=n(2179),xi=n.n(ki),Ti=n(2180),Si=n.n(Ti),qi=n(2181),Ci=n.n(qi),Ii=n(2182),Pi=n.n(Ii),Ai=n(2183),Mi=n.n(Ai),Di=n(2184),Ei=n.n(Di),Oi=n(2185),Ni=n.n(Oi),Ri=n(2186),Li=n.n(Ri),zi=n(2187),Ui=n.n(zi),Fi=n(2188),Bi=n.n(Fi),ji=n(2189),Hi=n.n(ji),Wi=n(2190),Gi=n.n(Wi),Qi=n(2191),Ki=n.n(Qi),Vi=n(2192),Xi=n.n(Vi),Yi=n(2193),$i=n.n(Yi),Ji=n(2194),Zi=n.n(Ji),eo=n(2195),to=n.n(eo),no=n(2196),so=n.n(no),ao=n(2197),io=n.n(ao),oo=n(2198),ro=n.n(oo),co=n(2199),_o=n.n(co),lo=n(2200),uo=n.n(lo),mo=n(2201),po=n.n(mo),ho=n(2202),go=n.n(ho),fo=n(2203),bo=n.n(fo),yo=n(2204),vo=n.n(yo),wo=n(2205),ko=n.n(wo);const xo=[{id:"activemq",name:"ActiveMQ",markdown:'# ActiveMQ Input Plugin\n\nThis plugin gather queues, topics & subscribers metrics using ActiveMQ Console API.\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.activemq]]\n  ## ActiveMQ WebConsole URL\n  url = "http://127.0.0.1:8161"\n\n  ## Required ActiveMQ Endpoint\n  ##   deprecated in 1.11; use the url option\n  # server = "192.168.50.10"\n  # port = 8161\n\n  ## Credentials for basic HTTP authentication\n  # username = "admin"\n  # password = "admin"\n\n  ## Required ActiveMQ webadmin root path\n  # webadmin = "admin"\n\n  ## Maximum time to receive response.\n  # response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\nEvery effort was made to preserve the names based on the XML response from the ActiveMQ Console API.\n\n- activemq_queues\n  - tags:\n    - name\n    - source\n    - port\n  - fields:\n    - size\n    - consumer_count\n    - enqueue_count\n    - dequeue_count\n+ activemq_topics\n  - tags:\n    - name\n    - source\n    - port\n  - fields:\n    - size\n    - consumer_count\n    - enqueue_count\n    - dequeue_count\n- activemq_subscribers\n  - tags:\n    - client_id\n    - subscription_name\n    - connection_id\n    - destination_name\n    - selector\n    - active\n    - source\n    - port\n  - fields:\n    - pending_queue_size\n    - dispatched_queue_size\n    - dispatched_counter\n    - enqueue_counter\n    - dequeue_counter\n\n### Example Output\n\n```\nactivemq_queues,name=sandra,host=88284b2fe51b,source=localhost,port=8161 consumer_count=0i,enqueue_count=0i,dequeue_count=0i,size=0i 1492610703000000000\nactivemq_queues,name=Test,host=88284b2fe51b,source=localhost,port=8161 dequeue_count=0i,size=0i,consumer_count=0i,enqueue_count=0i 1492610703000000000\nactivemq_topics,name=ActiveMQ.Advisory.MasterBroker\\ ,host=88284b2fe51b,source=localhost,port=8161 size=0i,consumer_count=0i,enqueue_count=1i,dequeue_count=0i 1492610703000000000\nactivemq_topics,host=88284b2fe51b,name=AAA\\,source=localhost,port=8161  size=0i,consumer_count=1i,enqueue_count=0i,dequeue_count=0i 1492610703000000000\nactivemq_topics,name=ActiveMQ.Advisory.Topic\\,source=localhost,port=8161 ,host=88284b2fe51b enqueue_count=1i,dequeue_count=0i,size=0i,consumer_count=0i 1492610703000000000\nactivemq_topics,name=ActiveMQ.Advisory.Queue\\,source=localhost,port=8161 ,host=88284b2fe51b size=0i,consumer_count=0i,enqueue_count=2i,dequeue_count=0i 1492610703000000000\nactivemq_topics,name=AAAA\\ ,host=88284b2fe51b,source=localhost,port=8161 consumer_count=0i,enqueue_count=0i,dequeue_count=0i,size=0i 1492610703000000000\nactivemq_subscribers,connection_id=NOTSET,destination_name=AAA,,source=localhost,port=8161,selector=AA,active=no,host=88284b2fe51b,client_id=AAA,subscription_name=AAA pending_queue_size=0i,dispatched_queue_size=0i,dispatched_counter=0i,enqueue_counter=0i,dequeue_counter=0i 1492610703000000000\n```\n',image:a.a},{id:"aerospike",name:"Aerospike",markdown:'# Aerospike Input Plugin\n\nThe aerospike plugin queries aerospike server(s) and get node statistics & stats for\nall the configured namespaces.\n\nFor what the measurements mean, please consult the [Aerospike Metrics Reference Docs](http://www.aerospike.com/docs/reference/metrics).\n\nThe metric names, to make it less complicated in querying, have replaced all `-` with `_` as Aerospike metrics come in both forms (no idea why).\n\nAll metrics are attempted to be cast to integers, then booleans, then strings.\n\n### Configuration:\n```toml\n# Read stats from aerospike server(s)\n[[inputs.aerospike]]\n  ## Aerospike servers to connect to (with port)\n  ## This plugin will query all namespaces the aerospike\n  ## server has configured and get stats for them.\n  servers = ["localhost:3000"]\n\n  # username = "telegraf"\n  # password = "pa$$word"\n\n  ## Optional TLS Config\n  # enable_tls = false\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## If false, skip chain & host verification\n  # insecure_skip_verify = true\n\n  # Feature Options\n  # Add namespace variable to limit the namespaces executed on\n  # Leave blank to do all\n  # disable_query_namespaces = true # default false\n  # namespaces = ["namespace1", "namespace2"]\n\n  # Enable set level telemetry\n  # query_sets = true # default: false\n  # Add namespace set combinations to limit sets executed on\n  # Leave blank to do all sets\n  # sets = ["namespace1/set1", "namespace1/set2", "namespace3"]\n\n  # Histograms\n  # enable_ttl_histogram = true # default: false\n  # enable_object_size_linear_histogram = true # default: false\n\n  # by default, aerospike produces a 100 bucket histogram\n  # this is not great for most graphing tools, this will allow\n  # the ability to squash this to a smaller number of buckets\n  # To have a balanced histogram, the number of buckets chosen \n  # should divide evenly into 100.\n  # num_histogram_buckets = 100 # default: 10\n```\n\n### Measurements:\n\nThe aerospike metrics are under a few measurement names:\n\n***aerospike_node***: These are the aerospike **node** measurements, which are\navailable from the aerospike `statistics` command.\n\n      ie,\n      ```\n        telnet localhost 3003\n        statistics\n        ...\n      ```\n\n***aerospike_namespace***: These are aerospike namespace measurements, which\nare available from the aerospike `namespace/<namespace_name>` command.\n\n      ie,\n      ```\n        telnet localhost 3003\n        namespaces\n        <namespace_1>;<namespace_2>;etc.\n        namespace/<namespace_name>\n        ...\n      ```\n***aerospike_set***: These are aerospike set measurements, which\nare available from the aerospike `sets/<namespace_name>/<set_name>` command.\n\n      ie,\n      ```\n        telnet localhost 3003\n        sets\n        sets/<namespace_name>\n        sets/<namespace_name>/<set_name>\n        ...\n      ```\n***aerospike_histogram_ttl***: These are aerospike ttl hisogram measurements, which\nis available from the aerospike `histogram:namespace=<namespace_name>;[set=<set_name>;]type=ttl` command.\n\n      ie,\n      ```\n        telnet localhost 3003\n        histogram:namespace=<namespace_name>;type=ttl\n        histogram:namespace=<namespace_name>;[set=<set_name>;]type=ttl\n        ...\n      ```\n***aerospike_histogram_object_size_linear***: These are aerospike object size linear histogram measurements, which is available from the aerospike `histogram:namespace=<namespace_name>;[set=<set_name>;]type=object_size_linear` command.\n\n      ie,\n      ```\n        telnet localhost 3003\n        histogram:namespace=<namespace_name>;type=object_size_linear\n        histogram:namespace=<namespace_name>;[set=<set_name>;]type=object_size_linear\n        ...\n      ```\n\n### Tags:\n\nAll measurements have tags:\n\n- aerospike_host\n- node_name\n\nNamespace metrics have tags:\n\n- namespace_name\n\nSet metrics have tags:\n\n- namespace_name\n- set_name\n\nHistogram metrics have tags:\n- namespace_name\n- set_name (optional)\n- type\n\n### Example Output:\n\n```\n% telegraf --input-filter aerospike --test\n> aerospike_node,aerospike_host=localhost:3000,node_name="BB9020011AC4202" batch_error=0i,batch_index_complete=0i,batch_index_created_buffers=0i,batch_index_destroyed_buffers=0i,batch_index_error=0i,batch_index_huge_buffers=0i,batch_index_initiate=0i,batch_index_queue="0:0,0:0,0:0,0:0",batch_index_timeout=0i,batch_index_unused_buffers=0i,batch_initiate=0i,batch_queue=0i,batch_timeout=0i,client_connections=6i,cluster_integrity=true,cluster_key="8AF422E05281249E",cluster_size=1i,delete_queue=0i,demarshal_error=0i,early_tsvc_batch_sub_error=0i,early_tsvc_client_error=0i,early_tsvc_udf_sub_error=0i,fabric_connections=16i,fabric_msgs_rcvd=0i,fabric_msgs_sent=0i,heartbeat_connections=0i,heartbeat_received_foreign=0i,heartbeat_received_self=0i,info_complete=47i,info_queue=0i,migrate_allowed=true,migrate_partitions_remaining=0i,migrate_progress_recv=0i,migrate_progress_send=0i,objects=0i,paxos_principal="BB9020011AC4202",proxy_in_progress=0i,proxy_retry=0i,query_long_running=0i,query_short_running=0i,reaped_fds=0i,record_refs=0i,rw_in_progress=0i,scans_active=0i,sindex_gc_activity_dur=0i,sindex_gc_garbage_cleaned=0i,sindex_gc_garbage_found=0i,sindex_gc_inactivity_dur=0i,sindex_gc_list_creation_time=0i,sindex_gc_list_deletion_time=0i,sindex_gc_locktimedout=0i,sindex_gc_objects_validated=0i,sindex_ucgarbage_found=0i,sub_objects=0i,system_free_mem_pct=92i,system_swapping=false,tsvc_queue=0i,uptime=1457i 1468923222000000000\n> aerospike_namespace,aerospike_host=localhost:3000,namespace=test,node_name="BB9020011AC4202" allow_nonxdr_writes=true,allow_xdr_writes=true,available_bin_names=32768i,batch_sub_proxy_complete=0i,batch_sub_proxy_error=0i,batch_sub_proxy_timeout=0i,batch_sub_read_error=0i,batch_sub_read_not_found=0i,batch_sub_read_success=0i,batch_sub_read_timeout=0i,batch_sub_tsvc_error=0i,batch_sub_tsvc_timeout=0i,client_delete_error=0i,client_delete_not_found=0i,client_delete_success=0i,client_delete_timeout=0i,client_lang_delete_success=0i,client_lang_error=0i,client_lang_read_success=0i,client_lang_write_success=0i,client_proxy_complete=0i,client_proxy_error=0i,client_proxy_timeout=0i,client_read_error=0i,client_read_not_found=0i,client_read_success=0i,client_read_timeout=0i,client_tsvc_error=0i,client_tsvc_timeout=0i,client_udf_complete=0i,client_udf_error=0i,client_udf_timeout=0i,client_write_error=0i,client_write_success=0i,client_write_timeout=0i,cold_start_evict_ttl=4294967295i,conflict_resolution_policy="generation",current_time=206619222i,data_in_index=false,default_ttl=432000i,device_available_pct=99i,device_free_pct=100i,device_total_bytes=4294967296i,device_used_bytes=0i,disallow_null_setname=false,enable_benchmarks_batch_sub=false,enable_benchmarks_read=false,enable_benchmarks_storage=false,enable_benchmarks_udf=false,enable_benchmarks_udf_sub=false,enable_benchmarks_write=false,enable_hist_proxy=false,enable_xdr=false,evict_hist_buckets=10000i,evict_tenths_pct=5i,evict_ttl=0i,evicted_objects=0i,expired_objects=0i,fail_generation=0i,fail_key_busy=0i,fail_record_too_big=0i,fail_xdr_forbidden=0i,geo2dsphere_within.earth_radius_meters=6371000i,geo2dsphere_within.level_mod=1i,geo2dsphere_within.max_cells=12i,geo2dsphere_within.max_level=30i,geo2dsphere_within.min_level=1i,geo2dsphere_within.strict=true,geo_region_query_cells=0i,geo_region_query_falsepos=0i,geo_region_query_points=0i,geo_region_query_reqs=0i,high_water_disk_pct=50i,high_water_memory_pct=60i,hwm_breached=false,ldt_enabled=false,ldt_gc_rate=0i,ldt_page_size=8192i,master_objects=0i,master_sub_objects=0i,max_ttl=315360000i,max_void_time=0i,memory_free_pct=100i,memory_size=1073741824i,memory_used_bytes=0i,memory_used_data_bytes=0i,memory_used_index_bytes=0i,memory_used_sindex_bytes=0i,migrate_order=5i,migrate_record_receives=0i,migrate_record_retransmits=0i,migrate_records_skipped=0i,migrate_records_transmitted=0i,migrate_rx_instances=0i,migrate_rx_partitions_active=0i,migrate_rx_partitions_initial=0i,migrate_rx_partitions_remaining=0i,migrate_sleep=1i,migrate_tx_instances=0i,migrate_tx_partitions_active=0i,migrate_tx_partitions_imbalance=0i,migrate_tx_partitions_initial=0i,migrate_tx_partitions_remaining=0i,non_expirable_objects=0i,ns_forward_xdr_writes=false,nsup_cycle_duration=0i,nsup_cycle_sleep_pct=0i,objects=0i,prole_objects=0i,prole_sub_objects=0i,query_agg=0i,query_agg_abort=0i,query_agg_avg_rec_count=0i,query_agg_error=0i,query_agg_success=0i,query_fail=0i,query_long_queue_full=0i,query_long_reqs=0i,query_lookup_abort=0i,query_lookup_avg_rec_count=0i,query_lookup_error=0i,query_lookup_success=0i,query_lookups=0i,query_reqs=0i,query_short_queue_full=0i,query_short_reqs=0i,query_udf_bg_failure=0i,query_udf_bg_success=0i,read_consistency_level_override="off",repl_factor=1i,scan_aggr_abort=0i,scan_aggr_complete=0i,scan_aggr_error=0i,scan_basic_abort=0i,scan_basic_complete=0i,scan_basic_error=0i,scan_udf_bg_abort=0i,scan_udf_bg_complete=0i,scan_udf_bg_error=0i,set_deleted_objects=0i,sets_enable_xdr=true,sindex.data_max_memory="ULONG_MAX",sindex.num_partitions=32i,single_bin=false,stop_writes=false,stop_writes_pct=90i,storage_engine="device",storage_engine.cold_start_empty=false,storage_engine.data_in_memory=true,storage_engine.defrag_lwm_pct=50i,storage_engine.defrag_queue_min=0i,storage_engine.defrag_sleep=1000i,storage_engine.defrag_startup_minimum=10i,storage_engine.disable_odirect=false,storage_engine.enable_osync=false,storage_engine.file="/opt/aerospike/data/test.dat",storage_engine.filesize=4294967296i,storage_engine.flush_max_ms=1000i,storage_engine.fsync_max_sec=0i,storage_engine.max_write_cache=67108864i,storage_engine.min_avail_pct=5i,storage_engine.post_write_queue=0i,storage_engine.scheduler_mode="null",storage_engine.write_block_size=1048576i,storage_engine.write_threads=1i,sub_objects=0i,udf_sub_lang_delete_success=0i,udf_sub_lang_error=0i,udf_sub_lang_read_success=0i,udf_sub_lang_write_success=0i,udf_sub_tsvc_error=0i,udf_sub_tsvc_timeout=0i,udf_sub_udf_complete=0i,udf_sub_udf_error=0i,udf_sub_udf_timeout=0i,write_commit_level_override="off",xdr_write_error=0i,xdr_write_success=0i,xdr_write_timeout=0i,{test}_query_hist_track_back=300i,{test}_query_hist_track_slice=10i,{test}_query_hist_track_thresholds="1,8,64",{test}_read_hist_track_back=300i,{test}_read_hist_track_slice=10i,{test}_read_hist_track_thresholds="1,8,64",{test}_udf_hist_track_back=300i,{test}_udf_hist_track_slice=10i,{test}_udf_hist_track_thresholds="1,8,64",{test}_write_hist_track_back=300i,{test}_write_hist_track_slice=10i,{test}_write_hist_track_thresholds="1,8,64" 1468923222000000000\n> aerospike_set,aerospike_host=localhost:3000,node_name=BB99458B42826B0,set=test/test disable_eviction=false,memory_data_bytes=0i,objects=0i,set_enable_xdr="use-default",stop_writes_count=0i,tombstones=0i,truncate_lut=0i 1598033805000000000\n>> aerospike_histogram_ttl,aerospike_host=localhost:3000,namespace=test,node_name=BB98EE5B42826B0,set=test 0=0i,1=0i,10=0i,11=0i,12=0i,13=0i,14=0i,15=0i,16=0i,17=0i,18=0i,19=0i,2=0i,20=0i,21=0i,22=0i,23=0i,24=0i,25=0i,26=0i,27=0i,28=0i,29=0i,3=0i,30=0i,31=0i,32=0i,33=0i,34=0i,35=0i,36=0i,37=0i,38=0i,39=0i,4=0i,40=0i,41=0i,42=0i,43=0i,44=0i,45=0i,46=0i,47=0i,48=0i,49=0i,5=0i,50=0i,51=0i,52=0i,53=0i,54=0i,55=0i,56=0i,57=0i,58=0i,59=0i,6=0i,60=0i,61=0i,62=0i,63=0i,64=0i,65=0i,66=0i,67=0i,68=0i,69=0i,7=0i,70=0i,71=0i,72=0i,73=0i,74=0i,75=0i,76=0i,77=0i,78=0i,79=0i,8=0i,80=0i,81=0i,82=0i,83=0i,84=0i,85=0i,86=0i,87=0i,88=0i,89=0i,9=0i,90=0i,91=0i,92=0i,93=0i,94=0i,95=0i,96=0i,97=0i,98=0i,99=0i 1598034191000000000\n\n```\n',image:o.a},{id:"aliyuncms",name:"Alibaba (Aliyun) CloudMonitor Service Statistics",markdown:'# Alibaba (Aliyun) CloudMonitor Service Statistics Input Plugin\n\nHere and after we use `Aliyun` instead `Alibaba` as it is default naming across web console and docs.\n\nThis plugin will pull Metric Statistics from Aliyun CMS.\n\n### Aliyun Authentication\n\nThis plugin uses an [AccessKey](https://www.alibabacloud.com/help/doc-detail/53045.htm?spm=a2c63.p38356.b99.127.5cba21fdt5MJKr&parentId=28572) credential for Authentication with the Aliyun OpenAPI endpoint.\nIn the following order the plugin will attempt to authenticate.\n1. Ram RoleARN credential if `access_key_id`, `access_key_secret`, `role_arn`, `role_session_name` is specified\n2. AccessKey STS token credential if `access_key_id`, `access_key_secret`, `access_key_sts_token` is specified\n3. AccessKey credential if `access_key_id`, `access_key_secret` is specified\n4. Ecs Ram Role Credential if `role_name` is specified\n5. RSA keypair credential if `private_key`, `public_key_id` is specified\n6. Environment variables credential\n7. Instance metadata credential\n\n### Configuration:\n\n```toml\n  ## Aliyun Credentials\n  ## Credentials are loaded in the following order\n  ## 1) Ram RoleArn credential\n  ## 2) AccessKey STS token credential\n  ## 3) AccessKey credential\n  ## 4) Ecs Ram Role credential\n  ## 5) RSA keypair credential\n  ## 6) Environment variables credential\n  ## 7) Instance metadata credential\n  \n  # access_key_id = ""\n  # access_key_secret = ""\n  # access_key_sts_token = ""\n  # role_arn = ""\n  # role_session_name = ""\n  # private_key = ""\n  # public_key_id = ""\n  # role_name = ""\n\n  ## Specify the ali cloud region list to be queried for metrics and objects discovery\n  ## If not set, all supported regions (see below) would be covered, it can provide a significant load on API, so the recommendation here \n  ## is to limit the list as much as possible. Allowed values: https://www.alibabacloud.com/help/zh/doc-detail/40654.htm\n  ## Default supported regions are:\n  ## 21 items: cn-qingdao,cn-beijing,cn-zhangjiakou,cn-huhehaote,cn-hangzhou,cn-shanghai,cn-shenzhen,\n  ##           cn-heyuan,cn-chengdu,cn-hongkong,ap-southeast-1,ap-southeast-2,ap-southeast-3,ap-southeast-5,\n  ##           ap-south-1,ap-northeast-1,us-west-1,us-east-1,eu-central-1,eu-west-1,me-east-1\n  ##\n  ## From discovery perspective it set the scope for object discovery, the discovered info can be used to enrich\n  ## the metrics with objects attributes/tags. Discovery is supported not for all projects (if not supported, then \n  ## it will be reported on the start - for example for \'acs_cdn\' project:\n  ## \'E! [inputs.aliyuncms] Discovery tool is not activated: no discovery support for project "acs_cdn"\' )\n  ## Currently, discovery supported for the following projects:\n  ## - acs_ecs_dashboard\n  ## - acs_rds_dashboard\n  ## - acs_slb_dashboard\n  ## - acs_vpc_eip   \n  regions = ["cn-hongkong"]\n\n  # The minimum period for AliyunCMS metrics is 1 minute (60s). However not all\n  # metrics are made available to the 1 minute period. Some are collected at\n  # 3 minute, 5 minute, or larger intervals.\n  # See: https://help.aliyun.com/document_detail/51936.html?spm=a2c4g.11186623.2.18.2bc1750eeOw1Pv\n  # Note that if a period is configured that is smaller than the minimum for a\n  # particular metric, that metric will not be returned by the Aliyun OpenAPI\n  # and will not be collected by Telegraf.\n  #\n  ## Requested AliyunCMS aggregation Period (required - must be a multiple of 60s)\n  period = "5m"\n  \n  ## Collection Delay (required - must account for metrics availability via AliyunCMS API)\n  delay = "1m"\n  \n  ## Recommended: use metric \'interval\' that is a multiple of \'period\' to avoid\n  ## gaps or overlap in pulled data\n  interval = "5m"\n  \n  ## Metric Statistic Project (required)\n  project = "acs_slb_dashboard"\n  \n  ## Maximum requests per second, default value is 200\n  ratelimit = 200\n  \n  ## How often the discovery API call executed (default 1m)\n  #discovery_interval = "1m"\n  \n  ## Metrics to Pull (Required)\n  [[inputs.aliyuncms.metrics]]\n  ## Metrics names to be requested, \n  ## described here (per project): https://help.aliyun.com/document_detail/28619.html?spm=a2c4g.11186623.6.690.1938ad41wg8QSq\n  names = ["InstanceActiveConnection", "InstanceNewConnection"]\n  \n  ## Dimension filters for Metric (these are optional).\n  ## This allows to get additional metric dimension. If dimension is not specified it can be returned or\n  ## the data can be aggregated - it depends on particular metric, you can find details here: https://help.aliyun.com/document_detail/28619.html?spm=a2c4g.11186623.6.690.1938ad41wg8QSq\n  ##\n  ## Note, that by default dimension filter includes the list of discovered objects in scope (if discovery is enabled)\n  ## Values specified here would be added into the list of discovered objects.\n  ## You can specify either single dimension:      \n  #dimensions = \'{"instanceId": "p-example"}\'\n  \n  ## Or you can specify several dimensions at once:\n  #dimensions = \'[{"instanceId": "p-example"},{"instanceId": "q-example"}]\'\n  \n  ## Enrichment tags, can be added from discovery (if supported)\n  ## Notation is <measurement_tag_name>:<JMES query path (https://jmespath.org/tutorial.html)>\n  ## To figure out which fields are available, consult the Describe<ObjectType> API per project.\n  ## For example, for SLB: https://api.aliyun.com/#/?product=Slb&version=2014-05-15&api=DescribeLoadBalancers&params={}&tab=MOCK&lang=GO\n  #tag_query_path = [\n  #    "address:Address",\n  #    "name:LoadBalancerName",\n  #    "cluster_owner:Tags.Tag[?TagKey==\'cs.cluster.name\'].TagValue | [0]"\n  #    ]\n  ## The following tags added by default: regionId (if discovery enabled), userId, instanceId.\n  \n  ## Allow metrics without discovery data, if discovery is enabled. If set to true, then metric without discovery\n  ## data would be emitted, otherwise dropped. This cane be of help, in case debugging dimension filters, or partial coverage \n  ## of discovery scope vs monitoring scope \n  #allow_dps_without_discovery = false\n```\n\n#### Requirements and Terminology\n\nPlugin Configuration utilizes [preset metric items references](https://www.alibabacloud.com/help/doc-detail/28619.htm?spm=a2c63.p38356.a3.2.389f233d0kPJn0)\n\n- `discovery_region` must be a valid Aliyun [Region](https://www.alibabacloud.com/help/doc-detail/40654.htm) value\n- `period` must be a valid duration value\n- `project` must be a preset project value\n- `names` must be preset metric names\n- `dimensions` must be preset dimension values\n\n### Measurements & Fields:\n\nEach Aliyun CMS Project monitored records a measurement with fields for each available Metric Statistic\nProject and Metrics are represented in [snake case](https://en.wikipedia.org/wiki/Snake_case)\n\n- aliyuncms_{project}\n  - {metric}_average     (metric Average value)\n  - {metric}_minimum     (metric Minimum value)\n  - {metric}_maximum     (metric Maximum value)\n  - {metric}_value       (metric Value value)\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter aliyuncms --test\n> aliyuncms_acs_slb_dashboard,instanceId=p-example,regionId=cn-hangzhou,userId=1234567890 latency_average=0.004810798017284538,latency_maximum=0.1100282669067383,latency_minimum=0.0006084442138671875\n```',image:c.a},{id:"amd_rocm_smi",name:"ROCm System Management Interface",markdown:'# ROCm System Management Interface (SMI) Input Plugin\n\nThis plugin uses a query on the [`rocm-smi`](https://github.com/RadeonOpenCompute/rocm_smi_lib/tree/master/python_smi_tools) binary to pull GPU stats including memory and GPU usage, temperatures and other.\n\n### Configuration\n\n```toml\n# Pulls statistics from nvidia GPUs attached to the host\n[[inputs.amd_rocm_smi]]\n  ## Optional: path to rocm-smi binary, defaults to $PATH via exec.LookPath\n  # bin_path = "/opt/rocm/bin/rocm-smi"\n\n  ## Optional: timeout for GPU polling\n  # timeout = "5s"\n```\n\n### Metrics\n- measurement: `amd_rocm_smi`\n  - tags\n    - `name` (entry name assigned by rocm-smi executable)\n    - `gpu_id` (id of the GPU according to rocm-smi)\n    - `gpu_unique_id` (unique id of the GPU)\n\n  - fields\n    - `driver_version` (integer)\n    - `fan_speed`(integer)\n    - `memory_total`(integer B)\n    - `memory_used`(integer B)\n    - `memory_free`(integer B)\n    - `temperature_sensor_edge` (float, Celsius)\n    - `temperature_sensor_junction` (float, Celsius)\n    - `temperature_sensor_memory` (float, Celsius)\n    - `utilization_gpu` (integer, percentage)\n    - `utilization_memory` (integer, percentage)\n    - `clocks_current_sm` (integer, Mhz)\n    - `clocks_current_memory` (integer, Mhz)\n    - `power_draw` (float, Watt)\n\n### Troubleshooting\nCheck the full output by running `rocm-smi` binary manually.\n\nLinux:\n```sh\nrocm-smi rocm-smi -o -l -m -M  -g -c -t -u -i -f -p -P -s -S -v --showreplaycount --showpids --showdriverversion --showmemvendor --showfwinfo --showproductname --showserial --showuniqueid --showbus --showpendingpages --showpagesinfo --showretiredpages --showunreservablepages --showmemuse --showvoltage --showtopo --showtopoweight --showtopohops --showtopotype --showtoponuma --showmeminfo all --json\n```\nPlease include the output of this command if opening a GitHub issue, together with ROCm version.\n### Example Output\n```\namd_rocm_smi,gpu_id=0x6861,gpu_unique_id=0x2150e7d042a1124,host=ali47xl,name=card0 clocks_current_memory=167i,clocks_current_sm=852i,driver_version=51114i,fan_speed=14i,memory_free=17145282560i,memory_total=17163091968i,memory_used=17809408i,power_draw=7,temperature_sensor_edge=28,temperature_sensor_junction=29,temperature_sensor_memory=92,utilization_gpu=0i 1630572551000000000\namd_rocm_smi,gpu_id=0x6861,gpu_unique_id=0x2150e7d042a1124,host=ali47xl,name=card0 clocks_current_memory=167i,clocks_current_sm=852i,driver_version=51114i,fan_speed=14i,memory_free=17145282560i,memory_total=17163091968i,memory_used=17809408i,power_draw=7,temperature_sensor_edge=29,temperature_sensor_junction=30,temperature_sensor_memory=91,utilization_gpu=0i 1630572701000000000\namd_rocm_smi,gpu_id=0x6861,gpu_unique_id=0x2150e7d042a1124,host=ali47xl,name=card0 clocks_current_memory=167i,clocks_current_sm=852i,driver_version=51114i,fan_speed=14i,memory_free=17145282560i,memory_total=17163091968i,memory_used=17809408i,power_draw=7,temperature_sensor_edge=29,temperature_sensor_junction=29,temperature_sensor_memory=92,utilization_gpu=0i 1630572749000000000\n```\n### Limitations and notices\nPlease notice that this plugin has been developed and tested on a limited number of versions and small set of GPUs. Currently the latest ROCm version tested is 4.3.0.\nNotice that depending on the device and driver versions the amount of information provided by `rocm-smi` can vary so that some fields would start/stop appearing in the metrics upon updates.\nThe `rocm-smi` JSON output is not perfectly homogeneous and is possibly changing in the future, hence parsing and unmarshaling can start failing upon updating ROCm.\n\nInspired by the current state of the art of the `nvidia-smi` plugin.\n',image:l.a},{id:"amqp_consumer",name:"AMQP Consumer",markdown:'# AMQP Consumer Input Plugin\n\nThis plugin provides a consumer for use with AMQP 0-9-1, a prominent implementation of this protocol being [RabbitMQ](https://www.rabbitmq.com/).\n\nMetrics are read from a topic exchange using the configured queue and binding_key.\n\nMessage payload should be formatted in one of the [Telegraf Data Formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).\n\nFor an introduction to AMQP see:\n- https://www.rabbitmq.com/tutorials/amqp-concepts.html\n- https://www.rabbitmq.com/getstarted.html\n\nThe following defaults are known to work with RabbitMQ:\n\n```toml\n[[inputs.amqp_consumer]]\n  ## Broker to consume from.\n  ##   deprecated in 1.7; use the brokers option\n  # url = "amqp://localhost:5672/influxdb"\n\n  ## Brokers to consume from.  If multiple brokers are specified a random broker\n  ## will be selected anytime a connection is established.  This can be\n  ## helpful for load balancing when not using a dedicated load balancer.\n  brokers = ["amqp://localhost:5672/influxdb"]\n\n  ## Authentication credentials for the PLAIN auth_method.\n  # username = ""\n  # password = ""\n\n  ## Name of the exchange to declare.  If unset, no exchange will be declared.\n  exchange = "telegraf"\n\n  ## Exchange type; common types are "direct", "fanout", "topic", "header", "x-consistent-hash".\n  # exchange_type = "topic"\n\n  ## If true, exchange will be passively declared.\n  # exchange_passive = false\n\n  ## Exchange durability can be either "transient" or "durable".\n  # exchange_durability = "durable"\n\n  ## Additional exchange arguments.\n  # exchange_arguments = { }\n  # exchange_arguments = {"hash_property" = "timestamp"}\n\n  ## AMQP queue name.\n  queue = "telegraf"\n\n  ## AMQP queue durability can be "transient" or "durable".\n  queue_durability = "durable"\n\n  ## If true, queue will be passively declared.\n  # queue_passive = false\n\n  ## A binding between the exchange and queue using this binding key is\n  ## created.  If unset, no binding is created.\n  binding_key = "#"\n\n  ## Maximum number of messages server should give to the worker.\n  # prefetch_count = 50\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Auth method. PLAIN and EXTERNAL are supported\n  ## Using EXTERNAL requires enabling the rabbitmq_auth_mechanism_ssl plugin as\n  ## described here: https://www.rabbitmq.com/plugins.html\n  # auth_method = "PLAIN"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Content encoding for message payloads, can be set to "gzip" to or\n  ## "identity" to apply no encoding.\n  # content_encoding = "identity"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n',image:d.a},{id:"apache",name:"Apache",markdown:'# Apache Input Plugin\n\nThe Apache plugin collects server performance information using the [`mod_status`](https://httpd.apache.org/docs/2.4/mod/mod_status.html) module of the [Apache HTTP Server](https://httpd.apache.org/).\n\nTypically, the `mod_status` module is configured to expose a page at the `/server-status?auto` location of the Apache server.  The [ExtendedStatus](https://httpd.apache.org/docs/2.4/mod/core.html#extendedstatus) option must be enabled in order to collect all available fields.  For information about how to configure your server reference the [module documentation](https://httpd.apache.org/docs/2.4/mod/mod_status.html#enable).\n\n### Configuration:\n\n```toml\n# Read Apache status information (mod_status)\n[[inputs.apache]]\n  ## An array of URLs to gather from, must be directed at the machine\n  ## readable version of the mod_status page including the auto query string.\n  ## Default is "http://localhost/server-status?auto".\n  urls = ["http://localhost/server-status?auto"]\n\n  ## Credentials for basic HTTP authentication.\n  # username = "myuser"\n  # password = "mypassword"\n\n  ## Maximum time to receive response.\n  # response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Measurements & Fields:\n\n- apache\n  - BusyWorkers (float)\n  - BytesPerReq (float)\n  - BytesPerSec (float)\n  - ConnsAsyncClosing (float)\n  - ConnsAsyncKeepAlive (float)\n  - ConnsAsyncWriting (float)\n  - ConnsTotal (float)\n  - CPUChildrenSystem (float)\n  - CPUChildrenUser (float)\n  - CPULoad (float)\n  - CPUSystem (float)\n  - CPUUser (float)\n  - IdleWorkers (float)\n  - Load1 (float)\n  - Load5 (float)\n  - Load15 (float)\n  - ParentServerConfigGeneration (float)\n  - ParentServerMPMGeneration (float)\n  - ReqPerSec (float)\n  - ServerUptimeSeconds (float)\n  - TotalAccesses (float)\n  - TotalkBytes (float)\n  - Uptime (float)\n\nThe following fields are collected from the `Scoreboard`, and represent the number of requests in the given state:\n\n- apache\n  - scboard_closing (float)\n  - scboard_dnslookup (float)\n  - scboard_finishing (float)\n  - scboard_idle_cleanup (float)\n  - scboard_keepalive (float)\n  - scboard_logging (float)\n  - scboard_open (float)\n  - scboard_reading (float)\n  - scboard_sending (float)\n  - scboard_starting (float)\n  - scboard_waiting (float)\n\n### Tags:\n\n- All measurements have the following tags:\n    - port\n    - server\n\n### Example Output:\n\n```\napache,port=80,server=debian-stretch-apache BusyWorkers=1,BytesPerReq=0,BytesPerSec=0,CPUChildrenSystem=0,CPUChildrenUser=0,CPULoad=0.00995025,CPUSystem=0.01,CPUUser=0.01,ConnsAsyncClosing=0,ConnsAsyncKeepAlive=0,ConnsAsyncWriting=0,ConnsTotal=0,IdleWorkers=49,Load1=0.01,Load15=0,Load5=0,ParentServerConfigGeneration=3,ParentServerMPMGeneration=2,ReqPerSec=0.00497512,ServerUptimeSeconds=201,TotalAccesses=1,TotalkBytes=0,Uptime=201,scboard_closing=0,scboard_dnslookup=0,scboard_finishing=0,scboard_idle_cleanup=0,scboard_keepalive=0,scboard_logging=0,scboard_open=100,scboard_reading=0,scboard_sending=1,scboard_starting=0,scboard_waiting=49 1502489900000000000\n```\n',image:p.a},{id:"apcupsd",name:"APCUPSD",markdown:'# APCUPSD Input Plugin\n\nThis plugin reads data from an apcupsd daemon over its NIS network protocol.\n\n### Requirements\n\napcupsd should be installed and it\'s daemon should be running.\n\n### Configuration\n\n```toml\n[[inputs.apcupsd]]\n  # A list of running apcupsd server to connect to.\n  # If not provided will default to tcp://127.0.0.1:3551\n  servers = ["tcp://127.0.0.1:3551"]\n\n  ## Timeout for dialing server.\n  timeout = "5s"\n```\n\n### Metrics\n\n- apcupsd\n  - tags:\n    - serial\n    - status (string representing the set status_flags)\n    - ups_name\n    - model\n  - fields:\n    - status_flags ([status-bits][])\n    - input_voltage\n    - load_percent\n    - battery_charge_percent\n    - time_left_ns\n    - output_voltage\n    - internal_temp\n    - battery_voltage\n    - input_frequency\n    - time_on_battery_ns\n    - battery_date\n    - nominal_input_voltage\n    - nominal_battery_voltage\n    - nominal_power\n    - firmware\n\n\n\n### Example output\n\n```\napcupsd,serial=AS1231515,status=ONLINE,ups_name=name1 time_on_battery=0,load_percent=9.7,time_left_minutes=98,output_voltage=230.4,internal_temp=32.4,battery_voltage=27.4,input_frequency=50.2,input_voltage=230.4,battery_charge_percent=100,status_flags=8i 1490035922000000000\n```\n\n[status-bits]: http://www.apcupsd.org/manual/manual.html#status-bits\n',image:g.a},{id:"aurora",name:"Aurora",markdown:'# Aurora Input Plugin\n\nThe Aurora Input Plugin gathers metrics from [Apache Aurora](https://aurora.apache.org/) schedulers.\n\nFor monitoring recommendations reference [Monitoring your Aurora cluster](https://aurora.apache.org/documentation/latest/operations/monitoring/)\n\n### Configuration:\n\n```toml\n[[inputs.aurora]]\n  ## Schedulers are the base addresses of your Aurora Schedulers\n  schedulers = ["http://127.0.0.1:8081"]\n\n  ## Set of role types to collect metrics from.\n  ##\n  ## The scheduler roles are checked each interval by contacting the\n  ## scheduler nodes; zookeeper is not contacted.\n  # roles = ["leader", "follower"]\n\n  ## Timeout is the max time for total network operations.\n  # timeout = "5s"\n\n  ## Username and password are sent using HTTP Basic Auth.\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics:\n\n- aurora\n  - tags:\n    - scheduler (URL of scheduler)\n    - role (leader or follower)\n  - fields:\n    - Numeric metrics are collected from the `/vars` endpoint; string fields\n      are not gathered.\n\n\n### Troubleshooting:\n\nCheck the Scheduler role, the leader will return a 200 status:\n```\ncurl -v http://127.0.0.1:8081/leaderhealth\n```\n\nGet available metrics:\n```\ncurl http://127.0.0.1:8081/vars\n```\n\n### Example Output:\n\nThe example output below has been trimmed.\n```\n> aurora,role=leader,scheduler=http://debian-stretch-aurora-coordinator-3.virt:8081 CronBatchWorker_batch_locked_events=0i,CronBatchWorker_batch_locked_events_per_sec=0,CronBatchWorker_batch_locked_nanos_per_event=0,CronBatchWorker_batch_locked_nanos_total=0i,CronBatchWorker_batch_locked_nanos_total_per_sec=0,CronBatchWorker_batch_unlocked_events=0i,CronBatchWorker_batch_unlocked_events_per_sec=0,CronBatchWorker_batch_unlocked_nanos_per_event=0,CronBatchWorker_batch_unlocked_nanos_total=0i,CronBatchWorker_batch_unlocked_nanos_total_per_sec=0,CronBatchWorker_batches_processed=0i,CronBatchWorker_items_processed=0i,CronBatchWorker_last_processed_batch_size=0i,CronBatchWorker_queue_size=0i,TaskEventBatchWorker_batch_locked_events=0i,TaskEventBatchWorker_batch_locked_events_per_sec=0,TaskEventBatchWorker_batch_locked_nanos_per_event=0,TaskEventBatchWorker_batch_locked_nanos_total=0i,TaskEventBatchWorker_batch_locked_nanos_total_per_sec=0,TaskEventBatchWorker_batch_unlocked_events=0i,TaskEventBatchWorker_batch_unlocked_events_per_sec=0,TaskEventBatchWorker_batch_unlocked_nanos_per_event=0,TaskEventBatchWorker_batch_unlocked_nanos_total=0i,TaskEventBatchWorker_batch_unlocked_nanos_total_per_sec=0,TaskEventBatchWorker_batches_processed=0i,TaskEventBatchWorker_items_processed=0i,TaskEventBatchWorker_last_processed_batch_size=0i,TaskEventBatchWorker_queue_size=0i,TaskGroupBatchWorker_batch_locked_events=0i,TaskGroupBatchWorker_batch_locked_events_per_sec=0,TaskGroupBatchWorker_batch_locked_nanos_per_event=0,TaskGroupBatchWorker_batch_locked_nanos_total=0i,TaskGroupBatchWorker_batch_locked_nanos_total_per_sec=0,TaskGroupBatchWorker_batch_unlocked_events=0i,TaskGroupBatchWorker_batch_unlocked_events_per_sec=0,TaskGroupBatchWorker_batch_unlocked_nanos_per_event=0,TaskGroupBatchWorker_batch_unlocked_nanos_total=0i,TaskGroupBatchWorker_batch_unlocked_nanos_total_per_sec=0,TaskGroupBatchWorker_batches_processed=0i,TaskGroupBatchWorker_items_processed=0i,TaskGroupBatchWorker_last_processed_batch_size=0i,TaskGroupBatchWorker_queue_size=0i,assigner_launch_failures=0i,async_executor_uncaught_exceptions=0i,async_tasks_completed=1i,cron_job_collisions=0i,cron_job_concurrent_runs=0i,cron_job_launch_failures=0i,cron_job_misfires=0i,cron_job_parse_failures=0i,cron_job_triggers=0i,cron_jobs_loaded=1i,empty_slots_dedicated_large=0i,empty_slots_dedicated_medium=0i,empty_slots_dedicated_revocable_large=0i,empty_slots_dedicated_revocable_medium=0i,empty_slots_dedicated_revocable_small=0i,empty_slots_dedicated_revocable_xlarge=0i,empty_slots_dedicated_small=0i,empty_slots_dedicated_xlarge=0i,empty_slots_large=0i,empty_slots_medium=0i,empty_slots_revocable_large=0i,empty_slots_revocable_medium=0i,empty_slots_revocable_small=0i,empty_slots_revocable_xlarge=0i,empty_slots_small=0i,empty_slots_xlarge=0i,event_bus_dead_events=0i,event_bus_exceptions=1i,framework_registered=1i,globally_banned_offers_size=0i,http_200_responses_events=55i,http_200_responses_events_per_sec=0,http_200_responses_nanos_per_event=0,http_200_responses_nanos_total=310416694i,http_200_responses_nanos_total_per_sec=0,job_update_delete_errors=0i,job_update_recovery_errors=0i,job_update_state_change_errors=0i,job_update_store_delete_all_events=1i,job_update_store_delete_all_events_per_sec=0,job_update_store_delete_all_nanos_per_event=0,job_update_store_delete_all_nanos_total=1227254i,job_update_store_delete_all_nanos_total_per_sec=0,job_update_store_fetch_details_query_events=74i,job_update_store_fetch_details_query_events_per_sec=0,job_update_store_fetch_details_query_nanos_per_event=0,job_update_store_fetch_details_query_nanos_total=24643149i,job_update_store_fetch_details_query_nanos_total_per_sec=0,job_update_store_prune_history_events=59i,job_update_store_prune_history_events_per_sec=0,job_update_store_prune_history_nanos_per_event=0,job_update_store_prune_history_nanos_total=262868218i,job_update_store_prune_history_nanos_total_per_sec=0,job_updates_pruned=0i,jvm_available_processors=2i,jvm_class_loaded_count=6707i,jvm_class_total_loaded_count=6732i,jvm_class_unloaded_count=25i,jvm_gc_PS_MarkSweep_collection_count=2i,jvm_gc_PS_MarkSweep_collection_time_ms=223i,jvm_gc_PS_Scavenge_collection_count=27i,jvm_gc_PS_Scavenge_collection_time_ms=1691i,jvm_gc_collection_count=29i,jvm_gc_collection_time_ms=1914i,jvm_memory_free_mb=65i,jvm_memory_heap_mb_committed=157i,jvm_memory_heap_mb_max=446i,jvm_memory_heap_mb_used=91i,jvm_memory_max_mb=446i,jvm_memory_mb_total=157i,jvm_memory_non_heap_mb_committed=50i,jvm_memory_non_heap_mb_max=0i,jvm_memory_non_heap_mb_used=49i,jvm_threads_active=47i,jvm_threads_daemon=28i,jvm_threads_peak=48i,jvm_threads_started=62i,jvm_time_ms=1526530686927i,jvm_uptime_secs=79947i,log_entry_serialize_events=16i,log_entry_serialize_events_per_sec=0,log_entry_serialize_nanos_per_event=0,log_entry_serialize_nanos_total=4815321i,log_entry_serialize_nanos_total_per_sec=0,log_manager_append_events=16i,log_manager_append_events_per_sec=0,log_manager_append_nanos_per_event=0,log_manager_append_nanos_total=506453428i,log_manager_append_nanos_total_per_sec=0,log_manager_deflate_events=14i,log_manager_deflate_events_per_sec=0,log_manager_deflate_nanos_per_event=0,log_manager_deflate_nanos_total=21010565i,log_manager_deflate_nanos_total_per_sec=0 1526530687000000000\n```\n',image:b.a},{id:"azure_storage_queue",name:"Azure Storage Queue",markdown:'# Azure Storage Queue Input Plugin\n\nThis plugin gathers sizes of Azure Storage Queues.\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.azure_storage_queue]]\n  ## Required Azure Storage Account name\n  account_name = "mystorageaccount"\n\n  ## Required Azure Storage Account access key\n  account_key = "storageaccountaccesskey"\n  \n  ## Set to false to disable peeking age of oldest message (executes faster)\n  # peek_oldest_message_age = true\n```\n\n### Metrics\n- azure_storage_queues\n  - tags:\n    - queue\n    - account\n  - fields:\n    - size (integer, count)\n    - oldest_message_age_ns (integer, nanoseconds) Age of message at the head of the queue.\n      Requires `peek_oldest_message_age` to be configured to `true`.\n      \n### Example Output\n\n```\nazure_storage_queues,queue=myqueue,account=mystorageaccount oldest_message_age=799714900i,size=7i 1565970503000000000\nazure_storage_queues,queue=myemptyqueue,account=mystorageaccount size=0i 1565970502000000000\n```',image:v.a},{id:"bcache",name:"bcache",markdown:'# bcache Input Plugin\n\nGet bcache stat from stats_total directory and dirty_data file.\n\n# Measurements\n\nMeta:\n\n- tags: `backing_dev=dev bcache_dev=dev`\n\nMeasurement names:\n\n- dirty_data\n- bypassed\n- cache_bypass_hits\n- cache_bypass_misses\n- cache_hit_ratio\n- cache_hits\n- cache_miss_collisions\n- cache_misses\n- cache_readaheads\n\n### Description\n\n```\ndirty_data\n  Amount of dirty data for this backing device in the cache. Continuously\n  updated unlike the cache set\'s version, but may be slightly off.\n\nbypassed\n  Amount of IO (both reads and writes) that has bypassed the cache\n\n\ncache_bypass_hits\ncache_bypass_misses\n  Hits and misses for IO that is intended to skip the cache are still counted,\n  but broken out here.\n\ncache_hits\ncache_misses\ncache_hit_ratio\n  Hits and misses are counted per individual IO as bcache sees them; a\n  partial hit is counted as a miss.\n\ncache_miss_collisions\n  Counts instances where data was going to be inserted into the cache from a\n  cache miss, but raced with a write and data was already present (usually 0\n  since the synchronization for cache misses was rewritten)\n\ncache_readaheads\n  Count of times readahead occurred.\n```\n\n# Example output\n\nUsing this configuration:\n\n```toml\n[[inputs.bcache]]\n  ## Bcache sets path\n  ## If not specified, then default is:\n  bcachePath = "/sys/fs/bcache"\n\n  ## By default, Telegraf gather stats for all bcache devices\n  ## Setting devices will restrict the stats to the specified\n  ## bcache devices.\n  bcacheDevs = ["bcache0"]\n```\n\nWhen run with:\n\n```\n./telegraf --config telegraf.conf --input-filter bcache --test\n```\n\nIt produces:\n\n```\n* Plugin: bcache, Collection 1\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_dirty_data value=11639194\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_bypassed value=5167704440832\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_bypass_hits value=146270986\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_bypass_misses value=0\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_hit_ratio value=90\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_hits value=511941651\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_miss_collisions value=157678\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_misses value=50647396\n> [backing_dev="md10" bcache_dev="bcache0"] bcache_cache_readaheads value=0\n```\n',image:k.a},{id:"beanstalkd",name:"Beanstalkd",markdown:'# Beanstalkd Input Plugin\n\nThe `beanstalkd` plugin collects server stats as well as tube stats (reported by `stats` and `stats-tube` commands respectively).\n\n### Configuration:\n\n```toml\n[[inputs.beanstalkd]]\n  ## Server to collect data from\n  server = "localhost:11300"\n\n  ## List of tubes to gather stats about.\n  ## If no tubes specified then data gathered for each tube on server reported by list-tubes command\n  tubes = ["notifications"]\n```\n\n### Metrics:\n\nPlease see the [Beanstalk Protocol doc](https://raw.githubusercontent.com/kr/beanstalkd/master/doc/protocol.txt) for detailed explanation of `stats` and `stats-tube` commands output.\n\n`beanstalkd_overview` – statistical information about the system as a whole\n- fields\n  - cmd_delete\n  - cmd_pause_tube\n  - current_jobs_buried\n  - current_jobs_delayed\n  - current_jobs_ready\n  - current_jobs_reserved\n  - current_jobs_urgent\n  - current_using\n  - current_waiting\n  - current_watching\n  - pause\n  - pause_time_left\n  - total_jobs\n- tags\n  - name\n  - server (address taken from config)\n\n`beanstalkd_tube` – statistical information about the specified tube\n- fields\n  - binlog_current_index\n  - binlog_max_size\n  - binlog_oldest_index\n  - binlog_records_migrated\n  - binlog_records_written\n  - cmd_bury\n  - cmd_delete\n  - cmd_ignore\n  - cmd_kick\n  - cmd_list_tube_used\n  - cmd_list_tubes\n  - cmd_list_tubes_watched\n  - cmd_pause_tube\n  - cmd_peek\n  - cmd_peek_buried\n  - cmd_peek_delayed\n  - cmd_peek_ready\n  - cmd_put\n  - cmd_release\n  - cmd_reserve\n  - cmd_reserve_with_timeout\n  - cmd_stats\n  - cmd_stats_job\n  - cmd_stats_tube\n  - cmd_touch\n  - cmd_use\n  - cmd_watch\n  - current_connections\n  - current_jobs_buried\n  - current_jobs_delayed\n  - current_jobs_ready\n  - current_jobs_reserved\n  - current_jobs_urgent\n  - current_producers\n  - current_tubes\n  - current_waiting\n  - current_workers\n  - job_timeouts\n  - max_job_size\n  - pid\n  - rusage_stime\n  - rusage_utime\n  - total_connections\n  - total_jobs\n  - uptime\n- tags\n  - hostname\n  - id\n  - server (address taken from config)\n  - version\n\n### Example Output:\n```\nbeanstalkd_overview,host=server.local,hostname=a2ab22ed12e0,id=232485800aa11b24,server=localhost:11300,version=1.10 cmd_stats_tube=29482i,current_jobs_delayed=0i,current_jobs_urgent=6i,cmd_kick=0i,cmd_stats=7378i,cmd_stats_job=0i,current_waiting=0i,max_job_size=65535i,pid=6i,cmd_bury=0i,cmd_reserve_with_timeout=0i,cmd_touch=0i,current_connections=1i,current_jobs_ready=6i,current_producers=0i,cmd_delete=0i,cmd_list_tubes=7369i,cmd_peek_ready=0i,cmd_put=6i,cmd_use=3i,cmd_watch=0i,current_jobs_reserved=0i,rusage_stime=6.07,cmd_list_tubes_watched=0i,cmd_pause_tube=0i,total_jobs=6i,binlog_records_migrated=0i,cmd_list_tube_used=0i,cmd_peek_delayed=0i,cmd_release=0i,current_jobs_buried=0i,job_timeouts=0i,binlog_current_index=0i,binlog_max_size=10485760i,total_connections=7378i,cmd_peek_buried=0i,cmd_reserve=0i,current_tubes=4i,binlog_records_written=0i,cmd_peek=0i,rusage_utime=1.13,uptime=7099i,binlog_oldest_index=0i,current_workers=0i,cmd_ignore=0i 1528801650000000000\n\nbeanstalkd_tube,host=server.local,name=notifications,server=localhost:11300 pause_time_left=0i,current_jobs_buried=0i,current_jobs_delayed=0i,current_jobs_reserved=0i,current_using=0i,current_waiting=0i,pause=0i,total_jobs=3i,cmd_delete=0i,cmd_pause_tube=0i,current_jobs_ready=3i,current_jobs_urgent=3i,current_watching=0i 1528801650000000000\n```\n',image:T.a},{id:"beat",name:"Beat",markdown:'# Beat Input Plugin\nThe Beat plugin will collect metrics from the given Beat instances. It is\nknown to work with Filebeat and Kafkabeat.\n### Configuration:\n```toml\n  ## An URL from which to read Beat-formatted JSON\n  ## Default is "http://127.0.0.1:5066".\n  url = "http://127.0.0.1:5066"\n\n  ## Enable collection of the listed stats\n  ## An empty list means collect all. Available options are currently\n  ## "beat", "libbeat", "system" and "filebeat".\n  # include = ["beat", "libbeat", "filebeat"]\n\n  ## HTTP method\n  # method = "GET"\n\n  ## Optional HTTP headers\n  # headers = {"X-Special-Header" = "Special-Value"}\n\n  ## Override HTTP "Host" header\n  # host_header = "logstash.example.com"\n\n  ## Timeout for HTTP requests\n  # timeout = "5s"\n\n  ## Optional HTTP Basic Auth credentials\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n### Measurements & Fields\n- **beat**\n  * Fields:\n    - cpu_system_ticks\n    - cpu_system_time_ms\n    - cpu_total_ticks\n    - cpu_total_time_ms\n    - cpu_total_value\n    - cpu_user_ticks\n    - cpu_user_time_ms\n    - info_uptime_ms\n    - memstats_gc_next\n    - memstats_memory_alloc\n    - memstats_memory_total\n    - memstats_rss\n  * Tags:\n    - beat_beat\n    - beat_host\n    - beat_id\n    - beat_name\n    - beat_version\n\n- **beat_filebeat**\n  * Fields:\n    - events_active\n    - events_added\n    - events_done\n    - harvester_closed\n    - harvester_open_files\n    - harvester_running\n    - harvester_skipped\n    - harvester_started\n    - input_log_files_renamed\n    - input_log_files_truncated\n  * Tags:\n    - beat_beat\n    - beat_host\n    - beat_id\n    - beat_name\n    - beat_version\n\n- **beat_libbeat**\n  * Fields:\n    - config_module_running\n    - config_module_starts\n    - config_module_stops\n    - config_reloads\n    - output_events_acked\n    - output_events_active\n    - output_events_batches\n    - output_events_dropped\n    - output_events_duplicates\n    - output_events_failed\n    - output_events_total\n    - output_type\n    - output_read_bytes\n    - output_read_errors\n    - output_write_bytes\n    - output_write_errors\n    - outputs_kafka_bytes_read\n    - outputs_kafka_bytes_write\n    - pipeline_clients\n    - pipeline_events_active\n    - pipeline_events_dropped\n    - pipeline_events_failed\n    - pipeline_events_filtered\n    - pipeline_events_published\n    - pipeline_events_retry\n    - pipeline_events_total\n    - pipeline_queue_acked\n  * Tags:\n    - beat_beat\n    - beat_host\n    - beat_id\n    - beat_name\n    - beat_version\n\n- **beat_system**\n  * Field:\n    - cpu_cores\n    - load_1\n    - load_15\n    - load_5\n    - load_norm_1\n    - load_norm_15\n    - load_norm_5\n  * Tags:\n    - beat_beat\n    - beat_host\n    - beat_id\n    - beat_name\n    - beat_version\n\n### Example Output:\n```\n$ telegraf --input-filter beat --test\n\n> beat,beat_beat=filebeat,beat_host=node-6,beat_id=9c1c8697-acb4-4df0-987d-28197814f788,beat_name=node-6-test,beat_version=6.4.2,host=node-6\n  cpu_system_ticks=656750,cpu_system_time_ms=656750,cpu_total_ticks=5461190,cpu_total_time_ms=5461198,cpu_total_value=5461190,cpu_user_ticks=4804440,cpu_user_time_ms=4804448,info_uptime_ms=342634196,memstats_gc_next=20199584,memstats_memory_alloc=12547424,memstats_memory_total=486296424792,memstats_rss=72552448 1540316047000000000\n> beat_libbeat,beat_beat=filebeat,beat_host=node-6,beat_id=9c1c8697-acb4-4df0-987d-28197814f788,beat_name=node-6-test,beat_version=6.4.2,host=node-6\n  config_module_running=0,config_module_starts=0,config_module_stops=0,config_reloads=0,output_events_acked=192404,output_events_active=0,output_events_batches=1607,output_events_dropped=0,output_events_duplicates=0,output_events_failed=0,output_events_total=192404,output_read_bytes=0,output_read_errors=0,output_write_bytes=0,output_write_errors=0,outputs_kafka_bytes_read=1118528,outputs_kafka_bytes_write=48002014,pipeline_clients=1,pipeline_events_active=0,pipeline_events_dropped=0,pipeline_events_failed=0,pipeline_events_filtered=11496,pipeline_events_published=192404,pipeline_events_retry=14,pipeline_events_total=203900,pipeline_queue_acked=192404 1540316047000000000\n> beat_system,beat_beat=filebeat,beat_host=node-6,beat_id=9c1c8697-acb4-4df0-987d-28197814f788,beat_name=node-6-test,beat_version=6.4.2,host=node-6\n  cpu_cores=32,load_1=46.08,load_15=49.82,load_5=47.88,load_norm_1=1.44,load_norm_15=1.5569,load_norm_5=1.4963 1540316047000000000\n> beat_filebeat,beat_beat=filebeat,beat_host=node-6,beat_id=9c1c8697-acb4-4df0-987d-28197814f788,beat_name=node-6-test,beat_version=6.4.2,host=node-6\n  events_active=0,events_added=3223,events_done=3223,harvester_closed=0,harvester_open_files=0,harvester_running=0,harvester_skipped=0,harvester_started=0,input_log_files_renamed=0,input_log_files_truncated=0 1540320286000000000\n```\n',image:q.a},{id:"bind",name:"BIND 9 Nameserver Statistics",markdown:'# BIND 9 Nameserver Statistics Input Plugin\n\nThis plugin decodes the JSON or XML statistics provided by BIND 9 nameservers.\n\n### XML Statistics Channel\n\nVersion 2 statistics (BIND 9.6 - 9.9) and version 3 statistics (BIND 9.9+) are supported. Note that\nfor BIND 9.9 to support version 3 statistics, it must be built with the `--enable-newstats` compile\nflag, and it must be specifically requested via the correct URL. Version 3 statistics are the\ndefault (and only) XML format in BIND 9.10+.\n\n### JSON Statistics Channel\n\nJSON statistics schema version 1 (BIND 9.10+) is supported. As of writing, some distros still do\nnot enable support for JSON statistics in their BIND packages.\n\n### Configuration:\n\n- **urls** []string: List of BIND statistics channel URLs to collect from. Do not include a\n  trailing slash in the URL. Default is "http://localhost:8053/xml/v3".\n- **gather_memory_contexts** bool: Report per-context memory statistics.\n- **gather_views** bool: Report per-view query statistics.\n- **timeout** Timeout for http requests made by bind nameserver (example: "4s").\n\nThe following table summarizes the URL formats which should be used, depending on your BIND\nversion and configured statistics channel.\n\n| BIND Version | Statistics Format | Example URL                   |\n| ------------ | ----------------- | ----------------------------- |\n| 9.6 - 9.8    | XML v2            | http://localhost:8053         |\n| 9.9          | XML v2            | http://localhost:8053/xml/v2  |\n| 9.9+         | XML v3            | http://localhost:8053/xml/v3  |\n| 9.10+        | JSON v1           | http://localhost:8053/json/v1 |\n\n#### Configuration of BIND Daemon\n\nAdd the following to your named.conf if running Telegraf on the same host as the BIND daemon:\n```\nstatistics-channels {\n    inet 127.0.0.1 port 8053;\n};\n```\n\nAlternatively, specify a wildcard address (e.g., 0.0.0.0) or specific IP address of an interface to\nconfigure the BIND daemon to listen on that address. Note that you should secure the statistics\nchannel with an ACL if it is publicly reachable. Consult the BIND Administrator Reference Manual\nfor more information.\n\n### Measurements & Fields:\n\n- bind_counter\n  - name=value (multiple)\n- bind_memory\n  - total_use\n  - in_use\n  - block_size\n  - context_size\n  - lost\n- bind_memory_context\n  - total\n  - in_use\n\n### Tags:\n\n- All measurements\n  - url\n  - source\n  - port\n- bind_counter\n  - type\n  - view (optional)\n- bind_memory_context\n  - id\n  - name\n\n### Sample Queries:\n\nThese are some useful queries (to generate dashboards or other) to run against data from this\nplugin:\n\n```sql\nSELECT non_negative_derivative(mean(/^A$|^PTR$/), 5m) FROM bind_counter \\\nWHERE "url" = \'localhost:8053\' AND "type" = \'qtype\' AND time > now() - 1h \\\nGROUP BY time(5m), "type"\n```\n\n```\nname: bind_counter\ntags: type=qtype\ntime                non_negative_derivative_A non_negative_derivative_PTR\n----                ------------------------- ---------------------------\n1553862000000000000 254.99444444430992        1388.311111111194\n1553862300000000000 354                       2135.716666666791\n1553862600000000000 316.8666666666977         2130.133333333768\n1553862900000000000 309.05000000004657        2126.75\n1553863200000000000 315.64999999990687        2128.483333332464\n1553863500000000000 308.9166666667443         2132.350000000559\n1553863800000000000 302.64999999990687        2131.1833333335817\n1553864100000000000 310.85000000009313        2132.449999999255\n1553864400000000000 314.3666666666977         2136.216666666791\n1553864700000000000 303.2333333331626         2133.8166666673496\n1553865000000000000 304.93333333334886        2127.333333333023\n1553865300000000000 317.93333333334886        2130.3166666664183\n1553865600000000000 280.6666666667443         1807.9071428570896\n```\n\n### Example Output\n\nHere is example output of this plugin:\n\n```\nbind_memory,host=LAP,port=8053,source=localhost,url=localhost:8053 block_size=12058624i,context_size=4575056i,in_use=4113717i,lost=0i,total_use=16663252i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=opcode,url=localhost:8053 IQUERY=0i,NOTIFY=0i,QUERY=9i,STATUS=0i,UPDATE=0i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=rcode,url=localhost:8053 17=0i,18=0i,19=0i,20=0i,21=0i,22=0i,BADCOOKIE=0i,BADVERS=0i,FORMERR=0i,NOERROR=7i,NOTAUTH=0i,NOTIMP=0i,NOTZONE=0i,NXDOMAIN=0i,NXRRSET=0i,REFUSED=0i,RESERVED11=0i,RESERVED12=0i,RESERVED13=0i,RESERVED14=0i,RESERVED15=0i,SERVFAIL=2i,YXDOMAIN=0i,YXRRSET=0i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=qtype,url=localhost:8053 A=1i,ANY=1i,NS=1i,PTR=5i,SOA=1i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=nsstat,url=localhost:8053 AuthQryRej=0i,CookieBadSize=0i,CookieBadTime=0i,CookieIn=9i,CookieMatch=0i,CookieNew=9i,CookieNoMatch=0i,DNS64=0i,ECSOpt=0i,ExpireOpt=0i,KeyTagOpt=0i,NSIDOpt=0i,OtherOpt=0i,QryAuthAns=7i,QryBADCOOKIE=0i,QryDropped=0i,QryDuplicate=0i,QryFORMERR=0i,QryFailure=0i,QryNXDOMAIN=0i,QryNXRedir=0i,QryNXRedirRLookup=0i,QryNoauthAns=0i,QryNxrrset=1i,QryRecursion=2i,QryReferral=0i,QrySERVFAIL=2i,QrySuccess=6i,QryTCP=1i,QryUDP=8i,RPZRewrites=0i,RateDropped=0i,RateSlipped=0i,RecQryRej=0i,RecursClients=0i,ReqBadEDNSVer=0i,ReqBadSIG=0i,ReqEdns0=9i,ReqSIG0=0i,ReqTCP=1i,ReqTSIG=0i,Requestv4=9i,Requestv6=0i,RespEDNS0=9i,RespSIG0=0i,RespTSIG=0i,Response=9i,TruncatedResp=0i,UpdateBadPrereq=0i,UpdateDone=0i,UpdateFail=0i,UpdateFwdFail=0i,UpdateRej=0i,UpdateReqFwd=0i,UpdateRespFwd=0i,XfrRej=0i,XfrReqDone=0i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=zonestat,url=localhost:8053 AXFRReqv4=0i,AXFRReqv6=0i,IXFRReqv4=0i,IXFRReqv6=0i,NotifyInv4=0i,NotifyInv6=0i,NotifyOutv4=0i,NotifyOutv6=0i,NotifyRej=0i,SOAOutv4=0i,SOAOutv6=0i,XfrFail=0i,XfrSuccess=0i 1554276619000000000\nbind_counter,host=LAP,port=8053,source=localhost,type=sockstat,url=localhost:8053 FDWatchClose=0i,FDwatchConn=0i,FDwatchConnFail=0i,FDwatchRecvErr=0i,FDwatchSendErr=0i,FdwatchBindFail=0i,RawActive=1i,RawClose=0i,RawOpen=1i,RawOpenFail=0i,RawRecvErr=0i,TCP4Accept=6i,TCP4AcceptFail=0i,TCP4Active=9i,TCP4BindFail=0i,TCP4Close=5i,TCP4Conn=0i,TCP4ConnFail=0i,TCP4Open=8i,TCP4OpenFail=0i,TCP4RecvErr=0i,TCP4SendErr=0i,TCP6Accept=0i,TCP6AcceptFail=0i,TCP6Active=2i,TCP6BindFail=0i,TCP6Close=0i,TCP6Conn=0i,TCP6ConnFail=0i,TCP6Open=2i,TCP6OpenFail=0i,TCP6RecvErr=0i,TCP6SendErr=0i,UDP4Active=18i,UDP4BindFail=14i,UDP4Close=14i,UDP4Conn=0i,UDP4ConnFail=0i,UDP4Open=32i,UDP4OpenFail=0i,UDP4RecvErr=0i,UDP4SendErr=0i,UDP6Active=3i,UDP6BindFail=0i,UDP6Close=6i,UDP6Conn=0i,UDP6ConnFail=6i,UDP6Open=9i,UDP6OpenFail=0i,UDP6RecvErr=0i,UDP6SendErr=0i,UnixAccept=0i,UnixAcceptFail=0i,UnixActive=0i,UnixBindFail=0i,UnixClose=0i,UnixConn=0i,UnixConnFail=0i,UnixOpen=0i,UnixOpenFail=0i,UnixRecvErr=0i,UnixSendErr=0i 1554276619000000000\n```\n',image:I.a},{id:"bond",name:"Bond",markdown:'# Bond Input Plugin\n\nThe Bond input plugin collects network bond interface status for both the\nnetwork bond interface as well as slave interfaces.\nThe plugin collects these metrics from `/proc/net/bonding/*` files.\n\n### Configuration:\n\n```toml\n[[inputs.bond]]\n  ## Sets \'proc\' directory path\n  ## If not specified, then default is /proc\n  # host_proc = "/proc"\n\n  ## By default, telegraf gather stats for all bond interfaces\n  ## Setting interfaces will restrict the stats to the specified\n  ## bond interfaces.\n  # bond_interfaces = ["bond0"]\n```\n\n### Measurements & Fields:\n\n- bond\n  - active_slave (for active-backup mode)\n  - status\n\n- bond_slave\n  - failures\n  - status\n\n### Description:\n\n```\nactive_slave\n  Currently active slave interface for active-backup mode.\n\nstatus\n  Status of bond interface or bonds\'s slave interface (down = 0, up = 1).\n\nfailures\n  Amount of failures for bond\'s slave interface.\n```\n\n### Tags:\n\n- bond\n  - bond\n\n- bond_slave\n  - bond\n  - interface\n\n### Example output:\n\nConfiguration:\n\n```\n[[inputs.bond]]\n  ## Sets \'proc\' directory path\n  ## If not specified, then default is /proc\n  host_proc = "/proc"\n\n  ## By default, telegraf gather stats for all bond interfaces\n  ## Setting interfaces will restrict the stats to the specified\n  ## bond interfaces.\n  bond_interfaces = ["bond0", "bond1"]\n```\n\nRun:\n\n```\ntelegraf --config telegraf.conf --input-filter bond --test\n```\n\nOutput:\n\n```\n* Plugin: inputs.bond, Collection 1\n> bond,bond=bond1,host=local active_slave="eth0",status=1i 1509704525000000000\n> bond_slave,bond=bond1,interface=eth0,host=local status=1i,failures=0i 1509704525000000000\n> bond_slave,host=local,bond=bond1,interface=eth1 status=1i,failures=0i 1509704525000000000\n> bond,bond=bond0,host=isvetlov-mac.local status=1i 1509704525000000000\n> bond_slave,bond=bond0,interface=eth1,host=local status=1i,failures=0i 1509704525000000000\n> bond_slave,bond=bond0,interface=eth2,host=local status=1i,failures=0i 1509704525000000000\n```\n',image:A.a},{id:"burrow",name:"Burrow Kafka Consumer Lag Checking",markdown:'# Burrow Kafka Consumer Lag Checking Input Plugin\n\nCollect Kafka topic, consumer and partition status\nvia [Burrow](https://github.com/linkedin/Burrow) HTTP [API](https://github.com/linkedin/Burrow/wiki/HTTP-Endpoint).\n\nSupported Burrow version: `1.x`\n\n### Configuration\n\n```toml\n[[inputs.burrow]]\n  ## Burrow API endpoints in format "schema://host:port".\n  ## Default is "http://localhost:8000".\n  servers = ["http://localhost:8000"]\n\n  ## Override Burrow API prefix.\n  ## Useful when Burrow is behind reverse-proxy.\n  # api_prefix = "/v3/kafka"\n\n  ## Maximum time to receive response.\n  # response_timeout = "5s"\n\n  ## Limit per-server concurrent connections.\n  ## Useful in case of large number of topics or consumer groups.\n  # concurrent_connections = 20\n\n  ## Filter clusters, default is no filtering.\n  ## Values can be specified as glob patterns.\n  # clusters_include = []\n  # clusters_exclude = []\n\n  ## Filter consumer groups, default is no filtering.\n  ## Values can be specified as glob patterns.\n  # groups_include = []\n  # groups_exclude = []\n\n  ## Filter topics, default is no filtering.\n  ## Values can be specified as glob patterns.\n  # topics_include = []\n  # topics_exclude = []\n\n  ## Credentials for basic HTTP authentication.\n  # username = ""\n  # password = ""\n\n  ## Optional SSL config\n  # ssl_ca = "/etc/telegraf/ca.pem"\n  # ssl_cert = "/etc/telegraf/cert.pem"\n  # ssl_key = "/etc/telegraf/key.pem"\n  # insecure_skip_verify = false\n```\n\n### Group/Partition Status mappings\n\n* `OK` = 1\n* `NOT_FOUND` = 2\n* `WARN` = 3\n* `ERR` = 4\n* `STOP` = 5\n* `STALL` = 6\n\n> unknown value will be mapped to 0\n\n### Fields\n\n* `burrow_group` (one event per each consumer group)\n  - status (string, see Partition Status mappings)\n  - status_code (int, `1..6`, see Partition status mappings)\n  - partition_count (int, `number of partitions`)\n  - offset (int64, `total offset of all partitions`)\n  - total_lag (int64, `totallag`)\n  - lag (int64, `maxlag.current_lag || 0`)\n  - timestamp (int64, `end.timestamp`)\n\n* `burrow_partition` (one event per each topic partition)\n  - status (string, see Partition Status mappings)\n  - status_code (int, `1..6`, see Partition status mappings)\n  - lag (int64, `current_lag || 0`)\n  - offset (int64, `end.timestamp`)\n  - timestamp (int64, `end.timestamp`)\n\n* `burrow_topic` (one event per topic offset)\n  - offset (int64)\n\n\n### Tags\n\n* `burrow_group`\n  - cluster (string)\n  - group (string)\n\n* `burrow_partition`\n  - cluster (string)\n  - group (string)\n  - topic (string)\n  - partition (int)\n  - owner (string)\n\n* `burrow_topic`\n  - cluster (string)\n  - topic (string)\n  - partition (int)\n',image:D.a},{id:"cassandra",name:"Cassandra",markdown:'# Cassandra Input Plugin\n\n### **Deprecated in version 1.7**: Please use the [jolokia2](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2) plugin with the [cassandra.conf](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/cassandra.conf) example configuration.\n\n#### Plugin arguments:\n- **context** string: Context root used for jolokia url\n- **servers** []string: List of servers with the format "<user:passwd@><host>:port"\n- **metrics** []string: List of Jmx paths that identify mbeans attributes\n\n#### Description\n\nThe Cassandra plugin collects Cassandra 3 / JVM metrics exposed as MBean\'s attributes through jolokia REST endpoint. All metrics are collected for each server configured.\n\nSee: https://jolokia.org/ and [Cassandra Documentation](http://docs.datastax.com/en/cassandra/3.x/cassandra/operations/monitoringCassandraTOC.html)\n\n# Measurements:\nCassandra plugin produces one or more measurements for each metric configured, adding Server\'s name  as `host` tag. More than one measurement is generated when querying table metrics with a wildcard for the keyspace or table name.\n\nGiven a configuration like:\n\n```toml\n# Read Cassandra metrics through Jolokia\n[[inputs.cassandra]]\n  ## DEPRECATED: The cassandra plugin has been deprecated.  Please use the\n  ## jolokia2 plugin instead.\n  ##\n  ## see https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\n\n  context = "/jolokia/read"\n  ## List of cassandra servers exposing jolokia read service\n  servers = ["myuser:mypassword@10.10.10.1:8778","10.10.10.2:8778",":8778"]\n  ## List of metrics collected on above servers\n  ## Each metric consists of a jmx path.\n  ## This will collect all heap memory usage metrics from the jvm and\n  ## ReadLatency metrics for all keyspaces and tables.\n  ## "type=Table" in the query works with Cassandra3.0. Older versions might\n  ## need to use "type=ColumnFamily"\n  metrics  = [\n    "/java.lang:type=Memory/HeapMemoryUsage",\n    "/org.apache.cassandra.metrics:type=Table,keyspace=*,scope=*,name=ReadLatency"\n  ]\n```\n\nThe collected metrics will be:\n\n```\njavaMemory,host=myHost,mname=HeapMemoryUsage HeapMemoryUsage_committed=1040187392,HeapMemoryUsage_init=1050673152,HeapMemoryUsage_max=1040187392,HeapMemoryUsage_used=368155000 1459551767230567084\n```\n\n# Useful Metrics:\n\nHere is a list of metrics that might be useful to monitor your cassandra cluster. This was put together from multiple sources on the web.\n\n- [How to monitor Cassandra performance metrics](https://www.datadoghq.com/blog/how-to-monitor-cassandra-performance-metrics)\n- [Cassandra Documentation](http://docs.datastax.com/en/cassandra/3.x/cassandra/operations/monitoringCassandraTOC.html)\n\n#### measurement = javaGarbageCollector\n\n- /java.lang:type=GarbageCollector,name=ConcurrentMarkSweep/CollectionTime\n- /java.lang:type=GarbageCollector,name=ConcurrentMarkSweep/CollectionCount\n- /java.lang:type=GarbageCollector,name=ParNew/CollectionTime\n- /java.lang:type=GarbageCollector,name=ParNew/CollectionCount\n\n#### measurement = javaMemory\n\n- /java.lang:type=Memory/HeapMemoryUsage\n- /java.lang:type=Memory/NonHeapMemoryUsage\n\n#### measurement = cassandraCache\n\n- /org.apache.cassandra.metrics:type=Cache,scope=KeyCache,name=Hits\n- /org.apache.cassandra.metrics:type=Cache,scope=KeyCache,name=Requests\n- /org.apache.cassandra.metrics:type=Cache,scope=KeyCache,name=Entries\n- /org.apache.cassandra.metrics:type=Cache,scope=KeyCache,name=Size\n- /org.apache.cassandra.metrics:type=Cache,scope=KeyCache,name=Capacity\n- /org.apache.cassandra.metrics:type=Cache,scope=RowCache,name=Hits\n- /org.apache.cassandra.metrics:type=Cache,scope=RowCache,name=Requests\n- /org.apache.cassandra.metrics:type=Cache,scope=RowCache,name=Entries\n- /org.apache.cassandra.metrics:type=Cache,scope=RowCache,name=Size\n- /org.apache.cassandra.metrics:type=Cache,scope=RowCache,name=Capacity\n\n#### measurement = cassandraClient\n\n- /org.apache.cassandra.metrics:type=Client,name=connectedNativeClients\n\n#### measurement = cassandraClientRequest\n\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=TotalLatency\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=TotalLatency\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=Latency\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Latency\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=Timeouts\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Timeouts\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=Unavailables\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Unavailables\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Read,name=Failures\n- /org.apache.cassandra.metrics:type=ClientRequest,scope=Write,name=Failures\n\n#### measurement = cassandraCommitLog\n\n- /org.apache.cassandra.metrics:type=CommitLog,name=PendingTasks\n- /org.apache.cassandra.metrics:type=CommitLog,name=TotalCommitLogSize\n\n#### measurement = cassandraCompaction\n\n- /org.apache.cassandra.metrics:type=Compaction,name=CompletedTasks\n- /org.apache.cassandra.metrics:type=Compaction,name=PendingTasks\n- /org.apache.cassandra.metrics:type=Compaction,name=TotalCompactionsCompleted\n- /org.apache.cassandra.metrics:type=Compaction,name=BytesCompacted\n\n#### measurement = cassandraStorage\n\n- /org.apache.cassandra.metrics:type=Storage,name=Load\n- /org.apache.cassandra.metrics:type=Storage,name=Exceptions\n\n#### measurement = cassandraTable\nUsing wildcards for "keyspace" and "scope" can create a lot of series as metrics will be reported for every table and keyspace including internal system tables. Specify a keyspace name and/or a table name to limit them.\n\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=LiveDiskSpaceUsed\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=TotalDiskSpaceUsed\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=ReadLatency\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=CoordinatorReadLatency\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=WriteLatency\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=ReadTotalLatency\n- /org.apache.cassandra.metrics:type=Table,keyspace=\\*,scope=\\*,name=WriteTotalLatency\n\n\n#### measurement = cassandraThreadPools\n\n- /org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=CompactionExecutor,name=ActiveTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=internal,scope=AntiEntropyStage,name=ActiveTasks\n-  /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=CounterMutationStage,name=PendingTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=CounterMutationStage,name=CurrentlyBlockedTasks        \n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=MutationStage,name=PendingTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=MutationStage,name=CurrentlyBlockedTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=ReadRepairStage,name=PendingTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=ReadRepairStage,name=CurrentlyBlockedTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=ReadStage,name=PendingTasks\n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=ReadStage,name=CurrentlyBlockedTasks\n-  /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=RequestResponseStage,name=PendingTasks        \n- /org.apache.cassandra.metrics:type=ThreadPools,path=request,scope=RequestResponseStage,name=CurrentlyBlockedTasks\n\n\n',image:O.a},{id:"ceph",name:"Ceph Storage",markdown:'# Ceph Storage Input Plugin\n\nCollects performance metrics from the MON and OSD nodes in a Ceph storage cluster.\n\nCeph has introduced a Telegraf and Influx plugin in the 13.x Mimic release. The Telegraf module sends to a Telegraf configured with a socket_listener. [Learn more in their docs](http://docs.ceph.com/docs/mimic/mgr/telegraf/)\n\n*Admin Socket Stats*\n\nThis gatherer works by scanning the configured SocketDir for OSD, MON, MDS and RGW socket files.  When it finds\na MON socket, it runs **ceph --admin-daemon $file perfcounters_dump**. For OSDs it runs **ceph --admin-daemon $file perf dump**\n\nThe resulting JSON is parsed and grouped into collections, based on top-level key.  Top-level keys are\nused as collection tags, and all sub-keys are flattened. For example:\n\n```json\n {\n   "paxos": {\n     "refresh": 9363435,\n     "refresh_latency": {\n       "avgcount": 9363435,\n       "sum": 5378.794002000\n     }\n   }\n }\n```\n\nWould be parsed into the following metrics, all of which would be tagged with collection=paxos:\n\n - refresh = 9363435\n - refresh_latency.avgcount: 9363435\n - refresh_latency.sum: 5378.794002000\n\n\n*Cluster Stats*\n\nThis gatherer works by invoking ceph commands against the cluster thus only requires the ceph client, valid\nceph configuration and an access key to function (the ceph_config and ceph_user configuration variables work\nin conjunction to specify these prerequisites). It may be run on any server you wish which has access to\nthe cluster.  The currently supported commands are:\n\n* ceph status\n* ceph df\n* ceph osd pool stats\n\n### Configuration:\n\n```toml\n# Collects performance metrics from the MON, OSD, MDS and RGW nodes in a Ceph storage cluster.\n[[inputs.ceph]]\n  ## This is the recommended interval to poll.  Too frequent and you will lose\n  ## data points due to timeouts during rebalancing and recovery\n  interval = \'1m\'\n\n  ## All configuration values are optional, defaults are shown below\n\n  ## location of ceph binary\n  ceph_binary = "/usr/bin/ceph"\n\n  ## directory in which to look for socket files\n  socket_dir = "/var/run/ceph"\n\n  ## prefix of MON and OSD socket files, used to determine socket type\n  mon_prefix = "ceph-mon"\n  osd_prefix = "ceph-osd"\n  mds_prefix = "ceph-mds"\n  rgw_prefix = "ceph-client"\n\n  ## suffix used to identify socket files\n  socket_suffix = "asok"\n\n  ## Ceph user to authenticate as, ceph will search for the corresponding keyring\n  ## e.g. client.admin.keyring in /etc/ceph, or the explicit path defined in the\n  ## client section of ceph.conf for example:\n  ##\n  ##     [client.telegraf]\n  ##         keyring = /etc/ceph/client.telegraf.keyring\n  ##\n  ## Consult the ceph documentation for more detail on keyring generation.\n  ceph_user = "client.admin"\n\n  ## Ceph configuration to use to locate the cluster\n  ceph_config = "/etc/ceph/ceph.conf"\n\n  ## Whether to gather statistics via the admin socket\n  gather_admin_socket_stats = true\n\n  ## Whether to gather statistics via ceph commands, requires ceph_user and ceph_config\n  ## to be specified\n  gather_cluster_stats = false\n```\n\n### Metrics:\n\n*Admin Socket Stats*\n\nAll fields are collected under the **ceph** measurement and stored as float64s. For a full list of fields, see the sample perf dumps in ceph_test.go.\n\nAll admin measurements will have the following tags:\n\n- type: either \'osd\', \'mon\', \'mds\' or \'rgw\' to indicate which type of node was queried\n- id: a unique string identifier, parsed from the socket file name for the node\n- collection: the top-level key under which these fields were reported. Possible values are:\n  - for MON nodes:\n    - cluster\n    - leveldb\n    - mon\n    - paxos\n    - throttle-mon_client_bytes\n    - throttle-mon_daemon_bytes\n    - throttle-msgr_dispatch_throttler-mon\n  - for OSD nodes:\n    - WBThrottle\n    - filestore\n    - leveldb\n    - mutex-FileJournal::completions_lock\n    - mutex-FileJournal::finisher_lock\n    - mutex-FileJournal::write_lock\n    - mutex-FileJournal::writeq_lock\n    - mutex-JOS::ApplyManager::apply_lock\n    - mutex-JOS::ApplyManager::com_lock\n    - mutex-JOS::SubmitManager::lock\n    - mutex-WBThrottle::lock\n    - objecter\n    - osd\n    - recoverystate_perf\n    - throttle-filestore_bytes\n    - throttle-filestore_ops\n    - throttle-msgr_dispatch_throttler-client\n    - throttle-msgr_dispatch_throttler-cluster\n    - throttle-msgr_dispatch_throttler-hb_back_server\n    - throttle-msgr_dispatch_throttler-hb_front_serve\n    - throttle-msgr_dispatch_throttler-hbclient\n    - throttle-msgr_dispatch_throttler-ms_objecter\n    - throttle-objecter_bytes\n    - throttle-objecter_ops\n    - throttle-osd_client_bytes\n    - throttle-osd_client_messages\n  - for MDS nodes:\n    - AsyncMessenger::Worker-0\n    - AsyncMessenger::Worker-1\n    - AsyncMessenger::Worker-2\n    - finisher-PurgeQueue\n    - mds\n    - mds_cache\n    - mds_log\n    - mds_mem\n    - mds_server\n    - mds_sessions\n    - objecter\n    - purge_queue\n    - throttle-msgr_dispatch_throttler-mds\n    - throttle-objecter_bytes\n    - throttle-objecter_ops\n    - throttle-write_buf_throttle\n  - for RGW nodes:\n    - AsyncMessenger::Worker-0\n    - AsyncMessenger::Worker-1\n    - AsyncMessenger::Worker-2\n    - cct\n    - finisher-radosclient\n    - mempool\n    - objecter\n    - rgw\n    - simple-throttler\n    - throttle-msgr_dispatch_throttler-radosclient\n    - throttle-objecter_bytes\n    - throttle-objecter_ops\n    - throttle-rgw_async_rados_ops\n\n*Cluster Stats*\n\n+ ceph_health\n  - fields:\n    - status\n    - overall_status\n\n- ceph_osdmap\n  - fields:\n    - epoch (float)\n    - num_osds (float)\n    - num_up_osds (float)\n    - num_in_osds (float)\n    - full (bool)\n    - nearfull (bool)\n    - num_remapped_pgs (float)\n\n+ ceph_pgmap\n  - fields:\n    - version (float)\n    - num_pgs (float)\n    - data_bytes (float)\n    - bytes_used (float)\n    - bytes_avail (float)\n    - bytes_total (float)\n    - read_bytes_sec (float)\n    - write_bytes_sec (float)\n    - op_per_sec (float, exists only in ceph <10)\n    - read_op_per_sec (float)\n    - write_op_per_sec (float)\n\n- ceph_pgmap_state\n  - tags:\n    - state\n  - fields:\n    - count (float)\n\n+ ceph_usage\n  - fields:\n    - total_bytes (float)\n    - total_used_bytes (float)\n    - total_avail_bytes (float)\n    - total_space (float, exists only in ceph <0.84)\n    - total_used (float, exists only in ceph <0.84)\n    - total_avail (float, exists only in ceph <0.84)\n\n- ceph_pool_usage\n  - tags:\n    - name\n  - fields:\n    - kb_used (float)\n    - bytes_used (float)\n    - objects (float)\n    - percent_used (float)\n    - max_avail (float)\n\n+ ceph_pool_stats\n  - tags:\n    - name\n  - fields:\n    - read_bytes_sec (float)\n    - write_bytes_sec (float)\n    - op_per_sec (float, exists only in ceph <10)\n    - read_op_per_sec (float)\n    - write_op_per_sec (float)\n    - recovering_objects_per_sec (float)\n    - recovering_bytes_per_sec (float)\n    - recovering_keys_per_sec (float)\n\n\n### Example Output:\n\n*Cluster Stats*\n\n```\nceph_health,host=stefanmon1 overall_status="",status="HEALTH_WARN" 1587118504000000000\nceph_osdmap,host=stefanmon1 epoch=203,full=false,nearfull=false,num_in_osds=8,num_osds=9,num_remapped_pgs=0,num_up_osds=8 1587118504000000000\nceph_pgmap,host=stefanmon1 bytes_avail=849879302144,bytes_total=858959904768,bytes_used=9080602624,data_bytes=5055,num_pgs=504,read_bytes_sec=0,read_op_per_sec=0,version=0,write_bytes_sec=0,write_op_per_sec=0 1587118504000000000\nceph_pgmap_state,host=stefanmon1,state=active+clean count=504 1587118504000000000\nceph_usage,host=stefanmon1 total_avail_bytes=849879302144,total_bytes=858959904768,total_used_bytes=196018176 1587118505000000000\nceph_pool_usage,host=stefanmon1,name=cephfs_data bytes_used=0,kb_used=0,max_avail=285804986368,objects=0,percent_used=0 1587118505000000000\nceph_pool_stats,host=stefanmon1,name=cephfs_data read_bytes_sec=0,read_op_per_sec=0,recovering_bytes_per_sec=0,recovering_keys_per_sec=0,recovering_objects_per_sec=0,write_bytes_sec=0,write_op_per_sec=0 1587118506000000000\n```\n\n*Admin Socket Stats*\n\n```\n> ceph,collection=cct,host=stefanmon1,id=stefanmon1,type=monitor total_workers=0,unhealthy_workers=0 1587117563000000000\n> ceph,collection=mempool,host=stefanmon1,id=stefanmon1,type=monitor bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=0,bluefs_items=0,bluestore_alloc_bytes=0,bluestore_alloc_items=0,bluestore_cache_data_bytes=0,bluestore_cache_data_items=0,bluestore_cache_onode_bytes=0,bluestore_cache_onode_items=0,bluestore_cache_other_bytes=0,bluestore_cache_other_items=0,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=0,bluestore_txc_items=0,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=0,bluestore_writing_deferred_items=0,bluestore_writing_items=0,buffer_anon_bytes=719152,buffer_anon_items=192,buffer_meta_bytes=352,buffer_meta_items=4,mds_co_bytes=0,mds_co_items=0,osd_bytes=0,osd_items=0,osd_mapbl_bytes=0,osd_mapbl_items=0,osd_pglog_bytes=0,osd_pglog_items=0,osdmap_bytes=15872,osdmap_items=138,osdmap_mapping_bytes=63112,osdmap_mapping_items=7626,pgmap_bytes=38680,pgmap_items=477,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117563000000000\n> ceph,collection=throttle-mon_client_bytes,host=stefanmon1,id=stefanmon1,type=monitor get=1041157,get_or_fail_fail=0,get_or_fail_success=1041157,get_started=0,get_sum=64928901,max=104857600,put=1041157,put_sum=64928901,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117563000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-mon,host=stefanmon1,id=stefanmon1,type=monitor get=12695426,get_or_fail_fail=0,get_or_fail_success=12695426,get_started=0,get_sum=42542216884,max=104857600,put=12695426,put_sum=42542216884,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117563000000000\n> ceph,collection=finisher-mon_finisher,host=stefanmon1,id=stefanmon1,type=monitor complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117563000000000\n> ceph,collection=finisher-monstore,host=stefanmon1,id=stefanmon1,type=monitor complete_latency.avgcount=1609831,complete_latency.avgtime=0.015857621,complete_latency.sum=25528.09131035,queue_len=0 1587117563000000000\n> ceph,collection=mon,host=stefanmon1,id=stefanmon1,type=monitor election_call=25,election_lose=0,election_win=22,num_elections=94,num_sessions=3,session_add=174679,session_rm=439316,session_trim=137 1587117563000000000\n> ceph,collection=throttle-mon_daemon_bytes,host=stefanmon1,id=stefanmon1,type=monitor get=72697,get_or_fail_fail=0,get_or_fail_success=72697,get_started=0,get_sum=32261199,max=419430400,put=72697,put_sum=32261199,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117563000000000\n> ceph,collection=rocksdb,host=stefanmon1,id=stefanmon1,type=monitor compact=1,compact_queue_len=0,compact_queue_merge=1,compact_range=19126,get=62449211,get_latency.avgcount=62449211,get_latency.avgtime=0.000022216,get_latency.sum=1387.371811726,rocksdb_write_delay_time.avgcount=0,rocksdb_write_delay_time.avgtime=0,rocksdb_write_delay_time.sum=0,rocksdb_write_memtable_time.avgcount=0,rocksdb_write_memtable_time.avgtime=0,rocksdb_write_memtable_time.sum=0,rocksdb_write_pre_and_post_time.avgcount=0,rocksdb_write_pre_and_post_time.avgtime=0,rocksdb_write_pre_and_post_time.sum=0,rocksdb_write_wal_time.avgcount=0,rocksdb_write_wal_time.avgtime=0,rocksdb_write_wal_time.sum=0,submit_latency.avgcount=0,submit_latency.avgtime=0,submit_latency.sum=0,submit_sync_latency.avgcount=3219961,submit_sync_latency.avgtime=0.007532173,submit_sync_latency.sum=24253.303584224,submit_transaction=0,submit_transaction_sync=3219961 1587117563000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanmon1,id=stefanmon1,type=monitor msgr_active_connections=148317,msgr_created_connections=162806,msgr_recv_bytes=11557888328,msgr_recv_messages=5113369,msgr_running_fast_dispatch_time=0,msgr_running_recv_time=868.377161686,msgr_running_send_time=1626.525392721,msgr_running_total_time=4222.235694322,msgr_send_bytes=91516226816,msgr_send_messages=6973706 1587117563000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanmon1,id=stefanmon1,type=monitor msgr_active_connections=146396,msgr_created_connections=159788,msgr_recv_bytes=2162802496,msgr_recv_messages=689168,msgr_running_fast_dispatch_time=0,msgr_running_recv_time=164.148550562,msgr_running_send_time=153.462890368,msgr_running_total_time=644.188791379,msgr_send_bytes=7422484152,msgr_send_messages=749381 1587117563000000000\n> ceph,collection=cluster,host=stefanmon1,id=stefanmon1,type=monitor num_bytes=5055,num_mon=3,num_mon_quorum=3,num_object=245,num_object_degraded=0,num_object_misplaced=0,num_object_unfound=0,num_osd=9,num_osd_in=8,num_osd_up=8,num_pg=504,num_pg_active=504,num_pg_active_clean=504,num_pg_peering=0,num_pool=17,osd_bytes=858959904768,osd_bytes_avail=849889787904,osd_bytes_used=9070116864,osd_epoch=203 1587117563000000000\n> ceph,collection=paxos,host=stefanmon1,id=stefanmon1,type=monitor accept_timeout=1,begin=1609847,begin_bytes.avgcount=1609847,begin_bytes.sum=41408662074,begin_keys.avgcount=1609847,begin_keys.sum=4829541,begin_latency.avgcount=1609847,begin_latency.avgtime=0.007213392,begin_latency.sum=11612.457661116,collect=0,collect_bytes.avgcount=0,collect_bytes.sum=0,collect_keys.avgcount=0,collect_keys.sum=0,collect_latency.avgcount=0,collect_latency.avgtime=0,collect_latency.sum=0,collect_timeout=1,collect_uncommitted=17,commit=1609831,commit_bytes.avgcount=1609831,commit_bytes.sum=41087428442,commit_keys.avgcount=1609831,commit_keys.sum=11637931,commit_latency.avgcount=1609831,commit_latency.avgtime=0.006236333,commit_latency.sum=10039.442388355,lease_ack_timeout=0,lease_timeout=0,new_pn=33,new_pn_latency.avgcount=33,new_pn_latency.avgtime=3.844272773,new_pn_latency.sum=126.86100151,refresh=1609856,refresh_latency.avgcount=1609856,refresh_latency.avgtime=0.005900486,refresh_latency.sum=9498.932866761,restart=109,share_state=2,share_state_bytes.avgcount=2,share_state_bytes.sum=39612,share_state_keys.avgcount=2,share_state_keys.sum=2,start_leader=22,start_peon=0,store_state=14,store_state_bytes.avgcount=14,store_state_bytes.sum=51908281,store_state_keys.avgcount=14,store_state_keys.sum=7016,store_state_latency.avgcount=14,store_state_latency.avgtime=11.668377665,store_state_latency.sum=163.357287311 1587117563000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-mon-mgrc,host=stefanmon1,id=stefanmon1,type=monitor get=13225,get_or_fail_fail=0,get_or_fail_success=13225,get_started=0,get_sum=158700,max=104857600,put=13225,put_sum=158700,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117563000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanmon1,id=stefanmon1,type=monitor msgr_active_connections=147680,msgr_created_connections=162374,msgr_recv_bytes=29781706740,msgr_recv_messages=7170733,msgr_running_fast_dispatch_time=0,msgr_running_recv_time=1728.559151358,msgr_running_send_time=2086.681244508,msgr_running_total_time=6084.532916585,msgr_send_bytes=94062125718,msgr_send_messages=9161564 1587117563000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-cluster,host=stefanosd1,id=0,type=osd get=281745,get_or_fail_fail=0,get_or_fail_success=281745,get_started=0,get_sum=446024457,max=104857600,put=281745,put_sum=446024457,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_bytes,host=stefanosd1,id=0,type=osd get=275707,get_or_fail_fail=0,get_or_fail_success=0,get_started=275707,get_sum=185073179842,max=67108864,put=268870,put_sum=185073179842,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_server,host=stefanosd1,id=0,type=osd get=2606982,get_or_fail_fail=0,get_or_fail_success=2606982,get_started=0,get_sum=5224391928,max=104857600,put=2606982,put_sum=5224391928,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=rocksdb,host=stefanosd1,id=0,type=osd compact=0,compact_queue_len=0,compact_queue_merge=0,compact_range=0,get=1570,get_latency.avgcount=1570,get_latency.avgtime=0.000051233,get_latency.sum=0.080436788,rocksdb_write_delay_time.avgcount=0,rocksdb_write_delay_time.avgtime=0,rocksdb_write_delay_time.sum=0,rocksdb_write_memtable_time.avgcount=0,rocksdb_write_memtable_time.avgtime=0,rocksdb_write_memtable_time.sum=0,rocksdb_write_pre_and_post_time.avgcount=0,rocksdb_write_pre_and_post_time.avgtime=0,rocksdb_write_pre_and_post_time.sum=0,rocksdb_write_wal_time.avgcount=0,rocksdb_write_wal_time.avgtime=0,rocksdb_write_wal_time.sum=0,submit_latency.avgcount=275707,submit_latency.avgtime=0.000174936,submit_latency.sum=48.231345334,submit_sync_latency.avgcount=268870,submit_sync_latency.avgtime=0.006097313,submit_sync_latency.sum=1639.384555624,submit_transaction=275707,submit_transaction_sync=268870 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_server,host=stefanosd1,id=0,type=osd get=2606982,get_or_fail_fail=0,get_or_fail_success=2606982,get_started=0,get_sum=5224391928,max=104857600,put=2606982,put_sum=5224391928,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-objecter_bytes,host=stefanosd1,id=0,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_client,host=stefanosd1,id=0,type=osd get=2610285,get_or_fail_fail=0,get_or_fail_success=2610285,get_started=0,get_sum=5231011140,max=104857600,put=2610285,put_sum=5231011140,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanosd1,id=0,type=osd msgr_active_connections=2093,msgr_created_connections=29142,msgr_recv_bytes=7214238199,msgr_recv_messages=3928206,msgr_running_fast_dispatch_time=171.289615064,msgr_running_recv_time=278.531155966,msgr_running_send_time=489.482588813,msgr_running_total_time=1134.004853662,msgr_send_bytes=9814725232,msgr_send_messages=3814927 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-client,host=stefanosd1,id=0,type=osd get=488206,get_or_fail_fail=0,get_or_fail_success=488206,get_started=0,get_sum=104085134,max=104857600,put=488206,put_sum=104085134,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=finisher-defered_finisher,host=stefanosd1,id=0,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=recoverystate_perf,host=stefanosd1,id=0,type=osd activating_latency.avgcount=87,activating_latency.avgtime=0.114348341,activating_latency.sum=9.948305683,active_latency.avgcount=25,active_latency.avgtime=1790.961574431,active_latency.sum=44774.039360795,backfilling_latency.avgcount=0,backfilling_latency.avgtime=0,backfilling_latency.sum=0,clean_latency.avgcount=25,clean_latency.avgtime=1790.830827794,clean_latency.sum=44770.770694867,down_latency.avgcount=0,down_latency.avgtime=0,down_latency.sum=0,getinfo_latency.avgcount=141,getinfo_latency.avgtime=0.446233476,getinfo_latency.sum=62.918920183,getlog_latency.avgcount=87,getlog_latency.avgtime=0.007708069,getlog_latency.sum=0.670602073,getmissing_latency.avgcount=87,getmissing_latency.avgtime=0.000077594,getmissing_latency.sum=0.006750701,incomplete_latency.avgcount=0,incomplete_latency.avgtime=0,incomplete_latency.sum=0,initial_latency.avgcount=166,initial_latency.avgtime=0.001313715,initial_latency.sum=0.218076764,notbackfilling_latency.avgcount=0,notbackfilling_latency.avgtime=0,notbackfilling_latency.sum=0,notrecovering_latency.avgcount=0,notrecovering_latency.avgtime=0,notrecovering_latency.sum=0,peering_latency.avgcount=141,peering_latency.avgtime=0.948324273,peering_latency.sum=133.713722563,primary_latency.avgcount=79,primary_latency.avgtime=567.706192991,primary_latency.sum=44848.78924634,recovered_latency.avgcount=87,recovered_latency.avgtime=0.000378284,recovered_latency.sum=0.032910791,recovering_latency.avgcount=2,recovering_latency.avgtime=0.338242008,recovering_latency.sum=0.676484017,replicaactive_latency.avgcount=23,replicaactive_latency.avgtime=1790.893991295,replicaactive_latency.sum=41190.561799786,repnotrecovering_latency.avgcount=25,repnotrecovering_latency.avgtime=1647.627024984,repnotrecovering_latency.sum=41190.675624616,reprecovering_latency.avgcount=2,reprecovering_latency.avgtime=0.311884638,reprecovering_latency.sum=0.623769276,repwaitbackfillreserved_latency.avgcount=0,repwaitbackfillreserved_latency.avgtime=0,repwaitbackfillreserved_latency.sum=0,repwaitrecoveryreserved_latency.avgcount=2,repwaitrecoveryreserved_latency.avgtime=0.000462873,repwaitrecoveryreserved_latency.sum=0.000925746,reset_latency.avgcount=372,reset_latency.avgtime=0.125056393,reset_latency.sum=46.520978537,start_latency.avgcount=372,start_latency.avgtime=0.000109397,start_latency.sum=0.040695881,started_latency.avgcount=206,started_latency.avgtime=418.299777245,started_latency.sum=86169.754112641,stray_latency.avgcount=231,stray_latency.avgtime=0.98203205,stray_latency.sum=226.849403565,waitactingchange_latency.avgcount=0,waitactingchange_latency.avgtime=0,waitactingchange_latency.sum=0,waitlocalbackfillreserved_latency.avgcount=0,waitlocalbackfillreserved_latency.avgtime=0,waitlocalbackfillreserved_latency.sum=0,waitlocalrecoveryreserved_latency.avgcount=2,waitlocalrecoveryreserved_latency.avgtime=0.002802377,waitlocalrecoveryreserved_latency.sum=0.005604755,waitremotebackfillreserved_latency.avgcount=0,waitremotebackfillreserved_latency.avgtime=0,waitremotebackfillreserved_latency.sum=0,waitremoterecoveryreserved_latency.avgcount=2,waitremoterecoveryreserved_latency.avgtime=0.012855439,waitremoterecoveryreserved_latency.sum=0.025710878,waitupthru_latency.avgcount=87,waitupthru_latency.avgtime=0.805727895,waitupthru_latency.sum=70.09832695 1587117698000000000\n> ceph,collection=cct,host=stefanosd1,id=0,type=osd total_workers=6,unhealthy_workers=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_client,host=stefanosd1,id=0,type=osd get=2610285,get_or_fail_fail=0,get_or_fail_success=2610285,get_started=0,get_sum=5231011140,max=104857600,put=2610285,put_sum=5231011140,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=bluefs,host=stefanosd1,id=0,type=osd bytes_written_slow=0,bytes_written_sst=9018781,bytes_written_wal=831081573,db_total_bytes=4294967296,db_used_bytes=434110464,files_written_sst=3,files_written_wal=2,gift_bytes=0,log_bytes=134291456,log_compactions=1,logged_bytes=1101668352,max_bytes_db=1234173952,max_bytes_slow=0,max_bytes_wal=0,num_files=11,reclaim_bytes=0,slow_total_bytes=0,slow_used_bytes=0,wal_total_bytes=0,wal_used_bytes=0 1587117698000000000\n> ceph,collection=mempool,host=stefanosd1,id=0,type=osd bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=10600,bluefs_items=458,bluestore_alloc_bytes=230288,bluestore_alloc_items=28786,bluestore_cache_data_bytes=622592,bluestore_cache_data_items=43,bluestore_cache_onode_bytes=249280,bluestore_cache_onode_items=380,bluestore_cache_other_bytes=192678,bluestore_cache_other_items=20199,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=8272,bluestore_txc_items=11,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=670130,bluestore_writing_deferred_items=176,bluestore_writing_items=0,buffer_anon_bytes=2412465,buffer_anon_items=297,buffer_meta_bytes=5896,buffer_meta_items=67,mds_co_bytes=0,mds_co_items=0,osd_bytes=2124800,osd_items=166,osd_mapbl_bytes=155152,osd_mapbl_items=10,osd_pglog_bytes=3214704,osd_pglog_items=6288,osdmap_bytes=710892,osdmap_items=4426,osdmap_mapping_bytes=0,osdmap_mapping_items=0,pgmap_bytes=0,pgmap_items=0,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117698000000000\n> ceph,collection=osd,host=stefanosd1,id=0,type=osd agent_evict=0,agent_flush=0,agent_skip=0,agent_wake=0,cached_crc=0,cached_crc_adjusted=0,copyfrom=0,heartbeat_to_peers=7,loadavg=11,map_message_epoch_dups=21,map_message_epochs=40,map_messages=31,messages_delayed_for_map=0,missed_crc=0,numpg=166,numpg_primary=62,numpg_removing=0,numpg_replica=104,numpg_stray=0,object_ctx_cache_hit=476529,object_ctx_cache_total=476536,op=476525,op_before_dequeue_op_lat.avgcount=755708,op_before_dequeue_op_lat.avgtime=0.000205759,op_before_dequeue_op_lat.sum=155.493843473,op_before_queue_op_lat.avgcount=755702,op_before_queue_op_lat.avgtime=0.000047877,op_before_queue_op_lat.sum=36.181069552,op_cache_hit=0,op_in_bytes=0,op_latency.avgcount=476525,op_latency.avgtime=0.000365956,op_latency.sum=174.387387878,op_out_bytes=10882,op_prepare_latency.avgcount=476527,op_prepare_latency.avgtime=0.000205307,op_prepare_latency.sum=97.834380034,op_process_latency.avgcount=476525,op_process_latency.avgtime=0.000139616,op_process_latency.sum=66.530847665,op_r=476521,op_r_latency.avgcount=476521,op_r_latency.avgtime=0.00036559,op_r_latency.sum=174.21148267,op_r_out_bytes=10882,op_r_prepare_latency.avgcount=476523,op_r_prepare_latency.avgtime=0.000205302,op_r_prepare_latency.sum=97.831473175,op_r_process_latency.avgcount=476521,op_r_process_latency.avgtime=0.000139396,op_r_process_latency.sum=66.425498624,op_rw=2,op_rw_in_bytes=0,op_rw_latency.avgcount=2,op_rw_latency.avgtime=0.048818975,op_rw_latency.sum=0.097637951,op_rw_out_bytes=0,op_rw_prepare_latency.avgcount=2,op_rw_prepare_latency.avgtime=0.000467887,op_rw_prepare_latency.sum=0.000935775,op_rw_process_latency.avgcount=2,op_rw_process_latency.avgtime=0.013741256,op_rw_process_latency.sum=0.027482512,op_w=2,op_w_in_bytes=0,op_w_latency.avgcount=2,op_w_latency.avgtime=0.039133628,op_w_latency.sum=0.078267257,op_w_prepare_latency.avgcount=2,op_w_prepare_latency.avgtime=0.000985542,op_w_prepare_latency.sum=0.001971084,op_w_process_latency.avgcount=2,op_w_process_latency.avgtime=0.038933264,op_w_process_latency.sum=0.077866529,op_wip=0,osd_map_bl_cache_hit=22,osd_map_bl_cache_miss=40,osd_map_cache_hit=4570,osd_map_cache_miss=15,osd_map_cache_miss_low=0,osd_map_cache_miss_low_avg.avgcount=0,osd_map_cache_miss_low_avg.sum=0,osd_pg_biginfo=2050,osd_pg_fastinfo=265780,osd_pg_info=274542,osd_tier_flush_lat.avgcount=0,osd_tier_flush_lat.avgtime=0,osd_tier_flush_lat.sum=0,osd_tier_promote_lat.avgcount=0,osd_tier_promote_lat.avgtime=0,osd_tier_promote_lat.sum=0,osd_tier_r_lat.avgcount=0,osd_tier_r_lat.avgtime=0,osd_tier_r_lat.sum=0,pull=0,push=2,push_out_bytes=10,recovery_bytes=10,recovery_ops=2,stat_bytes=107369988096,stat_bytes_avail=106271539200,stat_bytes_used=1098448896,subop=253554,subop_in_bytes=168644225,subop_latency.avgcount=253554,subop_latency.avgtime=0.0073036,subop_latency.sum=1851.857230388,subop_pull=0,subop_pull_latency.avgcount=0,subop_pull_latency.avgtime=0,subop_pull_latency.sum=0,subop_push=0,subop_push_in_bytes=0,subop_push_latency.avgcount=0,subop_push_latency.avgtime=0,subop_push_latency.sum=0,subop_w=253554,subop_w_in_bytes=168644225,subop_w_latency.avgcount=253554,subop_w_latency.avgtime=0.0073036,subop_w_latency.sum=1851.857230388,tier_clean=0,tier_delay=0,tier_dirty=0,tier_evict=0,tier_flush=0,tier_flush_fail=0,tier_promote=0,tier_proxy_read=0,tier_proxy_write=0,tier_try_flush=0,tier_try_flush_fail=0,tier_whiteout=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-ms_objecter,host=stefanosd1,id=0,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanosd1,id=0,type=osd msgr_active_connections=2055,msgr_created_connections=27411,msgr_recv_bytes=6431950009,msgr_recv_messages=3552443,msgr_running_fast_dispatch_time=162.271664213,msgr_running_recv_time=254.307853033,msgr_running_send_time=503.037285799,msgr_running_total_time=1130.21070681,msgr_send_bytes=10865436237,msgr_send_messages=3523374 1587117698000000000\n> ceph,collection=bluestore,host=stefanosd1,id=0,type=osd bluestore_allocated=24641536,bluestore_blob_split=0,bluestore_blobs=88,bluestore_buffer_bytes=622592,bluestore_buffer_hit_bytes=160578,bluestore_buffer_miss_bytes=540236,bluestore_buffers=43,bluestore_compressed=0,bluestore_compressed_allocated=0,bluestore_compressed_original=0,bluestore_extent_compress=0,bluestore_extents=88,bluestore_fragmentation_micros=1,bluestore_gc_merged=0,bluestore_onode_hits=532102,bluestore_onode_misses=388,bluestore_onode_reshard=0,bluestore_onode_shard_hits=0,bluestore_onode_shard_misses=0,bluestore_onodes=380,bluestore_read_eio=0,bluestore_reads_with_retries=0,bluestore_stored=1987856,bluestore_txc=275707,bluestore_write_big=0,bluestore_write_big_blobs=0,bluestore_write_big_bytes=0,bluestore_write_small=60,bluestore_write_small_bytes=343843,bluestore_write_small_deferred=22,bluestore_write_small_new=38,bluestore_write_small_pre_read=22,bluestore_write_small_unused=0,commit_lat.avgcount=275707,commit_lat.avgtime=0.00699778,commit_lat.sum=1929.337103334,compress_lat.avgcount=0,compress_lat.avgtime=0,compress_lat.sum=0,compress_rejected_count=0,compress_success_count=0,csum_lat.avgcount=67,csum_lat.avgtime=0.000032601,csum_lat.sum=0.002184323,decompress_lat.avgcount=0,decompress_lat.avgtime=0,decompress_lat.sum=0,deferred_write_bytes=0,deferred_write_ops=0,kv_commit_lat.avgcount=268870,kv_commit_lat.avgtime=0.006365428,kv_commit_lat.sum=1711.472749866,kv_final_lat.avgcount=268867,kv_final_lat.avgtime=0.000043227,kv_final_lat.sum=11.622427109,kv_flush_lat.avgcount=268870,kv_flush_lat.avgtime=0.000000223,kv_flush_lat.sum=0.060141588,kv_sync_lat.avgcount=268870,kv_sync_lat.avgtime=0.006365652,kv_sync_lat.sum=1711.532891454,omap_lower_bound_lat.avgcount=2,omap_lower_bound_lat.avgtime=0.000006524,omap_lower_bound_lat.sum=0.000013048,omap_next_lat.avgcount=6704,omap_next_lat.avgtime=0.000004721,omap_next_lat.sum=0.031654097,omap_seek_to_first_lat.avgcount=323,omap_seek_to_first_lat.avgtime=0.00000522,omap_seek_to_first_lat.sum=0.00168614,omap_upper_bound_lat.avgcount=4,omap_upper_bound_lat.avgtime=0.000013086,omap_upper_bound_lat.sum=0.000052344,read_lat.avgcount=227,read_lat.avgtime=0.000699457,read_lat.sum=0.158776879,read_onode_meta_lat.avgcount=311,read_onode_meta_lat.avgtime=0.000072207,read_onode_meta_lat.sum=0.022456667,read_wait_aio_lat.avgcount=84,read_wait_aio_lat.avgtime=0.001556141,read_wait_aio_lat.sum=0.130715885,state_aio_wait_lat.avgcount=275707,state_aio_wait_lat.avgtime=0.000000345,state_aio_wait_lat.sum=0.095246457,state_deferred_aio_wait_lat.avgcount=0,state_deferred_aio_wait_lat.avgtime=0,state_deferred_aio_wait_lat.sum=0,state_deferred_cleanup_lat.avgcount=0,state_deferred_cleanup_lat.avgtime=0,state_deferred_cleanup_lat.sum=0,state_deferred_queued_lat.avgcount=0,state_deferred_queued_lat.avgtime=0,state_deferred_queued_lat.sum=0,state_done_lat.avgcount=275696,state_done_lat.avgtime=0.00000286,state_done_lat.sum=0.788700007,state_finishing_lat.avgcount=275696,state_finishing_lat.avgtime=0.000000302,state_finishing_lat.sum=0.083437168,state_io_done_lat.avgcount=275707,state_io_done_lat.avgtime=0.000001041,state_io_done_lat.sum=0.287025147,state_kv_commiting_lat.avgcount=275707,state_kv_commiting_lat.avgtime=0.006424459,state_kv_commiting_lat.sum=1771.268407864,state_kv_done_lat.avgcount=275707,state_kv_done_lat.avgtime=0.000001627,state_kv_done_lat.sum=0.448805853,state_kv_queued_lat.avgcount=275707,state_kv_queued_lat.avgtime=0.000488565,state_kv_queued_lat.sum=134.7009424,state_prepare_lat.avgcount=275707,state_prepare_lat.avgtime=0.000082464,state_prepare_lat.sum=22.736065534,submit_lat.avgcount=275707,submit_lat.avgtime=0.000120236,submit_lat.sum=33.149934412,throttle_lat.avgcount=275707,throttle_lat.avgtime=0.000001571,throttle_lat.sum=0.433185935,write_pad_bytes=151773,write_penalty_read_ops=0 1587117698000000000\n> ceph,collection=finisher-objecter-finisher-0,host=stefanosd1,id=0,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=objecter,host=stefanosd1,id=0,type=osd command_active=0,command_resend=0,command_send=0,linger_active=0,linger_ping=0,linger_resend=0,linger_send=0,map_epoch=203,map_full=0,map_inc=19,omap_del=0,omap_rd=0,omap_wr=0,op=0,op_active=0,op_laggy=0,op_pg=0,op_r=0,op_reply=0,op_resend=0,op_rmw=0,op_send=0,op_send_bytes=0,op_w=0,osd_laggy=0,osd_session_close=0,osd_session_open=0,osd_sessions=0,osdop_append=0,osdop_call=0,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=0,osdop_delete=0,osdop_getxattr=0,osdop_mapext=0,osdop_notify=0,osdop_other=0,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=0,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=0,osdop_truncate=0,osdop_watch=0,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=0,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117698000000000\n> ceph,collection=finisher-commit_finisher,host=stefanosd1,id=0,type=osd complete_latency.avgcount=11,complete_latency.avgtime=0.003447516,complete_latency.sum=0.037922681,queue_len=0 1587117698000000000\n> ceph,collection=throttle-objecter_ops,host=stefanosd1,id=0,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=1024,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanosd1,id=0,type=osd msgr_active_connections=2128,msgr_created_connections=33685,msgr_recv_bytes=8679123051,msgr_recv_messages=4200356,msgr_running_fast_dispatch_time=151.889337454,msgr_running_recv_time=297.632294886,msgr_running_send_time=599.20020523,msgr_running_total_time=1321.361931202,msgr_send_bytes=11716202897,msgr_send_messages=4347418 1587117698000000000\n> ceph,collection=throttle-osd_client_bytes,host=stefanosd1,id=0,type=osd get=476554,get_or_fail_fail=0,get_or_fail_success=476554,get_started=0,get_sum=103413728,max=524288000,put=476587,put_sum=103413728,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_deferred_bytes,host=stefanosd1,id=0,type=osd get=11,get_or_fail_fail=0,get_or_fail_success=11,get_started=0,get_sum=7723117,max=201326592,put=0,put_sum=0,take=0,take_sum=0,val=7723117,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-cluster,host=stefanosd1,id=1,type=osd get=860895,get_or_fail_fail=0,get_or_fail_success=860895,get_started=0,get_sum=596482256,max=104857600,put=860895,put_sum=596482256,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-objecter_ops,host=stefanosd1,id=1,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=1024,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-objecter_bytes,host=stefanosd1,id=1,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=finisher-defered_finisher,host=stefanosd1,id=1,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=osd,host=stefanosd1,id=1,type=osd agent_evict=0,agent_flush=0,agent_skip=0,agent_wake=0,cached_crc=0,cached_crc_adjusted=0,copyfrom=0,heartbeat_to_peers=7,loadavg=11,map_message_epoch_dups=29,map_message_epochs=50,map_messages=39,messages_delayed_for_map=0,missed_crc=0,numpg=188,numpg_primary=71,numpg_removing=0,numpg_replica=117,numpg_stray=0,object_ctx_cache_hit=1349777,object_ctx_cache_total=2934118,op=1319230,op_before_dequeue_op_lat.avgcount=3792053,op_before_dequeue_op_lat.avgtime=0.000405802,op_before_dequeue_op_lat.sum=1538.826381623,op_before_queue_op_lat.avgcount=3778690,op_before_queue_op_lat.avgtime=0.000033273,op_before_queue_op_lat.sum=125.731131596,op_cache_hit=0,op_in_bytes=0,op_latency.avgcount=1319230,op_latency.avgtime=0.002858138,op_latency.sum=3770.541581676,op_out_bytes=1789210,op_prepare_latency.avgcount=1336472,op_prepare_latency.avgtime=0.000279458,op_prepare_latency.sum=373.488913339,op_process_latency.avgcount=1319230,op_process_latency.avgtime=0.002666408,op_process_latency.sum=3517.606407526,op_r=1075394,op_r_latency.avgcount=1075394,op_r_latency.avgtime=0.000303779,op_r_latency.sum=326.682443032,op_r_out_bytes=1789210,op_r_prepare_latency.avgcount=1075394,op_r_prepare_latency.avgtime=0.000171228,op_r_prepare_latency.sum=184.138580631,op_r_process_latency.avgcount=1075394,op_r_process_latency.avgtime=0.00011609,op_r_process_latency.sum=124.842894319,op_rw=243832,op_rw_in_bytes=0,op_rw_latency.avgcount=243832,op_rw_latency.avgtime=0.014123636,op_rw_latency.sum=3443.79445124,op_rw_out_bytes=0,op_rw_prepare_latency.avgcount=261072,op_rw_prepare_latency.avgtime=0.000725265,op_rw_prepare_latency.sum=189.346543463,op_rw_process_latency.avgcount=243832,op_rw_process_latency.avgtime=0.013914089,op_rw_process_latency.sum=3392.700241086,op_w=4,op_w_in_bytes=0,op_w_latency.avgcount=4,op_w_latency.avgtime=0.016171851,op_w_latency.sum=0.064687404,op_w_prepare_latency.avgcount=6,op_w_prepare_latency.avgtime=0.00063154,op_w_prepare_latency.sum=0.003789245,op_w_process_latency.avgcount=4,op_w_process_latency.avgtime=0.01581803,op_w_process_latency.sum=0.063272121,op_wip=0,osd_map_bl_cache_hit=36,osd_map_bl_cache_miss=40,osd_map_cache_hit=5404,osd_map_cache_miss=14,osd_map_cache_miss_low=0,osd_map_cache_miss_low_avg.avgcount=0,osd_map_cache_miss_low_avg.sum=0,osd_pg_biginfo=2333,osd_pg_fastinfo=576157,osd_pg_info=591751,osd_tier_flush_lat.avgcount=0,osd_tier_flush_lat.avgtime=0,osd_tier_flush_lat.sum=0,osd_tier_promote_lat.avgcount=0,osd_tier_promote_lat.avgtime=0,osd_tier_promote_lat.sum=0,osd_tier_r_lat.avgcount=0,osd_tier_r_lat.avgtime=0,osd_tier_r_lat.sum=0,pull=0,push=22,push_out_bytes=0,recovery_bytes=0,recovery_ops=21,stat_bytes=107369988096,stat_bytes_avail=106271997952,stat_bytes_used=1097990144,subop=306946,subop_in_bytes=204236742,subop_latency.avgcount=306946,subop_latency.avgtime=0.006744881,subop_latency.sum=2070.314452989,subop_pull=0,subop_pull_latency.avgcount=0,subop_pull_latency.avgtime=0,subop_pull_latency.sum=0,subop_push=0,subop_push_in_bytes=0,subop_push_latency.avgcount=0,subop_push_latency.avgtime=0,subop_push_latency.sum=0,subop_w=306946,subop_w_in_bytes=204236742,subop_w_latency.avgcount=306946,subop_w_latency.avgtime=0.006744881,subop_w_latency.sum=2070.314452989,tier_clean=0,tier_delay=0,tier_dirty=8,tier_evict=0,tier_flush=0,tier_flush_fail=0,tier_promote=0,tier_proxy_read=0,tier_proxy_write=0,tier_try_flush=0,tier_try_flush_fail=0,tier_whiteout=0 1587117698000000000\n> ceph,collection=objecter,host=stefanosd1,id=1,type=osd command_active=0,command_resend=0,command_send=0,linger_active=0,linger_ping=0,linger_resend=0,linger_send=0,map_epoch=203,map_full=0,map_inc=19,omap_del=0,omap_rd=0,omap_wr=0,op=0,op_active=0,op_laggy=0,op_pg=0,op_r=0,op_reply=0,op_resend=0,op_rmw=0,op_send=0,op_send_bytes=0,op_w=0,osd_laggy=0,osd_session_close=0,osd_session_open=0,osd_sessions=0,osdop_append=0,osdop_call=0,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=0,osdop_delete=0,osdop_getxattr=0,osdop_mapext=0,osdop_notify=0,osdop_other=0,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=0,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=0,osdop_truncate=0,osdop_watch=0,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=0,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanosd1,id=1,type=osd msgr_active_connections=1356,msgr_created_connections=12290,msgr_recv_bytes=8577187219,msgr_recv_messages=6387040,msgr_running_fast_dispatch_time=475.903632306,msgr_running_recv_time=425.937196699,msgr_running_send_time=783.676217521,msgr_running_total_time=1989.242459076,msgr_send_bytes=12583034449,msgr_send_messages=6074344 1587117698000000000\n> ceph,collection=bluestore,host=stefanosd1,id=1,type=osd bluestore_allocated=24182784,bluestore_blob_split=0,bluestore_blobs=88,bluestore_buffer_bytes=614400,bluestore_buffer_hit_bytes=142047,bluestore_buffer_miss_bytes=541480,bluestore_buffers=41,bluestore_compressed=0,bluestore_compressed_allocated=0,bluestore_compressed_original=0,bluestore_extent_compress=0,bluestore_extents=88,bluestore_fragmentation_micros=1,bluestore_gc_merged=0,bluestore_onode_hits=1403948,bluestore_onode_misses=1584732,bluestore_onode_reshard=0,bluestore_onode_shard_hits=0,bluestore_onode_shard_misses=0,bluestore_onodes=459,bluestore_read_eio=0,bluestore_reads_with_retries=0,bluestore_stored=1985647,bluestore_txc=593150,bluestore_write_big=0,bluestore_write_big_blobs=0,bluestore_write_big_bytes=0,bluestore_write_small=58,bluestore_write_small_bytes=343091,bluestore_write_small_deferred=20,bluestore_write_small_new=38,bluestore_write_small_pre_read=20,bluestore_write_small_unused=0,commit_lat.avgcount=593150,commit_lat.avgtime=0.006514834,commit_lat.sum=3864.274280733,compress_lat.avgcount=0,compress_lat.avgtime=0,compress_lat.sum=0,compress_rejected_count=0,compress_success_count=0,csum_lat.avgcount=60,csum_lat.avgtime=0.000028258,csum_lat.sum=0.001695512,decompress_lat.avgcount=0,decompress_lat.avgtime=0,decompress_lat.sum=0,deferred_write_bytes=0,deferred_write_ops=0,kv_commit_lat.avgcount=578129,kv_commit_lat.avgtime=0.00570707,kv_commit_lat.sum=3299.423186928,kv_final_lat.avgcount=578124,kv_final_lat.avgtime=0.000042752,kv_final_lat.sum=24.716171934,kv_flush_lat.avgcount=578129,kv_flush_lat.avgtime=0.000000209,kv_flush_lat.sum=0.121169044,kv_sync_lat.avgcount=578129,kv_sync_lat.avgtime=0.00570728,kv_sync_lat.sum=3299.544355972,omap_lower_bound_lat.avgcount=22,omap_lower_bound_lat.avgtime=0.000005979,omap_lower_bound_lat.sum=0.000131539,omap_next_lat.avgcount=13248,omap_next_lat.avgtime=0.000004836,omap_next_lat.sum=0.064077797,omap_seek_to_first_lat.avgcount=525,omap_seek_to_first_lat.avgtime=0.000004906,omap_seek_to_first_lat.sum=0.002575786,omap_upper_bound_lat.avgcount=0,omap_upper_bound_lat.avgtime=0,omap_upper_bound_lat.sum=0,read_lat.avgcount=406,read_lat.avgtime=0.000383254,read_lat.sum=0.155601529,read_onode_meta_lat.avgcount=483,read_onode_meta_lat.avgtime=0.000008805,read_onode_meta_lat.sum=0.004252832,read_wait_aio_lat.avgcount=77,read_wait_aio_lat.avgtime=0.001907361,read_wait_aio_lat.sum=0.146866799,state_aio_wait_lat.avgcount=593150,state_aio_wait_lat.avgtime=0.000000388,state_aio_wait_lat.sum=0.230498048,state_deferred_aio_wait_lat.avgcount=0,state_deferred_aio_wait_lat.avgtime=0,state_deferred_aio_wait_lat.sum=0,state_deferred_cleanup_lat.avgcount=0,state_deferred_cleanup_lat.avgtime=0,state_deferred_cleanup_lat.sum=0,state_deferred_queued_lat.avgcount=0,state_deferred_queued_lat.avgtime=0,state_deferred_queued_lat.sum=0,state_done_lat.avgcount=593140,state_done_lat.avgtime=0.000003048,state_done_lat.sum=1.80789161,state_finishing_lat.avgcount=593140,state_finishing_lat.avgtime=0.000000325,state_finishing_lat.sum=0.192952339,state_io_done_lat.avgcount=593150,state_io_done_lat.avgtime=0.000001202,state_io_done_lat.sum=0.713333116,state_kv_commiting_lat.avgcount=593150,state_kv_commiting_lat.avgtime=0.005788541,state_kv_commiting_lat.sum=3433.473378536,state_kv_done_lat.avgcount=593150,state_kv_done_lat.avgtime=0.000001472,state_kv_done_lat.sum=0.873559611,state_kv_queued_lat.avgcount=593150,state_kv_queued_lat.avgtime=0.000634215,state_kv_queued_lat.sum=376.18491577,state_prepare_lat.avgcount=593150,state_prepare_lat.avgtime=0.000089694,state_prepare_lat.sum=53.202464675,submit_lat.avgcount=593150,submit_lat.avgtime=0.000127856,submit_lat.sum=75.83816759,throttle_lat.avgcount=593150,throttle_lat.avgtime=0.000001726,throttle_lat.sum=1.023832181,write_pad_bytes=144333,write_penalty_read_ops=0 1587117698000000000\n> ceph,collection=throttle-osd_client_bytes,host=stefanosd1,id=1,type=osd get=2920772,get_or_fail_fail=0,get_or_fail_success=2920772,get_started=0,get_sum=739935873,max=524288000,put=4888498,put_sum=739935873,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_client,host=stefanosd1,id=1,type=osd get=2605442,get_or_fail_fail=0,get_or_fail_success=2605442,get_started=0,get_sum=5221305768,max=104857600,put=2605442,put_sum=5221305768,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanosd1,id=1,type=osd msgr_active_connections=1375,msgr_created_connections=12689,msgr_recv_bytes=6393440855,msgr_recv_messages=3260458,msgr_running_fast_dispatch_time=120.622437418,msgr_running_recv_time=225.24709441,msgr_running_send_time=499.150587343,msgr_running_total_time=1043.340296846,msgr_send_bytes=11134862571,msgr_send_messages=3450760 1587117698000000000\n> ceph,collection=bluefs,host=stefanosd1,id=1,type=osd bytes_written_slow=0,bytes_written_sst=19824993,bytes_written_wal=1788507023,db_total_bytes=4294967296,db_used_bytes=522190848,files_written_sst=4,files_written_wal=2,gift_bytes=0,log_bytes=1056768,log_compactions=2,logged_bytes=1933271040,max_bytes_db=1483735040,max_bytes_slow=0,max_bytes_wal=0,num_files=12,reclaim_bytes=0,slow_total_bytes=0,slow_used_bytes=0,wal_total_bytes=0,wal_used_bytes=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_client,host=stefanosd1,id=1,type=osd get=2605442,get_or_fail_fail=0,get_or_fail_success=2605442,get_started=0,get_sum=5221305768,max=104857600,put=2605442,put_sum=5221305768,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_deferred_bytes,host=stefanosd1,id=1,type=osd get=10,get_or_fail_fail=0,get_or_fail_success=10,get_started=0,get_sum=7052009,max=201326592,put=0,put_sum=0,take=0,take_sum=0,val=7052009,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=rocksdb,host=stefanosd1,id=1,type=osd compact=0,compact_queue_len=0,compact_queue_merge=0,compact_range=0,get=1586061,get_latency.avgcount=1586061,get_latency.avgtime=0.000083009,get_latency.sum=131.658296684,rocksdb_write_delay_time.avgcount=0,rocksdb_write_delay_time.avgtime=0,rocksdb_write_delay_time.sum=0,rocksdb_write_memtable_time.avgcount=0,rocksdb_write_memtable_time.avgtime=0,rocksdb_write_memtable_time.sum=0,rocksdb_write_pre_and_post_time.avgcount=0,rocksdb_write_pre_and_post_time.avgtime=0,rocksdb_write_pre_and_post_time.sum=0,rocksdb_write_wal_time.avgcount=0,rocksdb_write_wal_time.avgtime=0,rocksdb_write_wal_time.sum=0,submit_latency.avgcount=593150,submit_latency.avgtime=0.000172072,submit_latency.sum=102.064900673,submit_sync_latency.avgcount=578129,submit_sync_latency.avgtime=0.005447017,submit_sync_latency.sum=3149.078822012,submit_transaction=593150,submit_transaction_sync=578129 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_server,host=stefanosd1,id=1,type=osd get=2607669,get_or_fail_fail=0,get_or_fail_success=2607669,get_started=0,get_sum=5225768676,max=104857600,put=2607669,put_sum=5225768676,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=recoverystate_perf,host=stefanosd1,id=1,type=osd activating_latency.avgcount=104,activating_latency.avgtime=0.071646485,activating_latency.sum=7.451234493,active_latency.avgcount=33,active_latency.avgtime=1734.369034268,active_latency.sum=57234.178130859,backfilling_latency.avgcount=1,backfilling_latency.avgtime=2.598401698,backfilling_latency.sum=2.598401698,clean_latency.avgcount=33,clean_latency.avgtime=1734.213467342,clean_latency.sum=57229.044422292,down_latency.avgcount=0,down_latency.avgtime=0,down_latency.sum=0,getinfo_latency.avgcount=167,getinfo_latency.avgtime=0.373444627,getinfo_latency.sum=62.365252849,getlog_latency.avgcount=105,getlog_latency.avgtime=0.003575062,getlog_latency.sum=0.375381569,getmissing_latency.avgcount=104,getmissing_latency.avgtime=0.000157091,getmissing_latency.sum=0.016337565,incomplete_latency.avgcount=0,incomplete_latency.avgtime=0,incomplete_latency.sum=0,initial_latency.avgcount=188,initial_latency.avgtime=0.001833512,initial_latency.sum=0.344700343,notbackfilling_latency.avgcount=0,notbackfilling_latency.avgtime=0,notbackfilling_latency.sum=0,notrecovering_latency.avgcount=0,notrecovering_latency.avgtime=0,notrecovering_latency.sum=0,peering_latency.avgcount=167,peering_latency.avgtime=1.501818082,peering_latency.sum=250.803619796,primary_latency.avgcount=97,primary_latency.avgtime=591.344286378,primary_latency.sum=57360.395778762,recovered_latency.avgcount=104,recovered_latency.avgtime=0.000291138,recovered_latency.sum=0.030278433,recovering_latency.avgcount=2,recovering_latency.avgtime=0.142378096,recovering_latency.sum=0.284756192,replicaactive_latency.avgcount=32,replicaactive_latency.avgtime=1788.474901442,replicaactive_latency.sum=57231.196846165,repnotrecovering_latency.avgcount=34,repnotrecovering_latency.avgtime=1683.273587087,repnotrecovering_latency.sum=57231.301960987,reprecovering_latency.avgcount=2,reprecovering_latency.avgtime=0.418094818,reprecovering_latency.sum=0.836189637,repwaitbackfillreserved_latency.avgcount=0,repwaitbackfillreserved_latency.avgtime=0,repwaitbackfillreserved_latency.sum=0,repwaitrecoveryreserved_latency.avgcount=2,repwaitrecoveryreserved_latency.avgtime=0.000588413,repwaitrecoveryreserved_latency.sum=0.001176827,reset_latency.avgcount=433,reset_latency.avgtime=0.15669689,reset_latency.sum=67.849753631,start_latency.avgcount=433,start_latency.avgtime=0.000412707,start_latency.sum=0.178702508,started_latency.avgcount=245,started_latency.avgtime=468.419544137,started_latency.sum=114762.788313581,stray_latency.avgcount=266,stray_latency.avgtime=1.489291271,stray_latency.sum=396.151478238,waitactingchange_latency.avgcount=1,waitactingchange_latency.avgtime=0.982689906,waitactingchange_latency.sum=0.982689906,waitlocalbackfillreserved_latency.avgcount=1,waitlocalbackfillreserved_latency.avgtime=0.000542092,waitlocalbackfillreserved_latency.sum=0.000542092,waitlocalrecoveryreserved_latency.avgcount=2,waitlocalrecoveryreserved_latency.avgtime=0.00391669,waitlocalrecoveryreserved_latency.sum=0.007833381,waitremotebackfillreserved_latency.avgcount=1,waitremotebackfillreserved_latency.avgtime=0.003110409,waitremotebackfillreserved_latency.sum=0.003110409,waitremoterecoveryreserved_latency.avgcount=2,waitremoterecoveryreserved_latency.avgtime=0.012229338,waitremoterecoveryreserved_latency.sum=0.024458677,waitupthru_latency.avgcount=104,waitupthru_latency.avgtime=1.807608905,waitupthru_latency.sum=187.991326197 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanosd1,id=1,type=osd msgr_active_connections=1289,msgr_created_connections=9469,msgr_recv_bytes=8348149800,msgr_recv_messages=5048791,msgr_running_fast_dispatch_time=313.754567889,msgr_running_recv_time=372.054833029,msgr_running_send_time=694.900405016,msgr_running_total_time=1656.294769387,msgr_send_bytes=11550148208,msgr_send_messages=5175962 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_bytes,host=stefanosd1,id=1,type=osd get=593150,get_or_fail_fail=0,get_or_fail_success=0,get_started=593150,get_sum=398147414260,max=67108864,put=578129,put_sum=398147414260,take=0,take_sum=0,val=0,wait.avgcount=29,wait.avgtime=0.000972655,wait.sum=0.028207005 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-ms_objecter,host=stefanosd1,id=1,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=cct,host=stefanosd1,id=1,type=osd total_workers=6,unhealthy_workers=0 1587117698000000000\n> ceph,collection=mempool,host=stefanosd1,id=1,type=osd bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=13064,bluefs_items=593,bluestore_alloc_bytes=230288,bluestore_alloc_items=28786,bluestore_cache_data_bytes=614400,bluestore_cache_data_items=41,bluestore_cache_onode_bytes=301104,bluestore_cache_onode_items=459,bluestore_cache_other_bytes=230945,bluestore_cache_other_items=26119,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=7520,bluestore_txc_items=10,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=657768,bluestore_writing_deferred_items=172,bluestore_writing_items=0,buffer_anon_bytes=2328515,buffer_anon_items=271,buffer_meta_bytes=5808,buffer_meta_items=66,mds_co_bytes=0,mds_co_items=0,osd_bytes=2406400,osd_items=188,osd_mapbl_bytes=139623,osd_mapbl_items=9,osd_pglog_bytes=6768784,osd_pglog_items=18179,osdmap_bytes=710892,osdmap_items=4426,osdmap_mapping_bytes=0,osdmap_mapping_items=0,pgmap_bytes=0,pgmap_items=0,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-client,host=stefanosd1,id=1,type=osd get=2932513,get_or_fail_fail=0,get_or_fail_success=2932513,get_started=0,get_sum=740620215,max=104857600,put=2932513,put_sum=740620215,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_server,host=stefanosd1,id=1,type=osd get=2607669,get_or_fail_fail=0,get_or_fail_success=2607669,get_started=0,get_sum=5225768676,max=104857600,put=2607669,put_sum=5225768676,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=finisher-commit_finisher,host=stefanosd1,id=1,type=osd complete_latency.avgcount=10,complete_latency.avgtime=0.002884646,complete_latency.sum=0.028846469,queue_len=0 1587117698000000000\n> ceph,collection=finisher-objecter-finisher-0,host=stefanosd1,id=1,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=throttle-objecter_bytes,host=stefanosd1,id=2,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=finisher-commit_finisher,host=stefanosd1,id=2,type=osd complete_latency.avgcount=11,complete_latency.avgtime=0.002714416,complete_latency.sum=0.029858583,queue_len=0 1587117698000000000\n> ceph,collection=finisher-defered_finisher,host=stefanosd1,id=2,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=objecter,host=stefanosd1,id=2,type=osd command_active=0,command_resend=0,command_send=0,linger_active=0,linger_ping=0,linger_resend=0,linger_send=0,map_epoch=203,map_full=0,map_inc=19,omap_del=0,omap_rd=0,omap_wr=0,op=0,op_active=0,op_laggy=0,op_pg=0,op_r=0,op_reply=0,op_resend=0,op_rmw=0,op_send=0,op_send_bytes=0,op_w=0,osd_laggy=0,osd_session_close=0,osd_session_open=0,osd_sessions=0,osdop_append=0,osdop_call=0,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=0,osdop_delete=0,osdop_getxattr=0,osdop_mapext=0,osdop_notify=0,osdop_other=0,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=0,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=0,osdop_truncate=0,osdop_watch=0,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=0,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_client,host=stefanosd1,id=2,type=osd get=2607136,get_or_fail_fail=0,get_or_fail_success=2607136,get_started=0,get_sum=5224700544,max=104857600,put=2607136,put_sum=5224700544,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=mempool,host=stefanosd1,id=2,type=osd bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=11624,bluefs_items=522,bluestore_alloc_bytes=230288,bluestore_alloc_items=28786,bluestore_cache_data_bytes=614400,bluestore_cache_data_items=41,bluestore_cache_onode_bytes=228288,bluestore_cache_onode_items=348,bluestore_cache_other_bytes=174158,bluestore_cache_other_items=18527,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=8272,bluestore_txc_items=11,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=670130,bluestore_writing_deferred_items=176,bluestore_writing_items=0,buffer_anon_bytes=2311664,buffer_anon_items=244,buffer_meta_bytes=5456,buffer_meta_items=62,mds_co_bytes=0,mds_co_items=0,osd_bytes=1920000,osd_items=150,osd_mapbl_bytes=155152,osd_mapbl_items=10,osd_pglog_bytes=3393520,osd_pglog_items=9128,osdmap_bytes=710892,osdmap_items=4426,osdmap_mapping_bytes=0,osdmap_mapping_items=0,pgmap_bytes=0,pgmap_items=0,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117698000000000\n> ceph,collection=osd,host=stefanosd1,id=2,type=osd agent_evict=0,agent_flush=0,agent_skip=0,agent_wake=0,cached_crc=0,cached_crc_adjusted=0,copyfrom=0,heartbeat_to_peers=7,loadavg=11,map_message_epoch_dups=37,map_message_epochs=56,map_messages=37,messages_delayed_for_map=0,missed_crc=0,numpg=150,numpg_primary=59,numpg_removing=0,numpg_replica=91,numpg_stray=0,object_ctx_cache_hit=705923,object_ctx_cache_total=705951,op=690584,op_before_dequeue_op_lat.avgcount=1155697,op_before_dequeue_op_lat.avgtime=0.000217926,op_before_dequeue_op_lat.sum=251.856487141,op_before_queue_op_lat.avgcount=1148445,op_before_queue_op_lat.avgtime=0.000039696,op_before_queue_op_lat.sum=45.589516462,op_cache_hit=0,op_in_bytes=0,op_latency.avgcount=690584,op_latency.avgtime=0.002488685,op_latency.sum=1718.646504654,op_out_bytes=1026000,op_prepare_latency.avgcount=698700,op_prepare_latency.avgtime=0.000300375,op_prepare_latency.sum=209.872029659,op_process_latency.avgcount=690584,op_process_latency.avgtime=0.00230742,op_process_latency.sum=1593.46739165,op_r=548020,op_r_latency.avgcount=548020,op_r_latency.avgtime=0.000298287,op_r_latency.sum=163.467760649,op_r_out_bytes=1026000,op_r_prepare_latency.avgcount=548020,op_r_prepare_latency.avgtime=0.000186359,op_r_prepare_latency.sum=102.128629183,op_r_process_latency.avgcount=548020,op_r_process_latency.avgtime=0.00012716,op_r_process_latency.sum=69.686468884,op_rw=142562,op_rw_in_bytes=0,op_rw_latency.avgcount=142562,op_rw_latency.avgtime=0.010908597,op_rw_latency.sum=1555.151525732,op_rw_out_bytes=0,op_rw_prepare_latency.avgcount=150678,op_rw_prepare_latency.avgtime=0.000715043,op_rw_prepare_latency.sum=107.741399304,op_rw_process_latency.avgcount=142562,op_rw_process_latency.avgtime=0.01068836,op_rw_process_latency.sum=1523.754107887,op_w=2,op_w_in_bytes=0,op_w_latency.avgcount=2,op_w_latency.avgtime=0.013609136,op_w_latency.sum=0.027218273,op_w_prepare_latency.avgcount=2,op_w_prepare_latency.avgtime=0.001000586,op_w_prepare_latency.sum=0.002001172,op_w_process_latency.avgcount=2,op_w_process_latency.avgtime=0.013407439,op_w_process_latency.sum=0.026814879,op_wip=0,osd_map_bl_cache_hit=15,osd_map_bl_cache_miss=41,osd_map_cache_hit=4241,osd_map_cache_miss=14,osd_map_cache_miss_low=0,osd_map_cache_miss_low_avg.avgcount=0,osd_map_cache_miss_low_avg.sum=0,osd_pg_biginfo=1824,osd_pg_fastinfo=285998,osd_pg_info=294869,osd_tier_flush_lat.avgcount=0,osd_tier_flush_lat.avgtime=0,osd_tier_flush_lat.sum=0,osd_tier_promote_lat.avgcount=0,osd_tier_promote_lat.avgtime=0,osd_tier_promote_lat.sum=0,osd_tier_r_lat.avgcount=0,osd_tier_r_lat.avgtime=0,osd_tier_r_lat.sum=0,pull=0,push=1,push_out_bytes=0,recovery_bytes=0,recovery_ops=0,stat_bytes=107369988096,stat_bytes_avail=106271932416,stat_bytes_used=1098055680,subop=134165,subop_in_bytes=89501237,subop_latency.avgcount=134165,subop_latency.avgtime=0.007313523,subop_latency.sum=981.218888627,subop_pull=0,subop_pull_latency.avgcount=0,subop_pull_latency.avgtime=0,subop_pull_latency.sum=0,subop_push=0,subop_push_in_bytes=0,subop_push_latency.avgcount=0,subop_push_latency.avgtime=0,subop_push_latency.sum=0,subop_w=134165,subop_w_in_bytes=89501237,subop_w_latency.avgcount=134165,subop_w_latency.avgtime=0.007313523,subop_w_latency.sum=981.218888627,tier_clean=0,tier_delay=0,tier_dirty=4,tier_evict=0,tier_flush=0,tier_flush_fail=0,tier_promote=0,tier_proxy_read=0,tier_proxy_write=0,tier_try_flush=0,tier_try_flush_fail=0,tier_whiteout=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanosd1,id=2,type=osd msgr_active_connections=746,msgr_created_connections=15212,msgr_recv_bytes=8633229006,msgr_recv_messages=4284202,msgr_running_fast_dispatch_time=153.820479102,msgr_running_recv_time=282.031655658,msgr_running_send_time=585.444749736,msgr_running_total_time=1231.431789242,msgr_send_bytes=11962769351,msgr_send_messages=4440622 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-ms_objecter,host=stefanosd1,id=2,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_client,host=stefanosd1,id=2,type=osd get=2607136,get_or_fail_fail=0,get_or_fail_success=2607136,get_started=0,get_sum=5224700544,max=104857600,put=2607136,put_sum=5224700544,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=bluefs,host=stefanosd1,id=2,type=osd bytes_written_slow=0,bytes_written_sst=9065815,bytes_written_wal=901884611,db_total_bytes=4294967296,db_used_bytes=546308096,files_written_sst=3,files_written_wal=2,gift_bytes=0,log_bytes=225726464,log_compactions=1,logged_bytes=1195945984,max_bytes_db=1234173952,max_bytes_slow=0,max_bytes_wal=0,num_files=11,reclaim_bytes=0,slow_total_bytes=0,slow_used_bytes=0,wal_total_bytes=0,wal_used_bytes=0 1587117698000000000\n> ceph,collection=recoverystate_perf,host=stefanosd1,id=2,type=osd activating_latency.avgcount=88,activating_latency.avgtime=0.086149065,activating_latency.sum=7.581117751,active_latency.avgcount=29,active_latency.avgtime=1790.849396082,active_latency.sum=51934.632486379,backfilling_latency.avgcount=0,backfilling_latency.avgtime=0,backfilling_latency.sum=0,clean_latency.avgcount=29,clean_latency.avgtime=1790.754765195,clean_latency.sum=51931.888190683,down_latency.avgcount=0,down_latency.avgtime=0,down_latency.sum=0,getinfo_latency.avgcount=134,getinfo_latency.avgtime=0.427567953,getinfo_latency.sum=57.294105786,getlog_latency.avgcount=88,getlog_latency.avgtime=0.011810192,getlog_latency.sum=1.03929697,getmissing_latency.avgcount=88,getmissing_latency.avgtime=0.000104598,getmissing_latency.sum=0.009204673,incomplete_latency.avgcount=0,incomplete_latency.avgtime=0,incomplete_latency.sum=0,initial_latency.avgcount=150,initial_latency.avgtime=0.001251361,initial_latency.sum=0.187704197,notbackfilling_latency.avgcount=0,notbackfilling_latency.avgtime=0,notbackfilling_latency.sum=0,notrecovering_latency.avgcount=0,notrecovering_latency.avgtime=0,notrecovering_latency.sum=0,peering_latency.avgcount=134,peering_latency.avgtime=0.998405763,peering_latency.sum=133.786372331,primary_latency.avgcount=75,primary_latency.avgtime=693.473306562,primary_latency.sum=52010.497992212,recovered_latency.avgcount=88,recovered_latency.avgtime=0.000609715,recovered_latency.sum=0.053654964,recovering_latency.avgcount=1,recovering_latency.avgtime=0.100713031,recovering_latency.sum=0.100713031,replicaactive_latency.avgcount=21,replicaactive_latency.avgtime=1790.852354921,replicaactive_latency.sum=37607.89945336,repnotrecovering_latency.avgcount=21,repnotrecovering_latency.avgtime=1790.852315529,repnotrecovering_latency.sum=37607.898626121,reprecovering_latency.avgcount=0,reprecovering_latency.avgtime=0,reprecovering_latency.sum=0,repwaitbackfillreserved_latency.avgcount=0,repwaitbackfillreserved_latency.avgtime=0,repwaitbackfillreserved_latency.sum=0,repwaitrecoveryreserved_latency.avgcount=0,repwaitrecoveryreserved_latency.avgtime=0,repwaitrecoveryreserved_latency.sum=0,reset_latency.avgcount=346,reset_latency.avgtime=0.126826803,reset_latency.sum=43.882073917,start_latency.avgcount=346,start_latency.avgtime=0.000233277,start_latency.sum=0.080713962,started_latency.avgcount=196,started_latency.avgtime=457.885378797,started_latency.sum=89745.534244237,stray_latency.avgcount=212,stray_latency.avgtime=1.013774396,stray_latency.sum=214.920172121,waitactingchange_latency.avgcount=0,waitactingchange_latency.avgtime=0,waitactingchange_latency.sum=0,waitlocalbackfillreserved_latency.avgcount=0,waitlocalbackfillreserved_latency.avgtime=0,waitlocalbackfillreserved_latency.sum=0,waitlocalrecoveryreserved_latency.avgcount=1,waitlocalrecoveryreserved_latency.avgtime=0.001572379,waitlocalrecoveryreserved_latency.sum=0.001572379,waitremotebackfillreserved_latency.avgcount=0,waitremotebackfillreserved_latency.avgtime=0,waitremotebackfillreserved_latency.sum=0,waitremoterecoveryreserved_latency.avgcount=1,waitremoterecoveryreserved_latency.avgtime=0.012729633,waitremoterecoveryreserved_latency.sum=0.012729633,waitupthru_latency.avgcount=88,waitupthru_latency.avgtime=0.857137729,waitupthru_latency.sum=75.428120205 1587117698000000000\n> ceph,collection=throttle-objecter_ops,host=stefanosd1,id=2,type=osd get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=1024,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=bluestore,host=stefanosd1,id=2,type=osd bluestore_allocated=24248320,bluestore_blob_split=0,bluestore_blobs=83,bluestore_buffer_bytes=614400,bluestore_buffer_hit_bytes=161362,bluestore_buffer_miss_bytes=534799,bluestore_buffers=41,bluestore_compressed=0,bluestore_compressed_allocated=0,bluestore_compressed_original=0,bluestore_extent_compress=0,bluestore_extents=83,bluestore_fragmentation_micros=1,bluestore_gc_merged=0,bluestore_onode_hits=723852,bluestore_onode_misses=364,bluestore_onode_reshard=0,bluestore_onode_shard_hits=0,bluestore_onode_shard_misses=0,bluestore_onodes=348,bluestore_read_eio=0,bluestore_reads_with_retries=0,bluestore_stored=1984402,bluestore_txc=295997,bluestore_write_big=0,bluestore_write_big_blobs=0,bluestore_write_big_bytes=0,bluestore_write_small=60,bluestore_write_small_bytes=343843,bluestore_write_small_deferred=22,bluestore_write_small_new=38,bluestore_write_small_pre_read=22,bluestore_write_small_unused=0,commit_lat.avgcount=295997,commit_lat.avgtime=0.006994931,commit_lat.sum=2070.478673619,compress_lat.avgcount=0,compress_lat.avgtime=0,compress_lat.sum=0,compress_rejected_count=0,compress_success_count=0,csum_lat.avgcount=47,csum_lat.avgtime=0.000034434,csum_lat.sum=0.001618423,decompress_lat.avgcount=0,decompress_lat.avgtime=0,decompress_lat.sum=0,deferred_write_bytes=0,deferred_write_ops=0,kv_commit_lat.avgcount=291889,kv_commit_lat.avgtime=0.006347015,kv_commit_lat.sum=1852.624108527,kv_final_lat.avgcount=291885,kv_final_lat.avgtime=0.00004358,kv_final_lat.sum=12.720529751,kv_flush_lat.avgcount=291889,kv_flush_lat.avgtime=0.000000211,kv_flush_lat.sum=0.061636079,kv_sync_lat.avgcount=291889,kv_sync_lat.avgtime=0.006347227,kv_sync_lat.sum=1852.685744606,omap_lower_bound_lat.avgcount=1,omap_lower_bound_lat.avgtime=0.000004482,omap_lower_bound_lat.sum=0.000004482,omap_next_lat.avgcount=6933,omap_next_lat.avgtime=0.000003956,omap_next_lat.sum=0.027427456,omap_seek_to_first_lat.avgcount=309,omap_seek_to_first_lat.avgtime=0.000005879,omap_seek_to_first_lat.sum=0.001816658,omap_upper_bound_lat.avgcount=0,omap_upper_bound_lat.avgtime=0,omap_upper_bound_lat.sum=0,read_lat.avgcount=229,read_lat.avgtime=0.000394981,read_lat.sum=0.090450704,read_onode_meta_lat.avgcount=295,read_onode_meta_lat.avgtime=0.000016832,read_onode_meta_lat.sum=0.004965516,read_wait_aio_lat.avgcount=66,read_wait_aio_lat.avgtime=0.001237841,read_wait_aio_lat.sum=0.081697561,state_aio_wait_lat.avgcount=295997,state_aio_wait_lat.avgtime=0.000000357,state_aio_wait_lat.sum=0.105827433,state_deferred_aio_wait_lat.avgcount=0,state_deferred_aio_wait_lat.avgtime=0,state_deferred_aio_wait_lat.sum=0,state_deferred_cleanup_lat.avgcount=0,state_deferred_cleanup_lat.avgtime=0,state_deferred_cleanup_lat.sum=0,state_deferred_queued_lat.avgcount=0,state_deferred_queued_lat.avgtime=0,state_deferred_queued_lat.sum=0,state_done_lat.avgcount=295986,state_done_lat.avgtime=0.000003017,state_done_lat.sum=0.893199127,state_finishing_lat.avgcount=295986,state_finishing_lat.avgtime=0.000000306,state_finishing_lat.sum=0.090792683,state_io_done_lat.avgcount=295997,state_io_done_lat.avgtime=0.000001066,state_io_done_lat.sum=0.315577655,state_kv_commiting_lat.avgcount=295997,state_kv_commiting_lat.avgtime=0.006423586,state_kv_commiting_lat.sum=1901.362268572,state_kv_done_lat.avgcount=295997,state_kv_done_lat.avgtime=0.00000155,state_kv_done_lat.sum=0.458963064,state_kv_queued_lat.avgcount=295997,state_kv_queued_lat.avgtime=0.000477234,state_kv_queued_lat.sum=141.260101773,state_prepare_lat.avgcount=295997,state_prepare_lat.avgtime=0.000091806,state_prepare_lat.sum=27.174436583,submit_lat.avgcount=295997,submit_lat.avgtime=0.000135729,submit_lat.sum=40.17557682,throttle_lat.avgcount=295997,throttle_lat.avgtime=0.000002734,throttle_lat.sum=0.809479837,write_pad_bytes=151773,write_penalty_read_ops=0 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_bytes,host=stefanosd1,id=2,type=osd get=295997,get_or_fail_fail=0,get_or_fail_success=0,get_started=295997,get_sum=198686579299,max=67108864,put=291889,put_sum=198686579299,take=0,take_sum=0,val=0,wait.avgcount=83,wait.avgtime=0.003670612,wait.sum=0.304660858 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-cluster,host=stefanosd1,id=2,type=osd get=452060,get_or_fail_fail=0,get_or_fail_success=452060,get_started=0,get_sum=269934345,max=104857600,put=452060,put_sum=269934345,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-bluestore_throttle_deferred_bytes,host=stefanosd1,id=2,type=osd get=11,get_or_fail_fail=0,get_or_fail_success=11,get_started=0,get_sum=7723117,max=201326592,put=0,put_sum=0,take=0,take_sum=0,val=7723117,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_front_server,host=stefanosd1,id=2,type=osd get=2607433,get_or_fail_fail=0,get_or_fail_success=2607433,get_started=0,get_sum=5225295732,max=104857600,put=2607433,put_sum=5225295732,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=finisher-objecter-finisher-0,host=stefanosd1,id=2,type=osd complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117698000000000\n> ceph,collection=cct,host=stefanosd1,id=2,type=osd total_workers=6,unhealthy_workers=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanosd1,id=2,type=osd msgr_active_connections=670,msgr_created_connections=13455,msgr_recv_bytes=6334605563,msgr_recv_messages=3287843,msgr_running_fast_dispatch_time=137.016615819,msgr_running_recv_time=240.687997039,msgr_running_send_time=471.710658466,msgr_running_total_time=1034.029109337,msgr_send_bytes=9753423475,msgr_send_messages=3439611 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-client,host=stefanosd1,id=2,type=osd get=710355,get_or_fail_fail=0,get_or_fail_success=710355,get_started=0,get_sum=166306283,max=104857600,put=710355,put_sum=166306283,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-hb_back_server,host=stefanosd1,id=2,type=osd get=2607433,get_or_fail_fail=0,get_or_fail_success=2607433,get_started=0,get_sum=5225295732,max=104857600,put=2607433,put_sum=5225295732,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanosd1,id=2,type=osd msgr_active_connections=705,msgr_created_connections=17953,msgr_recv_bytes=7261438733,msgr_recv_messages=4496034,msgr_running_fast_dispatch_time=254.716476808,msgr_running_recv_time=272.196741555,msgr_running_send_time=571.102924903,msgr_running_total_time=1338.461077493,msgr_send_bytes=10772250508,msgr_send_messages=4192781 1587117698000000000\n> ceph,collection=rocksdb,host=stefanosd1,id=2,type=osd compact=0,compact_queue_len=0,compact_queue_merge=0,compact_range=0,get=1424,get_latency.avgcount=1424,get_latency.avgtime=0.000030752,get_latency.sum=0.043792142,rocksdb_write_delay_time.avgcount=0,rocksdb_write_delay_time.avgtime=0,rocksdb_write_delay_time.sum=0,rocksdb_write_memtable_time.avgcount=0,rocksdb_write_memtable_time.avgtime=0,rocksdb_write_memtable_time.sum=0,rocksdb_write_pre_and_post_time.avgcount=0,rocksdb_write_pre_and_post_time.avgtime=0,rocksdb_write_pre_and_post_time.sum=0,rocksdb_write_wal_time.avgcount=0,rocksdb_write_wal_time.avgtime=0,rocksdb_write_wal_time.sum=0,submit_latency.avgcount=295997,submit_latency.avgtime=0.000173137,submit_latency.sum=51.248072285,submit_sync_latency.avgcount=291889,submit_sync_latency.avgtime=0.006094397,submit_sync_latency.sum=1778.887521449,submit_transaction=295997,submit_transaction_sync=291889 1587117698000000000\n> ceph,collection=throttle-osd_client_bytes,host=stefanosd1,id=2,type=osd get=698701,get_or_fail_fail=0,get_or_fail_success=698701,get_started=0,get_sum=165630172,max=524288000,put=920880,put_sum=165630172,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117698000000000\n> ceph,collection=mds_sessions,host=stefanmds1,id=stefanmds1,type=mds average_load=0,avg_session_uptime=0,session_add=0,session_count=0,session_remove=0,sessions_open=0,sessions_stale=0,total_load=0 1587117476000000000\n> ceph,collection=mempool,host=stefanmds1,id=stefanmds1,type=mds bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=0,bluefs_items=0,bluestore_alloc_bytes=0,bluestore_alloc_items=0,bluestore_cache_data_bytes=0,bluestore_cache_data_items=0,bluestore_cache_onode_bytes=0,bluestore_cache_onode_items=0,bluestore_cache_other_bytes=0,bluestore_cache_other_items=0,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=0,bluestore_txc_items=0,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=0,bluestore_writing_deferred_items=0,bluestore_writing_items=0,buffer_anon_bytes=132069,buffer_anon_items=82,buffer_meta_bytes=0,buffer_meta_items=0,mds_co_bytes=44208,mds_co_items=154,osd_bytes=0,osd_items=0,osd_mapbl_bytes=0,osd_mapbl_items=0,osd_pglog_bytes=0,osd_pglog_items=0,osdmap_bytes=16952,osdmap_items=139,osdmap_mapping_bytes=0,osdmap_mapping_items=0,pgmap_bytes=0,pgmap_items=0,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117476000000000\n> ceph,collection=objecter,host=stefanmds1,id=stefanmds1,type=mds command_active=0,command_resend=0,command_send=0,linger_active=0,linger_ping=0,linger_resend=0,linger_send=0,map_epoch=203,map_full=0,map_inc=1,omap_del=0,omap_rd=28,omap_wr=1,op=33,op_active=0,op_laggy=0,op_pg=0,op_r=26,op_reply=33,op_resend=2,op_rmw=0,op_send=35,op_send_bytes=364,op_w=7,osd_laggy=0,osd_session_close=91462,osd_session_open=91468,osd_sessions=6,osdop_append=0,osdop_call=0,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=0,osdop_delete=5,osdop_getxattr=14,osdop_mapext=0,osdop_notify=0,osdop_other=0,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=8,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=2,osdop_truncate=0,osdop_watch=0,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=1,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117476000000000\n> ceph,collection=cct,host=stefanmds1,id=stefanmds1,type=mds total_workers=1,unhealthy_workers=0 1587117476000000000\n> ceph,collection=mds_server,host=stefanmds1,id=stefanmds1,type=mds cap_revoke_eviction=0,dispatch_client_request=0,dispatch_server_request=0,handle_client_request=0,handle_client_session=0,handle_slave_request=0,req_create_latency.avgcount=0,req_create_latency.avgtime=0,req_create_latency.sum=0,req_getattr_latency.avgcount=0,req_getattr_latency.avgtime=0,req_getattr_latency.sum=0,req_getfilelock_latency.avgcount=0,req_getfilelock_latency.avgtime=0,req_getfilelock_latency.sum=0,req_link_latency.avgcount=0,req_link_latency.avgtime=0,req_link_latency.sum=0,req_lookup_latency.avgcount=0,req_lookup_latency.avgtime=0,req_lookup_latency.sum=0,req_lookuphash_latency.avgcount=0,req_lookuphash_latency.avgtime=0,req_lookuphash_latency.sum=0,req_lookupino_latency.avgcount=0,req_lookupino_latency.avgtime=0,req_lookupino_latency.sum=0,req_lookupname_latency.avgcount=0,req_lookupname_latency.avgtime=0,req_lookupname_latency.sum=0,req_lookupparent_latency.avgcount=0,req_lookupparent_latency.avgtime=0,req_lookupparent_latency.sum=0,req_lookupsnap_latency.avgcount=0,req_lookupsnap_latency.avgtime=0,req_lookupsnap_latency.sum=0,req_lssnap_latency.avgcount=0,req_lssnap_latency.avgtime=0,req_lssnap_latency.sum=0,req_mkdir_latency.avgcount=0,req_mkdir_latency.avgtime=0,req_mkdir_latency.sum=0,req_mknod_latency.avgcount=0,req_mknod_latency.avgtime=0,req_mknod_latency.sum=0,req_mksnap_latency.avgcount=0,req_mksnap_latency.avgtime=0,req_mksnap_latency.sum=0,req_open_latency.avgcount=0,req_open_latency.avgtime=0,req_open_latency.sum=0,req_readdir_latency.avgcount=0,req_readdir_latency.avgtime=0,req_readdir_latency.sum=0,req_rename_latency.avgcount=0,req_rename_latency.avgtime=0,req_rename_latency.sum=0,req_renamesnap_latency.avgcount=0,req_renamesnap_latency.avgtime=0,req_renamesnap_latency.sum=0,req_rmdir_latency.avgcount=0,req_rmdir_latency.avgtime=0,req_rmdir_latency.sum=0,req_rmsnap_latency.avgcount=0,req_rmsnap_latency.avgtime=0,req_rmsnap_latency.sum=0,req_rmxattr_latency.avgcount=0,req_rmxattr_latency.avgtime=0,req_rmxattr_latency.sum=0,req_setattr_latency.avgcount=0,req_setattr_latency.avgtime=0,req_setattr_latency.sum=0,req_setdirlayout_latency.avgcount=0,req_setdirlayout_latency.avgtime=0,req_setdirlayout_latency.sum=0,req_setfilelock_latency.avgcount=0,req_setfilelock_latency.avgtime=0,req_setfilelock_latency.sum=0,req_setlayout_latency.avgcount=0,req_setlayout_latency.avgtime=0,req_setlayout_latency.sum=0,req_setxattr_latency.avgcount=0,req_setxattr_latency.avgtime=0,req_setxattr_latency.sum=0,req_symlink_latency.avgcount=0,req_symlink_latency.avgtime=0,req_symlink_latency.sum=0,req_unlink_latency.avgcount=0,req_unlink_latency.avgtime=0,req_unlink_latency.sum=0 1587117476000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanmds1,id=stefanmds1,type=mds msgr_active_connections=84,msgr_created_connections=68511,msgr_recv_bytes=238078,msgr_recv_messages=2655,msgr_running_fast_dispatch_time=0.004247777,msgr_running_recv_time=25.369012545,msgr_running_send_time=3.743427461,msgr_running_total_time=130.277111559,msgr_send_bytes=172767043,msgr_send_messages=18172 1587117476000000000\n> ceph,collection=mds_log,host=stefanmds1,id=stefanmds1,type=mds ev=0,evadd=0,evex=0,evexd=0,evexg=0,evtrm=0,expos=4194304,jlat.avgcount=0,jlat.avgtime=0,jlat.sum=0,rdpos=4194304,replayed=1,seg=1,segadd=0,segex=0,segexd=0,segexg=0,segtrm=0,wrpos=0 1587117476000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanmds1,id=stefanmds1,type=mds msgr_active_connections=595,msgr_created_connections=943825,msgr_recv_bytes=78618003,msgr_recv_messages=914080,msgr_running_fast_dispatch_time=0.001544386,msgr_running_recv_time=459.627068807,msgr_running_send_time=469.337032316,msgr_running_total_time=2744.084305898,msgr_send_bytes=61684163658,msgr_send_messages=1858008 1587117476000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-mds,host=stefanmds1,id=stefanmds1,type=mds get=1216458,get_or_fail_fail=0,get_or_fail_success=1216458,get_started=0,get_sum=51976882,max=104857600,put=1216458,put_sum=51976882,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117476000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanmds1,id=stefanmds1,type=mds msgr_active_connections=226,msgr_created_connections=42679,msgr_recv_bytes=63140151,msgr_recv_messages=299727,msgr_running_fast_dispatch_time=26.316138629,msgr_running_recv_time=36.969916165,msgr_running_send_time=70.457421128,msgr_running_total_time=226.230019936,msgr_send_bytes=193154464,msgr_send_messages=310481 1587117476000000000\n> ceph,collection=mds,host=stefanmds1,id=stefanmds1,type=mds caps=0,dir_commit=0,dir_fetch=12,dir_merge=0,dir_split=0,exported=0,exported_inodes=0,forward=0,imported=0,imported_inodes=0,inode_max=2147483647,inodes=10,inodes_bottom=3,inodes_expired=0,inodes_pin_tail=0,inodes_pinned=10,inodes_top=7,inodes_with_caps=0,load_cent=0,openino_backtrace_fetch=0,openino_dir_fetch=0,openino_peer_discover=0,q=0,reply=0,reply_latency.avgcount=0,reply_latency.avgtime=0,reply_latency.sum=0,request=0,subtrees=2,traverse=0,traverse_dir_fetch=0,traverse_discover=0,traverse_forward=0,traverse_hit=0,traverse_lock=0,traverse_remote_ino=0 1587117476000000000\n> ceph,collection=purge_queue,host=stefanmds1,id=stefanmds1,type=mds pq_executed=0,pq_executing=0,pq_executing_ops=0 1587117476000000000\n> ceph,collection=throttle-write_buf_throttle,host=stefanmds1,id=stefanmds1,type=mds get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=3758096384,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117476000000000\n> ceph,collection=throttle-write_buf_throttle-0x5624e9377f40,host=stefanmds1,id=stefanmds1,type=mds get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=3758096384,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117476000000000\n> ceph,collection=mds_cache,host=stefanmds1,id=stefanmds1,type=mds ireq_enqueue_scrub=0,ireq_exportdir=0,ireq_flush=0,ireq_fragmentdir=0,ireq_fragstats=0,ireq_inodestats=0,num_recovering_enqueued=0,num_recovering_prioritized=0,num_recovering_processing=0,num_strays=0,num_strays_delayed=0,num_strays_enqueuing=0,recovery_completed=0,recovery_started=0,strays_created=0,strays_enqueued=0,strays_migrated=0,strays_reintegrated=0 1587117476000000000\n> ceph,collection=throttle-objecter_bytes,host=stefanmds1,id=stefanmds1,type=mds get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=104857600,put=16,put_sum=1016,take=33,take_sum=1016,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117476000000000\n> ceph,collection=throttle-objecter_ops,host=stefanmds1,id=stefanmds1,type=mds get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=1024,put=33,put_sum=33,take=33,take_sum=33,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117476000000000\n> ceph,collection=mds_mem,host=stefanmds1,id=stefanmds1,type=mds cap=0,cap+=0,cap-=0,dir=12,dir+=12,dir-=0,dn=10,dn+=10,dn-=0,heap=322284,ino=13,ino+=13,ino-=0,rss=76032 1587117476000000000\n> ceph,collection=finisher-PurgeQueue,host=stefanmds1,id=stefanmds1,type=mds complete_latency.avgcount=4,complete_latency.avgtime=0.000176985,complete_latency.sum=0.000707941,queue_len=0 1587117476000000000\n> ceph,collection=cct,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw total_workers=0,unhealthy_workers=0 1587117156000000000\n> ceph,collection=throttle-objecter_bytes,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=791732,get_or_fail_fail=0,get_or_fail_success=791732,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=rgw,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw cache_hit=0,cache_miss=791706,failed_req=0,get=0,get_b=0,get_initial_lat.avgcount=0,get_initial_lat.avgtime=0,get_initial_lat.sum=0,keystone_token_cache_hit=0,keystone_token_cache_miss=0,pubsub_event_lost=0,pubsub_event_triggered=0,pubsub_events=0,pubsub_push_failed=0,pubsub_push_ok=0,pubsub_push_pending=0,pubsub_store_fail=0,pubsub_store_ok=0,put=0,put_b=0,put_initial_lat.avgcount=0,put_initial_lat.avgtime=0,put_initial_lat.sum=0,qactive=0,qlen=0,req=791705 1587117156000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-radosclient,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=2697988,get_or_fail_fail=0,get_or_fail_success=2697988,get_started=0,get_sum=444563051,max=104857600,put=2697988,put_sum=444563051,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=finisher-radosclient,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw complete_latency.avgcount=2,complete_latency.avgtime=0.003530161,complete_latency.sum=0.007060323,queue_len=0 1587117156000000000\n> ceph,collection=throttle-rgw_async_rados_ops,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=0,get_or_fail_fail=0,get_or_fail_success=0,get_started=0,get_sum=0,max=64,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=throttle-objecter_ops,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=791732,get_or_fail_fail=0,get_or_fail_success=791732,get_started=0,get_sum=791732,max=24576,put=791732,put_sum=791732,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=throttle-objecter_bytes-0x5598969981c0,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=1637900,get_or_fail_fail=0,get_or_fail_success=1637900,get_started=0,get_sum=0,max=104857600,put=0,put_sum=0,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=objecter,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw command_active=0,command_resend=0,command_send=0,linger_active=8,linger_ping=1905736,linger_resend=4,linger_send=13,map_epoch=203,map_full=0,map_inc=17,omap_del=0,omap_rd=0,omap_wr=0,op=2697488,op_active=0,op_laggy=0,op_pg=0,op_r=791730,op_reply=2697476,op_resend=1,op_rmw=0,op_send=2697490,op_send_bytes=362,op_w=1905758,osd_laggy=5,osd_session_close=59558,osd_session_open=59566,osd_sessions=8,osdop_append=0,osdop_call=1,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=8,osdop_delete=0,osdop_getxattr=0,osdop_mapext=0,osdop_notify=0,osdop_other=791714,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=16,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=791706,osdop_truncate=0,osdop_watch=1905750,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=0,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117156000000000\n> ceph,collection=AsyncMessenger::Worker-2,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw msgr_active_connections=11,msgr_created_connections=59839,msgr_recv_bytes=342697143,msgr_recv_messages=1441603,msgr_running_fast_dispatch_time=161.807937536,msgr_running_recv_time=118.174064257,msgr_running_send_time=207.679154333,msgr_running_total_time=698.527662129,msgr_send_bytes=530785909,msgr_send_messages=1679950 1587117156000000000\n> ceph,collection=mempool,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw bloom_filter_bytes=0,bloom_filter_items=0,bluefs_bytes=0,bluefs_items=0,bluestore_alloc_bytes=0,bluestore_alloc_items=0,bluestore_cache_data_bytes=0,bluestore_cache_data_items=0,bluestore_cache_onode_bytes=0,bluestore_cache_onode_items=0,bluestore_cache_other_bytes=0,bluestore_cache_other_items=0,bluestore_fsck_bytes=0,bluestore_fsck_items=0,bluestore_txc_bytes=0,bluestore_txc_items=0,bluestore_writing_bytes=0,bluestore_writing_deferred_bytes=0,bluestore_writing_deferred_items=0,bluestore_writing_items=0,buffer_anon_bytes=225471,buffer_anon_items=163,buffer_meta_bytes=0,buffer_meta_items=0,mds_co_bytes=0,mds_co_items=0,osd_bytes=0,osd_items=0,osd_mapbl_bytes=0,osd_mapbl_items=0,osd_pglog_bytes=0,osd_pglog_items=0,osdmap_bytes=33904,osdmap_items=278,osdmap_mapping_bytes=0,osdmap_mapping_items=0,pgmap_bytes=0,pgmap_items=0,unittest_1_bytes=0,unittest_1_items=0,unittest_2_bytes=0,unittest_2_items=0 1587117156000000000\n> ceph,collection=throttle-msgr_dispatch_throttler-radosclient-0x559896998120,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=1652935,get_or_fail_fail=0,get_or_fail_success=1652935,get_started=0,get_sum=276333029,max=104857600,put=1652935,put_sum=276333029,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=AsyncMessenger::Worker-1,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw msgr_active_connections=17,msgr_created_connections=84859,msgr_recv_bytes=211170759,msgr_recv_messages=922646,msgr_running_fast_dispatch_time=31.487443762,msgr_running_recv_time=83.190789333,msgr_running_send_time=174.670510496,msgr_running_total_time=484.22086275,msgr_send_bytes=1322113179,msgr_send_messages=1636839 1587117156000000000\n> ceph,collection=finisher-radosclient-0x559896998080,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw complete_latency.avgcount=0,complete_latency.avgtime=0,complete_latency.sum=0,queue_len=0 1587117156000000000\n> ceph,collection=throttle-objecter_ops-0x559896997b80,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw get=1637900,get_or_fail_fail=0,get_or_fail_success=1637900,get_started=0,get_sum=1637900,max=24576,put=1637900,put_sum=1637900,take=0,take_sum=0,val=0,wait.avgcount=0,wait.avgtime=0,wait.sum=0 1587117156000000000\n> ceph,collection=AsyncMessenger::Worker-0,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw msgr_active_connections=18,msgr_created_connections=74757,msgr_recv_bytes=489001094,msgr_recv_messages=1986686,msgr_running_fast_dispatch_time=168.60950961,msgr_running_recv_time=142.903031533,msgr_running_send_time=267.911165712,msgr_running_total_time=824.885614951,msgr_send_bytes=707973504,msgr_send_messages=2463727 1587117156000000000\n> ceph,collection=objecter-0x559896997720,host=stefanrgw1,id=rgw.stefanrgw1.4219.94113851143184,type=rgw command_active=0,command_resend=0,command_send=0,linger_active=0,linger_ping=0,linger_resend=0,linger_send=0,map_epoch=203,map_full=0,map_inc=8,omap_del=0,omap_rd=0,omap_wr=0,op=1637998,op_active=0,op_laggy=0,op_pg=0,op_r=1062803,op_reply=1637998,op_resend=15,op_rmw=0,op_send=1638013,op_send_bytes=63321099,op_w=575195,osd_laggy=0,osd_session_close=125555,osd_session_open=125563,osd_sessions=8,osdop_append=0,osdop_call=1637886,osdop_clonerange=0,osdop_cmpxattr=0,osdop_create=0,osdop_delete=0,osdop_getxattr=0,osdop_mapext=0,osdop_notify=0,osdop_other=112,osdop_pgls=0,osdop_pgls_filter=0,osdop_read=0,osdop_resetxattrs=0,osdop_rmxattr=0,osdop_setxattr=0,osdop_sparse_read=0,osdop_src_cmpxattr=0,osdop_stat=0,osdop_truncate=0,osdop_watch=0,osdop_write=0,osdop_writefull=0,osdop_writesame=0,osdop_zero=0,poolop_active=0,poolop_resend=0,poolop_send=0,poolstat_active=0,poolstat_resend=0,poolstat_send=0,statfs_active=0,statfs_resend=0,statfs_send=0 1587117156000000000\n```\n',image:R.a},{id:"cgroup",name:"CGroup",markdown:'# CGroup Input Plugin\n\nThis input plugin will capture specific statistics per cgroup.\n\nConsider restricting paths to the set of cgroups you really\nwant to monitor if you have a large number of cgroups, to avoid\nany cardinality issues.\n\nFollowing file formats are supported:\n\n* Single value\n\n```\nVAL\\n\n```\n\n* New line separated values\n\n```\nVAL0\\n\nVAL1\\n\n```\n\n* Space separated values\n\n```\nVAL0 VAL1 ...\\n\n```\n\n* New line separated key-space-value\'s\n\n```\nKEY0 VAL0\\n\nKEY1 VAL1\\n\n```\n\n\n### Tags:\n\nAll measurements have the following tags:\n  - path\n\n\n### Configuration:\n\n```toml\n# Read specific statistics per cgroup\n# [[inputs.cgroup]]\n  ## Directories in which to look for files, globs are supported.\n  ## Consider restricting paths to the set of cgroups you really\n  ## want to monitor if you have a large number of cgroups, to avoid\n  ## any cardinality issues.\n  # paths = [\n  #   "/sys/fs/cgroup/memory",\n  #   "/sys/fs/cgroup/memory/child1",\n  #   "/sys/fs/cgroup/memory/child2/*",\n  # ]\n  ## cgroup stat fields, as file names, globs are supported.\n  ## these file names are appended to each path from above.\n  # files = ["memory.*usage*", "memory.limit_in_bytes"]\n```\n\n### usage examples:\n\n```toml\n# [[inputs.cgroup]]\n  # paths = [\n  #   "/sys/fs/cgroup/cpu",              # root cgroup\n  #   "/sys/fs/cgroup/cpu/*",            # all container cgroups\n  #   "/sys/fs/cgroup/cpu/*/*",          # all children cgroups under each container cgroup\n  # ]\n  # files = ["cpuacct.usage", "cpu.cfs_period_us", "cpu.cfs_quota_us"]\n\n# [[inputs.cgroup]]\n  # paths = [\n  #   "/sys/fs/cgroup/unified/*",        # root cgroup\n  # ]\n  # files = ["*"]\n```\n',image:z.a},{id:"chrony",name:"chrony",markdown:"# chrony Input Plugin\n\nGet standard chrony metrics, requires chronyc executable.\n\nBelow is the documentation of the various headers returned by `chronyc tracking`.\n\n- Reference ID - This is the refid and name (or IP address) if available, of the\nserver to which the computer is currently synchronised. If this is 127.127.1.1\nit means the computer is not synchronised to any external source and that you\nhave the ‘local’ mode operating (via the local command in chronyc (see section local),\nor the local directive in the ‘/etc/chrony.conf’ file (see section local)).\n- Stratum - The stratum indicates how many hops away from a computer with an attached\nreference clock we are. Such a computer is a stratum-1 computer, so the computer in the\nexample is two hops away (i.e. a.b.c is a stratum-2 and is synchronised from a stratum-1).\n- Ref time - This is the time (UTC) at which the last measurement from the reference\nsource was processed.\n- System time - In normal operation, chronyd never steps the system clock, because any\njump in the timescale can have adverse consequences for certain application programs.\nInstead, any error in the system clock is corrected by slightly speeding up or slowing\ndown the system clock until the error has been removed, and then returning to the system\nclock’s normal speed. A consequence of this is that there will be a period when the\nsystem clock (as read by other programs using the gettimeofday() system call, or by the\ndate command in the shell) will be different from chronyd's estimate of the current true\ntime (which it reports to NTP clients when it is operating in server mode). The value\nreported on this line is the difference due to this effect.\n- Last offset - This is the estimated local offset on the last clock update.\n- RMS offset - This is a long-term average of the offset value.\n- Frequency - The ‘frequency’ is the rate by which the system’s clock would be\nwrong if chronyd was not correcting it. It is expressed in ppm (parts per million).\nFor example, a value of 1ppm would mean that when the system’s clock thinks it has\nadvanced 1 second, it has actually advanced by 1.000001 seconds relative to true time.\n- Residual freq - This shows the ‘residual frequency’ for the currently selected\nreference source. This reflects any difference between what the measurements from the\nreference source indicate the frequency should be and the frequency currently being used.\nThe reason this is not always zero is that a smoothing procedure is applied to the\nfrequency. Each time a measurement from the reference source is obtained and a new\nresidual frequency computed, the estimated accuracy of this residual is compared with the\nestimated accuracy (see ‘skew’ next) of the existing frequency value. A weighted average\nis computed for the new frequency, with weights depending on these accuracies. If the\nmeasurements from the reference source follow a consistent trend, the residual will be\ndriven to zero over time.\n- Skew - This is the estimated error bound on the frequency.\n- Root delay - This is the total of the network path delays to the stratum-1 computer\nfrom which the computer is ultimately synchronised. In certain extreme situations, this\nvalue can be negative. (This can arise in a symmetric peer arrangement where the computers’\nfrequencies are not tracking each other and the network delay is very short relative to the\nturn-around time at each computer.)\n- Root dispersion - This is the total dispersion accumulated through all the computers\nback to the stratum-1 computer from which the computer is ultimately synchronised.\nDispersion is due to system clock resolution, statistical measurement variations etc.\n- Leap status - This is the leap status, which can be Normal, Insert second,\nDelete second or Not synchronised.\n\n### Configuration:\n\n```toml\n# Get standard chrony metrics, requires chronyc executable.\n[[inputs.chrony]]\n  ## If true, chronyc tries to perform a DNS lookup for the time server.\n  # dns_lookup = false\n```\n\n### Measurements & Fields:\n\n- chrony\n    - system_time (float, seconds)\n    - last_offset (float, seconds)\n    - rms_offset (float, seconds)\n    - frequency (float, ppm)\n    - residual_freq (float, ppm)\n    - skew (float, ppm)\n    - root_delay (float, seconds)\n    - root_dispersion (float, seconds)\n    - update_interval (float, seconds)\n\n### Tags:\n\n- All measurements have the following tags:\n    - reference_id\n    - stratum\n    - leap_status\n\n### Example Output:\n\n```\n$ telegraf --config telegraf.conf --input-filter chrony --test\n* Plugin: chrony, Collection 1\n> chrony,leap_status=normal,reference_id=192.168.1.1,stratum=3 frequency=-35.657,system_time=0.000027073,last_offset=-0.000013616,residual_freq=-0,rms_offset=0.000027073,root_delay=0.000644,root_dispersion=0.003444,skew=0.001,update_interval=1031.2 1463750789687639161\n```\n\n\n\n\n",image:F.a},{id:"cisco_telemetry_mdt",name:"Cisco Model-Driven Telemetry (MDT)",markdown:'# Cisco model-driven telemetry (MDT) Input Plugin\n\nCisco model-driven telemetry (MDT) is an input plugin that consumes\ntelemetry data from Cisco IOS XR, IOS XE and NX-OS platforms. It supports TCP & GRPC dialout transports.\nRPC-based transport can utilize TLS for authentication and encryption.\nTelemetry data is expected to be GPB-KV (self-describing-gpb) encoded.\n\nThe GRPC dialout transport is supported on various IOS XR (64-bit) 6.1.x and later, IOS XE 16.10 and later, as well as NX-OS 7.x and later platforms.\n\nThe TCP dialout transport is supported on IOS XR (32-bit and 64-bit) 6.1.x and later.\n\n\n### Configuration:\n\n```toml\n[[inputs.cisco_telemetry_mdt]]\n ## Telemetry transport can be "tcp" or "grpc".  TLS is only supported when\n ## using the grpc transport.\n transport = "grpc"\n\n ## Address and port to host telemetry listener\n service_address = ":57000"\n\n ## Grpc Maximum Message Size, default is 4MB, increase the size.\n max_msg_size = 20000000\n\n ## Enable TLS; grpc transport only.\n # tls_cert = "/etc/telegraf/cert.pem"\n # tls_key = "/etc/telegraf/key.pem"\n\n ## Enable TLS client authentication and define allowed CA certificates; grpc\n ##  transport only.\n # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n ## Define (for certain nested telemetry measurements with embedded tags) which fields are tags\n # embedded_tags = ["Cisco-IOS-XR-qos-ma-oper:qos/interface-table/interface/input/service-policy-names/service-policy-instance/statistics/class-stats/class-name"]\n\n ## Define aliases to map telemetry encoding paths to simple measurement names\n [inputs.cisco_telemetry_mdt.aliases]\n   ifstats = "ietf-interfaces:interfaces-state/interface/statistics"\n [inputs.cisco_telemetry_mdt.dmes]\n#    Global Property Xformation.\n#    prop1 = "uint64 to int"\n#    prop2 = "uint64 to string"\n#    prop3 = "string to uint64"\n#    prop4 = "string to int64"\n#    prop5 = "string to float64"\n#    auto-prop-xfrom = "auto-float-xfrom" #Xform any property which is string, and has float number to type float64\n#    Per Path property xformation, Name is telemetry configuration under sensor-group, path configuration "WORD         Distinguished Name"\n#    Per Path configuration is better as it avoid property collision issue of types.\n#    dnpath = \'{"Name": "show ip route summary","prop": [{"Key": "routes","Value": "string"}, {"Key": "best-paths","Value": "string"}]}\'\n#    dnpath2 = \'{"Name": "show processes cpu","prop": [{"Key": "kernel_percent","Value": "float"}, {"Key": "idle_percent","Value": "float"}, {"Key": "process","Value": "string"}, {"Key": "user_percent","Value": "float"}, {"Key": "onesec","Value": "float"}]}\'\n#    dnpath3 = \'{"Name": "show processes memory physical","prop": [{"Key": "processname","Value": "string"}]}\'\n```\n\n### Example Output:\n```\nifstats,path=ietf-interfaces:interfaces-state/interface/statistics,host=linux,name=GigabitEthernet2,source=csr1kv,subscription=101 in-unicast-pkts=27i,in-multicast-pkts=0i,discontinuity-time="2019-05-23T07:40:23.000362+00:00",in-octets=5233i,in-errors=0i,out-multicast-pkts=0i,out-discards=0i,in-broadcast-pkts=0i,in-discards=0i,in-unknown-protos=0i,out-unicast-pkts=0i,out-broadcast-pkts=0i,out-octets=0i,out-errors=0i 1559150462624000000\nifstats,path=ietf-interfaces:interfaces-state/interface/statistics,host=linux,name=GigabitEthernet1,source=csr1kv,subscription=101 in-octets=3394770806i,in-broadcast-pkts=0i,in-multicast-pkts=0i,out-broadcast-pkts=0i,in-unknown-protos=0i,out-octets=350212i,in-unicast-pkts=9477273i,in-discards=0i,out-unicast-pkts=2726i,out-discards=0i,discontinuity-time="2019-05-23T07:40:23.000363+00:00",in-errors=30i,out-multicast-pkts=0i,out-errors=0i 1559150462624000000\n```\n\n### NX-OS Configuration Example:\n```\nRequirement      DATA-SOURCE   Configuration\n-----------------------------------------\nEnvironment      DME           path sys/ch query-condition query-target=subtree&target-subtree-class=eqptPsuSlot,eqptFtSlot,eqptSupCSlot,eqptPsu,eqptFt,eqptSensor,eqptLCSlot\n                 DME           path sys/ch depth 5  (Another configuration option)\nEnvironment      NXAPI         show environment power\n                 NXAPI         show environment fan\n                 NXAPI         show environment temperature\nInterface Stats  DME           path sys/intf query-condition query-target=subtree&target-subtree-class=rmonIfIn,rmonIfOut,rmonIfHCIn,rmonIfHCOut,rmonEtherStats\nInterface State  DME           path sys/intf depth unbounded query-condition query-target=subtree&target-subtree-class=l1PhysIf,pcAggrIf,l3EncRtdIf,l3LbRtdIf,ethpmPhysIf\nVPC              DME           path sys/vpc query-condition query-target=subtree&target-subtree-class=vpcDom,vpcIf\nResources cpu    DME           path sys/procsys query-condition query-target=subtree&target-subtree-class=procSystem,procSysCore,procSysCpuSummary,procSysCpu,procIdle,procIrq,procKernel,procNice,procSoftirq,procTotal,procUser,procWait,procSysCpuHistory,procSysLoad\nResources Mem    DME           path sys/procsys/sysmem/sysmemused\n                               path sys/procsys/sysmem/sysmemusage\n                               path sys/procsys/sysmem/sysmemfree\nPer Process cpu  DME           path sys/proc depth unbounded query-condition rsp-foreign-subtree=ephemeral\nvxlan(svi stats) DME           path sys/bd query-condition query-target=subtree&target-subtree-class=l2VlanStats\nBGP              DME           path sys/bgp query-condition query-target=subtree&target-subtree-class=bgpDom,bgpPeer,bgpPeerAf,bgpDomAf,bgpPeerAfEntry,bgpOperRtctrlL3,bgpOperRttP,bgpOperRttEntry,bgpOperAfCtrl\nmac dynamic      DME           path sys/mac query-condition query-target=subtree&target-subtree-class=l2MacAddressTable\nbfd              DME           path sys/bfd/inst depth unbounded\nlldp             DME           path sys/lldp depth unbounded\nurib             DME           path sys/urib depth unbounded query-condition rsp-foreign-subtree=ephemeral\nu6rib            DME           path sys/u6rib depth unbounded query-condition rsp-foreign-subtree=ephemeral\nmulticast flow   DME           path sys/mca/show/flows depth unbounded\nmulticast stats  DME           path sys/mca/show/stats depth unbounded\nmulticast igmp   NXAPI         show ip igmp groups vrf all\nmulticast igmp   NXAPI         show ip igmp interface vrf all\nmulticast igmp   NXAPI         show ip igmp snooping\nmulticast igmp   NXAPI         show ip igmp snooping groups\nmulticast igmp   NXAPI         show ip igmp snooping groups detail\nmulticast igmp   NXAPI         show ip igmp snooping groups summary\nmulticast igmp   NXAPI         show ip igmp snooping mrouter\nmulticast igmp   NXAPI         show ip igmp snooping statistics        \nmulticast pim    NXAPI         show ip pim interface vrf all\nmulticast pim    NXAPI         show ip pim neighbor vrf all\nmulticast pim    NXAPI         show ip pim route vrf all\nmulticast pim    NXAPI         show ip pim rp vrf all\nmulticast pim    NXAPI         show ip pim statistics vrf all\nmulticast pim    NXAPI         show ip pim vrf all\n\n\n```\n',image:j.a},{id:"clickhouse",name:"ClickHouse",markdown:'# ClickHouse Input Plugin\n\nThis plugin gathers the statistic data from [ClickHouse](https://github.com/ClickHouse/ClickHouse) server.\n\n### Configuration\n```toml\n# Read metrics from one or many ClickHouse servers\n[[inputs.clickhouse]]\n  ## Username for authorization on ClickHouse server\n  ## example: username = "default"\n  username = "default"\n\n  ## Password for authorization on ClickHouse server\n  ## example: password = "super_secret"\n\n  ## HTTP(s) timeout while getting metrics values\n  ## The timeout includes connection time, any redirects, and reading the response body.\n  ##   example: timeout = 1s\n  # timeout = 5s\n\n  ## List of servers for metrics scraping\n  ## metrics scrape via HTTP(s) clickhouse interface\n  ## https://clickhouse.tech/docs/en/interfaces/http/\n  ##    example: servers = ["http://127.0.0.1:8123","https://custom-server.mdb.yandexcloud.net"]\n  servers         = ["http://127.0.0.1:8123"]\n\n  ## If "auto_discovery"" is "true" plugin tries to connect to all servers available in the cluster\n  ## with using same "user:password" described in "user" and "password" parameters\n  ## and get this server hostname list from "system.clusters" table\n  ## see\n  ## - https://clickhouse.tech/docs/en/operations/system_tables/#system-clusters\n  ## - https://clickhouse.tech/docs/en/operations/server_settings/settings/#server_settings_remote_servers\n  ## - https://clickhouse.tech/docs/en/operations/table_engines/distributed/\n  ## - https://clickhouse.tech/docs/en/operations/table_engines/replication/#creating-replicated-tables\n  ##    example: auto_discovery = false\n  # auto_discovery = true\n\n  ## Filter cluster names in "system.clusters" when "auto_discovery" is "true"\n  ## when this filter present then "WHERE cluster IN (...)" filter will apply\n  ## please use only full cluster names here, regexp and glob filters is not allowed\n  ## for "/etc/clickhouse-server/config.d/remote.xml"\n  ## <yandex>\n  ##  <remote_servers>\n  ##    <my-own-cluster>\n  ##        <shard>\n  ##          <replica><host>clickhouse-ru-1.local</host><port>9000</port></replica>\n  ##          <replica><host>clickhouse-ru-2.local</host><port>9000</port></replica>\n  ##        </shard>\n  ##        <shard>\n  ##          <replica><host>clickhouse-eu-1.local</host><port>9000</port></replica>\n  ##          <replica><host>clickhouse-eu-2.local</host><port>9000</port></replica>\n  ##        </shard>\n  ##    </my-onw-cluster>\n  ##  </remote_servers>\n  ##\n  ## </yandex>\n  ##\n  ## example: cluster_include = ["my-own-cluster"]\n  # cluster_include = []\n\n  ## Filter cluster names in "system.clusters" when "auto_discovery" is "true"\n  ## when this filter present then "WHERE cluster NOT IN (...)" filter will apply\n  ##    example: cluster_exclude = ["my-internal-not-discovered-cluster"]\n  # cluster_exclude = []\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- clickhouse_events\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - all rows from [system.events][]\n\n+ clickhouse_metrics\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - all rows from [system.metrics][]\n\n- clickhouse_asynchronous_metrics\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - all rows from [system.asynchronous_metrics][]\n\n+ clickhouse_tables\n  - tags:\n    - source (ClickHouse server hostname)\n    - table\n    - database\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - bytes\n    - parts\n    - rows\n\n- clickhouse_zookeeper\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - root_nodes (count of node from [system.zookeeper][] where path=/)   \n\n+ clickhouse_replication_queue\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - too_many_tries_replicas (count of replicas which have  num_tries > 1 in `system.replication_queue`)\n\n- clickhouse_detached_parts\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - detached_parts (total detached parts for all tables and databases from [system.detached_parts][])\n    \n+ clickhouse_dictionaries\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n    - dict_origin (xml Filename when dictionary created from *_dictionary.xml, database.table when dictionary created from DDL)\n  - fields:\n    - is_loaded (0 - when dictionary data not successful load, 1 - when dictionary data loading fail, see [system.dictionaries][] for details)\n    - bytes_allocated (how many bytes allocated in RAM after a dictionary loaded)\n\n- clickhouse_mutations\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - running - gauge which show how much mutation doesn\'t complete now, see [system.mutations][] for details\n    - failed - counter which show total failed mutations from first clickhouse-server run\n    - completed - counter which show total successful finished mutations from first clickhouse-server run\n\n+ clickhouse_disks\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n    - name (disk name in storage configuration)\n    - path (path to disk)\n  - fields:\n    - free_space_percent - 0-100, gauge which show current percent of free disk space bytes relative to total disk space bytes        \n    - keep_free_space_percent - 0-100, gauge which show current percent of required keep free disk bytes relative to total disk space bytes             \n\n- clickhouse_processes\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n  - fields:\n    - percentile_50 - float gauge which show 50% percentile (quantile 0.5) for `elapsed` field of running processes, see [system.processes][] for details     \n    - percentile_90 - float gauge which show 90% percentile (quantile 0.9) for `elapsed` field of running processes, see [system.processes][] for details     \n    - longest_running - float gauge which show maximum value for `elapsed` field of running processes, see [system.processes][] for details\n\n- clickhouse_text_log\n  - tags:\n    - source (ClickHouse server hostname)\n    - cluster (Name of the cluster [optional])\n    - shard_num (Shard number in the cluster [optional])\n    - level (message level, only message with level less or equal Notice is collects), see details on [system.text_log][]   \n  - fields:\n    - messages_last_10_min - gauge which show how many messages collected\n           \n### Example Output\n\n```\nclickhouse_events,cluster=test_cluster_two_shards_localhost,host=kshvakov,source=localhost,shard_num=1 read_compressed_bytes=212i,arena_alloc_chunks=35i,function_execute=85i,merge_tree_data_writer_rows=3i,rw_lock_acquired_read_locks=421i,file_open=46i,io_buffer_alloc_bytes=86451985i,inserted_bytes=196i,regexp_created=3i,real_time_microseconds=116832i,query=23i,network_receive_elapsed_microseconds=268i,merge_tree_data_writer_compressed_bytes=1080i,arena_alloc_bytes=212992i,disk_write_elapsed_microseconds=556i,inserted_rows=3i,compressed_read_buffer_bytes=81i,read_buffer_from_file_descriptor_read_bytes=148i,write_buffer_from_file_descriptor_write=47i,merge_tree_data_writer_blocks=3i,soft_page_faults=896i,hard_page_faults=7i,select_query=21i,merge_tree_data_writer_uncompressed_bytes=196i,merge_tree_data_writer_blocks_already_sorted=3i,user_time_microseconds=40196i,compressed_read_buffer_blocks=5i,write_buffer_from_file_descriptor_write_bytes=3246i,io_buffer_allocs=296i,created_write_buffer_ordinary=12i,disk_read_elapsed_microseconds=59347044i,network_send_elapsed_microseconds=1538i,context_lock=1040i,insert_query=1i,system_time_microseconds=14582i,read_buffer_from_file_descriptor_read=3i 1569421000000000000\nclickhouse_asynchronous_metrics,cluster=test_cluster_two_shards_localhost,host=kshvakov,source=localhost,shard_num=1 jemalloc.metadata_thp=0i,replicas_max_relative_delay=0i,jemalloc.mapped=1803177984i,jemalloc.allocated=1724839256i,jemalloc.background_thread.run_interval=0i,jemalloc.background_thread.num_threads=0i,uncompressed_cache_cells=0i,replicas_max_absolute_delay=0i,mark_cache_bytes=0i,compiled_expression_cache_count=0i,replicas_sum_queue_size=0i,number_of_tables=35i,replicas_max_merges_in_queue=0i,replicas_max_inserts_in_queue=0i,replicas_sum_merges_in_queue=0i,replicas_max_queue_size=0i,mark_cache_files=0i,jemalloc.background_thread.num_runs=0i,jemalloc.active=1726210048i,uptime=158i,jemalloc.retained=380481536i,replicas_sum_inserts_in_queue=0i,uncompressed_cache_bytes=0i,number_of_databases=2i,jemalloc.metadata=9207704i,max_part_count_for_partition=1i,jemalloc.resident=1742442496i 1569421000000000000\nclickhouse_metrics,cluster=test_cluster_two_shards_localhost,host=kshvakov,source=localhost,shard_num=1 replicated_send=0i,write=0i,ephemeral_node=0i,zoo_keeper_request=0i,distributed_files_to_insert=0i,replicated_fetch=0i,background_schedule_pool_task=0i,interserver_connection=0i,leader_replica=0i,delayed_inserts=0i,global_thread_active=41i,merge=0i,readonly_replica=0i,memory_tracking_in_background_schedule_pool=0i,memory_tracking_for_merges=0i,zoo_keeper_session=0i,context_lock_wait=0i,storage_buffer_bytes=0i,background_pool_task=0i,send_external_tables=0i,zoo_keeper_watch=0i,part_mutation=0i,disk_space_reserved_for_merge=0i,distributed_send=0i,version_integer=19014003i,local_thread=0i,replicated_checks=0i,memory_tracking=0i,memory_tracking_in_background_processing_pool=0i,leader_election=0i,revision=54425i,open_file_for_read=0i,open_file_for_write=0i,storage_buffer_rows=0i,rw_lock_waiting_readers=0i,rw_lock_waiting_writers=0i,rw_lock_active_writers=0i,local_thread_active=0i,query_preempted=0i,tcp_connection=1i,http_connection=1i,read=2i,query_thread=0i,dict_cache_requests=0i,rw_lock_active_readers=1i,global_thread=43i,query=1i 1569421000000000000\nclickhouse_tables,cluster=test_cluster_two_shards_localhost,database=system,host=kshvakov,source=localhost,shard_num=1,table=trace_log bytes=754i,parts=1i,rows=1i 1569421000000000000\nclickhouse_tables,cluster=test_cluster_two_shards_localhost,database=default,host=kshvakov,source=localhost,shard_num=1,table=example bytes=326i,parts=2i,rows=2i 1569421000000000000\n```\n\n[system.events]: https://clickhouse.tech/docs/en/operations/system-tables/events/\n[system.metrics]: https://clickhouse.tech/docs/en/operations/system-tables/metrics/\n[system.asynchronous_metrics]: https://clickhouse.tech/docs/en/operations/system-tables/asynchronous_metrics/\n[system.zookeeper]: https://clickhouse.tech/docs/en/operations/system-tables/zookeeper/ \n[system.detached_parts]: https://clickhouse.tech/docs/en/operations/system-tables/detached_parts/\n[system.dictionaries]: https://clickhouse.tech/docs/en/operations/system-tables/dictionaries/  \n[system.mutations]: https://clickhouse.tech/docs/en/operations/system-tables/mutations/  \n[system.disks]: https://clickhouse.tech/docs/en/operations/system-tables/disks/  \n[system.processes]: https://clickhouse.tech/docs/en/operations/system-tables/processes/  \n[system.text_log]: https://clickhouse.tech/docs/en/operations/system-tables/text_log/  \n',image:W.a},{id:"cloud_pubsub",name:"Google Cloud PubSub",markdown:'# Google Cloud PubSub Input Plugin\n\nThe GCP PubSub plugin ingests metrics from [Google Cloud PubSub][pubsub]\nand creates metrics using one of the supported [input data formats][].\n\n\n### Configuration\n\n```toml\n[[inputs.cloud_pubsub]]\n  ## Required. Name of Google Cloud Platform (GCP) Project that owns\n  ## the given PubSub subscription.\n  project = "my-project"\n\n  ## Required. Name of PubSub subscription to ingest metrics from.\n  subscription = "my-subscription"\n\n  ## Required. Data format to consume.\n  ## Each data format has its own unique set of configuration options.\n  ## Read more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n\n  ## Optional. Filepath for GCP credentials JSON file to authorize calls to\n  ## PubSub APIs. If not set explicitly, Telegraf will attempt to use\n  ## Application Default Credentials, which is preferred.\n  # credentials_file = "path/to/my/creds.json"\n\n  ## Optional. Number of seconds to wait before attempting to restart the \n  ## PubSub subscription receiver after an unexpected error. \n  ## If the streaming pull for a PubSub Subscription fails (receiver),\n  ## the agent attempts to restart receiving messages after this many seconds.\n  # retry_delay_seconds = 5\n\n  ## Optional. Maximum byte length of a message to consume.\n  ## Larger messages are dropped with an error. If less than 0 or unspecified,\n  ## treated as no limit.\n  # max_message_len = 1000000\n\n  ## Optional. Maximum messages to read from PubSub that have not been written\n  ## to an output. Defaults to %d.\n  ## For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message contains 10 metrics and the output\n  ## metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## The following are optional Subscription ReceiveSettings in PubSub.\n  ## Read more about these values:\n  ## https://godoc.org/cloud.google.com/go/pubsub#ReceiveSettings\n\n  ## Optional. Maximum number of seconds for which a PubSub subscription\n  ## should auto-extend the PubSub ACK deadline for each message. If less than\n  ## 0, auto-extension is disabled.\n  # max_extension = 0\n\n  ## Optional. Maximum number of unprocessed messages in PubSub\n  ## (unacknowledged but not yet expired in PubSub).\n  ## A value of 0 is treated as the default PubSub value.\n  ## Negative values will be treated as unlimited.\n  # max_outstanding_messages = 0\n\n  ## Optional. Maximum size in bytes of unprocessed messages in PubSub\n  ## (unacknowledged but not yet expired in PubSub).\n  ## A value of 0 is treated as the default PubSub value.\n  ## Negative values will be treated as unlimited.\n  # max_outstanding_bytes = 0\n\n  ## Optional. Max number of goroutines a PubSub Subscription receiver can spawn\n  ## to pull messages from PubSub concurrently. This limit applies to each\n  ## subscription separately and is treated as the PubSub default if less than\n  ## 1. Note this setting does not limit the number of messages that can be\n  ## processed concurrently (use "max_outstanding_messages" instead).\n  # max_receiver_go_routines = 0\n\n  ## Optional. If true, Telegraf will attempt to base64 decode the \n  ## PubSub message data before parsing. Many GCP services that\n  ## output JSON to Google PubSub base64-encode the JSON payload.\n  # base64_data = false\n```\n\n### Multiple Subscriptions and Topics\n\nThis plugin assumes you have already created a PULL subscription for a given\nPubSub topic. To learn how to do so, see [how to create a subscription][pubsub create sub].\n\nEach plugin agent can listen to one subscription at a time, so you will\nneed to run multiple instances of the plugin to pull messages from multiple\nsubscriptions/topics.\n\n\n\n[pubsub]: https://cloud.google.com/pubsub\n[pubsub create sub]: https://cloud.google.com/pubsub/docs/admin#create_a_pull_subscription\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n',image:V.a},{id:"cloud_pubsub_push",name:"Google Cloud PubSub Push",markdown:'# Google Cloud PubSub Push Input Plugin\n\nThe Google Cloud PubSub Push listener is a service input plugin that listens for messages sent via an HTTP POST from [Google Cloud PubSub][pubsub].\nThe plugin expects messages in Google\'s Pub/Sub JSON Format ONLY.\nThe intent of the plugin is to allow Telegraf to serve as an endpoint of the Google Pub/Sub \'Push\' service.\nGoogle\'s PubSub service will **only** send over HTTPS/TLS so this plugin must be behind a valid proxy or must be configured to use TLS.\n\nEnable TLS by specifying the file names of a service TLS certificate and key.\n\nEnable mutually authenticated TLS and authorize client connections by signing certificate authority by including a list of allowed CA certificate file names in `tls_allowed_cacerts`.\n\n\n### Configuration:\n\nThis is a sample configuration for the plugin.\n\n```toml\n[[inputs.cloud_pubsub_push]]\n  ## Address and port to host HTTP listener on\n  service_address = ":8080"\n\n  ## Application secret to verify messages originate from Cloud Pub/Sub\n  # token = ""\n\n  ## Path to listen to.\n  # path = "/"\n\n  ## Maximum duration before timing out read of the request\n  # read_timeout = "10s"\n  ## Maximum duration before timing out write of the response. This should be set to a value\n  ## large enough that you can send at least \'metric_batch_size\' number of messages within the\n  ## duration.\n  # write_timeout = "10s"\n\n  ## Maximum allowed http request body size in bytes.\n  ## 0 means to use the default of 524,288,00 bytes (500 mebibytes)\n  # max_body_size = "500MB"\n\n  ## Whether to add the pubsub metadata, such as message attributes and subscription as a tag.\n  # add_meta = false\n\n  ## Optional. Maximum messages to read from PubSub that have not been written\n  ## to an output. Defaults to 1000.\n  ## For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message contains 10 metrics and the output\n  ## metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Set one or more allowed client CA certificate file names to\n  ## enable mutually authenticated TLS connections\n  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n  ## Add service certificate and key\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\nThis plugin assumes you have already created a PUSH subscription for a given\nPubSub topic.\n\n[pubsub]: https://cloud.google.com/pubsub\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n',image:Q.a},{id:"cloudwatch",name:"Amazon CloudWatch Statistics",markdown:'# Amazon CloudWatch Statistics Input Plugin\n\nThis plugin will pull Metric Statistics from Amazon CloudWatch.\n\n### Amazon Authentication\n\nThis plugin uses a credential chain for Authentication with the CloudWatch\nAPI endpoint. In the following order the plugin will attempt to authenticate.\n1. Assumed credentials via STS if `role_arn` attribute is specified (source credentials are evaluated from subsequent rules)\n2. Explicit credentials from `access_key`, `secret_key`, and `token` attributes\n3. Shared profile from `profile` attribute\n4. [Environment Variables](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#environment-variables)\n5. [Shared Credentials](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#shared-credentials-file)\n6. [EC2 Instance Profile](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html)\n\n### Configuration:\n\n```toml\n# Pull Metric Statistics from Amazon CloudWatch\n[[inputs.cloudwatch]]\n  ## Amazon Region\n  region = "us-east-1"\n\n  ## Amazon Credentials\n  ## Credentials are loaded in the following order\n  ## 1) Assumed credentials via STS if role_arn is specified\n  ## 2) explicit credentials from \'access_key\' and \'secret_key\'\n  ## 3) shared profile from \'profile\'\n  ## 4) environment variables\n  ## 5) shared credentials file\n  ## 6) EC2 Instance Profile\n  # access_key = ""\n  # secret_key = ""\n  # token = ""\n  # role_arn = ""\n  # profile = ""\n  # shared_credential_file = ""\n\n  ## Endpoint to make request against, the correct endpoint is automatically\n  ## determined and this option should only be set if you wish to override the\n  ## default.\n  ##   ex: endpoint_url = "http://localhost:8000"\n  # endpoint_url = ""\n\n  ## Set http_proxy (telegraf uses the system wide proxy settings if it\'s is not set)\n  # http_proxy_url = "http://localhost:8888"\n\n  # The minimum period for Cloudwatch metrics is 1 minute (60s). However not all\n  # metrics are made available to the 1 minute period. Some are collected at\n  # 3 minute, 5 minute, or larger intervals. See https://aws.amazon.com/cloudwatch/faqs/#monitoring.\n  # Note that if a period is configured that is smaller than the minimum for a\n  # particular metric, that metric will not be returned by the Cloudwatch API\n  # and will not be collected by Telegraf.\n  #\n  ## Requested CloudWatch aggregation Period (required - must be a multiple of 60s)\n  period = "5m"\n\n  ## Collection Delay (required - must account for metrics availability via CloudWatch API)\n  delay = "5m"\n\n  ## Recommended: use metric \'interval\' that is a multiple of \'period\' to avoid\n  ## gaps or overlap in pulled data\n  interval = "5m"\n\n  ## Recommended if "delay" and "period" are both within 3 hours of request time. Invalid values will be ignored.\n  ## Recently Active feature will only poll for CloudWatch ListMetrics values that occurred within the last 3 Hours.\n  ## If enabled, it will reduce total API usage of the CloudWatch ListMetrics API and require less memory to retain.\n  ## Do not enable if "period" or "delay" is longer than 3 hours, as it will not return data more than 3 hours old.\n  ## See https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_ListMetrics.html\n  #recently_active = "PT3H"\n\n  ## Configure the TTL for the internal cache of metrics.\n  # cache_ttl = "1h"\n\n  ## Metric Statistic Namespace (required)\n  namespace = "AWS/ELB"\n\n  ## Maximum requests per second. Note that the global default AWS rate limit is\n  ## 50 reqs/sec, so if you define multiple namespaces, these should add up to a\n  ## maximum of 50.\n  ## See http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_limits.html\n  # ratelimit = 25\n\n  ## Timeout for http requests made by the cloudwatch client.\n  # timeout = "5s"\n\n  ## Namespace-wide statistic filters. These allow fewer queries to be made to\n  ## cloudwatch.\n  # statistic_include = [ "average", "sum", "minimum", "maximum", sample_count" ]\n  # statistic_exclude = []\n\n  ## Metrics to Pull\n  ## Defaults to all Metrics in Namespace if nothing is provided\n  ## Refreshes Namespace available metrics every 1h\n  #[[inputs.cloudwatch.metrics]]\n  #  names = ["Latency", "RequestCount"]\n  #\n  #  ## Statistic filters for Metric.  These allow for retrieving specific\n  #  ## statistics for an individual metric.\n  #  # statistic_include = [ "average", "sum", "minimum", "maximum", sample_count" ]\n  #  # statistic_exclude = []\n  #\n  #  ## Dimension filters for Metric.  All dimensions defined for the metric names\n  #  ## must be specified in order to retrieve the metric statistics.\n  #  ## \'value\' has wildcard / \'glob\' matching support such as \'p-*\'.\n  #  [[inputs.cloudwatch.metrics.dimensions]]\n  #    name = "LoadBalancerName"\n  #    value = "p-example"\n```\n#### Requirements and Terminology\n\nPlugin Configuration utilizes [CloudWatch concepts](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html) and access pattern to allow monitoring of any CloudWatch Metric.\n\n- `region` must be a valid AWS [Region](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#CloudWatchRegions) value\n- `period` must be a valid CloudWatch [Period](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#CloudWatchPeriods) value\n- `namespace` must be a valid CloudWatch [Namespace](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#Namespace) value\n- `names` must be valid CloudWatch [Metric](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#Metric) names\n- `dimensions` must be valid CloudWatch [Dimension](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/cloudwatch_concepts.html#Dimension) name/value pairs\n\nOmitting or specifying a value of `\'*\'` for a dimension value configures all available metrics that contain a dimension with the specified name\nto be retrieved. If specifying >1 dimension, then the metric must contain *all* the configured dimensions where the the value of the\nwildcard dimension is ignored.\n\nExample:\n```\n[[inputs.cloudwatch]]\n  period = "1m"\n  interval = "5m"\n\n  [[inputs.cloudwatch.metrics]]\n    names = ["Latency"]\n\n    ## Dimension filters for Metric (optional)\n    [[inputs.cloudwatch.metrics.dimensions]]\n      name = "LoadBalancerName"\n      value = "p-example"\n\n    [[inputs.cloudwatch.metrics.dimensions]]\n      name = "AvailabilityZone"\n      value = "*"\n```\n\nIf the following ELBs are available:\n- name: `p-example`, availabilityZone: `us-east-1a`\n- name: `p-example`, availabilityZone: `us-east-1b`\n- name: `q-example`, availabilityZone: `us-east-1a`\n- name: `q-example`, availabilityZone: `us-east-1b`\n\n\nThen 2 metrics will be output:\n- name: `p-example`, availabilityZone: `us-east-1a`\n- name: `p-example`, availabilityZone: `us-east-1b`\n\nIf the `AvailabilityZone` wildcard dimension was omitted, then a single metric (name: `p-example`)\nwould be exported containing the aggregate values of the ELB across availability zones.\n\nTo maximize efficiency and savings, consider making fewer requests by increasing `interval` but keeping `period` at the duration you would like metrics to be reported. The above example will request metrics from Cloudwatch every 5 minutes but will output five metrics timestamped one minute apart.\n\n#### Restrictions and Limitations\n- CloudWatch metrics are not available instantly via the CloudWatch API. You should adjust your collection `delay` to account for this lag in metrics availability based on your [monitoring subscription level](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-cloudwatch-new.html)\n- CloudWatch API usage incurs cost - see [GetMetricData Pricing](https://aws.amazon.com/cloudwatch/pricing/)\n\n### Measurements & Fields:\n\nEach CloudWatch Namespace monitored records a measurement with fields for each available Metric Statistic.\nNamespace and Metrics are represented in [snake case](https://en.wikipedia.org/wiki/Snake_case)\n\n- cloudwatch_{namespace}\n  - {metric}_sum         (metric Sum value)\n  - {metric}_average     (metric Average value)\n  - {metric}_minimum     (metric Minimum value)\n  - {metric}_maximum     (metric Maximum value)\n  - {metric}_sample_count (metric SampleCount value)\n\n\n### Tags:\nEach measurement is tagged with the following identifiers to uniquely identify the associated metric\nTag Dimension names are represented in [snake case](https://en.wikipedia.org/wiki/Snake_case)\n\n- All measurements have the following tags:\n  - region           (CloudWatch Region)\n  - {dimension-name} (Cloudwatch Dimension value - one for each metric dimension)\n\n### Troubleshooting:\n\nYou can use the aws cli to get a list of available metrics and dimensions:\n```\naws cloudwatch list-metrics --namespace AWS/EC2 --region us-east-1\naws cloudwatch list-metrics --namespace AWS/EC2 --region us-east-1 --metric-name CPUCreditBalance\n```\n\nIf the expected metrics are not returned, you can try getting them manually\nfor a short period of time:\n```\naws cloudwatch get-metric-data \\\n  --start-time 2018-07-01T00:00:00Z \\\n  --end-time 2018-07-01T00:15:00Z \\\n  --metric-data-queries \'[\n  {\n    "Id": "avgCPUCreditBalance",\n    "MetricStat": {\n      "Metric": {\n        "Namespace": "AWS/EC2",\n        "MetricName": "CPUCreditBalance",\n        "Dimensions": [\n          {\n            "Name": "InstanceId",\n            "Value": "i-deadbeef"\n          }\n        ]\n      },\n      "Period": 300,\n      "Stat": "Average"\n    },\n    "Label": "avgCPUCreditBalance"\n  }\n]\'\n```\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter cloudwatch --test\n> cloudwatch_aws_elb,load_balancer_name=p-example,region=us-east-1 latency_average=0.004810798017284538,latency_maximum=0.1100282669067383,latency_minimum=0.0006084442138671875,latency_sample_count=4029,latency_sum=19.382705211639404 1459542420000000000\n```\n',image:Y.a},{id:"conntrack",name:"Conntrack",markdown:'# Conntrack Input Plugin\n\nCollects stats from Netfilter\'s conntrack-tools.\n\nThe conntrack-tools provide a mechanism for tracking various aspects of\nnetwork connections as they are processed by netfilter. At runtime, \nconntrack exposes many of those connection statistics within /proc/sys/net.\nDepending on your kernel version, these files can be found in either\n/proc/sys/net/ipv4/netfilter or /proc/sys/net/netfilter and will be\nprefixed with either ip_ or nf_.  This plugin reads the files specified \nin its configuration and publishes each one as a field, with the prefix\nnormalized to ip_.  \n\nIn order to simplify configuration in a heterogeneous environment, a superset\nof directory and filenames can be specified.  Any locations that don\'t exist\nwill be ignored.\n\nFor more information on conntrack-tools, see the \n[Netfilter Documentation](http://conntrack-tools.netfilter.org/).\n\n\n### Configuration:\n\n```toml\n # Collects conntrack stats from the configured directories and files.\n [[inputs.conntrack]]\n   ## The following defaults would work with multiple versions of conntrack.\n   ## Note the nf_ and ip_ filename prefixes are mutually exclusive across\n   ## kernel versions, as are the directory locations.\n\n   ## Superset of filenames to look for within the conntrack dirs.\n   ## Missing files will be ignored.\n   files = ["ip_conntrack_count","ip_conntrack_max",\n            "nf_conntrack_count","nf_conntrack_max"]\n\n   ## Directories to search within for the conntrack files above.\n   ## Missing directories will be ignored.\n   dirs = ["/proc/sys/net/ipv4/netfilter","/proc/sys/net/netfilter"]\n```\n\n### Measurements & Fields:\n\n- conntrack\n    - ip_conntrack_count (int, count): the number of entries in the conntrack table \n    - ip_conntrack_max (int, size): the max capacity of the conntrack table\n\n### Tags:\n\nThis input does not use tags.\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter conntrack --test\nconntrack,host=myhost ip_conntrack_count=2,ip_conntrack_max=262144 1461620427667995735\n```\n',image:J.a},{id:"consul",name:"Consul",markdown:'# Consul Input Plugin\n\nThis plugin will collect statistics about all health checks registered in the\nConsul. It uses [Consul API](https://www.consul.io/docs/agent/http/health.html#health_state)\nto query the data. It will not report the\n[telemetry](https://www.consul.io/docs/agent/telemetry.html) but Consul can\nreport those stats already using StatsD protocol if needed.\n\n### Configuration:\n\n```toml\n# Gather health check statuses from services registered in Consul\n[[inputs.consul]]\n  ## Consul server address\n  # address = "localhost:8500"\n\n  ## URI scheme for the Consul server, one of "http", "https"\n  # scheme = "http"\n\n  ## Metric version controls the mapping from Consul metrics into\n  ## Telegraf metrics. Version 2 moved all fields with string values\n  ## to tags.\n  ##\n  ##   example: metric_version = 1; deprecated in 1.16\n  ##            metric_version = 2; recommended version\n  # metric_version = 1\n\n  ## ACL token used in every request\n  # token = ""\n\n  ## HTTP Basic Authentication username and password.\n  # username = ""\n  # password = ""\n\n  ## Data center to query the health checks from\n  # datacenter = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = true\n\n  ## Consul checks\' tag splitting\n  # When tags are formatted like "key:value" with ":" as a delimiter then\n  # they will be splitted and reported as proper key:value in Telegraf\n  # tag_delimiter = ":"\n```\n\n### Metrics:\n##### metric_version = 1:\n- consul_health_checks\n  - tags:\n  \t- node (node that check/service is registered on)\n  \t- service_name\n  \t- check_id\n  - fields:\n    - check_name\n    - service_id\n    - status\n    - passing (integer)\n    - critical (integer)\n    - warning (integer)\n\n##### metric_version = 2:\n- consul_health_checks\n  - tags:\n  \t- node (node that check/service is registered on)\n  \t- service_name\n  \t- check_id\n  \t- check_name\n    - service_id\n    - status\n  - fields:\n    - passing (integer)\n    - critical (integer)\n    - warning (integer)\n    \n`passing`, `critical`, and `warning` are integer representations of the health\ncheck state. A value of `1` represents that the status was the state of the\nthe health check at this sample. `status` is string representation of the same state.\n\n## Example output\n\n```\nconsul_health_checks,host=wolfpit,node=consul-server-node,check_id="serfHealth" check_name="Serf Health Status",service_id="",status="passing",passing=1i,critical=0i,warning=0i 1464698464486439902\nconsul_health_checks,host=wolfpit,node=consul-server-node,service_name=www.example.com,check_id="service:www-example-com.test01" check_name="Service \'www.example.com\' check",service_id="www-example-com.test01",status="critical",passing=0i,critical=1i,warning=0i 1464698464486519036\n```\n',image:ee.a},{id:"couchbase",name:"Couchbase",markdown:'# Couchbase Input Plugin\nCouchbase is a distributed NoSQL database.\nThis plugin gets metrics for each Couchbase node, as well as detailed metrics for each bucket, for a given couchbase server.\n\n## Configuration:\n\n```toml\n# Read per-node and per-bucket metrics from Couchbase\n[[inputs.couchbase]]\n  ## specify servers via a url matching:\n  ##  [protocol://][:password]@address[:port]\n  ##  e.g.\n  ##    http://couchbase-0.example.com/\n  ##    http://admin:secret@couchbase-0.example.com:8091/\n  ##\n  ## If no servers are specified, then localhost is used as the host.\n  ## If no protocol is specified, HTTP is used.\n  ## If no port is specified, 8091 is used.\n  servers = ["http://localhost:8091"]\n\n  ## Filter bucket fields to include only here.\n  # bucket_stats_included = ["quota_percent_used", "ops_per_sec", "disk_fetches", "item_count", "disk_used", "data_used", "mem_used"]\n```\n\n## Measurements:\n\n### couchbase_node\n\nTags:\n- cluster: sanitized string from `servers` configuration field e.g.: `http://user:password@couchbase-0.example.com:8091/endpoint` -> `http://couchbase-0.example.com:8091/endpoint`\n- hostname: Couchbase\'s name for the node and port, e.g., `172.16.10.187:8091`\n\nFields:\n- memory_free (unit: bytes, example: 23181365248.0)\n- memory_total (unit: bytes, example: 64424656896.0)\n\n### couchbase_bucket\n\nTags:\n- cluster: whatever you called it in `servers` in the configuration, e.g.: `http://couchbase-0.example.com/`)\n- bucket: the name of the couchbase bucket, e.g., `blastro-df`\n\nDefault bucket fields:\n- quota_percent_used (unit: percent, example: 68.85424936294555)\n- ops_per_sec (unit: count, example: 5686.789686789687)\n- disk_fetches (unit: count, example: 0.0)\n- item_count (unit: count, example: 943239752.0)\n- disk_used (unit: bytes, example: 409178772321.0)\n- data_used (unit: bytes, example: 212179309111.0)\n- mem_used (unit: bytes, example: 202156957464.0)\n\nAdditional fields that can be configured with the `bucket_stats_included` option:\n- couch_total_disk_size                    \n- couch_docs_fragmentation\n- couch_views_fragmentation\n- hit_ratio\n- ep_cache_miss_rate\n- ep_resident_items_rate\n- vb_avg_active_queue_age\n- vb_avg_replica_queue_age\n- vb_avg_pending_queue_age\n- vb_avg_total_queue_age\n- vb_active_resident_items_ratio\n- vb_replica_resident_items_ratio\n- vb_pending_resident_items_ratio\n- avg_disk_update_time\n- avg_disk_commit_time\n- avg_bg_wait_time\n- avg_active_timestamp_drift\n- avg_replica_timestamp_drift\n- ep_dcp_views+indexes_count\n- ep_dcp_views+indexes_items_remaining\n- ep_dcp_views+indexes_producer_count\n- ep_dcp_views+indexes_total_backlog_size\n- ep_dcp_views+indexes_items_sent\n- ep_dcp_views+indexes_total_bytes\n- ep_dcp_views+indexes_backoff\n- bg_wait_count\n- bg_wait_total\n- bytes_read\n- bytes_written\n- cas_badval\n- cas_hits\n- cas_misses\n- cmd_get\n- cmd_lookup\n- cmd_set\n- couch_docs_actual_disk_size\n- couch_docs_data_size\n- couch_docs_disk_size\n- couch_spatial_data_size\n- couch_spatial_disk_size\n- couch_spatial_ops\n- couch_views_actual_disk_size\n- couch_views_data_size\n- couch_views_disk_size\n- couch_views_ops\n- curr_connections\n- curr_items\n- curr_items_tot\n- decr_hits\n- decr_misses\n- delete_hits\n- delete_misses\n- disk_commit_count\n- disk_commit_total\n- disk_update_count\n- disk_update_total\n- disk_write_queue\n- ep_active_ahead_exceptions\n- ep_active_hlc_drift\n- ep_active_hlc_drift_count\n- ep_bg_fetched\n- ep_clock_cas_drift_threshold_exceeded\n- ep_data_read_failed\n- ep_data_write_failed\n- ep_dcp_2i_backoff\n- ep_dcp_2i_count\n- ep_dcp_2i_items_remaining\n- ep_dcp_2i_items_sent\n- ep_dcp_2i_producer_count\n- ep_dcp_2i_total_backlog_size\n- ep_dcp_2i_total_bytes\n- ep_dcp_cbas_backoff\n- ep_dcp_cbas_count\n- ep_dcp_cbas_items_remaining\n- ep_dcp_cbas_items_sent\n- ep_dcp_cbas_producer_count\n- ep_dcp_cbas_total_backlog_size\n- ep_dcp_cbas_total_bytes\n- ep_dcp_eventing_backoff\n- ep_dcp_eventing_count\n- ep_dcp_eventing_items_remaining\n- ep_dcp_eventing_items_sent\n- ep_dcp_eventing_producer_count\n- ep_dcp_eventing_total_backlog_size\n- ep_dcp_eventing_total_bytes\n- ep_dcp_fts_backoff\n- ep_dcp_fts_count\n- ep_dcp_fts_items_remaining\n- ep_dcp_fts_items_sent\n- ep_dcp_fts_producer_count\n- ep_dcp_fts_total_backlog_size\n- ep_dcp_fts_total_bytes\n- ep_dcp_other_backoff\n- ep_dcp_other_count\n- ep_dcp_other_items_remaining\n- ep_dcp_other_items_sent\n- ep_dcp_other_producer_count\n- ep_dcp_other_total_backlog_size\n- ep_dcp_other_total_bytes\n- ep_dcp_replica_backoff\n- ep_dcp_replica_count\n- ep_dcp_replica_items_remaining\n- ep_dcp_replica_items_sent\n- ep_dcp_replica_producer_count\n- ep_dcp_replica_total_backlog_size\n- ep_dcp_replica_total_bytes\n- ep_dcp_views_backoff\n- ep_dcp_views_count\n- ep_dcp_views_items_remaining\n- ep_dcp_views_items_sent\n- ep_dcp_views_producer_count\n- ep_dcp_views_total_backlog_size\n- ep_dcp_views_total_bytes\n- ep_dcp_xdcr_backoff\n- ep_dcp_xdcr_count\n- ep_dcp_xdcr_items_remaining\n- ep_dcp_xdcr_items_sent\n- ep_dcp_xdcr_producer_count\n- ep_dcp_xdcr_total_backlog_size\n- ep_dcp_xdcr_total_bytes\n- ep_diskqueue_drain\n- ep_diskqueue_fill\n- ep_diskqueue_items\n- ep_flusher_todo\n- ep_item_commit_failed\n- ep_kv_size\n- ep_max_size\n- ep_mem_high_wat\n- ep_mem_low_wat\n- ep_meta_data_memory\n- ep_num_non_resident\n- ep_num_ops_del_meta\n- ep_num_ops_del_ret_meta\n- ep_num_ops_get_meta\n- ep_num_ops_set_meta\n- ep_num_ops_set_ret_meta\n- ep_num_value_ejects\n- ep_oom_errors\n- ep_ops_create\n- ep_ops_update\n- ep_overhead\n- ep_queue_size\n- ep_replica_ahead_exceptions\n- ep_replica_hlc_drift\n- ep_replica_hlc_drift_count\n- ep_tmp_oom_errors\n- ep_vb_total\n- evictions\n- get_hits\n- get_misses\n- incr_hits\n- incr_misses\n- mem_used\n- misses\n- ops\n- timestamp\n- vb_active_eject\n- vb_active_itm_memory\n- vb_active_meta_data_memory\n- vb_active_num\n- vb_active_num_non_resident\n- vb_active_ops_create\n- vb_active_ops_update\n- vb_active_queue_age\n- vb_active_queue_drain\n- vb_active_queue_fill\n- vb_active_queue_size\n- vb_active_sync_write_aborted_count\n- vb_active_sync_write_accepted_count\n- vb_active_sync_write_committed_count\n- vb_pending_curr_items\n- vb_pending_eject\n- vb_pending_itm_memory\n- vb_pending_meta_data_memory\n- vb_pending_num\n- vb_pending_num_non_resident\n- vb_pending_ops_create\n- vb_pending_ops_update\n- vb_pending_queue_age\n- vb_pending_queue_drain\n- vb_pending_queue_fill\n- vb_pending_queue_size\n- vb_replica_curr_items\n- vb_replica_eject\n- vb_replica_itm_memory\n- vb_replica_meta_data_memory\n- vb_replica_num\n- vb_replica_num_non_resident\n- vb_replica_ops_create\n- vb_replica_ops_update\n- vb_replica_queue_age\n- vb_replica_queue_drain\n- vb_replica_queue_fill\n- vb_replica_queue_size\n- vb_total_queue_age\n- xdc_ops\n- allocstall\n- cpu_cores_available\n- cpu_irq_rate\n- cpu_stolen_rate\n- cpu_sys_rate\n- cpu_user_rate\n- cpu_utilization_rate\n- hibernated_requests\n- hibernated_waked\n- mem_actual_free\n- mem_actual_used\n- mem_free\n- mem_limit\n- mem_total\n- mem_used_sys\n- odp_report_failed\n- rest_requests\n- swap_total\n- swap_used\n\n\n## Example output\n\n```\ncouchbase_node,cluster=http://localhost:8091/,hostname=172.17.0.2:8091 memory_free=7705575424,memory_total=16558182400 1547829754000000000\ncouchbase_bucket,bucket=beer-sample,cluster=http://localhost:8091/ quota_percent_used=27.09285736083984,ops_per_sec=0,disk_fetches=0,item_count=7303,disk_used=21662946,data_used=9325087,mem_used=28408920 1547829754000000000\n```\n',image:ne.a},{id:"couchdb",name:"CouchDB",markdown:'# CouchDB Input Plugin\n\nThe CouchDB plugin gathers metrics of CouchDB using [_stats] endpoint.\n\n### Configuration\n\n```toml\n[[inputs.couchdb]]\n  ## Works with CouchDB stats endpoints out of the box\n  ## Multiple Hosts from which to read CouchDB stats:\n  hosts = ["http://localhost:8086/_stats"]\n\n  ## Use HTTP Basic Authentication.\n  # basic_username = "telegraf"\n  # basic_password = "p@ssw0rd"\n```\n\n### Measurements & Fields:\n\nStatistics specific to the internals of CouchDB:\n\n- couchdb_auth_cache_misses\n- couchdb_database_writes\n- couchdb_open_databases\n- couchdb_auth_cache_hits\n- couchdb_request_time\n- couchdb_database_reads\n- couchdb_open_os_files\n\nStatistics of HTTP requests by method:\n\n- httpd_request_methods_put\n- httpd_request_methods_get\n- httpd_request_methods_copy\n- httpd_request_methods_delete\n- httpd_request_methods_post\n- httpd_request_methods_head\n\nStatistics of HTTP requests by response code:\n\n- httpd_status_codes_200\n- httpd_status_codes_201\n- httpd_status_codes_202\n- httpd_status_codes_301\n- httpd_status_codes_304\n- httpd_status_codes_400\n- httpd_status_codes_401\n- httpd_status_codes_403\n- httpd_status_codes_404\n- httpd_status_codes_405\n- httpd_status_codes_409\n- httpd_status_codes_412\n- httpd_status_codes_500\n\nhttpd statistics:\n\n- httpd_clients_requesting_changes\n- httpd_temporary_view_reads\n- httpd_requests\n- httpd_bulk_requests\n- httpd_view_reads\n\n### Tags:\n\n- server (url of the couchdb _stats endpoint)\n\n### Example output:\n\n**Post Couchdb 2.0**\n```\ncouchdb,server=http://couchdb22:5984/_node/_local/_stats couchdb_auth_cache_hits_value=0,httpd_request_methods_delete_value=0,couchdb_auth_cache_misses_value=0,httpd_request_methods_get_value=42,httpd_status_codes_304_value=0,httpd_status_codes_400_value=0,httpd_request_methods_head_value=0,httpd_status_codes_201_value=0,couchdb_database_reads_value=0,httpd_request_methods_copy_value=0,couchdb_request_time_max=0,httpd_status_codes_200_value=42,httpd_status_codes_301_value=0,couchdb_open_os_files_value=2,httpd_request_methods_put_value=0,httpd_request_methods_post_value=0,httpd_status_codes_202_value=0,httpd_status_codes_403_value=0,httpd_status_codes_409_value=0,couchdb_database_writes_value=0,couchdb_request_time_min=0,httpd_status_codes_412_value=0,httpd_status_codes_500_value=0,httpd_status_codes_401_value=0,httpd_status_codes_404_value=0,httpd_status_codes_405_value=0,couchdb_open_databases_value=0 1536707179000000000\n```\n\n**Pre Couchdb 2.0**\n```\ncouchdb,server=http://couchdb16:5984/_stats couchdb_request_time_sum=96,httpd_status_codes_200_sum=37,httpd_status_codes_200_min=0,httpd_requests_mean=0.005,httpd_requests_min=0,couchdb_request_time_stddev=3.833,couchdb_request_time_min=1,httpd_request_methods_get_stddev=0.073,httpd_request_methods_get_min=0,httpd_status_codes_200_mean=0.005,httpd_status_codes_200_max=1,httpd_requests_sum=37,couchdb_request_time_current=96,httpd_request_methods_get_sum=37,httpd_request_methods_get_mean=0.005,httpd_request_methods_get_max=1,httpd_status_codes_200_stddev=0.073,couchdb_request_time_mean=2.595,couchdb_request_time_max=25,httpd_request_methods_get_current=37,httpd_status_codes_200_current=37,httpd_requests_current=37,httpd_requests_stddev=0.073,httpd_requests_max=1 1536707179000000000\n```\n\n[_stats]: http://docs.couchdb.org/en/1.6.1/api/server/common.html?highlight=stats#get--_stats\n',image:ae.a},{id:"cpu",name:"CPU",markdown:"# CPU Input Plugin\n\nThe `cpu` plugin gather metrics on the system CPUs.\n\n#### Configuration\n```toml\n# Read metrics about cpu usage\n[[inputs.cpu]]\n  ## Whether to report per-cpu stats or not\n  percpu = true\n  ## Whether to report total system cpu stats or not\n  totalcpu = true\n  ## If true, collect raw CPU time metrics\n  collect_cpu_time = false\n  ## If true, compute and report the sum of all non-idle CPU states\n  report_active = false\n```\n\n### Metrics\n\nOn Linux, consult `man proc` for details on the meanings of these values.\n\n- cpu\n  - tags:\n    - cpu (CPU ID or `cpu-total`)\n  - fields:\n    - time_user (float)\n    - time_system (float)\n    - time_idle (float)\n    - time_active (float)\n    - time_nice (float)\n    - time_iowait (float)\n    - time_irq (float)\n    - time_softirq (float)\n    - time_steal (float)\n    - time_guest (float)\n    - time_guest_nice (float)\n    - usage_user (float, percent)\n    - usage_system (float, percent)\n    - usage_idle (float, percent)\n    - usage_active (float)\n    - usage_nice (float, percent)\n    - usage_iowait (float, percent)\n    - usage_irq (float, percent)\n    - usage_softirq (float, percent)\n    - usage_steal (float, percent)\n    - usage_guest (float, percent)\n    - usage_guest_nice (float, percent)\n\n### Troubleshooting\n\nOn Linux systems the `/proc/stat` file is used to gather CPU times.\nPercentages are based on the last 2 samples.\n\n### Example Output\n\n```\ncpu,cpu=cpu0,host=loaner time_active=202224.15999999992,time_guest=30250.35,time_guest_nice=0,time_idle=1527035.04,time_iowait=1352,time_irq=0,time_nice=169.28,time_softirq=6281.4,time_steal=0,time_system=40097.14,time_user=154324.34 1568760922000000000\ncpu,cpu=cpu0,host=loaner usage_active=31.249999981810106,usage_guest=2.083333333080696,usage_guest_nice=0,usage_idle=68.7500000181899,usage_iowait=0,usage_irq=0,usage_nice=0,usage_softirq=0,usage_steal=0,usage_system=4.166666666161392,usage_user=25.000000002273737 1568760922000000000\ncpu,cpu=cpu1,host=loaner time_active=201890.02000000002,time_guest=30508.41,time_guest_nice=0,time_idle=264641.18,time_iowait=210.44,time_irq=0,time_nice=181.75,time_softirq=4537.88,time_steal=0,time_system=39480.7,time_user=157479.25 1568760922000000000\ncpu,cpu=cpu1,host=loaner usage_active=12.500000010610771,usage_guest=2.0833333328280585,usage_guest_nice=0,usage_idle=87.49999998938922,usage_iowait=0,usage_irq=0,usage_nice=0,usage_softirq=2.0833333332070145,usage_steal=0,usage_system=4.166666665656117,usage_user=4.166666666414029 1568760922000000000\ncpu,cpu=cpu2,host=loaner time_active=201382.78999999998,time_guest=30325.8,time_guest_nice=0,time_idle=264686.63,time_iowait=202.77,time_irq=0,time_nice=162.81,time_softirq=3378.34,time_steal=0,time_system=39270.59,time_user=158368.28 1568760922000000000\ncpu,cpu=cpu2,host=loaner usage_active=15.999999993480742,usage_guest=1.9999999999126885,usage_guest_nice=0,usage_idle=84.00000000651926,usage_iowait=0,usage_irq=0,usage_nice=0,usage_softirq=2.0000000002764864,usage_steal=0,usage_system=3.999999999825377,usage_user=7.999999998923158 1568760922000000000\ncpu,cpu=cpu3,host=loaner time_active=198953.51000000007,time_guest=30344.43,time_guest_nice=0,time_idle=265504.09,time_iowait=187.64,time_irq=0,time_nice=197.47,time_softirq=2301.47,time_steal=0,time_system=39313.73,time_user=156953.2 1568760922000000000\ncpu,cpu=cpu3,host=loaner usage_active=10.41666667424579,usage_guest=0,usage_guest_nice=0,usage_idle=89.58333332575421,usage_iowait=0,usage_irq=0,usage_nice=0,usage_softirq=0,usage_steal=0,usage_system=4.166666666666667,usage_user=6.249999998484175 1568760922000000000\ncpu,cpu=cpu-total,host=loaner time_active=804450.5299999998,time_guest=121429,time_guest_nice=0,time_idle=2321866.96,time_iowait=1952.86,time_irq=0,time_nice=711.32,time_softirq=16499.1,time_steal=0,time_system=158162.17,time_user=627125.08 1568760922000000000\ncpu,cpu=cpu-total,host=loaner usage_active=17.616580305880305,usage_guest=1.036269430422946,usage_guest_nice=0,usage_idle=82.3834196941197,usage_iowait=0,usage_irq=0,usage_nice=0,usage_softirq=1.0362694300459534,usage_steal=0,usage_system=4.145077721691784,usage_user=11.398963731636465 1568760922000000000\n```\n",image:oe.a},{id:"csgo",name:"Counter-Strike: Global Offensive (CSGO)",markdown:'# Counter-Strike: Global Offensive (CSGO) Input Plugin\n\nThe `csgo` plugin gather metrics from Counter-Strike: Global Offensive servers.\n\n#### Configuration\n```toml\n# Fetch metrics from a CSGO SRCDS\n[[inputs.csgo]]\n  ## Specify servers using the following format:\n  ##    servers = [\n  ##      ["ip1:port1", "rcon_password1"],\n  ##      ["ip2:port2", "rcon_password2"],\n  ##    ]\n  #\n  ## If no servers are specified, no data will be collected\n  servers = []\n```\n\n### Metrics\n\nThe plugin retrieves the output of the `stats` command that is executed via rcon.\n\nIf no servers are specified, no data will be collected\n\n- csgo\n  - tags:\n    - host\n  - fields:\n    - cpu (float)\n    - net_in (float)\n    - net_out (float)\n    - uptime_minutes (float)\n    - maps (float)\n    - fps (float)\n    - players (float)\n    - sv_ms (float)\n    - variance_ms (float)\n    - tick_ms (float)\n',image:ce.a},{id:"dcos",name:"DC/OS",markdown:'# DC/OS Input Plugin\n\nThis input plugin gathers metrics from a DC/OS cluster\'s [metrics component](https://docs.mesosphere.com/1.10/metrics/).\n\n**Series Cardinality Warning**\n\nDepending on the work load of your DC/OS cluster, this plugin can quickly\ncreate a high number of series which, when unchecked, can cause high load on\nyour database.\n\n- Use the\n  [measurement filtering](https://docs.influxdata.com/telegraf/latest/administration/configuration/#measurement-filtering)\n  options to exclude unneeded tags.\n- Write to a database with an appropriate\n  [retention policy](https://docs.influxdata.com/influxdb/latest/guides/downsampling_and_retention/).\n- Consider using the\n  [Time Series Index](https://docs.influxdata.com/influxdb/latest/concepts/time-series-index/).\n- Monitor your databases\n  [series cardinality](https://docs.influxdata.com/influxdb/latest/query_language/spec/#show-cardinality).\n\n### Configuration:\n```toml\n[[inputs.dcos]]\n  ## The DC/OS cluster URL.\n  cluster_url = "https://dcos-master-1"\n\n  ## The ID of the service account.\n  service_account_id = "telegraf"\n  ## The private key file for the service account.\n  service_account_private_key = "/etc/telegraf/telegraf-sa-key.pem"\n\n  ## Path containing login token.  If set, will read on every gather.\n  # token_file = "/home/dcos/.dcos/token"\n\n  ## In all filter options if both include and exclude are empty all items\n  ## will be collected.  Arrays may contain glob patterns.\n  ##\n  ## Node IDs to collect metrics from.  If a node is excluded, no metrics will\n  ## be collected for its containers or apps.\n  # node_include = []\n  # node_exclude = []\n  ## Container IDs to collect container metrics from.\n  # container_include = []\n  # container_exclude = []\n  ## Container IDs to collect app metrics from.\n  # app_include = []\n  # app_exclude = []\n\n  ## Maximum concurrent connections to the cluster.\n  # max_connections = 10\n  ## Maximum time to receive a response from cluster.\n  # response_timeout = "20s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## If false, skip chain & host verification\n  # insecure_skip_verify = true\n\n  ## Recommended filtering to reduce series cardinality.\n  # [inputs.dcos.tagdrop]\n  #   path = ["/var/lib/mesos/slave/slaves/*"]\n```\n\n#### Enterprise Authentication\n\nWhen using Enterprise DC/OS, it is recommended to use a service account to\nauthenticate with the cluster.\n\nThe plugin requires the following permissions:\n```\ndcos:adminrouter:ops:system-metrics full\ndcos:adminrouter:ops:mesos full\n```\n\nFollow the directions to [create a service account and assign permissions](https://docs.mesosphere.com/1.10/security/service-auth/custom-service-auth/).\n\nQuick configuration using the Enterprise CLI:\n```\ndcos security org service-accounts keypair telegraf-sa-key.pem telegraf-sa-cert.pem\ndcos security org service-accounts create -p telegraf-sa-cert.pem -d "Telegraf DC/OS input plugin" telegraf\ndcos security org users grant telegraf dcos:adminrouter:ops:system-metrics full\ndcos security org users grant telegraf dcos:adminrouter:ops:mesos full\n```\n\n#### Open Source Authentication\n\nThe Open Source DC/OS does not provide service accounts.  Instead you can use\nof the following options:\n\n1. [Disable authentication](https://dcos.io/docs/1.10/security/managing-authentication/#authentication-opt-out)\n2. Use the `token_file` parameter to read a authentication token from a file.\n\nThen `token_file` can be set by using the [dcos cli] to login periodically.\nThe cli can login for at most XXX days, you will need to ensure the cli\nperforms a new login before this time expires.\n```\ndcos auth login --username foo --password bar\ndcos config show core.dcos_acs_token > ~/.dcos/token\n```\n\nAnother option to create a `token_file` is to generate a token using the\ncluster secret.  This will allow you to set the expiration date manually or\neven create a never expiring token.  However, if the cluster secret or the\ntoken is compromised it cannot be revoked and may require a full reinstall of\nthe cluster.  For more information on this technique reference\n[this blog post](https://medium.com/@richardgirges/authenticating-open-source-dc-os-with-third-party-services-125fa33a5add).\n\n### Metrics:\n\nPlease consult the [Metrics Reference](https://docs.mesosphere.com/1.10/metrics/reference/)\nfor details about field interpretation.\n\n- dcos_node\n  - tags:\n    - cluster\n    - hostname\n    - path (filesystem fields only)\n    - interface (network fields only)\n  - fields:\n    - system_uptime (float)\n    - cpu_cores (float)\n    - cpu_total (float)\n    - cpu_user (float)\n    - cpu_system (float)\n    - cpu_idle (float)\n    - cpu_wait (float)\n    - load_1min (float)\n    - load_5min (float)\n    - load_15min (float)\n    - filesystem_capacity_total_bytes (int)\n    - filesystem_capacity_used_bytes (int)\n    - filesystem_capacity_free_bytes (int)\n    - filesystem_inode_total (float)\n    - filesystem_inode_used (float)\n    - filesystem_inode_free (float)\n    - memory_total_bytes (int)\n    - memory_free_bytes (int)\n    - memory_buffers_bytes (int)\n    - memory_cached_bytes (int)\n    - swap_total_bytes (int)\n    - swap_free_bytes (int)\n    - swap_used_bytes (int)\n    - network_in_bytes (int)\n    - network_out_bytes (int)\n    - network_in_packets (float)\n    - network_out_packets (float)\n    - network_in_dropped (float)\n    - network_out_dropped (float)\n    - network_in_errors (float)\n    - network_out_errors (float)\n    - process_count (float)\n\n- dcos_container\n  - tags:\n    - cluster\n    - hostname\n    - container_id\n    - task_name\n  - fields:\n    - cpus_limit (float)\n    - cpus_system_time (float)\n    - cpus_throttled_time (float)\n    - cpus_user_time (float)\n    - disk_limit_bytes (int)\n    - disk_used_bytes (int)\n    - mem_limit_bytes (int)\n    - mem_total_bytes (int)\n    - net_rx_bytes (int)\n    - net_rx_dropped (float)\n    - net_rx_errors (float)\n    - net_rx_packets (float)\n    - net_tx_bytes (int)\n    - net_tx_dropped (float)\n    - net_tx_errors (float)\n    - net_tx_packets (float)\n\n- dcos_app\n  - tags:\n    - cluster\n    - hostname\n    - container_id\n    - task_name\n  - fields:\n    - fields are application specific\n\n### Example Output:\n\n```\ndcos_node,cluster=enterprise,hostname=192.168.122.18,path=/boot filesystem_capacity_free_bytes=918188032i,filesystem_capacity_total_bytes=1063256064i,filesystem_capacity_used_bytes=145068032i,filesystem_inode_free=523958,filesystem_inode_total=524288,filesystem_inode_used=330 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=dummy0 network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=0i,network_out_dropped=0,network_out_errors=0,network_out_packets=0 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=docker0 network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=0i,network_out_dropped=0,network_out_errors=0,network_out_packets=0 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18 cpu_cores=2,cpu_idle=81.62,cpu_system=4.19,cpu_total=13.670000000000002,cpu_user=9.48,cpu_wait=0,load_15min=0.7,load_1min=0.22,load_5min=0.6,memory_buffers_bytes=970752i,memory_cached_bytes=1830473728i,memory_free_bytes=1178636288i,memory_total_bytes=3975073792i,process_count=198,swap_free_bytes=859828224i,swap_total_bytes=859828224i,swap_used_bytes=0i,system_uptime=18874 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=lo network_in_bytes=1090992450i,network_in_dropped=0,network_in_errors=0,network_in_packets=1546938,network_out_bytes=1090992450i,network_out_dropped=0,network_out_errors=0,network_out_packets=1546938 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,path=/ filesystem_capacity_free_bytes=1668378624i,filesystem_capacity_total_bytes=6641680384i,filesystem_capacity_used_bytes=4973301760i,filesystem_inode_free=3107856,filesystem_inode_total=3248128,filesystem_inode_used=140272 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=minuteman network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=210i,network_out_dropped=0,network_out_errors=0,network_out_packets=3 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=eth0 network_in_bytes=539886216i,network_in_dropped=1,network_in_errors=0,network_in_packets=979808,network_out_bytes=112395836i,network_out_dropped=0,network_out_errors=0,network_out_packets=891239 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=spartan network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=210i,network_out_dropped=0,network_out_errors=0,network_out_packets=3 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,path=/var/lib/docker/overlay filesystem_capacity_free_bytes=1668378624i,filesystem_capacity_total_bytes=6641680384i,filesystem_capacity_used_bytes=4973301760i,filesystem_inode_free=3107856,filesystem_inode_total=3248128,filesystem_inode_used=140272 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=vtep1024 network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=0i,network_out_dropped=0,network_out_errors=0,network_out_packets=0 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,path=/var/lib/docker/plugins filesystem_capacity_free_bytes=1668378624i,filesystem_capacity_total_bytes=6641680384i,filesystem_capacity_used_bytes=4973301760i,filesystem_inode_free=3107856,filesystem_inode_total=3248128,filesystem_inode_used=140272 1511859222000000000\ndcos_node,cluster=enterprise,hostname=192.168.122.18,interface=d-dcos network_in_bytes=0i,network_in_dropped=0,network_in_errors=0,network_in_packets=0,network_out_bytes=0i,network_out_dropped=0,network_out_errors=0,network_out_packets=0 1511859222000000000\ndcos_app,cluster=enterprise,container_id=9a78d34a-3bbf-467e-81cf-a57737f154ee,hostname=192.168.122.18 container_received_bytes_per_sec=0,container_throttled_bytes_per_sec=0 1511859222000000000\ndcos_container,cluster=enterprise,container_id=cbf19b77-3b8d-4bcf-b81f-824b67279629,hostname=192.168.122.18 cpus_limit=0.3,cpus_system_time=307.31,cpus_throttled_time=102.029930607,cpus_user_time=268.57,disk_limit_bytes=268435456i,disk_used_bytes=30953472i,mem_limit_bytes=570425344i,mem_total_bytes=13316096i,net_rx_bytes=0i,net_rx_dropped=0,net_rx_errors=0,net_rx_packets=0,net_tx_bytes=0i,net_tx_dropped=0,net_tx_errors=0,net_tx_packets=0 1511859222000000000\ndcos_app,cluster=enterprise,container_id=cbf19b77-3b8d-4bcf-b81f-824b67279629,hostname=192.168.122.18 container_received_bytes_per_sec=0,container_throttled_bytes_per_sec=0 1511859222000000000\ndcos_container,cluster=enterprise,container_id=5725e219-f66e-40a8-b3ab-519d85f4c4dc,hostname=192.168.122.18,task_name=hello-world cpus_limit=0.6,cpus_system_time=25.6,cpus_throttled_time=327.977109217,cpus_user_time=566.54,disk_limit_bytes=0i,disk_used_bytes=0i,mem_limit_bytes=1107296256i,mem_total_bytes=335941632i,net_rx_bytes=0i,net_rx_dropped=0,net_rx_errors=0,net_rx_packets=0,net_tx_bytes=0i,net_tx_dropped=0,net_tx_errors=0,net_tx_packets=0 1511859222000000000\ndcos_app,cluster=enterprise,container_id=5725e219-f66e-40a8-b3ab-519d85f4c4dc,hostname=192.168.122.18 container_received_bytes_per_sec=0,container_throttled_bytes_per_sec=0 1511859222000000000\ndcos_app,cluster=enterprise,container_id=c76e1488-4fb7-4010-a4cf-25725f8173f9,hostname=192.168.122.18 container_received_bytes_per_sec=0,container_throttled_bytes_per_sec=0 1511859222000000000\ndcos_container,cluster=enterprise,container_id=cbe0b2f9-061f-44ac-8f15-4844229e8231,hostname=192.168.122.18,task_name=telegraf cpus_limit=0.2,cpus_system_time=8.109999999,cpus_throttled_time=93.183916045,cpus_user_time=17.97,disk_limit_bytes=0i,disk_used_bytes=0i,mem_limit_bytes=167772160i,mem_total_bytes=0i,net_rx_bytes=0i,net_rx_dropped=0,net_rx_errors=0,net_rx_packets=0,net_tx_bytes=0i,net_tx_dropped=0,net_tx_errors=0,net_tx_packets=0 1511859222000000000\ndcos_container,cluster=enterprise,container_id=b64115de-3d2a-431d-a805-76e7c46453f1,hostname=192.168.122.18 cpus_limit=0.2,cpus_system_time=2.69,cpus_throttled_time=20.064861214,cpus_user_time=6.56,disk_limit_bytes=268435456i,disk_used_bytes=29360128i,mem_limit_bytes=297795584i,mem_total_bytes=13733888i,net_rx_bytes=0i,net_rx_dropped=0,net_rx_errors=0,net_rx_packets=0,net_tx_bytes=0i,net_tx_dropped=0,net_tx_errors=0,net_tx_packets=0 1511859222000000000\ndcos_app,cluster=enterprise,container_id=b64115de-3d2a-431d-a805-76e7c46453f1,hostname=192.168.122.18 container_received_bytes_per_sec=0,container_throttled_bytes_per_sec=0 1511859222000000000\n```\n',image:le.a},{id:"directory_monitor",name:"Directory Monitor",markdown:'# Directory Monitor Input Plugin\n\nThis plugin monitors a single directory (without looking at sub-directories), and takes in each file placed in the directory.\nThe plugin will gather all files in the directory at a configurable interval (`monitor_interval`), and parse the ones that haven\'t been picked up yet.\n\nThis plugin is intended to read files that are moved or copied to the monitored directory, and thus files should also not be used by another process or else they may fail to be gathered. Please be advised that this plugin pulls files directly after they\'ve been in the directory for the length of the configurable `directory_duration_threshold`, and thus files should not be written \'live\' to the monitored directory. If you absolutely must write files directly, they must be guaranteed to finish writing before the `directory_duration_threshold`.\n\n### Configuration:\n\n```toml\n[[inputs.directory_monitor]]\n  ## The directory to monitor and read files from.\n  directory = ""\n  #\n  ## The directory to move finished files to.\n  finished_directory = ""\n  #\n  ## The directory to move files to upon file error.\n  ## If not provided, erroring files will stay in the monitored directory.\n  # error_directory = ""\n  #\n  ## The amount of time a file is allowed to sit in the directory before it is picked up.\n  ## This time can generally be low but if you choose to have a very large file written to the directory and it\'s potentially slow,\n  ## set this higher so that the plugin will wait until the file is fully copied to the directory.\n  # directory_duration_threshold = "50ms" \n  #\n  ## A list of the only file names to monitor, if necessary. Supports regex. If left blank, all files are ingested.\n  # files_to_monitor = ["^.*\\.csv"]\n  #\n  ## A list of files to ignore, if necessary. Supports regex.\n  # files_to_ignore = [".DS_Store"]\n  #\n  ## Maximum lines of the file to process that have not yet be written by the\n  ## output. For best throughput set to the size of the output\'s metric_buffer_limit.\n  ## Warning: setting this number higher than the output\'s metric_buffer_limit can cause dropped metrics.\n  # max_buffered_metrics = 10000\n  #\n  ## The maximum amount of file paths to queue up for processing at once, before waiting until files are processed to find more files.\n  ## Lowering this value will result in *slightly* less memory use, with a potential sacrifice in speed efficiency, if absolutely necessary.\n  #\tfile_queue_size = 100000\n  #\n  ## The dataformat to be read from the files.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  ## NOTE: We currently only support parsing newline-delimited JSON. See the format here: https://github.com/ndjson/ndjson-spec\n  data_format = "influx"\n```\n',image:de.a},{id:"disk",name:"Disk",markdown:'# Disk Input Plugin\n\nThe disk input plugin gathers metrics about disk usage.\n\nNote that `used_percent` is calculated by doing `used / (used + free)`, _not_\n`used / total`, which is how the unix `df` command does it. See\nhttps://en.wikipedia.org/wiki/Df_(Unix) for more details.\n\n### Configuration:\n\n```toml\n[[inputs.disk]]\n  ## By default stats will be gathered for all mount points.\n  ## Set mount_points will restrict the stats to only the specified mount points.\n  # mount_points = ["/"]\n\n  ## Ignore mount points by filesystem type.\n  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]\n```\n\n#### Docker container\n\nTo monitor the Docker engine host from within a container you will need to\nmount the host\'s filesystem into the container and set the `HOST_PROC`\nenvironment variable to the location of the `/proc` filesystem.  If desired, you can\nalso set the `HOST_MOUNT_PREFIX` environment variable to the prefix containing\nthe `/proc` directory, when present this variable is stripped from the\nreported `path` tag.\n\n```\ndocker run -v /:/hostfs:ro -e HOST_MOUNT_PREFIX=/hostfs -e HOST_PROC=/hostfs/proc telegraf\n```\n\n### Metrics:\n\n- disk\n  - tags:\n    - fstype (filesystem type)\n    - device (device file)\n    - path (mount point path)\n    - mode (whether the mount is rw or ro)\n  - fields:\n    - free (integer, bytes)\n    - total (integer, bytes)\n    - used (integer, bytes)\n    - used_percent (float, percent)\n    - inodes_free (integer, files)\n    - inodes_total (integer, files)\n    - inodes_used (integer, files)\n\n### Troubleshooting\n\nOn Linux, the list of disks is taken from the `/proc/self/mounts` file and a\n[statfs] call is made on the second column.  If any expected filesystems are\nmissing ensure that the `telegraf` user can read these files:\n```\n$ sudo -u telegraf cat /proc/self/mounts | grep sda2\n/dev/sda2 /home ext4 rw,relatime,data=ordered 0 0\n$ sudo -u telegraf stat /home\n```\n\nIt may be desired to use POSIX ACLs to provide additional access:\n```\nsudo setfacl -R -m u:telegraf:X /var/lib/docker/volumes/\n```\n\n### Example Output:\n\n```\ndisk,fstype=hfs,mode=ro,path=/ free=398407520256i,inodes_free=97267461i,inodes_total=121847806i,inodes_used=24580345i,total=499088621568i,used=100418957312i,used_percent=20.131039916242397 1453832006274071563\ndisk,fstype=devfs,mode=rw,path=/dev free=0i,inodes_free=0i,inodes_total=628i,inodes_used=628i,total=185856i,used=185856i,used_percent=100 1453832006274137913\ndisk,fstype=autofs,mode=rw,path=/net free=0i,inodes_free=0i,inodes_total=0i,inodes_used=0i,total=0i,used=0i,used_percent=0 1453832006274157077\ndisk,fstype=autofs,mode=rw,path=/home free=0i,inodes_free=0i,inodes_total=0i,inodes_used=0i,total=0i,used=0i,used_percent=0 1453832006274169688\n```\n\n[statfs]: http://man7.org/linux/man-pages/man2/statfs.2.html\n',image:ge.a},{id:"diskio",name:"DiskIO",markdown:'# DiskIO Input Plugin\n\nThe diskio input plugin gathers metrics about disk traffic and timing.\n\n### Configuration:\n\n```toml\n# Read metrics about disk IO by device\n[[inputs.diskio]]\n  ## By default, telegraf will gather stats for all devices including\n  ## disk partitions.\n  ## Setting devices will restrict the stats to the specified devices.\n  # devices = ["sda", "sdb"]\n  ## Uncomment the following line if you need disk serial numbers.\n  # skip_serial_number = false\n  #\n  ## On systems which support it, device metadata can be added in the form of\n  ## tags.\n  ## Currently only Linux is supported via udev properties. You can view\n  ## available properties for a device by running:\n  ## \'udevadm info -q property -n /dev/sda\'\n  ## Note: Most, but not all, udev properties can be accessed this way. Properties\n  ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.\n  # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]\n  #\n  ## Using the same metadata source as device_tags, you can also customize the\n  ## name of the device via templates.\n  ## The \'name_templates\' parameter is a list of templates to try and apply to\n  ## the device. The template may contain variables in the form of \'$PROPERTY\' or\n  ## \'${PROPERTY}\'. The first template which does not contain any variables not\n  ## present for the device is used as the device name tag.\n  ## The typical use case is for LVM volumes, to get the VG/LV name instead of\n  ## the near-meaningless DM-0 name.\n  # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]\n```\n\n#### Docker container\n\nTo monitor the Docker engine host from within a container you will need to\nmount the host\'s filesystem into the container and set the `HOST_PROC`\nenvironment variable to the location of the `/proc` filesystem.  Additionally,\nit is required to use privileged mode to provide access to `/dev`.\n\nIf you are using the `device_tags` or `name_templates` options, you will need\nto bind mount `/run/udev` into the container.\n\n```\ndocker run --privileged -v /:/hostfs:ro -v /run/udev:/run/udev:ro -e HOST_PROC=/hostfs/proc telegraf\n```\n\n### Metrics:\n\n- diskio\n  - tags:\n    - name (device name)\n    - serial (device serial number)\n  - fields:\n    - reads (integer, counter)\n    - writes (integer, counter)\n    - read_bytes (integer, counter, bytes)\n    - write_bytes (integer, counter, bytes)\n    - read_time (integer, counter, milliseconds)\n    - write_time (integer, counter, milliseconds)\n    - io_time (integer, counter, milliseconds)\n    - weighted_io_time (integer, counter, milliseconds)\n    - iops_in_progress (integer, gauge)\n    - merged_reads (integer, counter)\n    - merged_writes (integer, counter)\n\nOn linux these values correspond to the values in\n[`/proc/diskstats`](https://www.kernel.org/doc/Documentation/ABI/testing/procfs-diskstats)\nand\n[`/sys/block/<dev>/stat`](https://www.kernel.org/doc/Documentation/block/stat.txt).\n\n#### `reads` & `writes`:\n\nThese values increment when an I/O request completes.\n\n#### `read_bytes` & `write_bytes`:\n\nThese values count the number of bytes read from or written to this\nblock device.\n\n#### `read_time` & `write_time`:\n\nThese values count the number of milliseconds that I/O requests have\nwaited on this block device.  If there are multiple I/O requests waiting,\nthese values will increase at a rate greater than 1000/second; for\nexample, if 60 read requests wait for an average of 30 ms, the read_time\nfield will increase by 60*30 = 1800.\n\n#### `io_time`:\n\nThis value counts the number of milliseconds during which the device has\nhad I/O requests queued.\n\n#### `weighted_io_time`:\n\nThis value counts the number of milliseconds that I/O requests have waited\non this block device.  If there are multiple I/O requests waiting, this\nvalue will increase as the product of the number of milliseconds times the\nnumber of requests waiting (see `read_time` above for an example).\n\n#### `iops_in_progress`:\n\nThis value counts the number of I/O requests that have been issued to\nthe device driver but have not yet completed.  It does not include I/O\nrequests that are in the queue but not yet issued to the device driver.\n\n#### `merged_reads` & `merged_writes`:\n\nReads and writes which are adjacent to each other may be merged for\nefficiency.  Thus two 4K reads may become one 8K read before it is\nultimately handed to the disk, and so it will be counted (and queued)\nas only one I/O. These fields lets you know how often this was done.\n\n### Sample Queries:\n\n#### Calculate percent IO utilization per disk and host:\n```\nSELECT non_negative_derivative(last("io_time"),1ms) FROM "diskio" WHERE time > now() - 30m GROUP BY "host","name",time(60s)\n```\n\n#### Calculate average queue depth:\n`iops_in_progress` will give you an instantaneous value. This will give you the average between polling intervals.\n```\nSELECT non_negative_derivative(last("weighted_io_time"),1ms) from "diskio" WHERE time > now() - 30m GROUP BY "host","name",time(60s)\n```\n\n### Example Output:\n\n```\ndiskio,name=sda1 merged_reads=0i,reads=2353i,writes=10i,write_bytes=2117632i,write_time=49i,io_time=1271i,weighted_io_time=1350i,read_bytes=31350272i,read_time=1303i,iops_in_progress=0i,merged_writes=0i 1578326400000000000\ndiskio,name=centos/var_log reads=1063077i,writes=591025i,read_bytes=139325491712i,write_bytes=144233131520i,read_time=650221i,write_time=24368817i,io_time=852490i,weighted_io_time=25037394i,iops_in_progress=1i,merged_reads=0i,merged_writes=0i 1578326400000000000\ndiskio,name=sda write_time=49i,io_time=1317i,weighted_io_time=1404i,reads=2495i,read_time=1357i,write_bytes=2117632i,iops_in_progress=0i,merged_reads=0i,merged_writes=0i,writes=10i,read_bytes=38956544i 1578326400000000000\n\n```\n',image:pe.a},{id:"disque",name:"Disque",markdown:'# Disque Input Plugin\n\n[Disque](https://github.com/antirez/disque) is an ongoing experiment to build a distributed, in-memory, message broker.\n\n\n### Configuration:\n\n```toml\n[[inputs.disque]]  \n  ## An array of URI to gather stats about. Specify an ip or hostname\n  ## with optional port and password.\n  ## ie disque://localhost, disque://10.10.3.33:18832, 10.0.0.1:10000, etc.\n  ## If no servers are specified, then localhost is used as the host.\n  servers = ["localhost"]\n```\n\n### Metrics\n\n\n- disque\n  - disque_host\n    - uptime_in_seconds\n    - connected_clients\n    - blocked_clients\n    - used_memory\n    - used_memory_rss\n    - used_memory_peak\n    - total_connections_received\n    - total_commands_processed\n    - instantaneous_ops_per_sec\n    - latest_fork_usec\n    - mem_fragmentation_ratio\n    - used_cpu_sys\n    - used_cpu_user\n    - used_cpu_sys_children\n    - used_cpu_user_children\n    - registered_jobs\n    - registered_queues\n',image:be.a},{id:"dmcache",name:"DMCache",markdown:"# DMCache Input Plugin\n\nThis plugin provide a native collection for dmsetup based statistics for dm-cache.\n\nThis plugin requires sudo, that is why you should setup and be sure that the telegraf is able to execute sudo without a password.\n\n`sudo /sbin/dmsetup status --target cache` is the full command that telegraf will run for debugging purposes.\n\n### Configuration\n\n```toml\n[[inputs.dmcache]]\n  ## Whether to report per-device stats or not\n  per_device = true\n```\n\n### Measurements & Fields:\n\n- dmcache\n    - length\n    - target\n    - metadata_blocksize\n    - metadata_used\n    - metadata_total\n    - cache_blocksize\n    - cache_used\n    - cache_total\n    - read_hits\n    - read_misses\n    - write_hits\n    - write_misses\n    - demotions\n    - promotions\n    - dirty\n\n### Tags:\n\n- All measurements have the following tags:\n    - device\n\n### Example Output:\n\n```\n$ ./telegraf --test --config /etc/telegraf/telegraf.conf --input-filter dmcache\n* Plugin: inputs.dmcache, Collection 1\n> dmcache,device=example cache_blocksize=0i,read_hits=995134034411520i,read_misses=916807089127424i,write_hits=195107267543040i,metadata_used=12861440i,write_misses=563725346013184i,promotions=3265223720960i,dirty=0i,metadata_blocksize=0i,cache_used=1099511627776ii,cache_total=0i,length=0i,metadata_total=1073741824i,demotions=3265223720960i 1491482035000000000\n```\n",image:ve.a},{id:"dns_query",name:"DNS Query",markdown:'# DNS Query Input Plugin\n\nThe DNS plugin gathers dns query times in miliseconds - like [Dig](https://en.wikipedia.org/wiki/Dig_\\(command\\))\n\n### Configuration:\n```toml\n# Query given DNS server and gives statistics\n[[inputs.dns_query]]\n  ## servers to query\n  servers = ["8.8.8.8"]\n\n  ## Network is the network protocol name.\n  # network = "udp"\n\n  ## Domains or subdomains to query.\n  # domains = ["."]\n\n  ## Query record type.\n  ## Possible values: A, AAAA, CNAME, MX, NS, PTR, TXT, SOA, SPF, SRV.\n  # record_type = "A"\n\n  ## Dns server port.\n  # port = 53\n\n  ## Query timeout in seconds.\n  # timeout = 2\n```\n\n### Metrics:\n\n- dns_query\n  - tags:\n    - server\n    - domain\n    - record_type\n    - result\n    - rcode\n  - fields:\n    - query_time_ms (float)\n    - result_code (int, success = 0, timeout = 1, error = 2)\n    - rcode_value (int)\n\n\n### Rcode Descriptions\n|rcode_value|rcode|Description|\n|---|-----------|-----------------------------------|\n|0  | NoError   | No Error                          |\n|1  | FormErr   | Format Error                      |\n|2  | ServFail  | Server Failure                    |\n|3  | NXDomain  | Non-Existent Domain               |\n|4  | NotImp    | Not Implemented                   |\n|5  | Refused   | Query Refused                     |\n|6  | YXDomain  | Name Exists when it should not    |\n|7  | YXRRSet   | RR Set Exists when it should not  |\n|8  | NXRRSet   | RR Set that should exist does not |\n|9  | NotAuth   | Server Not Authoritative for zone |\n|10 | NotZone   | Name not contained in zone        |\n|16 | BADSIG    | TSIG Signature Failure            |\n|16 | BADVERS   | Bad OPT Version                   |\n|17 | BADKEY    | Key not recognized                |\n|18 | BADTIME   | Signature out of time window      |\n|19 | BADMODE   | Bad TKEY Mode                     |\n|20 | BADNAME   | Duplicate key name                |\n|21 | BADALG    | Algorithm not supported           |\n|22 | BADTRUNC  | Bad Truncation                    |\n|23 | BADCOOKIE | Bad/missing Server Cookie         |\n\n\n### Example Output:\n\n```\ndns_query,domain=google.com,rcode=NOERROR,record_type=A,result=success,server=127.0.0.1 rcode_value=0i,result_code=0i,query_time_ms=0.13746 1550020750001000000\n```\n',image:ke.a},{id:"docker",name:"Docker",markdown:'# Docker Input Plugin\n\nThe docker plugin uses the Docker Engine API to gather metrics on running\ndocker containers.\n\nThe docker plugin uses the [Official Docker Client](https://github.com/moby/moby/tree/master/client)\nto gather stats from the [Engine API](https://docs.docker.com/engine/api/v1.24/).\n\n### Configuration:\n\n```toml\n# Read metrics about docker containers\n[[inputs.docker]]\n  ## Docker Endpoint\n  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"\n  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"\n  endpoint = "unix:///var/run/docker.sock"\n\n  ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)\n  ## Note: configure this in one of the manager nodes in a Swarm cluster.\n  ## configuring in multiple Swarm managers results in duplication of metrics.\n  gather_services = false\n\n  ## Only collect metrics for these containers. Values will be appended to\n  ## container_name_include.\n  ## Deprecated (1.4.0), use container_name_include\n  container_names = []\n\n  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars\n  source_tag = false\n\n  ## Containers to include and exclude. Collect all if empty. Globs accepted.\n  container_name_include = []\n  container_name_exclude = []\n\n  ## Container states to include and exclude. Globs accepted.\n  ## When empty only containers in the "running" state will be captured.\n  ## example: container_state_include = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]\n  ## example: container_state_exclude = ["created", "restarting", "running", "removing", "paused", "exited", "dead"]\n  # container_state_include = []\n  # container_state_exclude = []\n\n  ## Timeout for docker list, info, and stats commands\n  timeout = "5s"\n\n  ## Whether to report for each container per-device blkio (8:0, 8:1...),\n  ## network (eth0, eth1, ...) and cpu (cpu0, cpu1, ...) stats or not.\n  ## Usage of this setting is discouraged since it will be deprecated in favor of \'perdevice_include\'.\n  ## Default value is \'true\' for backwards compatibility, please set it to \'false\' so that \'perdevice_include\' setting \n  ## is honored.\n  perdevice = true\n  \n  ## Specifies for which classes a per-device metric should be issued\n  ## Possible values are \'cpu\' (cpu0, cpu1, ...), \'blkio\' (8:0, 8:1, ...) and \'network\' (eth0, eth1, ...)\n  ## Please note that this setting has no effect if \'perdevice\' is set to \'true\'\n  # perdevice_include = ["cpu"]\n  \n  ## Whether to report for each container total blkio and network stats or not.\n  ## Usage of this setting is discouraged since it will be deprecated in favor of \'total_include\'.\n  ## Default value is \'false\' for backwards compatibility, please set it to \'true\' so that \'total_include\' setting \n  ## is honored.\n  total = false\n  \n  ## Specifies for which classes a total metric should be issued. Total is an aggregated of the \'perdevice\' values.\n  ## Possible values are \'cpu\', \'blkio\' and \'network\'  \n  ## Total \'cpu\' is reported directly by Docker daemon, and \'network\' and \'blkio\' totals are aggregated by this plugin.\n  ## Please note that this setting has no effect if \'total\' is set to \'false\'\n  # total_include = ["cpu", "blkio", "network"]\n\n  ## docker labels to include and exclude as tags.  Globs accepted.\n  ## Note that an empty array for both will include all labels as tags\n  docker_label_include = []\n  docker_label_exclude = []\n\n  ## Which environment variables should we use as a tag\n  tag_env = ["JAVA_HOME", "HEAP_SIZE"]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n#### Environment Configuration\n\nWhen using the `"ENV"` endpoint, the connection is configured using the\n[cli Docker environment variables](https://godoc.org/github.com/moby/moby/client#NewEnvClient).\n\n#### Security\n\nGiving telegraf access to the Docker daemon expands the [attack surface](https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface) that could result in an attacker gaining root access to a machine. This is especially relevant if the telegraf configuration can be changed by untrusted users.\n\n#### Docker Daemon Permissions\n\nTypically, telegraf must be given permission to access the docker daemon unix\nsocket when using the default endpoint. This can be done by adding the\n`telegraf` unix user (created when installing a Telegraf package) to the\n`docker` unix group with the following command:\n\n```\nsudo usermod -aG docker telegraf\n```\n\nIf telegraf is run within a container, the unix socket will need to be exposed\nwithin the telegraf container. This can be done in the docker CLI by add the\noption `-v /var/run/docker.sock:/var/run/docker.sock` or adding the following\nlines to the telegraf container definition in a docker compose file:\n\n```\nvolumes:\n  - /var/run/docker.sock:/var/run/docker.sock\n```\n\n#### source tag\n\nSelecting the containers measurements can be tricky if you have many containers with the same name.\nTo alleviate this issue you can set the below value to `true`\n\n```toml\nsource_tag = true\n```\n\nThis will cause all measurements to have the `source` tag be set to the first 12 characters of the container id. The first 12 characters is the common hostname for containers that have no explicit hostname set, as defined by docker.\n\n#### Kubernetes Labels\n\nKubernetes may add many labels to your containers, if they are not needed you\nmay prefer to exclude them:\n```\n  docker_label_exclude = ["annotation.kubernetes*"]\n```\n\n\n#### Docker-compose Labels\n\nDocker-compose will add labels to your containers. You can limit restrict labels to selected ones, e.g. \n\n```\n  docker_label_include = [\n    "com.docker.compose.config-hash",\n    "com.docker.compose.container-number",\n    "com.docker.compose.oneoff",\n    "com.docker.compose.project",\n    "com.docker.compose.service",\n  ]\n```\n\n\n### Metrics:\n\n- docker\n  - tags:\n    - unit\n    - engine_host\n    - server_version\n  + fields:\n    - n_used_file_descriptors\n    - n_cpus\n    - n_containers\n    - n_containers_running\n    - n_containers_stopped\n    - n_containers_paused\n    - n_images\n    - n_goroutines\n    - n_listener_events\n    - memory_total\n    - pool_blocksize (requires devicemapper storage driver) (deprecated see: `docker_devicemapper`)\n\nThe `docker_data` and `docker_metadata` measurements are available only for\nsome storage drivers such as devicemapper.\n\n+ docker_data (deprecated see: `docker_devicemapper`)\n  - tags:\n    - unit\n    - engine_host\n    - server_version\n  + fields:\n    - available\n    - total\n    - used\n\n- docker_metadata (deprecated see: `docker_devicemapper`)\n  - tags:\n    - unit\n    - engine_host\n    - server_version\n  + fields:\n    - available\n    - total\n    - used\n\nThe above measurements for the devicemapper storage driver can now be found in the new `docker_devicemapper` measurement\n\n- docker_devicemapper\n  - tags:\n    - engine_host\n    - server_version\n    - pool_name\n  + fields:\n    - pool_blocksize_bytes\n    - data_space_used_bytes\n    - data_space_total_bytes\n    - data_space_available_bytes\n    - metadata_space_used_bytes\n    - metadata_space_total_bytes\n    - metadata_space_available_bytes\n    - thin_pool_minimum_free_space_bytes\n\n+ docker_container_mem\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n  + fields:\n    - total_pgmajfault\n    - cache\n    - mapped_file\n    - total_inactive_file\n    - pgpgout\n    - rss\n    - total_mapped_file\n    - writeback\n    - unevictable\n    - pgpgin\n    - total_unevictable\n    - pgmajfault\n    - total_rss\n    - total_rss_huge\n    - total_writeback\n    - total_inactive_anon\n    - rss_huge\n    - hierarchical_memory_limit\n    - total_pgfault\n    - total_active_file\n    - active_anon\n    - total_active_anon\n    - total_pgpgout\n    - total_cache\n    - inactive_anon\n    - active_file\n    - pgfault\n    - inactive_file\n    - total_pgpgin\n    - max_usage\n    - usage\n    - failcnt\n    - limit\n    - container_id\n\n- docker_container_cpu\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n    - cpu\n  + fields:\n    - throttling_periods\n    - throttling_throttled_periods\n    - throttling_throttled_time\n    - usage_in_kernelmode\n    - usage_in_usermode\n    - usage_system\n    - usage_total\n    - usage_percent\n    - container_id\n\n+ docker_container_net\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n    - network\n  + fields:\n    - rx_dropped\n    - rx_bytes\n    - rx_errors\n    - tx_packets\n    - tx_dropped\n    - rx_packets\n    - tx_errors\n    - tx_bytes\n    - container_id\n\n- docker_container_blkio\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n    - device\n  - fields:\n    - io_service_bytes_recursive_async\n    - io_service_bytes_recursive_read\n    - io_service_bytes_recursive_sync\n    - io_service_bytes_recursive_total\n    - io_service_bytes_recursive_write\n    - io_serviced_recursive_async\n    - io_serviced_recursive_read\n    - io_serviced_recursive_sync\n    - io_serviced_recursive_total\n    - io_serviced_recursive_write\n    - container_id\n\nThe `docker_container_health` measurements report on a containers\n[HEALTHCHECK](https://docs.docker.com/engine/reference/builder/#healthcheck)\nstatus if configured.\n\n- docker_container_health (container must use the HEALTHCHECK)\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n  - fields:\n  \t- health_status (string)\n  \t- failing_streak (integer)\n\n- docker_container_status\n  - tags:\n    - engine_host\n    - server_version\n    - container_image\n    - container_name\n    - container_status\n    - container_version\n  - fields:\n    - container_id\n    - oomkilled (boolean)\n    - pid (integer)\n    - exitcode (integer)\n    - started_at (integer)\n    - finished_at (integer)\n    - uptime_ns (integer)\n\n- docker_swarm\n  - tags:\n    - service_id\n    - service_name\n    - service_mode\n  - fields:\n    - tasks_desired\n    - tasks_running\n\n### Example Output:\n\n```\ndocker,engine_host=debian-stretch-docker,server_version=17.09.0-ce n_containers=6i,n_containers_paused=0i,n_containers_running=1i,n_containers_stopped=5i,n_cpus=2i,n_goroutines=41i,n_images=2i,n_listener_events=0i,n_used_file_descriptors=27i 1524002041000000000\ndocker,engine_host=debian-stretch-docker,server_version=17.09.0-ce,unit=bytes memory_total=2101661696i 1524002041000000000\ndocker_container_mem,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,engine_host=debian-stretch-docker,server_version=17.09.0-ce active_anon=8327168i,active_file=2314240i,cache=27402240i,container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",hierarchical_memory_limit=9223372036854771712i,inactive_anon=0i,inactive_file=25088000i,limit=2101661696i,mapped_file=20582400i,max_usage=36646912i,pgfault=4193i,pgmajfault=214i,pgpgin=9243i,pgpgout=520i,rss=8327168i,rss_huge=0i,total_active_anon=8327168i,total_active_file=2314240i,total_cache=27402240i,total_inactive_anon=0i,total_inactive_file=25088000i,total_mapped_file=20582400i,total_pgfault=4193i,total_pgmajfault=214i,total_pgpgin=9243i,total_pgpgout=520i,total_rss=8327168i,total_rss_huge=0i,total_unevictable=0i,total_writeback=0i,unevictable=0i,usage=36528128i,usage_percent=0.4342225020025297,writeback=0i 1524002042000000000\ndocker_container_cpu,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,cpu=cpu-total,engine_host=debian-stretch-docker,server_version=17.09.0-ce container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",throttling_periods=0i,throttling_throttled_periods=0i,throttling_throttled_time=0i,usage_in_kernelmode=40000000i,usage_in_usermode=100000000i,usage_percent=0,usage_system=6394210000000i,usage_total=117319068i 1524002042000000000\ndocker_container_cpu,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,cpu=cpu0,engine_host=debian-stretch-docker,server_version=17.09.0-ce container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",usage_total=20825265i 1524002042000000000\ndocker_container_cpu,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,cpu=cpu1,engine_host=debian-stretch-docker,server_version=17.09.0-ce container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",usage_total=96493803i 1524002042000000000\ndocker_container_net,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,engine_host=debian-stretch-docker,network=eth0,server_version=17.09.0-ce container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",rx_bytes=1576i,rx_dropped=0i,rx_errors=0i,rx_packets=20i,tx_bytes=0i,tx_dropped=0i,tx_errors=0i,tx_packets=0i 1524002042000000000\ndocker_container_blkio,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,device=254:0,engine_host=debian-stretch-docker,server_version=17.09.0-ce container_id="adc4ba9593871bf2ab95f3ffde70d1b638b897bb225d21c2c9c84226a10a8cf4",io_service_bytes_recursive_async=27398144i,io_service_bytes_recursive_read=27398144i,io_service_bytes_recursive_sync=0i,io_service_bytes_recursive_total=27398144i,io_service_bytes_recursive_write=0i,io_serviced_recursive_async=529i,io_serviced_recursive_read=529i,io_serviced_recursive_sync=0i,io_serviced_recursive_total=529i,io_serviced_recursive_write=0i 1524002042000000000\ndocker_container_health,container_image=telegraf,container_name=zen_ritchie,container_status=running,container_version=unknown,engine_host=debian-stretch-docker,server_version=17.09.0-ce failing_streak=0i,health_status="healthy" 1524007529000000000\ndocker_swarm,service_id=xaup2o9krw36j2dy1mjx1arjw,service_mode=replicated,service_name=test tasks_desired=3,tasks_running=3 1508968160000000000\n```\n',image:qe.a},{id:"docker_log",name:"Docker Log",markdown:'# Docker Log Input Plugin\n\nThe docker log plugin uses the Docker Engine API to get logs on running\ndocker containers.\n\nThe docker plugin uses the [Official Docker Client][] to gather logs from the\n[Engine API][].\n\n**Note:** This plugin works only for containers with the `local` or\n`json-file` or `journald` logging driver.\n\n[Official Docker Client]: https://github.com/moby/moby/tree/master/client\n[Engine API]: https://docs.docker.com/engine/api/v1.24/\n\n### Configuration\n\n```toml\n[[inputs.docker_log]]\n  ## Docker Endpoint\n  ##   To use TCP, set endpoint = "tcp://[ip]:[port]"\n  ##   To use environment variables (ie, docker-machine), set endpoint = "ENV"\n  # endpoint = "unix:///var/run/docker.sock"\n\n  ## When true, container logs are read from the beginning; otherwise\n  ## reading begins at the end of the log.\n  # from_beginning = false\n\n  ## Timeout for Docker API calls.\n  # timeout = "5s"\n\n  ## Containers to include and exclude. Globs accepted.\n  ## Note that an empty array for both will include all containers\n  # container_name_include = []\n  # container_name_exclude = []\n\n  ## Container states to include and exclude. Globs accepted.\n  ## When empty only containers in the "running" state will be captured.\n  # container_state_include = []\n  # container_state_exclude = []\n\n  ## docker labels to include and exclude as tags.  Globs accepted.\n  ## Note that an empty array for both will include all labels as tags\n  # docker_label_include = []\n  # docker_label_exclude = []\n\n  ## Set the source tag for the metrics to the container ID hostname, eg first 12 chars\n  source_tag = false\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n#### Environment Configuration\n\nWhen using the `"ENV"` endpoint, the connection is configured using the\n[CLI Docker environment variables][env]\n\n[env]: https://godoc.org/github.com/moby/moby/client#NewEnvClient\n\n### source tag\n\nSelecting the containers can be tricky if you have many containers with the same name.\nTo alleviate this issue you can set the below value to `true`\n\n```toml\nsource_tag = true\n```\n\nThis will cause all data points to have the `source` tag be set to the first 12 characters of the container id. The first 12 characters is the common hostname for containers that have no explicit hostname set, as defined by docker.\n\n### Metrics\n\n- docker_log\n  - tags:\n    - container_image\n    - container_version\n    - container_name\n    - stream (stdout, stderr, or tty)\n    - source\n  - fields:\n    - container_id\n    - message\n\n### Example Output\n\n```\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! [agent] Config: Interval:10s, Quiet:false, Hostname:\\"371ee5d3e587\\", Flush Interval:10s" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Tags enabled: host=371ee5d3e587" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Loaded outputs: file" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Loaded processors:" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Loaded aggregators:" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Loaded inputs: net" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Using config file: /etc/telegraf/telegraf.conf" 1560913872000000000\ndocker_log,container_image=telegraf,container_name=sharp_bell,container_version=alpine,stream=stderr container_id="371ee5d3e58726112f499be62cddef800138ca72bbba635ed2015fbf475b1023",message="2019-06-19T03:11:11Z I! Starting Telegraf 1.10.4" 1560913872000000000\n```\n',image:Te.a},{id:"dovecot",name:"Dovecot",markdown:'# Dovecot Input Plugin\n\nThe dovecot plugin uses the Dovecot [v2.1 stats protocol][stats old] to gather\nmetrics on configured domains.\n\nWhen using Dovecot v2.3 you are still able to use this protocol by following\nthe [upgrading steps][upgrading].\n\n### Configuration:\n\n```toml\n# Read metrics about dovecot servers\n[[inputs.dovecot]]\n  ## specify dovecot servers via an address:port list\n  ##  e.g.\n  ##    localhost:24242\n  ## or as an UDS socket\n  ##  e.g.\n  ##    /var/run/dovecot/old-stats\n  ##\n  ## If no servers are specified, then localhost is used as the host.\n  servers = ["localhost:24242"]\n\n  ## Type is one of "user", "domain", "ip", or "global"\n  type = "global"\n  \n  ## Wildcard matches like "*.com". An empty string "" is same as "*"\n  ## If type = "ip" filters should be <IP/network>\n  filters = [""]\n```\n\n### Metrics:\n\n- dovecot\n  - tags:\n\t- server (hostname)\n\t- type (query type)\n\t- ip (ip addr)\n\t- user (username)\n\t- domain (domain name)\n  - fields:\n\t- reset_timestamp (string)\n\t- last_update (string)\n\t- num_logins (integer)\n\t- num_cmds (integer)\n\t- num_connected_sessions (integer)\n\t- user_cpu (float)\n\t- sys_cpu (float)\n\t- clock_time (float)\n\t- min_faults (integer)\n\t- maj_faults (integer)\n\t- vol_cs (integer)\n\t- invol_cs (integer)\n\t- disk_input (integer)\n\t- disk_output (integer)\n\t- read_count (integer)\n\t- read_bytes (integer)\n\t- write_count (integer)\n\t- write_bytes (integer)\n\t- mail_lookup_path (integer)\n\t- mail_lookup_attr (integer)\n\t- mail_read_count (integer)\n\t- mail_read_bytes (integer)\n\t- mail_cache_hits (integer)\n\n\n### Example Output:\n\n```\ndovecot,server=dovecot-1.domain.test,type=global clock_time=101196971074203.94,disk_input=6493168218112i,disk_output=17978638815232i,invol_cs=1198855447i,last_update="2016-04-08 11:04:13.000379245 +0200 CEST",mail_cache_hits=68192209i,mail_lookup_attr=0i,mail_lookup_path=653861i,mail_read_bytes=86705151847i,mail_read_count=566125i,maj_faults=17208i,min_faults=1286179702i,num_cmds=917469i,num_connected_sessions=8896i,num_logins=174827i,read_bytes=30327690466186i,read_count=1772396430i,reset_timestamp="2016-04-08 10:28:45 +0200 CEST",sys_cpu=157965.692,user_cpu=219337.48,vol_cs=2827615787i,write_bytes=17150837661940i,write_count=992653220i 1460106266642153907\n```\n\n[stats old]: http://wiki2.dovecot.org/Statistics/Old\n[upgrading]: https://wiki2.dovecot.org/Upgrading/2.3#Statistics_Redesign\n',image:Ie.a},{id:"dpdk",name:"Data Plane Development Kit (DPDK)",markdown:'# Data Plane Development Kit (DPDK) Input Plugin\n\nThe `dpdk` plugin collects metrics exposed by applications built with [Data Plane Development Kit](https://www.dpdk.org/)\nwhich is an extensive set of open source libraries designed for accelerating packet processing workloads.\n\nDPDK provides APIs that enable exposing various statistics from the devices used by DPDK applications and enable exposing\nKPI metrics directly from applications. Device statistics include e.g. common statistics available across NICs, like:\nreceived and sent packets, received and sent bytes etc. In addition to this generic statistics, an extended statistics API\nis available that allows providing more detailed, driver-specific metrics that are not available as generic statistics.\n\n[DPDK Release 20.05](https://doc.dpdk.org/guides/rel_notes/release_20_05.html) introduced updated telemetry interface\nthat enables DPDK libraries and applications to provide their telemetry. This is referred to as `v2` version of this\nsocket-based telemetry interface. This release enabled e.g. reading driver-specific extended stats (`/ethdev/xstats`)\nvia this new interface.\n\n[DPDK Release 20.11](https://doc.dpdk.org/guides/rel_notes/release_20_11.html) introduced reading via `v2` interface\ncommon statistics (`/ethdev/stats`) in addition to existing (`/ethdev/xstats`).\n\nThe example usage of `v2` telemetry interface can be found in [Telemetry User Guide](https://doc.dpdk.org/guides/howto/telemetry.html).\nA variety of [DPDK Sample Applications](https://doc.dpdk.org/guides/sample_app_ug/index.html) is also available for users\nto discover and test the capabilities of DPDK libraries and to explore the exposed metrics.\n\n> **DPDK Version Info:** This plugin uses this `v2` interface to read telemetry data from applications build with\n> `DPDK version >= 20.05`. The default configuration include reading common statistics from `/ethdev/stats` that is\n> available from `DPDK version >= 20.11`. When using `DPDK 20.05 <= version < DPDK 20.11` it is recommended to disable\n> querying `/ethdev/stats` by setting corresponding `exclude_commands` configuration option.\n\n> **NOTE:** Since DPDK will most likely run with root privileges, the socket telemetry interface exposed by DPDK\n> will also require root access. This means that either access permissions have to be adjusted for socket telemetry\n> interface to allow Telegraf to access it, or Telegraf should run with root privileges.\n\n## Configuration\nThis plugin offers multiple configuration options, please review examples below for additional usage information.\n```toml\n# Reads metrics from DPDK applications using v2 telemetry interface.\n[[inputs.dpdk]]\n  ## Path to DPDK telemetry socket. This shall point to v2 version of DPDK telemetry interface.\n  # socket_path = "/var/run/dpdk/rte/dpdk_telemetry.v2"\n\n  ## Duration that defines how long the connected socket client will wait for a response before terminating connection.\n  ## This includes both writing to and reading from socket. Since it\'s local socket access\n  ## to a fast packet processing application, the timeout should be sufficient for most users.\n  ## Setting the value to 0 disables the timeout (not recommended)\n  # socket_access_timeout = "200ms"\n\n  ## Enables telemetry data collection for selected device types.\n  ## Adding "ethdev" enables collection of telemetry from DPDK NICs (stats, xstats, link_status).\n  ## Adding "rawdev" enables collection of telemetry from DPDK Raw Devices (xstats).\n  # device_types = ["ethdev"]\n\n  ## List of custom, application-specific telemetry commands to query\n  ## The list of available commands depend on the application deployed. Applications can register their own commands\n  ##   via telemetry library API http://doc.dpdk.org/guides/prog_guide/telemetry_lib.html#registering-commands\n  ## For e.g. L3 Forwarding with Power Management Sample Application this could be: \n  ##   additional_commands = ["/l3fwd-power/stats"]\n  # additional_commands = []\n\n  ## Allows turning off collecting data for individual "ethdev" commands.\n  ## Remove "/ethdev/link_status" from list to start getting link status metrics.\n  [inputs.dpdk.ethdev]\n    exclude_commands = ["/ethdev/link_status"]\n\n  ## When running multiple instances of the plugin it\'s recommended to add a unique tag to each instance to identify\n  ## metrics exposed by an instance of DPDK application. This is useful when multiple DPDK apps run on a single host.  \n  ##  [inputs.dpdk.tags]\n  ##    dpdk_instance = "my-fwd-app"\n```\n\n### Example: Minimal Configuration for NIC metrics\nThis configuration allows getting metrics for all devices reported via `/ethdev/list` command:\n* `/ethdev/stats` - basic device statistics (since `DPDK 20.11`)\n* `/ethdev/xstats` - extended device statistics\n* `/ethdev/link_status` - up/down link status\n```toml\n[[inputs.dpdk]]\n  device_types = ["ethdev"]\n```\nSince this configuration will query `/ethdev/link_status` it\'s recommended to increase timeout to `socket_access_timeout = "10s"`.\n\nThe [plugin collecting interval](https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#input-plugins)\nshould be adjusted accordingly (e.g. `interval = "30s"`).\n\n### Example: Excluding NIC link status from being collected\nChecking link status depending on underlying implementation may take more time to complete.\nThis configuration can be used to exclude this telemetry command to allow faster response for metrics.\n```toml\n[[inputs.dpdk]]\n  device_types = ["ethdev"]\n\n  [inputs.dpdk.ethdev]\n    exclude_commands = ["/ethdev/link_status"]\n```\nA separate plugin instance with higher timeout settings can be used to get `/ethdev/link_status` independently.\nConsult [Independent NIC link status configuration](#example-independent-nic-link-status-configuration)\nand [Getting metrics from multiple DPDK instances running on same host](#example-getting-metrics-from-multiple-dpdk-instances-running-on-same-host)\nexamples for further details.\n\n### Example: Independent NIC link status configuration\nThis configuration allows getting `/ethdev/link_status` using separate configuration, with higher timeout.\n```toml\n[[inputs.dpdk]]\n  interval = "30s"\n  socket_access_timeout = "10s"\n  device_types = ["ethdev"]\n\n  [inputs.dpdk.ethdev]\n    exclude_commands = ["/ethdev/stats", "/ethdev/xstats"]\n```\n\n### Example: Getting application-specific metrics\nThis configuration allows reading custom metrics exposed by applications. Example telemetry command obtained from  \n[L3 Forwarding with Power Management Sample Application](https://doc.dpdk.org/guides/sample_app_ug/l3_forward_power_man.html).\n```toml\n[[inputs.dpdk]]\n  device_types = ["ethdev"]\n  additional_commands = ["/l3fwd-power/stats"]\n\n  [inputs.dpdk.ethdev]\n    exclude_commands = ["/ethdev/link_status"]\n```\nCommand entries specified in `additional_commands` should match DPDK command format:\n* Command entry format: either `command` or `command,params` for commands that expect parameters, where comma (`,`) separates command from params.\n* Command entry length (command with params) should be `< 1024` characters.\n* Command length (without params) should be `< 56` characters.\n* Commands have to start with `/`.\n\nProviding invalid commands will prevent the plugin from starting. Additional commands allow duplicates, but they\nwill be removed during execution so each command will be executed only once during each metric gathering interval. \n\n### Example: Getting metrics from multiple DPDK instances running on same host\nThis configuration allows getting metrics from two separate applications exposing their telemetry interfaces\nvia separate sockets. For each plugin instance a unique tag `[inputs.dpdk.tags]` allows distinguishing between them. \n```toml\n# Instance #1 - L3 Forwarding with Power Management Application\n[[inputs.dpdk]]\n  socket_path = "/var/run/dpdk/rte/l3fwd-power_telemetry.v2"\n  device_types = ["ethdev"]\n  additional_commands = ["/l3fwd-power/stats"]\n\n  [inputs.dpdk.ethdev]\n    exclude_commands = ["/ethdev/link_status"]\n\n  [inputs.dpdk.tags]\n    dpdk_instance = "l3fwd-power"\n\n# Instance #2 - L2 Forwarding with Intel Cache Allocation Technology (CAT) Application\n[[inputs.dpdk]]\n  socket_path = "/var/run/dpdk/rte/l2fwd-cat_telemetry.v2"\n  device_types = ["ethdev"]\n\n[inputs.dpdk.ethdev]\n  exclude_commands = ["/ethdev/link_status"]\n\n  [inputs.dpdk.tags]\n    dpdk_instance = "l2fwd-cat"\n```\nThis utilizes Telegraf\'s standard capability of [adding custom tags](https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#input-plugins)\nto input plugin\'s measurements.\n\n## Metrics\nThe DPDK socket accepts `command,params` requests and returns metric data in JSON format. All metrics from DPDK socket\nbecome flattened using [Telegraf\'s JSON Flattener](https://github.com/influxdata/telegraf/tree/master/plugins/parsers/json) and exposed as fields. \nIf DPDK response contains no information (is empty or is null) then such response will be discarded.\n\n> **NOTE:**  Since DPDK allows registering custom metrics in its telemetry framework the JSON response from DPDK \n> may contain various sets of metrics. While metrics from `/ethdev/stats` should be most stable, the `/ethdev/xstats`\n> may contain driver-specific metrics (depending on DPDK application configuration). The application-specific commands\n> like `/l3fwd-power/stats` can return their own specific set of metrics.\n\n## Example output\nThe output consists of plugin name (`dpdk`), and a set of tags that identify querying hierarchy:\n```\ndpdk,host=dpdk-host,dpdk_instance=l3fwd-power,command=/ethdev/stats,params=0 [fields] [timestamp]\n```\n\n| Tag | Description |\n|-----|-------------|\n| `host` | hostname of the machine (consult [Telegraf Agent configuration](https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#agent) for additional details) |\n| `dpdk_instance` | custom tag from `[inputs.dpdk.tags]` (optional) |\n| `command` | executed command (without params) |\n| `params` | command parameter, e.g. for `/ethdev/stats` it is the id of NIC as exposed by `/ethdev/list`<br>For DPDK app that uses 2 NICs the metrics will output e.g. `params=0`, `params=1`. |\n\nWhen running plugin configuration below...\n```toml\n[[inputs.dpdk]]\n  device_types = ["ethdev"]\n  additional_commands = ["/l3fwd-power/stats"]\n  [inputs.dpdk.tags]\n    dpdk_instance = "l3fwd-power"\n```\n\n...expected output for `dpdk` plugin instance running on host named `host=dpdk-host`:\n```\ndpdk,command=/ethdev/stats,dpdk_instance=l3fwd-power,host=dpdk-host,params=0 q_opackets_0=0,q_ipackets_5=0,q_errors_11=0,ierrors=0,q_obytes_5=0,q_obytes_10=0,q_opackets_10=0,q_ipackets_4=0,q_ipackets_7=0,q_ipackets_15=0,q_ibytes_5=0,q_ibytes_6=0,q_ibytes_9=0,obytes=0,q_opackets_1=0,q_opackets_11=0,q_obytes_7=0,q_errors_5=0,q_errors_10=0,q_ibytes_4=0,q_obytes_6=0,q_errors_1=0,q_opackets_5=0,q_errors_3=0,q_errors_12=0,q_ipackets_11=0,q_ipackets_12=0,q_obytes_14=0,q_opackets_15=0,q_obytes_2=0,q_errors_8=0,q_opackets_12=0,q_errors_0=0,q_errors_9=0,q_opackets_14=0,q_ibytes_3=0,q_ibytes_15=0,q_ipackets_13=0,q_ipackets_14=0,q_obytes_3=0,q_errors_13=0,q_opackets_3=0,q_ibytes_0=7092,q_ibytes_2=0,q_ibytes_8=0,q_ipackets_8=0,q_ipackets_10=0,q_obytes_4=0,q_ibytes_10=0,q_ibytes_13=0,q_ibytes_1=0,q_ibytes_12=0,opackets=0,q_obytes_1=0,q_errors_15=0,q_opackets_2=0,oerrors=0,rx_nombuf=0,q_opackets_8=0,q_ibytes_11=0,q_ipackets_3=0,q_obytes_0=0,q_obytes_12=0,q_obytes_11=0,q_obytes_13=0,q_errors_6=0,q_ipackets_1=0,q_ipackets_6=0,q_ipackets_9=0,q_obytes_15=0,q_opackets_7=0,q_ibytes_14=0,ipackets=98,q_ipackets_2=0,q_opackets_6=0,q_ibytes_7=0,imissed=0,q_opackets_4=0,q_opackets_9=0,q_obytes_8=0,q_obytes_9=0,q_errors_4=0,q_errors_14=0,q_opackets_13=0,ibytes=7092,q_ipackets_0=98,q_errors_2=0,q_errors_7=0 1606310780000000000\ndpdk,command=/ethdev/stats,dpdk_instance=l3fwd-power,host=dpdk-host,params=1 q_opackets_0=0,q_ipackets_5=0,q_errors_11=0,ierrors=0,q_obytes_5=0,q_obytes_10=0,q_opackets_10=0,q_ipackets_4=0,q_ipackets_7=0,q_ipackets_15=0,q_ibytes_5=0,q_ibytes_6=0,q_ibytes_9=0,obytes=0,q_opackets_1=0,q_opackets_11=0,q_obytes_7=0,q_errors_5=0,q_errors_10=0,q_ibytes_4=0,q_obytes_6=0,q_errors_1=0,q_opackets_5=0,q_errors_3=0,q_errors_12=0,q_ipackets_11=0,q_ipackets_12=0,q_obytes_14=0,q_opackets_15=0,q_obytes_2=0,q_errors_8=0,q_opackets_12=0,q_errors_0=0,q_errors_9=0,q_opackets_14=0,q_ibytes_3=0,q_ibytes_15=0,q_ipackets_13=0,q_ipackets_14=0,q_obytes_3=0,q_errors_13=0,q_opackets_3=0,q_ibytes_0=7092,q_ibytes_2=0,q_ibytes_8=0,q_ipackets_8=0,q_ipackets_10=0,q_obytes_4=0,q_ibytes_10=0,q_ibytes_13=0,q_ibytes_1=0,q_ibytes_12=0,opackets=0,q_obytes_1=0,q_errors_15=0,q_opackets_2=0,oerrors=0,rx_nombuf=0,q_opackets_8=0,q_ibytes_11=0,q_ipackets_3=0,q_obytes_0=0,q_obytes_12=0,q_obytes_11=0,q_obytes_13=0,q_errors_6=0,q_ipackets_1=0,q_ipackets_6=0,q_ipackets_9=0,q_obytes_15=0,q_opackets_7=0,q_ibytes_14=0,ipackets=98,q_ipackets_2=0,q_opackets_6=0,q_ibytes_7=0,imissed=0,q_opackets_4=0,q_opackets_9=0,q_obytes_8=0,q_obytes_9=0,q_errors_4=0,q_errors_14=0,q_opackets_13=0,ibytes=7092,q_ipackets_0=98,q_errors_2=0,q_errors_7=0 1606310780000000000\ndpdk,command=/ethdev/xstats,dpdk_instance=l3fwd-power,host=dpdk-host,params=0 out_octets_encrypted=0,rx_fcoe_mbuf_allocation_errors=0,tx_q1packets=0,rx_priority0_xoff_packets=0,rx_priority7_xoff_packets=0,rx_errors=0,mac_remote_errors=0,in_pkts_invalid=0,tx_priority3_xoff_packets=0,tx_errors=0,rx_fcoe_bytes=0,rx_flow_control_xon_packets=0,rx_priority4_xoff_packets=0,tx_priority2_xoff_packets=0,rx_illegal_byte_errors=0,rx_xoff_packets=0,rx_management_packets=0,rx_priority7_dropped=0,rx_priority4_dropped=0,in_pkts_unchecked=0,rx_error_bytes=0,rx_size_256_to_511_packets=0,tx_priority4_xoff_packets=0,rx_priority6_xon_packets=0,tx_priority4_xon_to_xoff_packets=0,in_pkts_delayed=0,rx_priority0_mbuf_allocation_errors=0,out_octets_protected=0,tx_priority7_xon_to_xoff_packets=0,tx_priority1_xon_to_xoff_packets=0,rx_fcoe_no_direct_data_placement_ext_buff=0,tx_priority6_xon_to_xoff_packets=0,flow_director_filter_add_errors=0,rx_total_packets=99,rx_crc_errors=0,flow_director_filter_remove_errors=0,rx_missed_errors=0,tx_size_64_packets=0,rx_priority3_dropped=0,flow_director_matched_filters=0,tx_priority2_xon_to_xoff_packets=0,rx_priority1_xon_packets=0,rx_size_65_to_127_packets=99,rx_fragment_errors=0,in_pkts_notusingsa=0,rx_q0bytes=7162,rx_fcoe_dropped=0,rx_priority1_dropped=0,rx_fcoe_packets=0,rx_priority5_xoff_packets=0,out_pkts_protected=0,tx_total_packets=0,rx_priority2_dropped=0,in_pkts_late=0,tx_q1bytes=0,in_pkts_badtag=0,rx_multicast_packets=99,rx_priority6_xoff_packets=0,tx_flow_control_xoff_packets=0,rx_flow_control_xoff_packets=0,rx_priority0_xon_packets=0,in_pkts_untagged=0,tx_fcoe_packets=0,rx_priority7_mbuf_allocation_errors=0,tx_priority0_xon_to_xoff_packets=0,tx_priority5_xon_to_xoff_packets=0,tx_flow_control_xon_packets=0,tx_q0packets=0,tx_xoff_packets=0,rx_size_512_to_1023_packets=0,rx_priority3_xon_packets=0,rx_q0errors=0,rx_oversize_errors=0,tx_priority4_xon_packets=0,tx_priority5_xoff_packets=0,rx_priority5_xon_packets=0,rx_total_missed_packets=0,rx_priority4_mbuf_allocation_errors=0,tx_priority1_xon_packets=0,tx_management_packets=0,rx_priority5_mbuf_allocation_errors=0,rx_fcoe_no_direct_data_placement=0,rx_undersize_errors=0,tx_priority1_xoff_packets=0,rx_q0packets=99,tx_q2packets=0,tx_priority6_xon_packets=0,rx_good_packets=99,tx_priority5_xon_packets=0,tx_size_256_to_511_packets=0,rx_priority6_dropped=0,rx_broadcast_packets=0,tx_size_512_to_1023_packets=0,tx_priority3_xon_to_xoff_packets=0,in_pkts_unknownsci=0,in_octets_validated=0,tx_priority6_xoff_packets=0,tx_priority7_xoff_packets=0,rx_jabber_errors=0,tx_priority7_xon_packets=0,tx_priority0_xon_packets=0,in_pkts_unusedsa=0,tx_priority0_xoff_packets=0,mac_local_errors=33,rx_total_bytes=7162,in_pkts_notvalid=0,rx_length_errors=0,in_octets_decrypted=0,rx_size_128_to_255_packets=0,rx_good_bytes=7162,tx_size_65_to_127_packets=0,rx_mac_short_packet_dropped=0,tx_size_1024_to_max_packets=0,rx_priority2_mbuf_allocation_errors=0,flow_director_added_filters=0,tx_multicast_packets=0,rx_fcoe_crc_errors=0,rx_priority1_xoff_packets=0,flow_director_missed_filters=0,rx_xon_packets=0,tx_size_128_to_255_packets=0,out_pkts_encrypted=0,rx_priority4_xon_packets=0,rx_priority0_dropped=0,rx_size_1024_to_max_packets=0,tx_good_bytes=0,rx_management_dropped=0,rx_mbuf_allocation_errors=0,tx_xon_packets=0,rx_priority3_xoff_packets=0,tx_good_packets=0,tx_fcoe_bytes=0,rx_priority6_mbuf_allocation_errors=0,rx_priority2_xon_packets=0,tx_broadcast_packets=0,tx_q2bytes=0,rx_priority7_xon_packets=0,out_pkts_untagged=0,rx_priority2_xoff_packets=0,rx_priority1_mbuf_allocation_errors=0,tx_q0bytes=0,rx_size_64_packets=0,rx_priority5_dropped=0,tx_priority2_xon_packets=0,in_pkts_nosci=0,flow_director_removed_filters=0,in_pkts_ok=0,rx_l3_l4_xsum_error=0,rx_priority3_mbuf_allocation_errors=0,tx_priority3_xon_packets=0 1606310780000000000\ndpdk,command=/ethdev/xstats,dpdk_instance=l3fwd-power,host=dpdk-host,params=1 tx_priority5_xoff_packets=0,in_pkts_unknownsci=0,tx_q0packets=0,tx_total_packets=0,rx_crc_errors=0,rx_priority4_xoff_packets=0,rx_priority5_dropped=0,tx_size_65_to_127_packets=0,rx_good_packets=98,tx_priority6_xoff_packets=0,tx_fcoe_bytes=0,out_octets_protected=0,out_pkts_encrypted=0,rx_priority1_xon_packets=0,tx_size_128_to_255_packets=0,rx_flow_control_xoff_packets=0,rx_priority7_xoff_packets=0,tx_priority0_xon_to_xoff_packets=0,rx_broadcast_packets=0,tx_priority1_xon_packets=0,rx_xon_packets=0,rx_fragment_errors=0,tx_flow_control_xoff_packets=0,tx_q0bytes=0,out_pkts_untagged=0,rx_priority4_xon_packets=0,tx_priority5_xon_packets=0,rx_priority1_xoff_packets=0,rx_good_bytes=7092,rx_priority4_mbuf_allocation_errors=0,in_octets_decrypted=0,tx_priority2_xon_to_xoff_packets=0,rx_priority3_dropped=0,tx_multicast_packets=0,mac_local_errors=33,in_pkts_ok=0,rx_illegal_byte_errors=0,rx_xoff_packets=0,rx_q0errors=0,flow_director_added_filters=0,rx_size_256_to_511_packets=0,rx_priority3_xon_packets=0,rx_l3_l4_xsum_error=0,rx_priority6_dropped=0,in_pkts_notvalid=0,rx_size_64_packets=0,tx_management_packets=0,rx_length_errors=0,tx_priority7_xon_to_xoff_packets=0,rx_mbuf_allocation_errors=0,rx_missed_errors=0,rx_priority1_mbuf_allocation_errors=0,rx_fcoe_no_direct_data_placement=0,tx_priority3_xoff_packets=0,in_pkts_delayed=0,tx_errors=0,rx_size_512_to_1023_packets=0,tx_priority4_xon_packets=0,rx_q0bytes=7092,in_pkts_unchecked=0,tx_size_512_to_1023_packets=0,rx_fcoe_packets=0,in_pkts_nosci=0,rx_priority6_mbuf_allocation_errors=0,rx_priority1_dropped=0,tx_q2packets=0,rx_priority7_dropped=0,tx_size_1024_to_max_packets=0,rx_management_packets=0,rx_multicast_packets=98,rx_total_bytes=7092,mac_remote_errors=0,tx_priority3_xon_packets=0,rx_priority2_mbuf_allocation_errors=0,rx_priority5_mbuf_allocation_errors=0,tx_q2bytes=0,rx_size_128_to_255_packets=0,in_pkts_badtag=0,out_pkts_protected=0,rx_management_dropped=0,rx_fcoe_bytes=0,flow_director_removed_filters=0,tx_priority2_xoff_packets=0,rx_fcoe_crc_errors=0,rx_priority0_mbuf_allocation_errors=0,rx_priority0_xon_packets=0,rx_fcoe_dropped=0,tx_priority1_xon_to_xoff_packets=0,rx_size_65_to_127_packets=98,rx_q0packets=98,tx_priority0_xoff_packets=0,rx_priority6_xon_packets=0,rx_total_packets=98,rx_undersize_errors=0,flow_director_missed_filters=0,rx_jabber_errors=0,in_pkts_invalid=0,in_pkts_late=0,rx_priority5_xon_packets=0,tx_priority4_xoff_packets=0,out_octets_encrypted=0,tx_q1packets=0,rx_priority5_xoff_packets=0,rx_priority6_xoff_packets=0,rx_errors=0,in_octets_validated=0,rx_priority3_xoff_packets=0,tx_priority4_xon_to_xoff_packets=0,tx_priority5_xon_to_xoff_packets=0,tx_flow_control_xon_packets=0,rx_priority0_dropped=0,flow_director_filter_add_errors=0,tx_q1bytes=0,tx_priority6_xon_to_xoff_packets=0,flow_director_matched_filters=0,tx_priority2_xon_packets=0,rx_fcoe_mbuf_allocation_errors=0,rx_priority2_xoff_packets=0,tx_priority7_xoff_packets=0,rx_priority0_xoff_packets=0,rx_oversize_errors=0,in_pkts_notusingsa=0,tx_size_64_packets=0,rx_size_1024_to_max_packets=0,tx_priority6_xon_packets=0,rx_priority2_dropped=0,rx_priority4_dropped=0,rx_priority7_mbuf_allocation_errors=0,rx_flow_control_xon_packets=0,tx_good_bytes=0,tx_priority3_xon_to_xoff_packets=0,rx_total_missed_packets=0,rx_error_bytes=0,tx_priority7_xon_packets=0,rx_mac_short_packet_dropped=0,tx_priority1_xoff_packets=0,tx_good_packets=0,tx_broadcast_packets=0,tx_xon_packets=0,in_pkts_unusedsa=0,rx_priority2_xon_packets=0,in_pkts_untagged=0,tx_fcoe_packets=0,flow_director_filter_remove_errors=0,rx_priority3_mbuf_allocation_errors=0,tx_priority0_xon_packets=0,rx_priority7_xon_packets=0,rx_fcoe_no_direct_data_placement_ext_buff=0,tx_xoff_packets=0,tx_size_256_to_511_packets=0 1606310780000000000\ndpdk,command=/ethdev/link_status,dpdk_instance=l3fwd-power,host=dpdk-host,params=0 status="UP",speed=10000,duplex="full-duplex" 1606310780000000000\ndpdk,command=/ethdev/link_status,dpdk_instance=l3fwd-power,host=dpdk-host,params=1 status="UP",speed=10000,duplex="full-duplex" 1606310780000000000\ndpdk,command=/l3fwd-power/stats,dpdk_instance=l3fwd-power,host=dpdk-host empty_poll=49506395979901,full_poll=0,busy_percent=0 1606310780000000000\n```\n',image:Ae.a},{id:"ecs",name:"Amazon ECS",markdown:'# Amazon ECS Input Plugin\n\nAmazon ECS, Fargate compatible, input plugin which uses the Amazon ECS metadata and\nstats [v2][task-metadata-endpoint-v2] or [v3][task-metadata-endpoint-v3] API endpoints\nto gather stats on running containers in a Task.\n\nThe telegraf container must be run in the same Task as the workload it is\ninspecting.\n\nThis is similar to (and reuses a few pieces of) the [Docker][docker-input]\ninput plugin, with some ECS specific modifications for AWS metadata and stats\nformats.\n\nThe amazon-ecs-agent (though it _is_ a container running on the host) is not\npresent in the metadata/stats endpoints.\n\n### Configuration\n\n```toml\n# Read metrics about ECS containers\n[[inputs.ecs]]\n  ## ECS metadata url.\n  ## Metadata v2 API is used if set explicitly. Otherwise,\n  ## v3 metadata endpoint API is used if available.\n  # endpoint_url = ""\n\n  ## Containers to include and exclude. Globs accepted.\n  ## Note that an empty array for both will include all containers\n  # container_name_include = []\n  # container_name_exclude = []\n\n  ## Container states to include and exclude. Globs accepted.\n  ## When empty only containers in the "RUNNING" state will be captured.\n  ## Possible values are "NONE", "PULLED", "CREATED", "RUNNING",\n  ## "RESOURCES_PROVISIONED", "STOPPED".\n  # container_status_include = []\n  # container_status_exclude = []\n\n  ## ecs labels to include and exclude as tags.  Globs accepted.\n  ## Note that an empty array for both will include all labels as tags\n  ecs_label_include = [ "com.amazonaws.ecs.*" ]\n  ecs_label_exclude = []\n\n  ## Timeout for queries.\n  # timeout = "5s"\n```\n\n### Configuration (enforce v2 metadata)\n\n```toml\n# Read metrics about ECS containers\n[[inputs.ecs]]\n  ## ECS metadata url.\n  ## Metadata v2 API is used if set explicitly. Otherwise,\n  ## v3 metadata endpoint API is used if available.\n  endpoint_url = "http://169.254.170.2"\n\n  ## Containers to include and exclude. Globs accepted.\n  ## Note that an empty array for both will include all containers\n  # container_name_include = []\n  # container_name_exclude = []\n\n  ## Container states to include and exclude. Globs accepted.\n  ## When empty only containers in the "RUNNING" state will be captured.\n  ## Possible values are "NONE", "PULLED", "CREATED", "RUNNING",\n  ## "RESOURCES_PROVISIONED", "STOPPED".\n  # container_status_include = []\n  # container_status_exclude = []\n\n  ## ecs labels to include and exclude as tags.  Globs accepted.\n  ## Note that an empty array for both will include all labels as tags\n  ecs_label_include = [ "com.amazonaws.ecs.*" ]\n  ecs_label_exclude = []\n\n  ## Timeout for queries.\n  # timeout = "5s"\n```\n\n### Metrics\n\n- ecs_task\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n  - fields:\n    - desired_status (string)\n    - known_status (string)\n    - limit_cpu (float)\n    - limit_mem (float)\n\n+ ecs_container_mem\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n  - fields:\n    - container_id\n    - active_anon\n    - active_file\n    - cache\n    - hierarchical_memory_limit\n    - inactive_anon\n    - inactive_file\n    - mapped_file\n    - pgfault\n    - pgmajfault\n    - pgpgin\n    - pgpgout\n    - rss\n    - rss_huge\n    - total_active_anon\n    - total_active_file\n    - total_cache\n    - total_inactive_anon\n    - total_inactive_file\n    - total_mapped_file\n    - total_pgfault\n    - total_pgmajfault\n    - total_pgpgin\n    - total_pgpgout\n    - total_rss\n    - total_rss_huge\n    - total_unevictable\n    - total_writeback\n    - unevictable\n    - writeback\n    - fail_count\n    - limit\n    - max_usage\n    - usage\n    - usage_percent\n\n- ecs_container_cpu\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n    - cpu\n  - fields:\n    - container_id\n    - usage_total\n    - usage_in_usermode\n    - usage_in_kernelmode\n    - usage_system\n    - throttling_periods\n    - throttling_throttled_periods\n    - throttling_throttled_time\n    - usage_percent\n    - usage_total\n\n+ ecs_container_net\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n    - network\n  - fields:\n    - container_id\n    - rx_packets\n    - rx_dropped\n    - rx_bytes\n    - rx_errors\n    - tx_packets\n    - tx_dropped\n    - tx_bytes\n    - tx_errors\n\n- ecs_container_blkio\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n    - device\n  - fields:\n    - container_id\n    - io_service_bytes_recursive_async\n    - io_service_bytes_recursive_read\n    - io_service_bytes_recursive_sync\n    - io_service_bytes_recursive_total\n    - io_service_bytes_recursive_write\n    - io_serviced_recursive_async\n    - io_serviced_recursive_read\n    - io_serviced_recursive_sync\n    - io_serviced_recursive_total\n    - io_serviced_recursive_write\n\n+ ecs_container_meta\n  - tags:\n    - cluster\n    - task_arn\n    - family\n    - revision\n    - id\n    - name\n  - fields:\n    - container_id\n    - docker_name\n    - image\n    - image_id\n    - desired_status\n    - known_status\n    - limit_cpu\n    - limit_mem\n    - created_at\n    - started_at\n    - type\n\n\n### Example Output\n\n```\necs_task,cluster=test,family=nginx,host=c4b301d4a123,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a desired_status="RUNNING",known_status="RUNNING",limit_cpu=0.5,limit_mem=512 1542641488000000000\necs_container_mem,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a active_anon=40960i,active_file=8192i,cache=790528i,pgpgin=1243i,total_pgfault=1298i,total_rss=40960i,limit=1033658368i,max_usage=4825088i,hierarchical_memory_limit=536870912i,rss=40960i,total_active_file=8192i,total_mapped_file=618496i,usage_percent=0.05349543109392212,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",pgfault=1298i,pgmajfault=6i,pgpgout=1040i,total_active_anon=40960i,total_inactive_file=782336i,total_pgpgin=1243i,usage=552960i,inactive_file=782336i,mapped_file=618496i,total_cache=790528i,total_pgpgout=1040i 1542642001000000000\necs_container_cpu,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,cpu=cpu-total,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a usage_in_kernelmode=0i,throttling_throttled_periods=0i,throttling_periods=0i,throttling_throttled_time=0i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",usage_percent=0,usage_total=26426156i,usage_in_usermode=20000000i,usage_system=2336100000000i 1542642001000000000\necs_container_cpu,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,cpu=cpu0,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",usage_total=26426156i 1542642001000000000\necs_container_net,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,network=eth0,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a rx_errors=0i,rx_packets=36i,tx_errors=0i,tx_bytes=648i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",rx_dropped=0i,rx_bytes=5338i,tx_packets=8i,tx_dropped=0i 1542642001000000000\necs_container_net,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,network=eth5,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a rx_errors=0i,tx_packets=9i,rx_packets=26i,tx_errors=0i,rx_bytes=4641i,tx_dropped=0i,tx_bytes=690i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",rx_dropped=0i 1542642001000000000\necs_container_net,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,network=total,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a rx_dropped=0i,rx_bytes=9979i,rx_errors=0i,rx_packets=62i,tx_bytes=1338i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",tx_packets=17i,tx_dropped=0i,tx_errors=0i 1542642001000000000\necs_container_blkio,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,device=253:1,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a io_service_bytes_recursive_sync=790528i,io_service_bytes_recursive_total=790528i,io_serviced_recursive_sync=10i,io_serviced_recursive_write=0i,io_serviced_recursive_async=0i,io_serviced_recursive_total=10i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",io_service_bytes_recursive_read=790528i,io_service_bytes_recursive_write=0i,io_service_bytes_recursive_async=0i,io_serviced_recursive_read=10i 1542642001000000000\necs_container_blkio,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,device=253:2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a io_service_bytes_recursive_sync=790528i,io_service_bytes_recursive_total=790528i,io_serviced_recursive_async=0i,io_serviced_recursive_total=10i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",io_service_bytes_recursive_read=790528i,io_service_bytes_recursive_write=0i,io_service_bytes_recursive_async=0i,io_serviced_recursive_read=10i,io_serviced_recursive_write=0i,io_serviced_recursive_sync=10i 1542642001000000000\necs_container_blkio,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,device=253:4,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a io_service_bytes_recursive_write=0i,io_service_bytes_recursive_sync=790528i,io_service_bytes_recursive_async=0i,io_service_bytes_recursive_total=790528i,io_serviced_recursive_async=0i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",io_service_bytes_recursive_read=790528i,io_serviced_recursive_read=10i,io_serviced_recursive_write=0i,io_serviced_recursive_sync=10i,io_serviced_recursive_total=10i 1542642001000000000\necs_container_blkio,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,device=202:26368,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a io_serviced_recursive_read=10i,io_serviced_recursive_write=0i,io_serviced_recursive_sync=10i,io_serviced_recursive_async=0i,io_serviced_recursive_total=10i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",io_service_bytes_recursive_sync=790528i,io_service_bytes_recursive_total=790528i,io_service_bytes_recursive_async=0i,io_service_bytes_recursive_read=790528i,io_service_bytes_recursive_write=0i 1542642001000000000\necs_container_blkio,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,device=total,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a io_serviced_recursive_async=0i,io_serviced_recursive_read=40i,io_serviced_recursive_sync=40i,io_serviced_recursive_write=0i,io_serviced_recursive_total=40i,io_service_bytes_recursive_read=3162112i,io_service_bytes_recursive_write=0i,io_service_bytes_recursive_async=0i,container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",io_service_bytes_recursive_sync=3162112i,io_service_bytes_recursive_total=3162112i 1542642001000000000\necs_container_meta,cluster=test,com.amazonaws.ecs.cluster=test,com.amazonaws.ecs.container-name=~internal~ecs~pause,com.amazonaws.ecs.task-arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a,com.amazonaws.ecs.task-definition-family=nginx,com.amazonaws.ecs.task-definition-version=2,family=nginx,host=c4b301d4a123,id=e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba,name=~internal~ecs~pause,revision=2,task_arn=arn:aws:ecs:aws-region-1:012345678901:task/a1234abc-a0a0-0a01-ab01-0abc012a0a0a limit_mem=0,type="CNI_PAUSE",container_id="e6af031b91deb3136a2b7c42f262ed2ab554e2fe2736998c7d8edf4afe708dba",docker_name="ecs-nginx-2-internalecspause",limit_cpu=0,known_status="RESOURCES_PROVISIONED",image="amazon/amazon-ecs-pause:0.1.0",image_id="",desired_status="RESOURCES_PROVISIONED" 1542642001000000000\n```\n\n[docker-input]: /plugins/inputs/docker/README.md\n[task-metadata-endpoint-v2]: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v2.html\n[task-metadata-endpoint-v3] https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v3.html\n',image:De.a},{id:"elasticsearch",name:"Elasticsearch",markdown:'# Elasticsearch Input Plugin\n\nThe [elasticsearch](https://www.elastic.co/) plugin queries endpoints to obtain\n[Node Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html)\nand optionally\n[Cluster-Health](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html)\nmetrics.\n\nIn addition, the following optional queries are only made by the master node:\n [Cluster Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-stats.html)\n [Indices Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html)\n [Shard Stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html)\n\nSpecific Elasticsearch endpoints that are queried:\n- Node: either /_nodes/stats or /_nodes/_local/stats depending on \'local\' configuration setting\n- Cluster Heath:  /_cluster/health?level=indices\n- Cluster Stats:  /_cluster/stats\n- Indices Stats:  /_all/_stats\n- Shard Stats:  /_all/_stats?level=shards\n\nNote that specific statistics information can change between Elasticsearch versions. In general, this plugin attempts to stay as version-generic as possible by tagging high-level categories only and using a generic json parser to make unique field names of whatever statistics names are provided at the mid-low level.\n\n### Configuration\n\n```toml\n[[inputs.elasticsearch]]\n  ## specify a list of one or more Elasticsearch servers\n  ## you can add username and password to your url to use basic authentication:\n  ## servers = ["http://user:pass@localhost:9200"]\n  servers = ["http://localhost:9200"]\n\n  ## Timeout for HTTP requests to the elastic search server(s)\n  http_timeout = "5s"\n\n  ## When local is true (the default), the node will read only its own stats.\n  ## Set local to false when you want to read the node stats from all nodes\n  ## of the cluster.\n  local = true\n\n  ## Set cluster_health to true when you want to obtain cluster health stats\n  cluster_health = false\n\n  ## Adjust cluster_health_level when you want to obtain detailed health stats\n  ## The options are\n  ##  - indices (default)\n  ##  - cluster\n  # cluster_health_level = "indices"\n\n  ## Set cluster_stats to true when you want to obtain cluster stats.\n  cluster_stats = false\n\n  ## Only gather cluster_stats from the master node. To work this require local = true\n  cluster_stats_only_from_master = true\n\n  ## Indices to collect; can be one or more indices names or _all\n  ## Use of wildcards is allowed. Use a wildcard at the end to retrieve index names that end with a changing value, like a date.\n  indices_include = ["_all"]\n\n  ## One of "shards", "cluster", "indices"\n  ## Currently only "shards" is implemented\n  indices_level = "shards"\n\n  ## node_stats is a list of sub-stats that you want to have gathered. Valid options\n  ## are "indices", "os", "process", "jvm", "thread_pool", "fs", "transport", "http",\n  ## "breaker". Per default, all stats are gathered.\n  # node_stats = ["jvm", "http"]\n\n  ## HTTP Basic Authentication username and password.\n  # username = ""\n  # password = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Sets the number of most recent indices to return for indices that are configured with a date-stamped suffix.\n  ## Each \'indices_include\' entry ending with a wildcard (*) or glob matching pattern will group together all indices that match it, and ## sort them by the date or number after the wildcard. Metrics then are gathered for only the \'num_most_recent_indices\' amount of most ## recent indices.\n  # num_most_recent_indices = 0\n```\n\n### Metrics\n\nEmitted when `cluster_health = true`:\n\n- elasticsearch_cluster_health\n  - tags:\n    - name\n  - fields:\n    - active_primary_shards (integer)\n    - active_shards (integer)\n    - active_shards_percent_as_number (float)\n    - delayed_unassigned_shards (integer)\n    - initializing_shards (integer)\n    - number_of_data_nodes (integer)\n    - number_of_in_flight_fetch (integer)\n    - number_of_nodes (integer)\n    - number_of_pending_tasks (integer)\n    - relocating_shards (integer)\n    - status (string, one of green, yellow or red)\n    - status_code (integer, green = 1, yellow = 2, red = 3),\n    - task_max_waiting_in_queue_millis (integer)\n    - timed_out (boolean)\n    - unassigned_shards (integer)\n\nEmitted when `cluster_health = true` and `cluster_health_level = "indices"`:\n\n- elasticsearch_cluster_health_indices\n  - tags:\n    - index\n    - name\n  - fields:\n    - active_primary_shards (integer)\n    - active_shards (integer)\n    - initializing_shards (integer)\n    - number_of_replicas (integer)\n    - number_of_shards (integer)\n    - relocating_shards (integer)\n    - status (string, one of green, yellow or red)\n    - status_code (integer, green = 1, yellow = 2, red = 3),\n    - unassigned_shards (integer)\n\nEmitted when `cluster_stats = true`:\n\n- elasticsearch_clusterstats_indices\n  - tags:\n    - cluster_name\n    - node_name\n    - status\n  - fields:\n    - completion_size_in_bytes (float)\n    - count (float)\n    - docs_count (float)\n    - docs_deleted (float)\n    - fielddata_evictions (float)\n    - fielddata_memory_size_in_bytes (float)\n    - query_cache_cache_count (float)\n    - query_cache_cache_size (float)\n    - query_cache_evictions (float)\n    - query_cache_hit_count (float)\n    - query_cache_memory_size_in_bytes (float)\n    - query_cache_miss_count (float)\n    - query_cache_total_count (float)\n    - segments_count (float)\n    - segments_doc_values_memory_in_bytes (float)\n    - segments_fixed_bit_set_memory_in_bytes (float)\n    - segments_index_writer_memory_in_bytes (float)\n    - segments_max_unsafe_auto_id_timestamp (float)\n    - segments_memory_in_bytes (float)\n    - segments_norms_memory_in_bytes (float)\n    - segments_points_memory_in_bytes (float)\n    - segments_stored_fields_memory_in_bytes (float)\n    - segments_term_vectors_memory_in_bytes (float)\n    - segments_terms_memory_in_bytes (float)\n    - segments_version_map_memory_in_bytes (float)\n    - shards_index_primaries_avg (float)\n    - shards_index_primaries_max (float)\n    - shards_index_primaries_min (float)\n    - shards_index_replication_avg (float)\n    - shards_index_replication_max (float)\n    - shards_index_replication_min (float)\n    - shards_index_shards_avg (float)\n    - shards_index_shards_max (float)\n    - shards_index_shards_min (float)\n    - shards_primaries (float)\n    - shards_replication (float)\n    - shards_total (float)\n    - store_size_in_bytes (float)\n\n+ elasticsearch_clusterstats_nodes\n  - tags:\n    - cluster_name\n    - node_name\n    - status\n  - fields:\n    - count_coordinating_only (float)\n    - count_data (float)\n    - count_ingest (float)\n    - count_master (float)\n    - count_total (float)\n    - fs_available_in_bytes (float)\n    - fs_free_in_bytes (float)\n    - fs_total_in_bytes (float)\n    - jvm_max_uptime_in_millis (float)\n    - jvm_mem_heap_max_in_bytes (float)\n    - jvm_mem_heap_used_in_bytes (float)\n    - jvm_threads (float)\n    - jvm_versions_0_count (float)\n    - jvm_versions_0_version (string)\n    - jvm_versions_0_vm_name (string)\n    - jvm_versions_0_vm_vendor (string)\n    - jvm_versions_0_vm_version (string)\n    - network_types_http_types_security4 (float)\n    - network_types_transport_types_security4 (float)\n    - os_allocated_processors (float)\n    - os_available_processors (float)\n    - os_mem_free_in_bytes (float)\n    - os_mem_free_percent (float)\n    - os_mem_total_in_bytes (float)\n    - os_mem_used_in_bytes (float)\n    - os_mem_used_percent (float)\n    - os_names_0_count (float)\n    - os_names_0_name (string)\n    - os_pretty_names_0_count (float)\n    - os_pretty_names_0_pretty_name (string)\n    - process_cpu_percent (float)\n    - process_open_file_descriptors_avg (float)\n    - process_open_file_descriptors_max (float)\n    - process_open_file_descriptors_min (float)\n    - versions_0 (string)\n\nEmitted when the appropriate `node_stats` options are set.\n\n- elasticsearch_transport\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - rx_count (float)\n    - rx_size_in_bytes (float)\n    - server_open (float)\n    - tx_count (float)\n    - tx_size_in_bytes (float)\n\n+ elasticsearch_breakers\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - accounting_estimated_size_in_bytes (float)\n    - accounting_limit_size_in_bytes (float)\n    - accounting_overhead (float)\n    - accounting_tripped (float)\n    - fielddata_estimated_size_in_bytes (float)\n    - fielddata_limit_size_in_bytes (float)\n    - fielddata_overhead (float)\n    - fielddata_tripped (float)\n    - in_flight_requests_estimated_size_in_bytes (float)\n    - in_flight_requests_limit_size_in_bytes (float)\n    - in_flight_requests_overhead (float)\n    - in_flight_requests_tripped (float)\n    - parent_estimated_size_in_bytes (float)\n    - parent_limit_size_in_bytes (float)\n    - parent_overhead (float)\n    - parent_tripped (float)\n    - request_estimated_size_in_bytes (float)\n    - request_limit_size_in_bytes (float)\n    - request_overhead (float)\n    - request_tripped (float)\n\n- elasticsearch_fs\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - data_0_available_in_bytes (float)\n    - data_0_free_in_bytes (float)\n    - data_0_total_in_bytes (float)\n    - io_stats_devices_0_operations (float)\n    - io_stats_devices_0_read_kilobytes (float)\n    - io_stats_devices_0_read_operations (float)\n    - io_stats_devices_0_write_kilobytes (float)\n    - io_stats_devices_0_write_operations (float)\n    - io_stats_total_operations (float)\n    - io_stats_total_read_kilobytes (float)\n    - io_stats_total_read_operations (float)\n    - io_stats_total_write_kilobytes (float)\n    - io_stats_total_write_operations (float)\n    - timestamp (float)\n    - total_available_in_bytes (float)\n    - total_free_in_bytes (float)\n    - total_total_in_bytes (float)\n\n+ elasticsearch_http\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - current_open (float)\n    - total_opened (float)\n\n- elasticsearch_indices\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - completion_size_in_bytes (float)\n    - docs_count (float)\n    - docs_deleted (float)\n    - fielddata_evictions (float)\n    - fielddata_memory_size_in_bytes (float)\n    - flush_periodic (float)\n    - flush_total (float)\n    - flush_total_time_in_millis (float)\n    - get_current (float)\n    - get_exists_time_in_millis (float)\n    - get_exists_total (float)\n    - get_missing_time_in_millis (float)\n    - get_missing_total (float)\n    - get_time_in_millis (float)\n    - get_total (float)\n    - indexing_delete_current (float)\n    - indexing_delete_time_in_millis (float)\n    - indexing_delete_total (float)\n    - indexing_index_current (float)\n    - indexing_index_failed (float)\n    - indexing_index_time_in_millis (float)\n    - indexing_index_total (float)\n    - indexing_noop_update_total (float)\n    - indexing_throttle_time_in_millis (float)\n    - merges_current (float)\n    - merges_current_docs (float)\n    - merges_current_size_in_bytes (float)\n    - merges_total (float)\n    - merges_total_auto_throttle_in_bytes (float)\n    - merges_total_docs (float)\n    - merges_total_size_in_bytes (float)\n    - merges_total_stopped_time_in_millis (float)\n    - merges_total_throttled_time_in_millis (float)\n    - merges_total_time_in_millis (float)\n    - query_cache_cache_count (float)\n    - query_cache_cache_size (float)\n    - query_cache_evictions (float)\n    - query_cache_hit_count (float)\n    - query_cache_memory_size_in_bytes (float)\n    - query_cache_miss_count (float)\n    - query_cache_total_count (float)\n    - recovery_current_as_source (float)\n    - recovery_current_as_target (float)\n    - recovery_throttle_time_in_millis (float)\n    - refresh_listeners (float)\n    - refresh_total (float)\n    - refresh_total_time_in_millis (float)\n    - request_cache_evictions (float)\n    - request_cache_hit_count (float)\n    - request_cache_memory_size_in_bytes (float)\n    - request_cache_miss_count (float)\n    - search_fetch_current (float)\n    - search_fetch_time_in_millis (float)\n    - search_fetch_total (float)\n    - search_open_contexts (float)\n    - search_query_current (float)\n    - search_query_time_in_millis (float)\n    - search_query_total (float)\n    - search_scroll_current (float)\n    - search_scroll_time_in_millis (float)\n    - search_scroll_total (float)\n    - search_suggest_current (float)\n    - search_suggest_time_in_millis (float)\n    - search_suggest_total (float)\n    - segments_count (float)\n    - segments_doc_values_memory_in_bytes (float)\n    - segments_fixed_bit_set_memory_in_bytes (float)\n    - segments_index_writer_memory_in_bytes (float)\n    - segments_max_unsafe_auto_id_timestamp (float)\n    - segments_memory_in_bytes (float)\n    - segments_norms_memory_in_bytes (float)\n    - segments_points_memory_in_bytes (float)\n    - segments_stored_fields_memory_in_bytes (float)\n    - segments_term_vectors_memory_in_bytes (float)\n    - segments_terms_memory_in_bytes (float)\n    - segments_version_map_memory_in_bytes (float)\n    - store_size_in_bytes (float)\n    - translog_earliest_last_modified_age (float)\n    - translog_operations (float)\n    - translog_size_in_bytes (float)\n    - translog_uncommitted_operations (float)\n    - translog_uncommitted_size_in_bytes (float)\n    - warmer_current (float)\n    - warmer_total (float)\n    - warmer_total_time_in_millis (float)\n\n+ elasticsearch_jvm\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - buffer_pools_direct_count (float)\n    - buffer_pools_direct_total_capacity_in_bytes (float)\n    - buffer_pools_direct_used_in_bytes (float)\n    - buffer_pools_mapped_count (float)\n    - buffer_pools_mapped_total_capacity_in_bytes (float)\n    - buffer_pools_mapped_used_in_bytes (float)\n    - classes_current_loaded_count (float)\n    - classes_total_loaded_count (float)\n    - classes_total_unloaded_count (float)\n    - gc_collectors_old_collection_count (float)\n    - gc_collectors_old_collection_time_in_millis (float)\n    - gc_collectors_young_collection_count (float)\n    - gc_collectors_young_collection_time_in_millis (float)\n    - mem_heap_committed_in_bytes (float)\n    - mem_heap_max_in_bytes (float)\n    - mem_heap_used_in_bytes (float)\n    - mem_heap_used_percent (float)\n    - mem_non_heap_committed_in_bytes (float)\n    - mem_non_heap_used_in_bytes (float)\n    - mem_pools_old_max_in_bytes (float)\n    - mem_pools_old_peak_max_in_bytes (float)\n    - mem_pools_old_peak_used_in_bytes (float)\n    - mem_pools_old_used_in_bytes (float)\n    - mem_pools_survivor_max_in_bytes (float)\n    - mem_pools_survivor_peak_max_in_bytes (float)\n    - mem_pools_survivor_peak_used_in_bytes (float)\n    - mem_pools_survivor_used_in_bytes (float)\n    - mem_pools_young_max_in_bytes (float)\n    - mem_pools_young_peak_max_in_bytes (float)\n    - mem_pools_young_peak_used_in_bytes (float)\n    - mem_pools_young_used_in_bytes (float)\n    - threads_count (float)\n    - threads_peak_count (float)\n    - timestamp (float)\n    - uptime_in_millis (float)\n\n- elasticsearch_os\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - cgroup_cpu_cfs_period_micros (float)\n    - cgroup_cpu_cfs_quota_micros (float)\n    - cgroup_cpu_stat_number_of_elapsed_periods (float)\n    - cgroup_cpu_stat_number_of_times_throttled (float)\n    - cgroup_cpu_stat_time_throttled_nanos (float)\n    - cgroup_cpuacct_usage_nanos (float)\n    - cpu_load_average_15m (float)\n    - cpu_load_average_1m (float)\n    - cpu_load_average_5m (float)\n    - cpu_percent (float)\n    - mem_free_in_bytes (float)\n    - mem_free_percent (float)\n    - mem_total_in_bytes (float)\n    - mem_used_in_bytes (float)\n    - mem_used_percent (float)\n    - swap_free_in_bytes (float)\n    - swap_total_in_bytes (float)\n    - swap_used_in_bytes (float)\n    - timestamp (float)\n\n+ elasticsearch_process\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - cpu_percent (float)\n    - cpu_total_in_millis (float)\n    - max_file_descriptors (float)\n    - mem_total_virtual_in_bytes (float)\n    - open_file_descriptors (float)\n    - timestamp (float)\n\n- elasticsearch_thread_pool\n  - tags:\n    - cluster_name\n    - node_attribute_ml.enabled\n    - node_attribute_ml.machine_memory\n    - node_attribute_ml.max_open_jobs\n    - node_attribute_xpack.installed\n    - node_host\n    - node_id\n    - node_name\n  - fields:\n    - analyze_active (float)\n    - analyze_completed (float)\n    - analyze_largest (float)\n    - analyze_queue (float)\n    - analyze_rejected (float)\n    - analyze_threads (float)\n    - ccr_active (float)\n    - ccr_completed (float)\n    - ccr_largest (float)\n    - ccr_queue (float)\n    - ccr_rejected (float)\n    - ccr_threads (float)\n    - fetch_shard_started_active (float)\n    - fetch_shard_started_completed (float)\n    - fetch_shard_started_largest (float)\n    - fetch_shard_started_queue (float)\n    - fetch_shard_started_rejected (float)\n    - fetch_shard_started_threads (float)\n    - fetch_shard_store_active (float)\n    - fetch_shard_store_completed (float)\n    - fetch_shard_store_largest (float)\n    - fetch_shard_store_queue (float)\n    - fetch_shard_store_rejected (float)\n    - fetch_shard_store_threads (float)\n    - flush_active (float)\n    - flush_completed (float)\n    - flush_largest (float)\n    - flush_queue (float)\n    - flush_rejected (float)\n    - flush_threads (float)\n    - force_merge_active (float)\n    - force_merge_completed (float)\n    - force_merge_largest (float)\n    - force_merge_queue (float)\n    - force_merge_rejected (float)\n    - force_merge_threads (float)\n    - generic_active (float)\n    - generic_completed (float)\n    - generic_largest (float)\n    - generic_queue (float)\n    - generic_rejected (float)\n    - generic_threads (float)\n    - get_active (float)\n    - get_completed (float)\n    - get_largest (float)\n    - get_queue (float)\n    - get_rejected (float)\n    - get_threads (float)\n    - index_active (float)\n    - index_completed (float)\n    - index_largest (float)\n    - index_queue (float)\n    - index_rejected (float)\n    - index_threads (float)\n    - listener_active (float)\n    - listener_completed (float)\n    - listener_largest (float)\n    - listener_queue (float)\n    - listener_rejected (float)\n    - listener_threads (float)\n    - management_active (float)\n    - management_completed (float)\n    - management_largest (float)\n    - management_queue (float)\n    - management_rejected (float)\n    - management_threads (float)\n    - ml_autodetect_active (float)\n    - ml_autodetect_completed (float)\n    - ml_autodetect_largest (float)\n    - ml_autodetect_queue (float)\n    - ml_autodetect_rejected (float)\n    - ml_autodetect_threads (float)\n    - ml_datafeed_active (float)\n    - ml_datafeed_completed (float)\n    - ml_datafeed_largest (float)\n    - ml_datafeed_queue (float)\n    - ml_datafeed_rejected (float)\n    - ml_datafeed_threads (float)\n    - ml_utility_active (float)\n    - ml_utility_completed (float)\n    - ml_utility_largest (float)\n    - ml_utility_queue (float)\n    - ml_utility_rejected (float)\n    - ml_utility_threads (float)\n    - refresh_active (float)\n    - refresh_completed (float)\n    - refresh_largest (float)\n    - refresh_queue (float)\n    - refresh_rejected (float)\n    - refresh_threads (float)\n    - rollup_indexing_active (float)\n    - rollup_indexing_completed (float)\n    - rollup_indexing_largest (float)\n    - rollup_indexing_queue (float)\n    - rollup_indexing_rejected (float)\n    - rollup_indexing_threads (float)\n    - search_active (float)\n    - search_completed (float)\n    - search_largest (float)\n    - search_queue (float)\n    - search_rejected (float)\n    - search_threads (float)\n    - search_throttled_active (float)\n    - search_throttled_completed (float)\n    - search_throttled_largest (float)\n    - search_throttled_queue (float)\n    - search_throttled_rejected (float)\n    - search_throttled_threads (float)\n    - security-token-key_active (float)\n    - security-token-key_completed (float)\n    - security-token-key_largest (float)\n    - security-token-key_queue (float)\n    - security-token-key_rejected (float)\n    - security-token-key_threads (float)\n    - snapshot_active (float)\n    - snapshot_completed (float)\n    - snapshot_largest (float)\n    - snapshot_queue (float)\n    - snapshot_rejected (float)\n    - snapshot_threads (float)\n    - warmer_active (float)\n    - warmer_completed (float)\n    - warmer_largest (float)\n    - warmer_queue (float)\n    - warmer_rejected (float)\n    - warmer_threads (float)\n    - watcher_active (float)\n    - watcher_completed (float)\n    - watcher_largest (float)\n    - watcher_queue (float)\n    - watcher_rejected (float)\n    - watcher_threads (float)\n    - write_active (float)\n    - write_completed (float)\n    - write_largest (float)\n    - write_queue (float)\n    - write_rejected (float)\n    - write_threads (float)\n\nEmitted when the appropriate `indices_stats` options are set.\n\n- elasticsearch_indices_stats_(primaries|total)\n  - tags:\n    - index_name\n  - fields:\n    - completion_size_in_bytes (float)\n    - docs_count (float)\n    - docs_deleted (float)\n    - fielddata_evictions (float)\n    - fielddata_memory_size_in_bytes (float)\n    - flush_periodic (float)\n    - flush_total (float)\n    - flush_total_time_in_millis (float)\n    - get_current (float)\n    - get_exists_time_in_millis (float)\n    - get_exists_total (float)\n    - get_missing_time_in_millis (float)\n    - get_missing_total (float)\n    - get_time_in_millis (float)\n    - get_total (float)\n    - indexing_delete_current (float)\n    - indexing_delete_time_in_millis (float)\n    - indexing_delete_total (float)\n    - indexing_index_current (float)\n    - indexing_index_failed (float)\n    - indexing_index_time_in_millis (float)\n    - indexing_index_total (float)\n    - indexing_is_throttled (float)\n    - indexing_noop_update_total (float)\n    - indexing_throttle_time_in_millis (float)\n    - merges_current (float)\n    - merges_current_docs (float)\n    - merges_current_size_in_bytes (float)\n    - merges_total (float)\n    - merges_total_auto_throttle_in_bytes (float)\n    - merges_total_docs (float)\n    - merges_total_size_in_bytes (float)\n    - merges_total_stopped_time_in_millis (float)\n    - merges_total_throttled_time_in_millis (float)\n    - merges_total_time_in_millis (float)\n    - query_cache_cache_count (float)\n    - query_cache_cache_size (float)\n    - query_cache_evictions (float)\n    - query_cache_hit_count (float)\n    - query_cache_memory_size_in_bytes (float)\n    - query_cache_miss_count (float)\n    - query_cache_total_count (float)\n    - recovery_current_as_source (float)\n    - recovery_current_as_target (float)\n    - recovery_throttle_time_in_millis (float)\n    - refresh_external_total (float)\n    - refresh_external_total_time_in_millis (float)\n    - refresh_listeners (float)\n    - refresh_total (float)\n    - refresh_total_time_in_millis (float)\n    - request_cache_evictions (float)\n    - request_cache_hit_count (float)\n    - request_cache_memory_size_in_bytes (float)\n    - request_cache_miss_count (float)\n    - search_fetch_current (float)\n    - search_fetch_time_in_millis (float)\n    - search_fetch_total (float)\n    - search_open_contexts (float)\n    - search_query_current (float)\n    - search_query_time_in_millis (float)\n    - search_query_total (float)\n    - search_scroll_current (float)\n    - search_scroll_time_in_millis (float)\n    - search_scroll_total (float)\n    - search_suggest_current (float)\n    - search_suggest_time_in_millis (float)\n    - search_suggest_total (float)\n    - segments_count (float)\n    - segments_doc_values_memory_in_bytes (float)\n    - segments_fixed_bit_set_memory_in_bytes (float)\n    - segments_index_writer_memory_in_bytes (float)\n    - segments_max_unsafe_auto_id_timestamp (float)\n    - segments_memory_in_bytes (float)\n    - segments_norms_memory_in_bytes (float)\n    - segments_points_memory_in_bytes (float)\n    - segments_stored_fields_memory_in_bytes (float)\n    - segments_term_vectors_memory_in_bytes (float)\n    - segments_terms_memory_in_bytes (float)\n    - segments_version_map_memory_in_bytes (float)\n    - store_size_in_bytes (float)\n    - translog_earliest_last_modified_age (float)\n    - translog_operations (float)\n    - translog_size_in_bytes (float)\n    - translog_uncommitted_operations (float)\n    - translog_uncommitted_size_in_bytes (float)\n    - warmer_current (float)\n    - warmer_total (float)\n    - warmer_total_time_in_millis (float)\n\nEmitted when the appropriate `shards_stats` options are set.\n\n- elasticsearch_indices_stats_shards_total\n  - fields:\n    - failed (float)\n    - successful (float)\n    - total (float)\n\n- elasticsearch_indices_stats_shards\n  - tags:\n    - index_name\n    - node_name\n    - shard_name\n    - type\n  - fields:\n    - commit_generation (float)\n    - commit_num_docs (float)\n    - completion_size_in_bytes (float)\n    - docs_count (float)\n    - docs_deleted (float)\n    - fielddata_evictions (float)\n    - fielddata_memory_size_in_bytes (float)\n    - flush_periodic (float)\n    - flush_total (float)\n    - flush_total_time_in_millis (float)\n    - get_current (float)\n    - get_exists_time_in_millis (float)\n    - get_exists_total (float)\n    - get_missing_time_in_millis (float)\n    - get_missing_total (float)\n    - get_time_in_millis (float)\n    - get_total (float)\n    - indexing_delete_current (float)\n    - indexing_delete_time_in_millis (float)\n    - indexing_delete_total (float)\n    - indexing_index_current (float)\n    - indexing_index_failed (float)\n    - indexing_index_time_in_millis (float)\n    - indexing_index_total (float)\n    - indexing_is_throttled (bool)\n    - indexing_noop_update_total (float)\n    - indexing_throttle_time_in_millis (float)\n    - merges_current (float)\n    - merges_current_docs (float)\n    - merges_current_size_in_bytes (float)\n    - merges_total (float)\n    - merges_total_auto_throttle_in_bytes (float)\n    - merges_total_docs (float)\n    - merges_total_size_in_bytes (float)\n    - merges_total_stopped_time_in_millis (float)\n    - merges_total_throttled_time_in_millis (float)\n    - merges_total_time_in_millis (float)\n    - query_cache_cache_count (float)\n    - query_cache_cache_size (float)\n    - query_cache_evictions (float)\n    - query_cache_hit_count (float)\n    - query_cache_memory_size_in_bytes (float)\n    - query_cache_miss_count (float)\n    - query_cache_total_count (float)\n    - recovery_current_as_source (float)\n    - recovery_current_as_target (float)\n    - recovery_throttle_time_in_millis (float)\n    - refresh_external_total (float)\n    - refresh_external_total_time_in_millis (float)\n    - refresh_listeners (float)\n    - refresh_total (float)\n    - refresh_total_time_in_millis (float)\n    - request_cache_evictions (float)\n    - request_cache_hit_count (float)\n    - request_cache_memory_size_in_bytes (float)\n    - request_cache_miss_count (float)\n    - retention_leases_primary_term (float)\n    - retention_leases_version (float)\n    - routing_state (int) (UNASSIGNED = 1, INITIALIZING = 2, STARTED = 3, RELOCATING = 4, other = 0)\n    - search_fetch_current (float)\n    - search_fetch_time_in_millis (float)\n    - search_fetch_total (float)\n    - search_open_contexts (float)\n    - search_query_current (float)\n    - search_query_time_in_millis (float)\n    - search_query_total (float)\n    - search_scroll_current (float)\n    - search_scroll_time_in_millis (float)\n    - search_scroll_total (float)\n    - search_suggest_current (float)\n    - search_suggest_time_in_millis (float)\n    - search_suggest_total (float)\n    - segments_count (float)\n    - segments_doc_values_memory_in_bytes (float)\n    - segments_fixed_bit_set_memory_in_bytes (float)\n    - segments_index_writer_memory_in_bytes (float)\n    - segments_max_unsafe_auto_id_timestamp (float)\n    - segments_memory_in_bytes (float)\n    - segments_norms_memory_in_bytes (float)\n    - segments_points_memory_in_bytes (float)\n    - segments_stored_fields_memory_in_bytes (float)\n    - segments_term_vectors_memory_in_bytes (float)\n    - segments_terms_memory_in_bytes (float)\n    - segments_version_map_memory_in_bytes (float)\n    - seq_no_global_checkpoint (float)\n    - seq_no_local_checkpoint (float)\n    - seq_no_max_seq_no (float)\n    - shard_path_is_custom_data_path (bool)\n    - store_size_in_bytes (float)\n    - translog_earliest_last_modified_age (float)\n    - translog_operations (float)\n    - translog_size_in_bytes (float)\n    - translog_uncommitted_operations (float)\n    - translog_uncommitted_size_in_bytes (float)\n    - warmer_current (float)\n    - warmer_total (float)\n    - warmer_total_time_in_millis (float)\n',image:Oe.a},{id:"elasticsearch_query",name:"Elasticsearch Query",markdown:'# Elasticsearch query input plugin\n\nThis [elasticsearch](https://www.elastic.co/) query plugin queries endpoints to obtain metrics from data stored in an Elasticsearch cluster.\n\nThe following is supported:\n\n- return number of hits for a search query\n- calculate the avg/max/min/sum for a numeric field, filtered by a query, aggregated per tag\n- count number of terms for a particular field\n\n## Elasticsearch support\n\nThis plugins is tested against Elasticsearch 5.x and 6.x releases.\nCurrently it is known to break on 7.x or greater versions.\n\n## Configuration\n\n```toml\n[[inputs.elasticsearch_query]]\n  ## The full HTTP endpoint URL for your Elasticsearch instance\n  ## Multiple urls can be specified as part of the same cluster,\n  ## this means that only ONE of the urls will be written to each interval.\n  urls = [ "http://node1.es.example.com:9200" ] # required.\n\n  ## Elasticsearch client timeout, defaults to "5s".\n  # timeout = "5s"\n\n  ## Set to true to ask Elasticsearch a list of all cluster nodes,\n  ## thus it is not necessary to list all nodes in the urls config option\n  # enable_sniffer = false\n\n  ## Set the interval to check if the Elasticsearch nodes are available\n  ## This option is only used if enable_sniffer is also set (0s to disable it)\n  # health_check_interval = "10s"\n\n  ## HTTP basic authentication details (eg. when using x-pack)\n  # username = "telegraf"\n  # password = "mypassword"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  [[inputs.elasticsearch_query.aggregation]]\n    ## measurement name for the results of the aggregation query\n    measurement_name = "measurement"\n\n    ## Elasticsearch indexes to query (accept wildcards).\n    index = "index-*"\n\n    ## The date/time field in the Elasticsearch index (mandatory).\n    date_field = "@timestamp"\n\n    ## Time window to query (eg. "1m" to query documents from last minute).\n    ## Normally should be set to same as collection interval\n    query_period = "1m"\n\n    ## Lucene query to filter results\n    # filter_query = "*"\n\n    ## Fields to aggregate values (must be numeric fields)\n    # metric_fields = ["metric"]\n\n    ## Aggregation function to use on the metric fields\n    ## Must be set if \'metric_fields\' is set\n    ## Valid values are: avg, sum, min, max, sum\n    # metric_function = "avg"\n\n    ## Fields to be used as tags\n    ## Must be text, non-analyzed fields. Metric aggregations are performed per tag\n    # tags = ["field.keyword", "field2.keyword"]\n\n    ## Set to true to not ignore documents when the tag(s) above are missing\n    # include_missing_tag = false\n\n    ## String value of the tag when the tag does not exist\n    ## Used when include_missing_tag is true\n    # missing_tag_value = "null"\n```\n\n## Examples\n\nPlease note that the `[[inputs.elasticsearch_query]]` is still required for all of the examples below.\n\n### Search the average response time, per URI and per response status code\n\n```toml\n[[inputs.elasticsearch_query.aggregation]]\n  measurement_name = "http_logs"\n  index = "my-index-*"\n  filter_query = "*"\n  metric_fields = ["response_time"]\n  metric_function = "avg"\n  tags = ["URI.keyword", "response.keyword"]\n  include_missing_tag = true\n  missing_tag_value = "null"\n  date_field = "@timestamp"\n  query_period = "1m"\n```\n\n### Search the maximum response time per method and per URI\n\n```toml\n[[inputs.elasticsearch_query.aggregation]]\n  measurement_name = "http_logs"\n  index = "my-index-*"\n  filter_query = "*"\n  metric_fields = ["response_time"]\n  metric_function = "max"\n  tags = ["method.keyword","URI.keyword"]\n  include_missing_tag = false\n  missing_tag_value = "null"\n  date_field = "@timestamp"\n  query_period = "1m"\n```\n\n### Search number of documents matching a filter query in all indices\n\n```toml\n[[inputs.elasticsearch_query.aggregation]]\n  measurement_name = "http_logs"\n  index = "*"\n  filter_query = "product_1 AND HEAD"\n  query_period = "1m"\n  date_field = "@timestamp"\n```\n\n### Search number of documents matching a filter query, returning per response status code\n\n```toml\n[[inputs.elasticsearch_query.aggregation]]\n  measurement_name = "http_logs"\n  index = "*"\n  filter_query = "downloads"\n  tags = ["response.keyword"]\n  include_missing_tag = false\n  date_field = "@timestamp"\n  query_period = "1m"\n```\n\n### Required parameters\n\n- `measurement_name`: The target measurement to be stored the results of the aggregation query.\n- `index`: The index name to query on Elasticsearch\n- `query_period`: The time window to query (eg. "1m" to query documents from last minute). Normally should be set to same as collection\n- `date_field`: The date/time field in the Elasticsearch index\n\n### Optional parameters\n\n- `filter_query`: Lucene query to filter the results (default: "\\*")\n- `metric_fields`: The list of fields to perform metric aggregation (these must be indexed as numeric fields)\n- `metric_funcion`: The single-value metric aggregation function to be performed on the `metric_fields` defined. Currently supported aggregations are "avg", "min", "max", "sum". (see [https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics.html)\n- `tags`: The list of fields to be used as tags (these must be indexed as non-analyzed fields). A "terms aggregation" will be done per tag defined\n- `include_missing_tag`: Set to true to not ignore documents where the tag(s) specified above does not exist. (If false, documents without the specified tag field will be ignored in `doc_count` and in the metric aggregation)\n- `missing_tag_value`: The value of the tag that will be set for documents in which the tag field does not exist. Only used when `include_missing_tag` is set to `true`.\n',image:Oe.a},{id:"ethtool",name:"Ethtool",markdown:'# Ethtool Input Plugin\n\nThe ethtool input plugin pulls ethernet device stats. Fields pulled will depend on the network device and driver.\n\n### Configuration:\n\n```toml\n# Returns ethtool statistics for given interfaces\n[[inputs.ethtool]]\n  ## List of interfaces to pull metrics for\n  # interface_include = ["eth0"]\n\n  ## List of interfaces to ignore when pulling metrics.\n  # interface_exclude = ["eth1"]\n```\n\nInterfaces can be included or ignored using:\n\n- `interface_include`\n- `interface_exclude`\n\nNote that loopback interfaces will be automatically ignored.\n\n### Metrics:\n\nMetrics are dependent on the network device and driver.\n\n### Example Output:\n\n```\nethtool,driver=igb,host=test01,interface=mgmt0 tx_queue_1_packets=280782i,rx_queue_5_csum_err=0i,tx_queue_4_restart=0i,tx_multicast=7i,tx_queue_1_bytes=39674885i,rx_queue_2_alloc_failed=0i,tx_queue_5_packets=173970i,tx_single_coll_ok=0i,rx_queue_1_drops=0i,tx_queue_2_restart=0i,tx_aborted_errors=0i,rx_queue_6_csum_err=0i,tx_queue_5_restart=0i,tx_queue_4_bytes=64810835i,tx_abort_late_coll=0i,tx_queue_4_packets=109102i,os2bmc_tx_by_bmc=0i,tx_bytes=427527435i,tx_queue_7_packets=66665i,dropped_smbus=0i,rx_queue_0_csum_err=0i,tx_flow_control_xoff=0i,rx_packets=25926536i,rx_queue_7_csum_err=0i,rx_queue_3_bytes=84326060i,rx_multicast=83771i,rx_queue_4_alloc_failed=0i,rx_queue_3_drops=0i,rx_queue_3_csum_err=0i,rx_errors=0i,tx_errors=0i,tx_queue_6_packets=183236i,rx_broadcast=24378893i,rx_queue_7_packets=88680i,tx_dropped=0i,rx_frame_errors=0i,tx_queue_3_packets=161045i,tx_packets=1257017i,rx_queue_1_csum_err=0i,tx_window_errors=0i,tx_dma_out_of_sync=0i,rx_length_errors=0i,rx_queue_5_drops=0i,tx_timeout_count=0i,rx_queue_4_csum_err=0i,rx_flow_control_xon=0i,tx_heartbeat_errors=0i,tx_flow_control_xon=0i,collisions=0i,tx_queue_0_bytes=29465801i,rx_queue_6_drops=0i,rx_queue_0_alloc_failed=0i,tx_queue_1_restart=0i,rx_queue_0_drops=0i,tx_broadcast=9i,tx_carrier_errors=0i,tx_queue_7_bytes=13777515i,tx_queue_7_restart=0i,rx_queue_5_bytes=50732006i,rx_queue_7_bytes=35744457i,tx_deferred_ok=0i,tx_multi_coll_ok=0i,rx_crc_errors=0i,rx_fifo_errors=0i,rx_queue_6_alloc_failed=0i,tx_queue_2_packets=175206i,tx_queue_0_packets=107011i,rx_queue_4_bytes=201364548i,rx_queue_6_packets=372573i,os2bmc_rx_by_host=0i,multicast=83771i,rx_queue_4_drops=0i,rx_queue_5_packets=130535i,rx_queue_6_bytes=139488035i,tx_fifo_errors=0i,tx_queue_5_bytes=84899130i,rx_queue_0_packets=24529563i,rx_queue_3_alloc_failed=0i,rx_queue_7_drops=0i,tx_queue_6_bytes=96288614i,tx_queue_2_bytes=22132949i,tx_tcp_seg_failed=0i,rx_queue_1_bytes=246703840i,rx_queue_0_bytes=1506870738i,tx_queue_0_restart=0i,rx_queue_2_bytes=111344804i,tx_tcp_seg_good=0i,tx_queue_3_restart=0i,rx_no_buffer_count=0i,rx_smbus=0i,rx_queue_1_packets=273865i,rx_over_errors=0i,os2bmc_tx_by_host=0i,rx_queue_1_alloc_failed=0i,rx_queue_7_alloc_failed=0i,rx_short_length_errors=0i,tx_hwtstamp_timeouts=0i,tx_queue_6_restart=0i,rx_queue_2_packets=207136i,tx_queue_3_bytes=70391970i,rx_queue_3_packets=112007i,rx_queue_4_packets=212177i,tx_smbus=0i,rx_long_byte_count=2480280632i,rx_queue_2_csum_err=0i,rx_missed_errors=0i,rx_bytes=2480280632i,rx_queue_5_alloc_failed=0i,rx_queue_2_drops=0i,os2bmc_rx_by_bmc=0i,rx_align_errors=0i,rx_long_length_errors=0i,interface_up=1i,rx_hwtstamp_cleared=0i,rx_flow_control_xoff=0i 1564658080000000000\nethtool,driver=igb,host=test02,interface=mgmt0 rx_queue_2_bytes=111344804i,tx_queue_3_bytes=70439858i,multicast=83771i,rx_broadcast=24378975i,tx_queue_0_packets=107011i,rx_queue_6_alloc_failed=0i,rx_queue_6_drops=0i,rx_hwtstamp_cleared=0i,tx_window_errors=0i,tx_tcp_seg_good=0i,rx_queue_1_drops=0i,tx_queue_1_restart=0i,rx_queue_7_csum_err=0i,rx_no_buffer_count=0i,tx_queue_1_bytes=39675245i,tx_queue_5_bytes=84899130i,tx_broadcast=9i,rx_queue_1_csum_err=0i,tx_flow_control_xoff=0i,rx_queue_6_csum_err=0i,tx_timeout_count=0i,os2bmc_tx_by_bmc=0i,rx_queue_6_packets=372577i,rx_queue_0_alloc_failed=0i,tx_flow_control_xon=0i,rx_queue_2_drops=0i,tx_queue_2_packets=175206i,rx_queue_3_csum_err=0i,tx_abort_late_coll=0i,tx_queue_5_restart=0i,tx_dropped=0i,rx_queue_2_alloc_failed=0i,tx_multi_coll_ok=0i,rx_queue_1_packets=273865i,rx_flow_control_xon=0i,tx_single_coll_ok=0i,rx_length_errors=0i,rx_queue_7_bytes=35744457i,rx_queue_4_alloc_failed=0i,rx_queue_6_bytes=139488395i,rx_queue_2_csum_err=0i,rx_long_byte_count=2480288216i,rx_queue_1_alloc_failed=0i,tx_queue_0_restart=0i,rx_queue_0_csum_err=0i,tx_queue_2_bytes=22132949i,rx_queue_5_drops=0i,tx_dma_out_of_sync=0i,rx_queue_3_drops=0i,rx_queue_4_packets=212177i,tx_queue_6_restart=0i,rx_packets=25926650i,rx_queue_7_packets=88680i,rx_frame_errors=0i,rx_queue_3_bytes=84326060i,rx_short_length_errors=0i,tx_queue_7_bytes=13777515i,rx_queue_3_alloc_failed=0i,tx_queue_6_packets=183236i,rx_queue_0_drops=0i,rx_multicast=83771i,rx_queue_2_packets=207136i,rx_queue_5_csum_err=0i,rx_queue_5_packets=130535i,rx_queue_7_alloc_failed=0i,tx_smbus=0i,tx_queue_3_packets=161081i,rx_queue_7_drops=0i,tx_queue_2_restart=0i,tx_multicast=7i,tx_fifo_errors=0i,tx_queue_3_restart=0i,rx_long_length_errors=0i,tx_queue_6_bytes=96288614i,tx_queue_1_packets=280786i,tx_tcp_seg_failed=0i,rx_align_errors=0i,tx_errors=0i,rx_crc_errors=0i,rx_queue_0_packets=24529673i,rx_flow_control_xoff=0i,tx_queue_0_bytes=29465801i,rx_over_errors=0i,rx_queue_4_drops=0i,os2bmc_rx_by_bmc=0i,rx_smbus=0i,dropped_smbus=0i,tx_hwtstamp_timeouts=0i,rx_errors=0i,tx_queue_4_packets=109102i,tx_carrier_errors=0i,tx_queue_4_bytes=64810835i,tx_queue_4_restart=0i,rx_queue_4_csum_err=0i,tx_queue_7_packets=66665i,tx_aborted_errors=0i,rx_missed_errors=0i,tx_bytes=427575843i,collisions=0i,rx_queue_1_bytes=246703840i,rx_queue_5_bytes=50732006i,rx_bytes=2480288216i,os2bmc_rx_by_host=0i,rx_queue_5_alloc_failed=0i,rx_queue_3_packets=112007i,tx_deferred_ok=0i,os2bmc_tx_by_host=0i,tx_heartbeat_errors=0i,rx_queue_0_bytes=1506877506i,tx_queue_7_restart=0i,tx_packets=1257057i,rx_queue_4_bytes=201364548i,interface_up=0i,rx_fifo_errors=0i,tx_queue_5_packets=173970i 1564658090000000000\n```\n',image:Re.a},{id:"eventhub_consumer",name:"Event Hub Consumer",markdown:'# Event Hub Consumer Input Plugin\n\nThis plugin provides a consumer for use with Azure Event Hubs and Azure IoT Hub.\n\n### IoT Hub Setup\n\nThe main focus for development of this plugin is Azure IoT hub:\n\n1. Create an Azure IoT Hub by following any of the guides provided here: https://docs.microsoft.com/en-us/azure/iot-hub/\n2. Create a device, for example a [simulated Raspberry Pi](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-raspberry-pi-web-simulator-get-started)\n3. The connection string needed for the plugin is located under *Shared access policies*, both the *iothubowner* and *service* policies should work\n\n### Configuration\n\n```toml\n[[inputs.eventhub_consumer]]\n  ## The default behavior is to create a new Event Hub client from environment variables.\n  ## This requires one of the following sets of environment variables to be set:\n  ##\n  ## 1) Expected Environment Variables:\n  ##    - "EVENTHUB_CONNECTION_STRING"\n  ##\n  ## 2) Expected Environment Variables:\n  ##    - "EVENTHUB_NAMESPACE"\n  ##    - "EVENTHUB_NAME"\n  ##    - "EVENTHUB_KEY_NAME"\n  ##    - "EVENTHUB_KEY_VALUE"\n\n  ## 3) Expected Environment Variables:\n  ##    - "EVENTHUB_NAMESPACE"\n  ##    - "EVENTHUB_NAME"\n  ##    - "AZURE_TENANT_ID"\n  ##    - "AZURE_CLIENT_ID"\n  ##    - "AZURE_CLIENT_SECRET"\n\n  ## Uncommenting the option below will create an Event Hub client based solely on the connection string.\n  ## This can either be the associated environment variable or hard coded directly.\n  ## If this option is uncommented, environment variables will be ignored.\n  ## Connection string should contain EventHubName (EntityPath)\n  # connection_string = ""\n\n  ## Set persistence directory to a valid folder to use a file persister instead of an in-memory persister\n  # persistence_dir = ""\n\n  ## Change the default consumer group\n  # consumer_group = ""\n\n  ## By default the event hub receives all messages present on the broker, alternative modes can be set below.\n  ## The timestamp should be in https://github.com/toml-lang/toml#offset-date-time format (RFC 3339).\n  ## The 3 options below only apply if no valid persister is read from memory or file (e.g. first run).\n  # from_timestamp =\n  # latest = true\n\n  ## Set a custom prefetch count for the receiver(s)\n  # prefetch_count = 1000\n\n  ## Add an epoch to the receiver(s)\n  # epoch = 0\n\n  ## Change to set a custom user agent, "telegraf" is used by default\n  # user_agent = "telegraf"\n\n  ## To consume from a specific partition, set the partition_ids option.\n  ## An empty array will result in receiving from all partitions.\n  # partition_ids = ["0","1"]\n\n  ## Max undelivered messages\n  # max_undelivered_messages = 1000\n\n  ## Set either option below to true to use a system property as timestamp.\n  ## You have the choice between EnqueuedTime and IoTHubEnqueuedTime.\n  ## It is recommended to use this setting when the data itself has no timestamp.\n  # enqueued_time_as_ts = true\n  # iot_hub_enqueued_time_as_ts = true\n\n  ## Tags or fields to create from keys present in the application property bag.\n  ## These could for example be set by message enrichments in Azure IoT Hub.\n  # application_property_tags = []\n  # application_property_fields = []\n\n  ## Tag or field name to use for metadata\n  ## By default all metadata is disabled\n  # sequence_number_field = "SequenceNumber"\n  # enqueued_time_field = "EnqueuedTime"\n  # offset_field = "Offset"\n  # partition_id_tag = "PartitionID"\n  # partition_key_tag = "PartitionKey"\n  # iot_hub_device_connection_id_tag = "IoTHubDeviceConnectionID"\n  # iot_hub_auth_generation_id_tag = "IoTHubAuthGenerationID"\n  # iot_hub_connection_auth_method_tag = "IoTHubConnectionAuthMethod"\n  # iot_hub_connection_module_id_tag = "IoTHubConnectionModuleID"\n  # iot_hub_enqueued_time_field = "IoTHubEnqueuedTime"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n#### Environment Variables\n\n[Full documentation of the available environment variables][envvar].\n\n[envvar]: https://github.com/Azure/azure-event-hubs-go#environment-variables\n',image:ze.a},{id:"exec",name:"Exec",markdown:'# Exec Input Plugin\n\nThe `exec` plugin executes all the `commands` in parallel on every interval and parses metrics from\ntheir output in any one of the accepted [Input Data Formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).\n\nThis plugin can be used to poll for custom metrics from any source.\n\n### Configuration:\n\n```toml\n[[inputs.exec]]\n  ## Commands array\n  commands = [\n    "/tmp/test.sh",\n    "/usr/bin/mycollector --foo=bar",\n    "/tmp/collect_*.sh"\n  ]\n\n  ## Timeout for each command to complete.\n  timeout = "5s"\n\n  ## measurement name suffix (for separating different commands)\n  name_suffix = "_mycollector"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\nGlob patterns in the `command` option are matched on every run, so adding new\nscripts that match the pattern will cause them to be picked up immediately.\n\n### Example:\n\nThis script produces static values, since no timestamp is specified the values are at the current time.\n```sh\n#!/bin/sh\necho \'example,tag1=a,tag2=b i=42i,j=43i,k=44i\'\n```\n\nIt can be paired with the following configuration and will be run at the `interval` of the agent.\n```toml\n[[inputs.exec]]\n  commands = ["sh /tmp/test.sh"]\n  timeout = "5s"\n  data_format = "influx"\n```\n\n### Common Issues:\n\n#### My script works when I run it by hand, but not when Telegraf is running as a service.\n\nThis may be related to the Telegraf service running as a different user.  The\nofficial packages run Telegraf as the `telegraf` user and group on Linux\nsystems.\n\n#### With a PowerShell on Windows, the output of the script appears to be truncated.\n\nYou may need to set a variable in your script to increase the number of columns\navailable for output:\n```\n$host.UI.RawUI.BufferSize = new-object System.Management.Automation.Host.Size(1024,50)\n```\n',image:je.a},{id:"execd",name:"Execd",markdown:'# Execd Input Plugin\n\nThe `execd` plugin runs an external program as a long-running daemon. \nThe programs must output metrics in any one of the accepted \n[Input Data Formats][] on the process\'s STDOUT, and is expected to\nstay running. If you\'d instead like the process to collect metrics and then exit,\ncheck out the [inputs.exec][] plugin.\n\nThe `signal` can be configured to send a signal the running daemon on each\ncollection interval. This is used for when you want to have Telegraf notify the\nplugin when it\'s time to run collection. STDIN is recommended, which writes a\nnew line to the process\'s STDIN.\n\nSTDERR from the process will be relayed to Telegraf as errors in the logs.\n\n### Configuration:\n\n```toml\n[[inputs.execd]]\n  ## One program to run as daemon.\n  ## NOTE: process and each argument should each be their own string\n  command = ["telegraf-smartctl", "-d", "/dev/sda"]\n\n  ## Define how the process is signaled on each collection interval.\n  ## Valid values are:\n  ##   "none"    : Do not signal anything. (Recommended for service inputs)\n  ##               The process must output metrics by itself.\n  ##   "STDIN"   : Send a newline on STDIN. (Recommended for gather inputs)\n  ##   "SIGHUP"  : Send a HUP signal. Not available on Windows. (not recommended)\n  ##   "SIGUSR1" : Send a USR1 signal. Not available on Windows.\n  ##   "SIGUSR2" : Send a USR2 signal. Not available on Windows.\n  signal = "none"\n\n  ## Delay before the process is restarted after an unexpected termination\n  restart_delay = "10s"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n### Example\n\n##### Daemon written in bash using STDIN signaling\n\n```bash\n#!/bin/bash\n\ncounter=0\n\nwhile IFS= read -r LINE; do\n    echo "counter_bash count=${counter}"\n    let counter=counter+1\ndone\n```\n\n```toml\n[[inputs.execd]]\n  command = ["plugins/inputs/execd/examples/count.sh"]\n  signal = "STDIN"\n```\n\n##### Go daemon using SIGHUP\n\n```go\npackage main\n\nimport (\n    "fmt"\n    "os"\n    "os/signal"\n    "syscall"\n)\n\nfunc main() {\n    c := make(chan os.Signal, 1)\n    signal.Notify(c, syscall.SIGHUP)\n\n    counter := 0\n\n    for {\n        <-c\n\n        fmt.Printf("counter_go count=%d\\n", counter)\n        counter++\n    }\n}\n\n```\n\n```toml\n[[inputs.execd]]\n  command = ["plugins/inputs/execd/examples/count.go.exe"]\n  signal = "SIGHUP"\n```\n\n##### Ruby daemon running standalone\n\n```ruby\n#!/usr/bin/env ruby\n\ncounter = 0\n\nloop do\n  puts "counter_ruby count=#{counter}"\n  STDOUT.flush\n\n  counter += 1\n  sleep 1\nend\n```\n\n```toml\n[[inputs.execd]]\n  command = ["plugins/inputs/execd/examples/count.rb"]\n  signal = "none"\n```\n\n[Input Data Formats]: https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n[inputs.exec]: https://github.com/influxdata/telegraf/blob/master/plugins/inputs/exec/README.md\n',image:Fe.a},{id:"fail2ban",name:"Fail2ban",markdown:"# Fail2ban Input Plugin\n\nThe fail2ban plugin gathers the count of failed and banned ip addresses using\n[fail2ban](https://www.fail2ban.org).\n\nThis plugin runs the `fail2ban-client` command which generally requires root access.\nAcquiring the required permissions can be done using several methods:\n\n- [Use sudo](#using-sudo) run fail2ban-client.\n- Run telegraf as root. (not recommended)\n\n### Configuration\n\n```toml\n# Read metrics from fail2ban.\n[[inputs.fail2ban]]\n  ## Use sudo to run fail2ban-client\n  use_sudo = false\n```\n\n### Using sudo\n\nMake sure to set `use_sudo = true` in your configuration file.\n\nYou will also need to update your sudoers file.  It is recommended to modify a\nfile in the `/etc/sudoers.d` directory using `visudo`:\n\n```bash\n$ sudo visudo -f /etc/sudoers.d/telegraf\n```\n\nAdd the following lines to the file, these commands allow the `telegraf` user\nto call `fail2ban-client` without needing to provide a password and disables\nlogging of the call in the auth.log.  Consult `man 8 visudo` and `man 5\nsudoers` for details.\n```\nCmnd_Alias FAIL2BAN = /usr/bin/fail2ban-client status, /usr/bin/fail2ban-client status *\ntelegraf  ALL=(root) NOEXEC: NOPASSWD: FAIL2BAN\nDefaults!FAIL2BAN !logfile, !syslog, !pam_session\n```\n\n### Metrics\n\n- fail2ban\n  - tags:\n    - jail\n  - fields:\n    - failed (integer, count)\n    - banned (integer, count)\n\n### Example Output\n\n```\n# fail2ban-client status sshd\nStatus for the jail: sshd\n|- Filter\n|  |- Currently failed: 5\n|  |- Total failed:     20\n|  `- File list:        /var/log/secure\n`- Actions\n   |- Currently banned: 2\n   |- Total banned:     10\n   `- Banned IP list:   192.168.0.1 192.168.0.2\n```\n\n```\nfail2ban,jail=sshd failed=5i,banned=2i 1495868667000000000\n```\n",image:We.a},{id:"fibaro",name:"Fibaro",markdown:'# Fibaro Input Plugin\n\nThe Fibaro plugin makes HTTP calls to the Fibaro controller API to gather values of hooked devices.\nThose values could be true (1) or false (0) for switches, percentage for dimmers, temperature, etc.\n\n### Configuration:\n\n```toml\n# Read devices value(s) from a Fibaro controller\n[[inputs.fibaro]]\n  ## Required Fibaro controller address/hostname.\n  ## Note: at the time of writing this plugin, Fibaro only implemented http - no https available\n  url = "http://<controller>:80"\n\n  ## Required credentials to access the API (http://<controller/api/<component>)\n  username = "<username>"\n  password = "<password>"\n\n  ## Amount of time allowed to complete the HTTP request\n  # timeout = "5s"\n```\n\n### Metrics:\n\n- fibaro\n  - tags:\n    - deviceId (device id)\n    - section (section name)\n    - room (room name)\n    - name (device name)\n    - type (device type)\n  - fields:\n    - batteryLevel (float, when available from device)\n    - energy (float, when available from device)\n    - power (float, when available from device)\n    - value (float)\n    - value2 (float, when available from device)\n\n\n### Example Output:\n\n```\nfibaro,deviceId=9,host=vm1,name=Fenêtre\\ haute,room=Cuisine,section=Cuisine,type=com.fibaro.FGRM222 energy=2.04,power=0.7,value=99,value2=99 1529996807000000000\nfibaro,deviceId=10,host=vm1,name=Escaliers,room=Dégagement,section=Pièces\\ communes,type=com.fibaro.binarySwitch value=0 1529996807000000000\nfibaro,deviceId=13,host=vm1,name=Porte\\ fenêtre,room=Salon,section=Pièces\\ communes,type=com.fibaro.FGRM222 energy=4.33,power=0.7,value=99,value2=99 1529996807000000000\nfibaro,deviceId=21,host=vm1,name=LED\\ îlot\\ central,room=Cuisine,section=Cuisine,type=com.fibaro.binarySwitch value=0 1529996807000000000\nfibaro,deviceId=90,host=vm1,name=Détérioration,room=Entrée,section=Pièces\\ communes,type=com.fibaro.heatDetector value=0 1529996807000000000\nfibaro,deviceId=163,host=vm1,name=Température,room=Cave,section=Cave,type=com.fibaro.temperatureSensor value=21.62 1529996807000000000\nfibaro,deviceId=191,host=vm1,name=Présence,room=Garde-manger,section=Cuisine,type=com.fibaro.FGMS001 value=1 1529996807000000000\nfibaro,deviceId=193,host=vm1,name=Luminosité,room=Garde-manger,section=Cuisine,type=com.fibaro.lightSensor value=195 1529996807000000000\nfibaro,deviceId=200,host=vm1,name=Etat,room=Garage,section=Extérieur,type=com.fibaro.doorSensor value=0 1529996807000000000\nfibaro,deviceId=220,host=vm1,name=CO2\\ (ppm),room=Salon,section=Pièces\\ communes,type=com.fibaro.multilevelSensor value=536 1529996807000000000\nfibaro,deviceId=221,host=vm1,name=Humidité\\ (%),room=Salon,section=Pièces\\ communes,type=com.fibaro.humiditySensor value=61 1529996807000000000\nfibaro,deviceId=222,host=vm1,name=Pression\\ (mb),room=Salon,section=Pièces\\ communes,type=com.fibaro.multilevelSensor value=1013.7 1529996807000000000\nfibaro,deviceId=223,host=vm1,name=Bruit\\ (db),room=Salon,section=Pièces\\ communes,type=com.fibaro.multilevelSensor value=44 1529996807000000000\nfibaro,deviceId=248,host=vm1,name=Température,room=Garage,section=Extérieur,type=com.fibaro.temperatureSensor batteryLevel=85,value=10.8 1529996807000000000\n```\n',image:Qe.a},{id:"file",name:"File",markdown:'# File Input Plugin\n\nThe file plugin parses the **complete** contents of a file **every interval** using\nthe selected [input data format][].\n\n**Note:** If you wish to parse only newly appended lines use the [tail][] input\nplugin instead.\n\n### Configuration:\n\n```toml\n[[inputs.file]]\n  ## Files to parse each interval.  Accept standard unix glob matching rules,\n  ## as well as ** to match recursive files and directories.\n  files = ["/tmp/metrics.out"]\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n\n  ## Name a tag containing the name of the file the data was parsed from.  Leave empty\n  ## to disable.\n  # file_tag = ""\n```\n\n[input data format]: /docs/DATA_FORMATS_INPUT.md\n[tail]: /plugins/inputs/tail\n',image:Ye.a},{id:"filecount",name:"Filecount",markdown:'# Filecount Input Plugin\n\nReports the number and total size of files in specified directories.\n\n### Configuration:\n\n```toml\n[[inputs.filecount]]\n  ## Directory to gather stats about.\n  ##   deprecated in 1.9; use the directories option\n  # directory = "/var/cache/apt/archives"\n\n  ## Directories to gather stats about.\n  ## This accept standard unit glob matching rules, but with the addition of\n  ## ** as a "super asterisk". ie:\n  ##   /var/log/**    -> recursively find all directories in /var/log and count files in each directories\n  ##   /var/log/*/*   -> find all directories with a parent dir in /var/log and count files in each directories\n  ##   /var/log       -> count all files in /var/log and all of its subdirectories\n  directories = ["/var/cache/apt", "/tmp"]\n\n  ## Only count files that match the name pattern. Defaults to "*".\n  name = "*"\n\n  ## Count files in subdirectories. Defaults to true.\n  recursive = true\n\n  ## Only count regular files. Defaults to true.\n  regular_only = true\n\n  ## Follow all symlinks while walking the directory tree. Defaults to false.\n  follow_symlinks = false\n\n  ## Only count files that are at least this size. If size is\n  ## a negative number, only count files that are smaller than the\n  ## absolute value of size. Acceptable units are B, KiB, MiB, KB, ...\n  ## Without quotes and units, interpreted as size in bytes.\n  size = "0B"\n\n  ## Only count files that have not been touched for at least this\n  ## duration. If mtime is negative, only count files that have been\n  ## touched in this duration. Defaults to "0s".\n  mtime = "0s"\n```\n\n### Metrics\n\n- filecount\n  - tags:\n    - directory (the directory path)\n  - fields:\n    - count (integer)\n    - size_bytes (integer)\n\n### Example Output:\n\n```\nfilecount,directory=/var/cache/apt count=7i,size_bytes=7438336i 1530034445000000000\nfilecount,directory=/tmp count=17i,size_bytes=28934786i 1530034445000000000\n```\n',image:Ve.a},{id:"filestat",name:"filestat",markdown:'# filestat Input Plugin\n\nThe filestat plugin gathers metrics about file existence, size, and other stats.\n\n### Configuration:\n\n```toml\n# Read stats about given file(s)\n[[inputs.filestat]]\n  ## Files to gather stats about.\n  ## These accept standard unix glob matching rules, but with the addition of\n  ## ** as a "super asterisk". See https://github.com/gobwas/glob.\n  files = ["/etc/telegraf/telegraf.conf", "/var/log/**.log"]\n\n  ## If true, read the entire file and calculate an md5 checksum.\n  md5 = false\n```\n\n### Measurements & Fields:\n\n- filestat\n    - exists (int, 0 | 1)\n    - size_bytes (int, bytes)\n    - modification_time (int, unix time nanoseconds)\n    - md5 (optional, string)\n\n### Tags:\n\n- All measurements have the following tags:\n    - file (the path the to file, as specified in the config)\n\n### Example Output:\n\n```\n$ telegraf --config /etc/telegraf/telegraf.conf --input-filter filestat --test\n* Plugin: filestat, Collection 1\n> filestat,file=/tmp/foo/bar,host=tyrion exists=0i 1507218518192154351\n> filestat,file=/Users/sparrc/ws/telegraf.conf,host=tyrion exists=1i,size=47894i,modification_time=1507152973123456789i  1507218518192154351\n```\n',image:Je.a},{id:"fireboard",name:"Fireboard",markdown:'# Fireboard Input Plugin\n\nThe fireboard plugin gathers the real time temperature data from fireboard\nthermometers.  In order to use this input plugin, you\'ll need to sign up to use\nthe [Fireboard REST API](https://docs.fireboard.io/reference/restapi.html).\n\n### Configuration\n\n```toml\n[[inputs.fireboard]]\n  ## Specify auth token for your account\n  auth_token = "invalidAuthToken"\n  ## You can override the fireboard server URL if necessary\n  # url = https://fireboard.io/api/v1/devices.json\n  ## You can set a different http_timeout if you need to\n  # http_timeout = 4\n```\n\n#### auth_token\n\nIn lieu of requiring a username and password, this plugin requires an\nauthentication token that you can generate using the [Fireboard REST\nAPI](https://docs.fireboard.io/reference/restapi.html#Authentication).\n\n#### url\n\nWhile there should be no reason to override the URL, the option is available\nin case Fireboard changes their site, etc.\n\n#### http_timeout\n\nIf you need to increase the HTTP timeout, you can do so here. You can set this\nvalue in seconds. The default value is four (4) seconds.\n\n### Metrics\n\nThe Fireboard REST API docs have good examples of the data that is available,\ncurrently this input only returns the real time temperatures. Temperature\nvalues are included if they are less than a minute old.\n\n- fireboard\n  - tags:\n    - channel\n    - scale (Celcius; Farenheit)\n    - title (name of the Fireboard)\n    - uuid (UUID of the Fireboard)\n  - fields:\n    - temperature (float, unit)\n\n### Example Output\n\nThis section shows example output in Line Protocol format.  You can often use\n`telegraf --input-filter <plugin-name> --test` or use the `file` output to get\nthis information.\n\n```\nfireboard,channel=2,host=patas-mbp,scale=Farenheit,title=telegraf-FireBoard,uuid=b55e766c-b308-49b5-93a4-df89fe31efd0 temperature=78.2 1561690040000000000\n```\n',image:et.a},{id:"fluentd",name:"Fluentd",markdown:'# Fluentd Input Plugin\n\nThe fluentd plugin gathers metrics from plugin endpoint provided by [in_monitor plugin](https://docs.fluentd.org/input/monitor_agent).\nThis plugin understands data provided by /api/plugin.json resource (/api/config.json is not covered).\n\nYou might need to adjust your fluentd configuration, in order to reduce series cardinality in case your fluentd restarts frequently. Every time fluentd starts, `plugin_id` value is given a new random value.\nAccording to [fluentd documentation](https://docs.fluentd.org/configuration/config-file#common-plugin-parameter), you are able to add `@id`  parameter for each plugin to avoid this behaviour and define custom `plugin_id`.\n\nexample configuration with `@id` parameter for http plugin:\n```\n<source>\n  @type http\n  @id http\n  port 8888\n</source>\n```\n\n### Configuration:\n\n```toml\n# Read metrics exposed by fluentd in_monitor plugin\n[[inputs.fluentd]]\n  ## This plugin reads information exposed by fluentd (using /api/plugins.json endpoint).\n  ##\n  ## Endpoint:\n  ## - only one URI is allowed\n  ## - https is not supported\n  endpoint = "http://localhost:24220/api/plugins.json"\n\n  ## Define which plugins have to be excluded (based on "type" field - e.g. monitor_agent)\n  exclude = [\n\t  "monitor_agent",\n\t  "dummy",\n  ]\n```\n\n### Measurements & Fields:\n\nFields may vary depending on the plugin type\n\n- fluentd\n    - retry_count            (float, unit)\n    - buffer_queue_length     (float, unit)\n    - buffer_total_queued_size (float, unit)\n\n### Tags:\n\n- All measurements have the following tags:\n\t- plugin_id        (unique plugin id)\n\t- plugin_type      (type of the plugin e.g. s3)\n    - plugin_category  (plugin category e.g. output)\n\n### Example Output:\n\n```\n$ telegraf --config fluentd.conf --input-filter fluentd --test\n* Plugin: inputs.fluentd, Collection 1\n> fluentd,host=T440s,plugin_id=object:9f748c,plugin_category=input,plugin_type=dummy buffer_total_queued_size=0,buffer_queue_length=0,retry_count=0 1492006105000000000\n> fluentd,plugin_category=input,plugin_type=dummy,host=T440s,plugin_id=object:8da98c buffer_queue_length=0,retry_count=0,buffer_total_queued_size=0 1492006105000000000\n> fluentd,plugin_id=object:820190,plugin_category=input,plugin_type=monitor_agent,host=T440s retry_count=0,buffer_total_queued_size=0,buffer_queue_length=0 1492006105000000000\n> fluentd,plugin_id=object:c5e054,plugin_category=output,plugin_type=stdout,host=T440s buffer_queue_length=0,retry_count=0,buffer_total_queued_size=0 1492006105000000000\n> fluentd,plugin_type=s3,host=T440s,plugin_id=object:bd7a90,plugin_category=output buffer_queue_length=0,retry_count=0,buffer_total_queued_size=0 1492006105000000000\n\n```\n',image:nt.a},{id:"github",name:"GitHub",markdown:'# GitHub Input Plugin\n\nGather repository information from [GitHub][] hosted repositories.\n\n**Note:** Telegraf also contains the [webhook][] input which can be used as an\nalternative method for collecting repository information.\n\n### Configuration\n\n```toml\n[[inputs.github]]\n  ## List of repositories to monitor\n  repositories = [\n\t  "influxdata/telegraf",\n\t  "influxdata/influxdb"\n  ]\n\n  ## Github API access token.  Unauthenticated requests are limited to 60 per hour.\n  # access_token = ""\n\n  ## Github API enterprise url. Github Enterprise accounts must specify their base url.\n  # enterprise_base_url = ""\n\n  ## Timeout for HTTP requests.\n  # http_timeout = "5s"\n\n  ## List of additional fields to query.\n\t## NOTE: Getting those fields might involve issuing additional API-calls, so please\n\t##       make sure you do not exceed the rate-limit of GitHub.\n\t##\n\t## Available fields are:\n\t## \t- pull-requests\t\t\t-- number of open and closed pull requests (2 API-calls per repository)\n  # additional_fields = []\n```\n\n### Metrics\n\n- github_repository\n  - tags:\n    - name - The repository name\n    - owner - The owner of the repository\n    - language - The primary language of the repository\n    - license - The license set for the repository\n  - fields:\n    - forks (int)\n    - open_issues (int)\n    - networks (int)\n    - size (int)\n    - subscribers (int)\n    - stars (int)\n    - watchers (int)\n\nWhen the [internal][] input is enabled:\n\n+ internal_github\n  - tags:\n    - access_token - An obfuscated reference to the configured access token or "Unauthenticated"\n  - fields:\n    - limit - How many requests you are limited to (per hour)\n    - remaining - How many requests you have remaining (per hour)\n    - blocks - How many requests have been blocked due to rate limit\n\nWhen specifying `additional_fields` the plugin will collect the specified properties.\n**NOTE:** Querying this additional fields might require to perform additional API-calls.\nPlease make sure you don\'t exceed the query rate-limit by specifying too many additional fields.\nIn the following we list the available options with the required API-calls and the resulting fields\n\n- "pull-requests" (2 API-calls per repository)\n  - fields:\n    - open_pull_requests (int)\n    - closed_pull_requests (int)\n\n### Example Output\n\n```\ngithub_repository,language=Go,license=MIT\\ License,name=telegraf,owner=influxdata forks=2679i,networks=2679i,open_issues=794i,size=23263i,stars=7091i,subscribers=316i,watchers=7091i 1563901372000000000\ninternal_github,access_token=Unauthenticated closed_pull_requests=3522i,rate_limit_remaining=59i,rate_limit_limit=60i,rate_limit_blocks=0i,open_pull_requests=260i 1552653551000000000\n```\n\n[GitHub]: https://www.github.com\n[internal]: /plugins/inputs/internal\n[webhook]: /plugins/inputs/webhooks/github\n',image:at.a},{id:"gnmi",name:"gNMI (gRPC Network Management Interface)",markdown:'# gNMI (gRPC Network Management Interface) Input Plugin\n\nThis plugin consumes telemetry data based on the [gNMI](https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md) Subscribe method. TLS is supported for authentication and encryption.  This input plugin is vendor-agnostic and is supported on any platform that supports the gNMI spec.\n\nFor Cisco devices: \nIt has been optimized to support gNMI telemetry as produced by Cisco IOS XR (64-bit) version 6.5.1, Cisco NX-OS 9.3 and Cisco IOS XE 16.12 and later.\n\n\n### Configuration\n\n```toml\n[[inputs.gnmi]]\n  ## Address and port of the gNMI GRPC server\n  addresses = ["10.49.234.114:57777"]\n\n  ## define credentials\n  username = "cisco"\n  password = "cisco"\n\n  ## gNMI encoding requested (one of: "proto", "json", "json_ietf", "bytes")\n  # encoding = "proto"\n\n  ## redial in case of failures after\n  redial = "10s"\n\n  ## enable client-side TLS and define CA to authenticate the device\n  # enable_tls = true\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # insecure_skip_verify = true\n\n  ## define client-side TLS certificate & key to authenticate to the device\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## gNMI subscription prefix (optional, can usually be left empty)\n  ## See: https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md#222-paths\n  # origin = ""\n  # prefix = ""\n  # target = ""\n\n  ## Define additional aliases to map telemetry encoding paths to simple measurement names\n  # [inputs.gnmi.aliases]\n  #   ifcounters = "openconfig:/interfaces/interface/state/counters"\n\n  [[inputs.gnmi.subscription]]\n    ## Name of the measurement that will be emitted\n    name = "ifcounters"\n\n    ## Origin and path of the subscription\n    ## See: https://github.com/openconfig/reference/blob/master/rpc/gnmi/gnmi-specification.md#222-paths\n    ##\n    ## origin usually refers to a (YANG) data model implemented by the device\n    ## and path to a specific substructure inside it that should be subscribed to (similar to an XPath)\n    ## YANG models can be found e.g. here: https://github.com/YangModels/yang/tree/master/vendor/cisco/xr\n    origin = "openconfig-interfaces"\n    path = "/interfaces/interface/state/counters"\n\n    # Subscription mode (one of: "target_defined", "sample", "on_change") and interval\n    subscription_mode = "sample"\n    sample_interval = "10s"\n\n    ## Suppress redundant transmissions when measured values are unchanged\n    # suppress_redundant = false\n\n    ## If suppression is enabled, send updates at least every X seconds anyway\n    # heartbeat_interval = "60s"\n```\n\n### Example Output\n```\nifcounters,path=openconfig-interfaces:/interfaces/interface/state/counters,host=linux,name=MgmtEth0/RP0/CPU0/0,source=10.49.234.115 in-multicast-pkts=0i,out-multicast-pkts=0i,out-errors=0i,out-discards=0i,in-broadcast-pkts=0i,out-broadcast-pkts=0i,in-discards=0i,in-unknown-protos=0i,in-errors=0i,out-unicast-pkts=0i,in-octets=0i,out-octets=0i,last-clear="2019-05-22T16:53:21Z",in-unicast-pkts=0i 1559145777425000000\nifcounters,path=openconfig-interfaces:/interfaces/interface/state/counters,host=linux,name=GigabitEthernet0/0/0/0,source=10.49.234.115 out-multicast-pkts=0i,out-broadcast-pkts=0i,in-errors=0i,out-errors=0i,in-discards=0i,out-octets=0i,in-unknown-protos=0i,in-unicast-pkts=0i,in-octets=0i,in-multicast-pkts=0i,in-broadcast-pkts=0i,last-clear="2019-05-22T16:54:50Z",out-unicast-pkts=0i,out-discards=0i 1559145777425000000\n```\n',image:ot.a},{id:"graylog",name:"GrayLog",markdown:'# GrayLog Input Plugin\n\nThe Graylog plugin can collect data from remote Graylog service URLs.\n\nPlugin currently support two type of end points:-\n\n- multiple  (Ex http://[graylog-server-ip]:12900/system/metrics/multiple)\n- namespace (Ex http://[graylog-server-ip]:12900/system/metrics/namespace/{namespace})\n\nEnd Point can be a mix of one  multiple end point  and several namespaces end points\n\n\nNote: if namespace end point specified metrics array will be ignored for that call.\n\n### Configuration:\n\n```toml\n# Read flattened metrics from one or more GrayLog HTTP endpoints\n[[inputs.graylog]]\n  ## API endpoint, currently supported API:\n  ##\n  ##   - multiple  (Ex http://<host>:12900/system/metrics/multiple)\n  ##   - namespace (Ex http://<host>:12900/system/metrics/namespace/{namespace})\n  ##\n  ## For namespace endpoint, the metrics array will be ignored for that call.\n  ## Endpoint can contain namespace and multiple type calls.\n  ##\n  ## Please check http://[graylog-server-ip]:12900/api-browser for full list\n  ## of endpoints\n  servers = [\n    "http://[graylog-server-ip]:12900/system/metrics/multiple",\n  ]\n\n  ## Metrics list\n  ## List of metrics can be found on Graylog webservice documentation.\n  ## Or by hitting the web service api at:\n  ##   http://[graylog-host]:12900/system/metrics\n  metrics = [\n    "jvm.cl.loaded",\n    "jvm.memory.pools.Metaspace.committed"\n  ]\n\n  ## Username and password\n  username = ""\n  password = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\nPlease refer to GrayLog metrics api browser for full metric end points http://host:12900/api-browser\n',image:ct.a},{id:"haproxy",name:"HAProxy",markdown:'# HAProxy Input Plugin\n\nThe [HAProxy](http://www.haproxy.org/) input plugin gathers\n[statistics](https://cbonte.github.io/haproxy-dconv/1.9/intro.html#3.3.16)\nusing the [stats socket](https://cbonte.github.io/haproxy-dconv/1.9/management.html#9.3)\nor [HTTP statistics page](https://cbonte.github.io/haproxy-dconv/1.9/management.html#9) of a HAProxy server.\n\n### Configuration:\n\n```toml\n# Read metrics of HAProxy, via socket or HTTP stats page\n[[inputs.haproxy]]\n  ## An array of address to gather stats about. Specify an ip on hostname\n  ## with optional port. ie localhost, 10.10.3.33:1936, etc.\n  ## Make sure you specify the complete path to the stats endpoint\n  ## including the protocol, ie http://10.10.3.33:1936/haproxy?stats\n\n  ## Credentials for basic HTTP authentication\n  # username = "admin"\n  # password = "admin"\n\n  ## If no servers are specified, then default to 127.0.0.1:1936/haproxy?stats\n  servers = ["http://myhaproxy.com:1936/haproxy?stats"]\n\n  ## You can also use local socket with standard wildcard globbing.\n  ## Server address not starting with \'http\' will be treated as a possible\n  ## socket, so both examples below are valid.\n  # servers = ["socket:/run/haproxy/admin.sock", "/run/haproxy/*.sock"]\n\n  ## By default, some of the fields are renamed from what haproxy calls them.\n  ## Setting this option to true results in the plugin keeping the original\n  ## field names.\n  # keep_field_names = false\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n#### HAProxy Configuration\n\nThe following information may be useful when getting started, but please\nconsult the HAProxy documentation for complete and up to date instructions.\n\nThe [`stats enable`](https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#4-stats%20enable)\noption can be used to add unauthenticated access over HTTP using the default\nsettings.  To enable the unix socket begin by reading about the\n[`stats socket`](https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#3.1-stats%20socket)\noption.\n\n\n#### servers\n\nServer addresses must explicitly start with \'http\' if you wish to use HAProxy\nstatus page.  Otherwise, addresses will be assumed to be an UNIX socket and\nany protocol (if present) will be discarded.\n\nWhen using socket names, wildcard expansion is supported so plugin can gather\nstats from multiple sockets at once.\n\nTo use HTTP Basic Auth add the username and password in the userinfo section\nof the URL: `http://user:password@1.2.3.4/haproxy?stats`.  The credentials are\nsent via the `Authorization` header and not using the request URL.\n\n\n#### keep_field_names\n\nBy default, some of the fields are renamed from what haproxy calls them.\nSetting the `keep_field_names` parameter to `true` will result in the plugin\nkeeping the original field names.\n\nThe following renames are made:\n- `pxname` -> `proxy`\n- `svname` -> `sv`\n- `act` -> `active_servers`\n- `bck` -> `backup_servers`\n- `cli_abrt` -> `cli_abort`\n- `srv_abrt` -> `srv_abort`\n- `hrsp_1xx` -> `http_response.1xx`\n- `hrsp_2xx` -> `http_response.2xx`\n- `hrsp_3xx` -> `http_response.3xx`\n- `hrsp_4xx` -> `http_response.4xx`\n- `hrsp_5xx` -> `http_response.5xx`\n- `hrsp_other` -> `http_response.other`\n\n### Metrics:\n\nFor more details about collected metrics reference the [HAProxy CSV format\ndocumentation](https://cbonte.github.io/haproxy-dconv/1.8/management.html#9.1).\n\n- haproxy\n  - tags:\n    - `server` - address of the server data was gathered from\n    - `proxy` - proxy name\n    - `sv` - service name\n    - `type` - proxy session type\n  - fields:\n    - `status` (string)\n    - `check_status` (string)\n    - `last_chk` (string)\n    - `mode` (string)\n    - `tracked` (string)\n    - `agent_status` (string)\n    - `last_agt` (string)\n    - `addr` (string)\n    - `cookie` (string)\n    - `lastsess` (int)\n    - **all other stats** (int)\n\n### Example Output:\n```\nhaproxy,server=/run/haproxy/admin.sock,proxy=public,sv=FRONTEND,type=frontend http_response.other=0i,req_rate_max=1i,comp_byp=0i,status="OPEN",rate_lim=0i,dses=0i,req_rate=0i,comp_rsp=0i,bout=9287i,comp_in=0i,mode="http",smax=1i,slim=2000i,http_response.1xx=0i,conn_rate=0i,dreq=0i,ereq=0i,iid=2i,rate_max=1i,http_response.2xx=1i,comp_out=0i,intercepted=1i,stot=2i,pid=1i,http_response.5xx=1i,http_response.3xx=0i,http_response.4xx=0i,conn_rate_max=1i,conn_tot=2i,dcon=0i,bin=294i,rate=0i,sid=0i,req_tot=2i,scur=0i,dresp=0i 1513293519000000000\n```\n',image:lt.a},{id:"hddtemp",name:"HDDtemp",markdown:'# HDDtemp Input Plugin\n\nThis plugin reads data from hddtemp daemon.\n\nHddtemp should be installed and its daemon running.\n\n### Configuration\n\n```toml\n[[inputs.hddtemp]]\n  ## By default, telegraf gathers temps data from all disks detected by the\n  ## hddtemp.\n  ##\n  ## Only collect temps from the selected disks.\n  ##\n  ## A * as the device name will return the temperature values of all disks.\n  ##\n  # address = "127.0.0.1:7634"\n  # devices = ["sda", "*"]\n```\n\n### Metrics\n\n- hddtemp\n  - tags:\n    - device\n    - model\n    - unit\n    - status\n    - source\n  - fields:\n    - temperature\n\n\n### Example output\n\n```\nhddtemp,source=server1,unit=C,status=,device=sdb,model=WDC\\ WD740GD-00FLA1 temperature=43i 1481655647000000000\nhddtemp,device=sdc,model=SAMSUNG\\ HD103UI,unit=C,source=server1,status= temperature=38i 148165564700000000\nhddtemp,device=sdd,model=SAMSUNG\\ HD103UI,unit=C,source=server1,status= temperature=36i 1481655647000000000\n```\n',image:dt.a},{id:"http",name:"HTTP",markdown:'# HTTP Input Plugin\n\nThe HTTP input plugin collects metrics from one or more HTTP(S) endpoints.  The endpoint should have metrics formatted in one of the supported [input data formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).  Each data format has its own unique set of configuration options which can be added to the input configuration.\n\n\n### Configuration:\n\n```toml\n# Read formatted metrics from one or more HTTP endpoints\n[[inputs.http]]\n  ## One or more URLs from which to read formatted metrics\n  urls = [\n    "http://localhost/metrics"\n  ]\n\n  ## HTTP method\n  # method = "GET"\n\n  ## Optional HTTP headers\n  # headers = {"X-Special-Header" = "Special-Value"}\n\n  ## HTTP entity-body to send with POST/PUT requests.\n  # body = ""\n\n  ## HTTP Content-Encoding for write request body, can be set to "gzip" to\n  ## compress body or "identity" to apply no encoding.\n  # content_encoding = "identity"\n\n  ## Optional file with Bearer token\n  ## file content is added as an Authorization header\n  # bearer_token = "/path/to/file"\n\n  ## Optional HTTP Basic Auth Credentials\n  # username = "username"\n  # password = "pa$$word"\n\n  ## OAuth2 Client Credentials. The options \'client_id\', \'client_secret\', and \'token_url\' are required to use OAuth2.\n  # client_id = "clientid"\n  # client_secret = "secret"\n  # token_url = "https://indentityprovider/oauth2/v1/token"\n  # scopes = ["urn:opc:idm:__myscopes__"]\n\n  ## HTTP Proxy support\n  # http_proxy_url = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Amount of time allowed to complete the HTTP request\n  # timeout = "5s"\n\n  ## List of success status codes\n  # success_status_codes = [200]\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  # data_format = "influx"\n\n```\n\n### Metrics:\n\nThe metrics collected by this input plugin will depend on the configured `data_format` and the payload returned by the HTTP endpoint(s).\n\nThe default values below are added if the input format does not specify a value:\n\n- http\n  - tags:\n    - url\n',image:vt.a},{id:"http_listener_v2",name:"HTTP Listener v2",markdown:'# HTTP Listener v2 Input Plugin\n\nHTTP Listener v2 is a service input plugin that listens for metrics sent via\nHTTP. Metrics may be sent in any supported [data format][data_format]. For metrics in \n[InfluxDB Line Protocol][line_protocol] it\'s recommended to use the [`influxdb_listener`][influxdb_listener] \nor [`influxdb_v2_listener`][influxdb_v2_listener] instead. \n\n**Note:** The plugin previously known as `http_listener` has been renamed\n`influxdb_listener`.  If you would like Telegraf to act as a proxy/relay for\nInfluxDB it is recommended to use [`influxdb_listener`][influxdb_listener] or [`influxdb_v2_listener`][influxdb_v2_listener].\n\n### Configuration:\n\nThis is a sample configuration for the plugin.\n\n```toml\n[[inputs.http_listener_v2]]\n  ## Address and port to host HTTP listener on\n  service_address = ":8080"\n\n  ## Path to listen to.\n  # path = "/telegraf"\n\n  ## HTTP methods to accept.\n  # methods = ["POST", "PUT"]\n\n  ## maximum duration before timing out read of the request\n  # read_timeout = "10s"\n  ## maximum duration before timing out write of the response\n  # write_timeout = "10s"\n\n  ## Maximum allowed http request body size in bytes.\n  ## 0 means to use the default of 524,288,000 bytes (500 mebibytes)\n  # max_body_size = "500MB"\n\n  ## Part of the request to consume.  Available options are "body" and\n  ## "query".\n  # data_source = "body"\n\n  ## Set one or more allowed client CA certificate file names to\n  ## enable mutually authenticated TLS connections\n  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n  ## Add service certificate and key\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## Optional username and password to accept for HTTP basic authentication.\n  ## You probably want to make sure you have TLS configured above for this.\n  # basic_username = "foobar"\n  # basic_password = "barfoo"\n\n  ## Optional setting to map http headers into tags\n  ## If the http header is not present on the request, no corresponding tag will be added\n  ## If multiple instances of the http header are present, only the first value will be used\n  # http_header_tags = {"HTTP_HEADER" = "TAG_NAME"}\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "json"\n```\n\n### Metrics:\n\nMetrics are collected from the part of the request specified by the `data_source` param and are parsed depending on the value of `data_format`.\n\n### Troubleshooting:\n\n**Send Line Protocol**\n```\ncurl -i -XPOST \'http://localhost:8080/telegraf\' --data-binary \'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000\'\n```\n\n**Send JSON**\n```\ncurl -i -XPOST \'http://localhost:8080/telegraf\' --data-binary \'{"value1": 42, "value2": 42}\'\n```\n\n**Send query params**\n```\ncurl -i -XGET \'http://localhost:8080/telegraf?host=server01&value=0.42\'\n```\n\n[data_format]: /docs/DATA_FORMATS_INPUT.md\n[influxdb_listener]: /plugins/inputs/influxdb_listener/README.md\n[line_protocol]: https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/\n[influxdb_v2_listener]: /plugins/inputs/influxdb_v2_listener/README.md\n',image:pt.a},{id:"http_response",name:"HTTP Response",markdown:'# HTTP Response Input Plugin\n\nThis input plugin checks HTTP/HTTPS connections.\n\n### Configuration:\n\n```toml\n# HTTP/HTTPS request given an address a method and a timeout\n[[inputs.http_response]]\n  ## address is Deprecated in 1.12, use \'urls\'\n\n  ## List of urls to query.\n  # urls = ["http://localhost"]\n\n  ## Set http_proxy (telegraf uses the system wide proxy settings if it\'s is not set)\n  # http_proxy = "http://localhost:8888"\n\n  ## Set response_timeout (default 5 seconds)\n  # response_timeout = "5s"\n\n  ## HTTP Request Method\n  # method = "GET"\n\n  ## Whether to follow redirects from the server (defaults to false)\n  # follow_redirects = false\n\n  ## Optional file with Bearer token\n  ## file content is added as an Authorization header\n  # bearer_token = "/path/to/file"\n\n  ## Optional HTTP Basic Auth Credentials\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional HTTP Request Body\n  # body = \'\'\'\n  # {\'fake\':\'data\'}\n  # \'\'\'\n\n  ## Optional name of the field that will contain the body of the response.\n  ## By default it is set to an empty String indicating that the body\'s content won\'t be added\n  # response_body_field = \'\'\n\n  ## Maximum allowed HTTP response body size in bytes.\n  ## 0 means to use the default of 32MiB.\n  ## If the response body size exceeds this limit a "body_read_error" will be raised\n  # response_body_max_size = "32MiB"\n\n  ## Optional substring or regex match in body of the response (case sensitive)\n  # response_string_match = "\\"service_status\\": \\"up\\""\n  # response_string_match = "ok"\n  # response_string_match = "\\".*_status\\".?:.?\\"up\\""\n\n  ## Expected response status code.\n  ## The status code of the response is compared to this value. If they match, the field\n  ## "response_status_code_match" will be 1, otherwise it will be 0. If the\n  ## expected status code is 0, the check is disabled and the field won\'t be added.\n  # response_status_code = 0\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n  ## Use the given name as the SNI server name on each URL\n  # tls_server_name = ""\n\n  ## HTTP Request Headers (all values must be strings)\n  # [inputs.http_response.headers]\n  #   Host = "github.com"\n\n  ## Optional setting to map response http headers into tags\n  ## If the http header is not present on the request, no corresponding tag will be added\n  ## If multiple instances of the http header are present, only the first value will be used\n  # http_header_tags = {"HTTP_HEADER" = "TAG_NAME"}\n\n  ## Interface to use when dialing an address\n  # interface = "eth0"\n```\n\n### Metrics:\n\n- http_response\n  - tags:\n    - server (target URL)\n    - method (request method)\n    - status_code (response status code)\n    - result ([see below](#result--result_code))\n  - fields:\n    - response_time (float, seconds)\n    - content_length (int, response body length)\n    - response_string_match (int, 0 = mismatch / body read error, 1 = match)\n    - response_status_code_match (int, 0 = mismatch, 1 = match)\n    - http_response_code (int, response status code)\n    - result_type (string, deprecated in 1.6: use `result` tag and `result_code` field)\n    - result_code (int, [see below](#result--result_code))\n\n#### `result` / `result_code`\n\nUpon finishing polling the target server, the plugin registers the result of the operation in the `result` tag, and adds a numeric field called `result_code` corresponding with that tag value.\n\nThis tag is used to expose network and plugin errors. HTTP errors are considered a successful connection.\n\n|Tag value                     |Corresponding field value|Description|\n-------------------------------|-------------------------|-----------|\n|success                       | 0                       |The HTTP request completed, even if the HTTP code represents an error|\n|response_string_mismatch      | 1                       |The option `response_string_match` was used, and the body of the response didn\'t match the regex. HTTP errors with content in their body (like 4xx, 5xx) will trigger this error|\n|body_read_error               | 2                       |The option `response_string_match` was used, but the plugin wasn\'t able to read the body of the response. Responses with empty bodies (like 3xx, HEAD, etc) will trigger this error. Or the option `response_body_field` was used and the content of the response body was not a valid utf-8. Or the size of the body of the response exceeded the `response_body_max_size` |\n|connection_failed             | 3                       |Catch all for any network error not specifically handled by the plugin|\n|timeout                       | 4                       |The plugin timed out while awaiting the HTTP connection to complete|\n|dns_error                     | 5                       |There was a DNS error while attempting to connect to the host|\n|response_status_code_mismatch | 6                       |The option `response_status_code_match` was used, and the status code of the response didn\'t match the value.|\n\n\n### Example Output:\n\n```\nhttp_response,method=GET,result=success,server=http://github.com,status_code=200 content_length=87878i,http_response_code=200i,response_time=0.937655534,result_code=0i,result_type="success" 1565839598000000000\n```\n',image:gt.a},{id:"httpjson",name:"HTTP JSON",markdown:'# HTTP JSON Input Plugin\n\nThe httpjson plugin collects data from HTTP URLs which respond with JSON.  It flattens the JSON and finds all numeric values, treating them as floats.\n\nDeprecated (1.6): use the [http](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http) input.\n\n### Configuration:\n\n```toml\n[[inputs.httpjson]]\n  ## NOTE This plugin only reads numerical measurements, strings and booleans\n  ## will be ignored.\n\n  ## Name for the service being polled.  Will be appended to the name of the\n  ## measurement e.g. "httpjson_webserver_stats".\n  ##\n  ## Deprecated (1.3.0): Use name_override, name_suffix, name_prefix instead.\n  name = "webserver_stats"\n\n  ## URL of each server in the service\'s cluster\n  servers = [\n    "http://localhost:9999/stats/",\n    "http://localhost:9998/stats/",\n  ]\n  ## Set response_timeout (default 5 seconds)\n  response_timeout = "5s"\n\n  ## HTTP method to use: GET or POST (case-sensitive)\n  method = "GET"\n\n  ## Tags to extract from top-level of JSON server response.\n  # tag_keys = [\n  #   "my_tag_1",\n  #   "my_tag_2"\n  # ]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## HTTP Request Parameters (all values must be strings).  For "GET" requests, data\n  ## will be included in the query.  For "POST" requests, data will be included\n  ## in the request body as "x-www-form-urlencoded".\n  # [inputs.httpjson.parameters]\n  #   event_type = "cpu_spike"\n  #   threshold = "0.75"\n\n  ## HTTP Request Headers (all values must be strings).\n  # [inputs.httpjson.headers]\n  #   X-Auth-Token = "my-xauth-token"\n  #   apiVersion = "v1"\n```\n\n### Measurements & Fields:\n\n- httpjson\n\t- response_time (float): Response time in seconds\n\nAdditional fields are dependant on the response of the remote service being polled.\n\n### Tags:\n\n- All measurements have the following tags:\n\t- server: HTTP origin as defined in configuration as `servers`.\n\nAny top level keys listed under `tag_keys` in the configuration are added as tags.  Top level keys are defined as keys in the root level of the object in a single object response, or in the root level of each object within an array of objects.\n\n\n### Examples Output:\n\nThis plugin understands responses containing a single JSON object, or a JSON Array of Objects.\n\n**Object Output:**\n\nGiven the following response body:\n```json\n{\n    "a": 0.5,\n    "b": {\n        "c": "some text",\n        "d": 0.1,\n        "e": 5\n    },\n    "service": "service01"\n}\n```\nThe following metric is produced:\n\n`httpjson,server=http://localhost:9999/stats/ b_d=0.1,a=0.5,b_e=5,response_time=0.001`\n\nNote that only numerical values are extracted and the type is float.\n\nIf `tag_keys` is included in the configuration:\n\n```toml\n[[inputs.httpjson]]\n  tag_keys = ["service"]\n```\n\nThen the `service` tag will also be added:\n\n`httpjson,server=http://localhost:9999/stats/,service=service01 b_d=0.1,a=0.5,b_e=5,response_time=0.001`\n\n**Array Output:**\n\nIf the service returns an array of objects, one metric is be created for each object:\n\n```json\n[\n    {\n        "service": "service01",\n        "a": 0.5,\n        "b": {\n            "c": "some text",\n            "d": 0.1,\n            "e": 5\n        }\n    },\n    {\n        "service": "service02",\n        "a": 0.6,\n        "b": {\n            "c": "some text",\n            "d": 0.2,\n            "e": 6\n        }\n    }\n]\n```\n\n`httpjson,server=http://localhost:9999/stats/,service=service01 a=0.5,b_d=0.1,b_e=5,response_time=0.003`\n`httpjson,server=http://localhost:9999/stats/,service=service02 a=0.6,b_d=0.2,b_e=6,response_time=0.003`\n',image:bt.a},{id:"icinga2",name:"Icinga2",markdown:'# Icinga2 Input Plugin\n\nThis plugin gather services & hosts status using Icinga2 Remote API.\n\nThe icinga2 plugin uses the icinga2 remote API to gather status on running\nservices and hosts. You can read Icinga2\'s documentation for their remote API\n[here](https://docs.icinga.com/icinga2/latest/doc/module/icinga2/chapter/icinga2-api)\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.icinga2]]\n  ## Required Icinga2 server address\n  # server = "https://localhost:5665"\n  \n  ## Required Icinga2 object type ("services" or "hosts")\n  # object_type = "services"\n\n  ## Credentials for basic HTTP authentication\n  # username = "admin"\n  # password = "admin"\n\n  ## Maximum time to receive response.\n  # response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = true\n```\n\n### Measurements & Fields:\n\n- All measurements have the following fields:\n    - name (string)\n    - state_code (int)\n\n### Tags:\n\n- All measurements have the following tags:\n    - check_command - The short name of the check command\n    - display_name - The name of the service or host\n    - state - The state: UP/DOWN for hosts, OK/WARNING/CRITICAL/UNKNOWN for services\n    - source - The icinga2 host\n    - port - The icinga2 port\n    - scheme - The icinga2 protocol (http/https)\n    - server - The server the check_command is running for\n\n### Sample Queries:\n\n```sql\nSELECT * FROM "icinga2_services" WHERE state_code = 0 AND time > now() - 24h // Service with OK status\nSELECT * FROM "icinga2_services" WHERE state_code = 1 AND time > now() - 24h // Service with WARNING status\nSELECT * FROM "icinga2_services" WHERE state_code = 2 AND time > now() - 24h // Service with CRITICAL status\nSELECT * FROM "icinga2_services" WHERE state_code = 3 AND time > now() - 24h // Service with UNKNOWN status\n```\n\n### Example Output:\n\n```\n$ ./telegraf -config telegraf.conf -input-filter icinga2 -test\nicinga2_hosts,display_name=router-fr.eqx.fr,check_command=hostalive-custom,host=test-vm,source=localhost,port=5665,scheme=https,state=ok name="router-fr.eqx.fr",state=0 1492021603000000000\n```\n',image:kt.a},{id:"infiniband",name:"InfiniBand",markdown:"# InfiniBand Input Plugin\n\nThis plugin gathers statistics for all InfiniBand devices and ports on the\nsystem. These are the counters that can be found in\n`/sys/class/infiniband/<dev>/port/<port>/counters/`\n\n**Supported Platforms**: Linux\n\n### Configuration\n\n```toml\n[[inputs.infiniband]]\n  # no configuration\n```\n\n### Metrics\n\nActual metrics depend on the InfiniBand devices, the plugin uses a simple\nmapping from counter -> counter value.\n\n[Information about the counters][counters] collected is provided by Mellanox.\n\n[counters]: https://community.mellanox.com/s/article/understanding-mlx5-linux-counters-and-status-parameters\n\n- infiniband\n  - tags:\n    - device\n    - port\n  - fields:\n    - excessive_buffer_overrun_errors (integer)\n    - link_downed (integer)\n    - link_error_recovery (integer)\n    - local_link_integrity_errors (integer)\n    - multicast_rcv_packets (integer)\n    - multicast_xmit_packets (integer)\n    - port_rcv_constraint_errors (integer)\n    - port_rcv_data (integer)\n    - port_rcv_errors (integer)\n    - port_rcv_packets (integer)\n    - port_rcv_remote_physical_errors (integer)\n    - port_rcv_switch_relay_errors (integer)\n    - port_xmit_constraint_errors (integer)\n    - port_xmit_data (integer)\n    - port_xmit_discards (integer)\n    - port_xmit_packets (integer)\n    - port_xmit_wait (integer)\n    - symbol_error (integer)\n    - unicast_rcv_packets (integer)\n    - unicast_xmit_packets (integer)\n    - VL15_dropped (integer)\n\n\n\n### Example Output\n\n```\ninfiniband,device=mlx5_0,port=1 VL15_dropped=0i,excessive_buffer_overrun_errors=0i,link_downed=0i,link_error_recovery=0i,local_link_integrity_errors=0i,multicast_rcv_packets=0i,multicast_xmit_packets=0i,port_rcv_constraint_errors=0i,port_rcv_data=237159415345822i,port_rcv_errors=0i,port_rcv_packets=801977655075i,port_rcv_remote_physical_errors=0i,port_rcv_switch_relay_errors=0i,port_xmit_constraint_errors=0i,port_xmit_data=238334949937759i,port_xmit_discards=0i,port_xmit_packets=803162651391i,port_xmit_wait=4294967295i,symbol_error=0i,unicast_rcv_packets=801977655075i,unicast_xmit_packets=803162651391i 1573125558000000000\n```\n",image:Tt.a},{id:"influxdb",name:"InfluxDB",markdown:'# InfluxDB Input Plugin\n\nThe InfluxDB plugin will collect metrics on the given InfluxDB servers. Read our \n[documentation](https://docs.influxdata.com/platform/monitoring/influxdata-platform/tools/measurements-internal/) \nfor detailed information about `influxdb` metrics. \n\nThis plugin can also gather metrics from endpoints that expose\nInfluxDB-formatted endpoints. See below for more information.\n\n### Configuration:\n\n```toml\n# Read InfluxDB-formatted JSON metrics from one or more HTTP endpoints\n[[inputs.influxdb]]\n  ## Works with InfluxDB debug endpoints out of the box,\n  ## but other services can use this format too.\n  ## See the influxdb plugin\'s README for more details.\n\n  ## Multiple URLs from which to read InfluxDB-formatted JSON\n  ## Default is "http://localhost:8086/debug/vars".\n  urls = [\n    "http://localhost:8086/debug/vars"\n  ]\n\n  ## Username and password to send using HTTP Basic Authentication.\n  # username = ""\n  # password = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## http request & header timeout\n  timeout = "5s"\n```\n\n### Measurements & Fields\n\n**Note:** The measurements and fields included in this plugin are dynamically built from the InfluxDB source, and may vary between versions:\n\n- influxdb\n  - n_shards: The total number of shards in the specified database.\n- influxdb_ae _(Enterprise Only)_ : Statistics related to the Anti-Entropy (AE) engine in InfluxDB Enterprise clusters.\n- influxdb_cluster _(Enterprise Only)_ : Statistics related to the clustering features of the data nodes in InfluxDB Enterprise clusters.\n- influxdb_cq: The metrics related to continuous queries (CQs).\n- influxdb_database: The database metrics are being collected from.\n- influxdb_hh _(Enterprise Only)_ : Events resulting in new hinted handoff (HH) processors in InfluxDB Enterprise clusters.\n- influxdb_hh_database _(Enterprise Only)_ : Aggregates all hinted handoff queues for a single database and node.\n- influxdb_hh_processor _(Enterprise Only)_ : Statistics stored for a single queue (shard).\n- influxdb_httpd: The URL to listen for network requests. By default, `http://localhost:8086/debug/var`.\n- influxdb_measurement: The measurement that metrics are collected from.\n- influxdb_memstats: Statistics about the memory allocator in the specified database.\n  - heap_inuse: The number of bytes in in-use spans.\n  - heap_released: The number of bytes of physical memory returned to the OS.\n  - mspan_inuse: The number of bytes in in-use mspans.\n  - total_alloc: The cumulative bytes allocated for heap objects.\n  - sys: The total number of bytes of memory obtained from the OS. Measures the virtual address space reserved by the Go runtime for the heap, stacks, and other internal data structures.\n  - mallocs: The total number of heap objects allocated. (The total number of live objects are frees.)\n  - frees: The cumulative number of freed (live) heap objects.\n  - heap_idle: The number of bytes of idle heap objects.\n  - pause_total_ns: The total time garbage collection cycles are paused in nanoseconds.\n  - lookups: The number of pointer lookups performed by the runtime. Primarily useful for debugging runtime internals.\n  - heap_sys: The number of bytes of heap memory obtained from the OS. Measures the amount of virtual address space reserved for the heap.\n  - mcache_sys: The bytes of memory obtained from the OS for mcache structures.\n  - next_gc: The target heap size of the next garbage collection cycle.\n  - gc_cpu_fraction: The fraction of CPU time used by the garbage collection cycle.\n  - other_sys: The number of bytes of memory used other than heap_sys, stacks_sys, mspan_sys, mcache_sys, buckhash_sys, and gc_sys.\n  - alloc: The currently allocated number of bytes of heap objects.\n  - stack_inuse: The number of bytes in in-use stacks.\n  - stack_sys: The total number of bytes of memory obtained from the stack in use.\n  - buck_hash_sys: The bytes of memory in profiling bucket hash tables.\n  - gc_sys: The bytes of memory in garbage collection metadata.\n  - num_gc: The number of completed garbage collection cycles.\n  - heap_alloc: The size, in bytes, of all heap objects.\n  - heap_objects: The number of allocated heap objects.\n  - mspan_sys: The bytes of memory obtained from the OS for mspan.\n  - mcache_inuse: The bytes of allocated mcache structures.\n  - last_gc: Time the last garbage collection finished, as nanoseconds since 1970 (the UNIX epoch).\n- influxdb_queryExecutor: Query Executor metrics of the InfluxDB engine.\n- influxdb_rpc _(Enterprise Only)_ : Statistics are related to the use of RPC calls within InfluxDB Enterprise clusters.\n- influxdb_runtime: The shard metrics are collected from.\n- influxdb_shard: The shard metrics are collected from.\n- influxdb_subscriber: The InfluxDB subscription that metrics are collected from.\n- influxdb_tsm1_cache: The TSM cache that metrics are collected from.\n- influxdb_tsm1_engine: The TSM storage engine that metrics are collected from.\n- influxdb_tsm1_filestore: The TSM file store that metrics are collected from.\n- influxdb_tsm1_wal: The TSM Write Ahead Log (WAL) that metrics are collected from.\n- influxdb_write: The total writes to the specified database.\n\n### Example Output:\n\n```\ntelegraf --config ~/ws/telegraf.conf --input-filter influxdb --test\n* Plugin: influxdb, Collection 1\n> influxdb_database,database=_internal,host=tyrion,url=http://localhost:8086/debug/vars numMeasurements=10,numSeries=29 1463590500247354636\n> influxdb_httpd,bind=:8086,host=tyrion,url=http://localhost:8086/debug/vars req=7,reqActive=1,reqDurationNs=14227734 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=database,url=http://localhost:8086/debug/vars numSeries=1 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=httpd,url=http://localhost:8086/debug/vars numSeries=1 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=measurement,url=http://localhost:8086/debug/vars numSeries=10 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=runtime,url=http://localhost:8086/debug/vars numSeries=1 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=shard,url=http://localhost:8086/debug/vars numSeries=4 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=subscriber,url=http://localhost:8086/debug/vars numSeries=1 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=tsm1_cache,url=http://localhost:8086/debug/vars numSeries=4 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=tsm1_filestore,url=http://localhost:8086/debug/vars numSeries=2 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=tsm1_wal,url=http://localhost:8086/debug/vars numSeries=4 1463590500247354636\n> influxdb_measurement,database=_internal,host=tyrion,measurement=write,url=http://localhost:8086/debug/vars numSeries=1 1463590500247354636\n> influxdb_memstats,host=tyrion,url=http://localhost:8086/debug/vars alloc=7642384i,buck_hash_sys=1463471i,frees=1169558i,gc_sys=653312i,gc_cpu_fraction=0.00003825652361068311,heap_alloc=7642384i,heap_idle=9912320i,heap_inuse=9125888i,heap_objects=48276i,heap_released=0i,heap_sys=19038208i,last_gc=1463590480877651621i,lookups=90i,mallocs=1217834i,mcache_inuse=4800i,mcache_sys=16384i,mspan_inuse=70920i,mspan_sys=81920i,next_gc=11679787i,num_gc=141i,other_sys=1244233i,pause_total_ns=24034027i,stack_inuse=884736i,stack_sys=884736i,sys=23382264i,total_alloc=679012200i 1463590500277918755\n> influxdb_shard,database=_internal,engine=tsm1,host=tyrion,id=4,path=/Users/sparrc/.influxdb/data/_internal/monitor/4,retentionPolicy=monitor,url=http://localhost:8086/debug/vars fieldsCreate=65,seriesCreate=26,writePointsOk=7274,writeReq=280 1463590500247354636\n> influxdb_subscriber,host=tyrion,url=http://localhost:8086/debug/vars pointsWritten=7274 1463590500247354636\n> influxdb_tsm1_cache,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/1,retentionPolicy=monitor,url=http://localhost:8086/debug/vars WALCompactionTimeMs=0,cacheAgeMs=2809192,cachedBytes=0,diskBytes=0,memBytes=0,snapshotCount=0 1463590500247354636\n> influxdb_tsm1_cache,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/2,retentionPolicy=monitor,url=http://localhost:8086/debug/vars WALCompactionTimeMs=0,cacheAgeMs=2809184,cachedBytes=0,diskBytes=0,memBytes=0,snapshotCount=0 1463590500247354636\n> influxdb_tsm1_cache,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/3,retentionPolicy=monitor,url=http://localhost:8086/debug/vars WALCompactionTimeMs=0,cacheAgeMs=2809180,cachedBytes=0,diskBytes=0,memBytes=42368,snapshotCount=0 1463590500247354636\n> influxdb_tsm1_cache,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/4,retentionPolicy=monitor,url=http://localhost:8086/debug/vars WALCompactionTimeMs=0,cacheAgeMs=2799155,cachedBytes=0,diskBytes=0,memBytes=331216,snapshotCount=0 1463590500247354636\n> influxdb_tsm1_filestore,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/1,retentionPolicy=monitor,url=http://localhost:8086/debug/vars diskBytes=37892 1463590500247354636\n> influxdb_tsm1_filestore,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/data/_internal/monitor/2,retentionPolicy=monitor,url=http://localhost:8086/debug/vars diskBytes=52907 1463590500247354636\n> influxdb_tsm1_wal,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/wal/_internal/monitor/1,retentionPolicy=monitor,url=http://localhost:8086/debug/vars currentSegmentDiskBytes=0,oldSegmentsDiskBytes=0 1463590500247354636\n> influxdb_tsm1_wal,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/wal/_internal/monitor/2,retentionPolicy=monitor,url=http://localhost:8086/debug/vars currentSegmentDiskBytes=0,oldSegmentsDiskBytes=0 1463590500247354636\n> influxdb_tsm1_wal,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/wal/_internal/monitor/3,retentionPolicy=monitor,url=http://localhost:8086/debug/vars currentSegmentDiskBytes=0,oldSegmentsDiskBytes=65651 1463590500247354636\n> influxdb_tsm1_wal,database=_internal,host=tyrion,path=/Users/sparrc/.influxdb/wal/_internal/monitor/4,retentionPolicy=monitor,url=http://localhost:8086/debug/vars currentSegmentDiskBytes=495687,oldSegmentsDiskBytes=0 1463590500247354636\n> influxdb_write,host=tyrion,url=http://localhost:8086/debug/vars pointReq=7274,pointReqLocal=7274,req=280,subWriteOk=280,writeOk=280 1463590500247354636\n> influxdb_shard,host=tyrion n_shards=4i 1463590500247354636\n```\n\n### InfluxDB-formatted endpoints\n\nThe influxdb plugin can collect InfluxDB-formatted data from JSON endpoints.\nWhether associated with an Influx database or not.\n\nWith a configuration of:\n\n```toml\n[[inputs.influxdb]]\n  urls = [\n    "http://127.0.0.1:8086/debug/vars",\n    "http://192.168.2.1:8086/debug/vars"\n  ]\n```\n',image:Ot.a},{id:"influxdb_listener",name:"InfluxDB Listener",markdown:'# InfluxDB Listener Input Plugin\n\nInfluxDB Listener is a service input plugin that listens for requests sent\naccording to the [InfluxDB HTTP API](https://docs.influxdata.com/influxdb/v1.8/guides/write_data/).  The intent of the\nplugin is to allow Telegraf to serve as a proxy/router for the `/write`\nendpoint of the InfluxDB HTTP API.\n\n**Note:** This plugin was previously known as `http_listener`.  If you wish to\nsend general metrics via HTTP it is recommended to use the\n[`http_listener_v2`](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/http_listener_v2) instead.\n\nThe `/write` endpoint supports the `precision` query parameter and can be set\nto one of `ns`, `u`, `ms`, `s`, `m`, `h`.  All other parameters are ignored and\ndefer to the output plugins configuration.\n\nWhen chaining Telegraf instances using this plugin, CREATE DATABASE requests\nreceive a 200 OK response with message body `{"results":[]}` but they are not\nrelayed. The output configuration of the Telegraf instance which ultimately\nsubmits data to InfluxDB determines the destination database.\n\n### Configuration:\n\n```toml\n[[inputs.influxdb_listener]]\n  ## Address and port to host HTTP listener on\n  service_address = ":8186"\n\n  ## maximum duration before timing out read of the request\n  read_timeout = "10s"\n  ## maximum duration before timing out write of the response\n  write_timeout = "10s"\n\n  ## Maximum allowed HTTP request body size in bytes.\n  ## 0 means to use the default of 32MiB.\n  max_body_size = 0\n\n  ## Maximum line size allowed to be sent in bytes.\n  ##   deprecated in 1.14; parser now handles lines of unlimited length and option is ignored\n  # max_line_size = 0\n\n  ## Set one or more allowed client CA certificate file names to\n  ## enable mutually authenticated TLS connections\n  tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n  ## Add service certificate and key\n  tls_cert = "/etc/telegraf/cert.pem"\n  tls_key = "/etc/telegraf/key.pem"\n\n  ## Optional tag name used to store the database name.\n  ## If the write has a database in the query string then it will be kept in this tag name.\n  ## This tag can be used in downstream outputs.\n  ## The default value of nothing means it will be off and the database will not be recorded.\n  ## If you have a tag that is the same as the one specified below, and supply a database,\n  ## the tag will be overwritten with the database supplied.\n  # database_tag = ""\n\n  ## If set the retention policy specified in the write query will be added as\n  ## the value of this tag name.\n  # retention_policy_tag = ""\n\n  ## Optional username and password to accept for HTTP basic authentication.\n  ## You probably want to make sure you have TLS configured above for this.\n  # basic_username = "foobar"\n  # basic_password = "barfoo"\n```\n\n### Metrics:\n\nMetrics are created from InfluxDB Line Protocol in the request body.\n\n### Troubleshooting:\n\n**Example Query:**\n```\ncurl -i -XPOST \'http://localhost:8186/write\' --data-binary \'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000\'\n```',image:qt.a},{id:"influxdb_v2_listener",name:"InfluxDB V2 Listener",markdown:'# InfluxDB V2 Listener Input Plugin\n\nInfluxDB V2 Listener is a service input plugin that listens for requests sent\naccording to the [InfluxDB HTTP API][influxdb_http_api].  The intent of the\nplugin is to allow Telegraf to serve as a proxy/router for the `/api/v2/write`\nendpoint of the InfluxDB HTTP API.\n\nThe `/api/v2/write` endpoint supports the `precision` query parameter and can be set\nto one of `ns`, `us`, `ms`, `s`.  All other parameters are ignored and\ndefer to the output plugins configuration.\n\nTelegraf minimum version: Telegraf 1.16.0\n\n### Configuration:\n\n```toml\n[[inputs.influxdb_v2_listener]]\n  ## Address and port to host InfluxDB listener on\n  ## (Double check the port. Could be 9999 if using OSS Beta)\n  service_address = ":8086"\n\n  ## Maximum allowed HTTP request body size in bytes.\n  ## 0 means to use the default of 32MiB.\n  # max_body_size = "32MiB"\n\n  ## Optional tag to determine the bucket.\n  ## If the write has a bucket in the query string then it will be kept in this tag name.\n  ## This tag can be used in downstream outputs.\n  ## The default value of nothing means it will be off and the database will not be recorded.\n  # bucket_tag = ""\n\n  ## Set one or more allowed client CA certificate file names to\n  ## enable mutually authenticated TLS connections\n  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n  ## Add service certificate and key\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## Optional token to accept for HTTP authentication.\n  ## You probably want to make sure you have TLS configured above for this.\n  # token = "some-long-shared-secret-token"\n```\n\n### Metrics:\n\nMetrics are created from InfluxDB Line Protocol in the request body.\n\n### Troubleshooting:\n\n**Example Query:**\n```\ncurl -i -XPOST \'http://localhost:8186/api/v2/write\' --data-binary \'cpu_load_short,host=server01,region=us-west value=0.64 1434055562000000000\'\n```\n\n[influxdb_http_api]: https://docs.influxdata.com/influxdb/latest/api/\n',image:It.a},{id:"intel_powerstat",name:"Intel PowerStat",markdown:'# Intel PowerStat Input Plugin\nThis input plugin monitors power statistics on Intel-based platforms and assumes presence of Linux based OS. \n\nMain use cases are power saving and workload migration. Telemetry frameworks allow users to monitor critical platform level metrics. \nKey source of platform telemetry is power domain that is beneficial for MANO/Monitoring&Analytics systems \nto take preventive/corrective actions based on platform busyness, CPU temperature, actual CPU utilization and power statistics. \n\n### Configuration:\n```toml\n# Intel PowerStat plugin enables monitoring of platform metrics (power, TDP) and per-CPU metrics like temperature, power and utilization.\n[[inputs.intel_powerstat]]\n  ## All global metrics are always collected by Intel PowerStat plugin.\n  ## User can choose which per-CPU metrics are monitored by the plugin in cpu_metrics array.\n  ## Empty array means no per-CPU specific metrics will be collected by the plugin - in this case only platform level\n  ## telemetry will be exposed by Intel PowerStat plugin.\n  ## Supported options:\n  ## "cpu_frequency", "cpu_busy_frequency", "cpu_temperature", "cpu_c1_state_residency", "cpu_c6_state_residency", "cpu_busy_cycles"\n  # cpu_metrics = []\n```\n### Example: Configuration with no per-CPU telemetry\nThis configuration allows getting global metrics (processor package specific), no per-CPU metrics are collected:\n```toml\n[[inputs.intel_powerstat]]\n  cpu_metrics = []\n```\n\n### Example: Configuration with no per-CPU telemetry - equivalent case\nThis configuration allows getting global metrics (processor package specific), no per-CPU metrics are collected:\n```toml\n[[inputs.intel_powerstat]]\n```\n\n### Example: Configuration for CPU Temperature and Frequency only\nThis configuration allows getting global metrics plus subset of per-CPU metrics (CPU Temperature and Current Frequency):\n```toml\n[[inputs.intel_powerstat]]\n  cpu_metrics = ["cpu_frequency", "cpu_temperature"]\n```\n\n### Example: Configuration with all available metrics\nThis configuration allows getting global metrics and all per-CPU metrics:\n```toml\n[[inputs.intel_powerstat]]\n  cpu_metrics = ["cpu_frequency", "cpu_busy_frequency", "cpu_temperature", "cpu_c1_state_residency", "cpu_c6_state_residency", "cpu_busy_cycles"]\n```\n\n### SW Dependencies:\nPlugin is based on Linux Kernel modules that expose specific metrics over `sysfs` or `devfs` interfaces.\nThe following dependencies are expected by plugin:\n- _intel-rapl_ module which exposes Intel Runtime Power Limiting metrics over `sysfs` (`/sys/devices/virtual/powercap/intel-rapl`),\n- _msr_ kernel module that provides access to processor model specific registers over `devfs` (`/dev/cpu/cpu%d/msr`),\n- _cpufreq_ kernel module - which exposes per-CPU Frequency over `sysfs` (`/sys/devices/system/cpu/cpu%d/cpufreq/scaling_cur_freq`). \n\nMinimum kernel version required is 3.13 to satisfy all requirements.\n\nPlease make sure that kernel modules are loaded and running. You might have to manually enable them by using `modprobe`.\nExact commands to be executed are:\n```\nsudo modprobe cpufreq-stats\nsudo modprobe msr\nsudo modprobe intel_rapl\n```\n\n**Telegraf with Intel PowerStat plugin enabled may require root access to read model specific registers (MSRs)** \nto retrieve data for calculation of most critical per-CPU specific metrics:\n- `cpu_busy_frequency_mhz`\n- `cpu_temperature_celsius`\n- `cpu_c1_state_residency_percent`\n- `cpu_c6_state_residency_percent`\n- `cpu_busy_cycles_percent`\n\nTo expose other Intel PowerStat metrics root access may or may not be required (depending on OS type or configuration).\n\n### HW Dependencies:\nSpecific metrics require certain processor features to be present, otherwise Intel PowerStat plugin won\'t be able to \nread them. When using Linux Kernel based OS, user can detect supported processor features reading `/proc/cpuinfo` file. \nPlugin assumes crucial properties are the same for all CPU cores in the system.\nThe following processor properties are examined in more detail in this section:\nprocessor _cpu family_, _model_ and _flags_.\nThe following processor properties are required by the plugin:\n- Processor _cpu family_ must be Intel (0x6) - since data used by the plugin assumes Intel specific \nmodel specific registers for all features\n- The following processor flags shall be present:\n    - "_msr_" shall be present for plugin to read platform data from processor model specific registers and collect \n    the following metrics: _powerstat_core.cpu_temperature_, _powerstat_core.cpu_busy_frequency_, \n    _powerstat_core.cpu_busy_cycles_, _powerstat_core.cpu_c1_state_residency_, _powerstat_core._cpu_c6_state_residency_\n    - "_aperfmperf_" shall be present to collect the following metrics: _powerstat_core.cpu_busy_frequency_, \n    _powerstat_core.cpu_busy_cycles_, _powerstat_core.cpu_c1_state_residency_\n    - "_dts_" shall be present to collect _powerstat_core.cpu_temperature_\n- Processor _Model number_ must be one of the following values for plugin to read _powerstat_core.cpu_c1_state_residency_ \nand _powerstat_core.cpu_c6_state_residency_ metrics:\n\n| Model number | Processor name |\n|-----|-------------|\n| 0x37 | Intel Atom® Bay Trail |\n| 0x4D | Intel Atom® Avaton |\n| 0x5C | Intel Atom® Apollo Lake |\n| 0x5F | Intel Atom® Denverton | \n| 0x7A | Intel Atom® Goldmont |\n| 0x4C | Intel Atom® Airmont |\n| 0x86 | Intel Atom® Jacobsville |\n| 0x96 | Intel Atom® Elkhart Lake | \n| 0x9C | Intel Atom® Jasper Lake | \n| 0x1A | Intel Nehalem-EP |\n| 0x1E | Intel Nehalem |\n| 0x1F | Intel Nehalem-G |\n| 0x2E | Intel Nehalem-EX |\n| 0x25 | Intel Westmere |\n| 0x2C | Intel Westmere-EP |\n| 0x2F | Intel Westmere-EX |\n| 0x2A | Intel Sandybridge |\n| 0x2D | Intel Sandybridge-X |\n| 0x3A | Intel Ivybridge |\n| 0x3E | Intel Ivybridge-X |\n| 0x4E | Intel Atom® Silvermont-MID |\n| 0x5E | Intel Skylake |\n| 0x55 | Intel Skylake-X |\n| 0x8E | Intel Kabylake-L |\n| 0x9E | Intel Kabylake |\n| 0x6A | Intel Icelake-X |\n| 0x6C | Intel Icelake-D |\n| 0x7D | Intel Icelake |\n| 0x7E | Intel Icelake-L |\n| 0x9D | Intel Icelake-NNPI |\n| 0x3C | Intel Haswell |\n| 0x3F | Intel Haswell-X |\n| 0x45 | Intel Haswell-L |\n| 0x46 | Intel Haswell-G |\n| 0x3D | Intel Broadwell |\n| 0x47 | Intel Broadwell-G |\n| 0x4F | Intel Broadwell-X |\n| 0x56 | Intel Broadwell-D |\n| 0x66 | Intel Cannonlake-L |\n| 0x57 | Intel Xeon® PHI Knights Landing |\n| 0x85 | Intel Xeon® PHI Knights Mill |\n| 0xA5 | Intel CometLake |\n| 0xA6 | Intel CometLake-L |\n| 0x8F | Intel Sapphire Rapids X |\n| 0x8C | Intel TigerLake-L |\n| 0x8D | Intel TigerLake |\n \n### Metrics\nAll metrics collected by Intel PowerStat plugin are collected in fixed intervals.\nMetrics that reports processor C-state residency or power are calculated over elapsed intervals.\nWhen starting to measure metrics, plugin skips first iteration of metrics if they are based on deltas with previous value.\n \n**The following measurements are supported by Intel PowerStat plugin:**\n- powerstat_core\n\n   - The following Tags are returned by plugin with powerstat_core measurements:\n\n        | Tag | Description |\n        |-----|-------------|\n        | `package_id` | ID of platform package/socket |\n        | `core_id` | ID of physical processor core | \n        | `cpu_id` | ID of logical processor core  |\n   Measurement powerstat_core metrics are collected per-CPU (cpu_id is the key) \n   while core_id and package_id tags are additional topology information.\n\n    - Available metrics for powerstat_core measurement \n\n        | Metric name (field) | Description | Units |\n        |-----|-------------|-----|\n        | `cpu_frequency_mhz` | Current operational frequency of CPU Core | MHz |\n        | `cpu_busy_frequency_mhz` | CPU Core Busy Frequency measured as frequency adjusted to CPU Core busy cycles | MHz |\n        | `cpu_temperature_celsius` | Current temperature of CPU Core | Celsius degrees |\n        | `cpu_c1_state_residency_percent` | Percentage of time that CPU Core spent in C1 Core residency state | % |\n        | `cpu_c6_state_residency_percent` | Percentage of time that CPU Core spent in C6 Core residency state | % |\n        | `cpu_busy_cycles_percent` | CPU Core Busy cycles as a ratio of Cycles spent in C0 state residency to all cycles executed by CPU Core | % |\n\n\n\n- powerstat_package\n\n   - The following Tags are returned by plugin with powerstat_package measurements:\n\n        | Tag | Description |\n        |-----|-------------|\n        | `package_id` | ID of platform package/socket |\n   Measurement powerstat_package metrics are collected per processor package - _package_id_ tag indicates which \n   package metric refers to.\n\n    - Available metrics for powerstat_package measurement \n\n        | Metric name (field) | Description | Units |\n        |-----|-------------|-----|\n        | `thermal_design_power_watts` | \tMaximum Thermal Design Power (TDP) available for processor package | Watts |\n        | `current_power_consumption_watts` | Current power consumption of processor package | Watts |\n        | `current_dram_power_consumption_watts` | Current power consumption of processor package DRAM subsystem | Watts |\n\n\n### Example Output:\n\n```\npowerstat_package,host=ubuntu,package_id=0 thermal_design_power_watts=160 1606494744000000000\npowerstat_package,host=ubuntu,package_id=0 current_power_consumption_watts=35 1606494744000000000\npowerstat_package,host=ubuntu,package_id=0 current_dram_power_consumption_watts=13.94 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_frequency_mhz=1200.29 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_temperature_celsius=34i 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_c6_state_residency_percent=92.52 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_busy_cycles_percent=0.8 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_c1_state_residency_percent=6.68 1606494744000000000\npowerstat_core,core_id=0,cpu_id=0,host=ubuntu,package_id=0 cpu_busy_frequency_mhz=1213.24 1606494744000000000\n```\n',image:At.a},{id:"intel_rdt",name:"Intel RDT",markdown:'# Intel RDT Input Plugin\nThe `intel_rdt` plugin collects information provided by monitoring features of \nthe Intel Resource Director Technology (Intel(R) RDT). Intel RDT provides the hardware framework to monitor \nand control the utilization of shared resources (ex: last level cache, memory bandwidth). \n\n### About Intel RDT\nIntel’s Resource Director Technology (RDT) framework consists of:  \n- Cache Monitoring Technology (CMT) \n- Memory Bandwidth Monitoring (MBM)\n- Cache Allocation Technology (CAT) \n- Code and Data Prioritization (CDP) \n\nAs multithreaded and multicore platform architectures emerge, the last level cache and \nmemory bandwidth are key resources to manage for running workloads in single-threaded, \nmultithreaded, or complex virtual machine environments. Intel introduces CMT, MBM, CAT \nand CDP to manage these workloads across shared resources. \n\n### Prerequsities - PQoS Tool\nTo gather Intel RDT metrics, the `intel_rdt` plugin uses _pqos_ cli tool which is a \npart of [Intel(R) RDT Software Package](https://github.com/intel/intel-cmt-cat).\nBefore using this plugin please be sure _pqos_ is properly installed and configured regarding that the plugin\nrun _pqos_ to work with `OS Interface` mode. This plugin supports _pqos_ version 4.0.0 and above.\nNote: pqos tool needs root privileges to work properly.\n\nMetrics will be constantly reported from the following `pqos` commands within the given interval:\n\n#### In case of cores monitoring:\n```\npqos -r --iface-os --mon-file-type=csv --mon-interval=INTERVAL --mon-core=all:[CORES]\\;mbt:[CORES]\n```\nwhere `CORES` is equal to group of cores provided in config. User can provide many groups.\n\n#### In case of process monitoring:\n```\npqos -r --iface-os --mon-file-type=csv --mon-interval=INTERVAL --mon-pid=all:[PIDS]\\;mbt:[PIDS]\n```\nwhere `PIDS` is group of processes IDs which name are equal to provided process name in a config.\nUser can provide many process names which lead to create many processes groups.\n\nIn both cases `INTERVAL` is equal to sampling_interval from config.\n\nBecause PIDs association within system could change in every moment, Intel RDT plugin provides a \nfunctionality to check on every interval if desired processes change their PIDs association.\nIf some change is reported, plugin will restart _pqos_ tool with new arguments. If provided by user\nprocess name is not equal to any of available processes, will be omitted and plugin will constantly\ncheck for process availability.\n\n### Useful links\nPqos installation process: https://github.com/intel/intel-cmt-cat/blob/master/INSTALL  \nEnabling OS interface: https://github.com/intel/intel-cmt-cat/wiki, https://github.com/intel/intel-cmt-cat/wiki/resctrl  \nMore about Intel RDT: https://www.intel.com/content/www/us/en/architecture-and-technology/resource-director-technology.html\n\n### Configuration\n```toml\n# Read Intel RDT metrics\n[[inputs.intel_rdt]]\n  ## Optionally set sampling interval to Nx100ms. \n  ## This value is propagated to pqos tool. Interval format is defined by pqos itself.\n  ## If not provided or provided 0, will be set to 10 = 10x100ms = 1s.\n  # sampling_interval = "10"\n\t\n  ## Optionally specify the path to pqos executable. \n  ## If not provided, auto discovery will be performed.\n  # pqos_path = "/usr/local/bin/pqos"\n\n  ## Optionally specify if IPC and LLC_Misses metrics shouldn\'t be propagated.\n  ## If not provided, default value is false.\n  # shortened_metrics = false\n\n  ## Specify the list of groups of CPU core(s) to be provided as pqos input. \n  ## Mandatory if processes aren\'t set and forbidden if processes are specified.\n  ## e.g. ["0-3", "4,5,6"] or ["1-3,4"]\n  # cores = ["0-3"]\n\n  ## Specify the list of processes for which Metrics will be collected.\n  ## Mandatory if cores aren\'t set and forbidden if cores are specified.\n  ## e.g. ["qemu", "pmd"]\n  # processes = ["process"]\n```\n\n### Exposed metrics\n| Name          | Full name                                     | Description |\n|---------------|-----------------------------------------------|-------------|\n| MBL           | Memory Bandwidth on Local NUMA Node  |     Memory bandwidth utilization by the relevant CPU core/process on the local NUMA memory channel        |\n| MBR           | Memory Bandwidth on Remote NUMA Node |     Memory bandwidth utilization by the relevant CPU core/process on the remote NUMA memory channel        |\n| MBT           | Total Memory Bandwidth               |     Total memory bandwidth utilized by a CPU core/process on local and remote NUMA memory channels        |\n| LLC           | L3 Cache Occupancy                   |     Total Last Level Cache occupancy by a CPU core/process         |\n| LLC_Misses*    | L3 Cache Misses                      |    Total Last Level Cache misses by a CPU core/process       |\n| IPC*           | Instructions Per Cycle               |     Total instructions per cycle executed by a CPU core/process        |\n\n*optional\n\n### Troubleshooting\nPointing to non-existing cores will lead to throwing an error by _pqos_ and the plugin will not work properly.\nBe sure to check provided core number exists within desired system.  \n\nBe aware, reading Intel RDT metrics by _pqos_ cannot be done simultaneously on the same resource.\nDo not use any other _pqos_ instance that is monitoring the same cores or PIDs within the working system.\nIt is not possible to monitor same cores or PIDs on different groups.\n\nPIDs associated for the given process could be manually checked by `pidof` command. E.g:\n```\npidof PROCESS\n```\nwhere `PROCESS` is process name.\n\n### Example Output\n```\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=IPC,process=top value=0 1598962030000000000\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=LLC_Misses,process=top value=0 1598962030000000000\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=LLC,process=top value=0 1598962030000000000\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=MBL,process=top value=0 1598962030000000000\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=MBR,process=top value=0 1598962030000000000\n> rdt_metric,cores=12\\,19,host=r2-compute-20,name=MBT,process=top value=0 1598962030000000000\n```\n',image:Dt.a},{id:"internal",name:"Telegraf Internal",markdown:"# Telegraf Internal Input Plugin\n\nThe `internal` plugin collects metrics about the telegraf agent itself.\n\nNote that some metrics are aggregates across all instances of one type of\nplugin.\n\n### Configuration:\n\n```toml\n# Collect statistics about itself\n[[inputs.internal]]\n  ## If true, collect telegraf memory stats.\n  # collect_memstats = true\n```\n\n### Measurements & Fields:\n\nmemstats are taken from the Go runtime: https://golang.org/pkg/runtime/#MemStats\n\n- internal_memstats\n    - alloc_bytes\n    - frees\n    - heap_alloc_bytes\n    - heap_idle_bytes\n    - heap_in_use_bytes\n    - heap_objects_bytes\n    - heap_released_bytes\n    - heap_sys_bytes\n    - mallocs\n    - num_gc\n    - pointer_lookups\n    - sys_bytes\n    - total_alloc_bytes\n\nagent stats collect aggregate stats on all telegraf plugins.\n\n- internal_agent\n    - gather_errors\n    - metrics_dropped\n    - metrics_gathered\n    - metrics_written\n\ninternal_gather stats collect aggregate stats on all input plugins\nthat are of the same input type. They are tagged with `input=<plugin_name>`\n`version=<telegraf_version>` and `go_version=<go_build_version>`.\n\n- internal_gather\n    - gather_time_ns\n    - metrics_gathered\n\ninternal_write stats collect aggregate stats on all output plugins\nthat are of the same input type. They are tagged with `output=<plugin_name>`\nand `version=<telegraf_version>`.\n\n\n- internal_write\n    - buffer_limit\n    - buffer_size\n    - metrics_added\n    - metrics_written\n    - metrics_dropped\n    - metrics_filtered\n    - write_time_ns\n\ninternal_<plugin_name> are metrics which are defined on a per-plugin basis, and\nusually contain tags which differentiate each instance of a particular type of\nplugin and `version=<telegraf_version>`.\n\n- internal_<plugin_name>\n    - individual plugin-specific fields, such as requests counts.\n\n### Tags:\n\nAll measurements for specific plugins are tagged with information relevant\nto each particular plugin and with `version=<telegraf_version>`.\n\n\n### Example Output:\n\n```\ninternal_memstats,host=tyrion alloc_bytes=4457408i,sys_bytes=10590456i,pointer_lookups=7i,mallocs=17642i,frees=7473i,heap_sys_bytes=6848512i,heap_idle_bytes=1368064i,heap_in_use_bytes=5480448i,heap_released_bytes=0i,total_alloc_bytes=6875560i,heap_alloc_bytes=4457408i,heap_objects_bytes=10169i,num_gc=2i 1480682800000000000\ninternal_agent,host=tyrion,go_version=1.12.7,version=1.99.0 metrics_written=18i,metrics_dropped=0i,metrics_gathered=19i,gather_errors=0i 1480682800000000000\ninternal_write,output=file,host=tyrion,version=1.99.0 buffer_limit=10000i,write_time_ns=636609i,metrics_added=18i,metrics_written=18i,buffer_size=0i 1480682800000000000\ninternal_gather,input=internal,host=tyrion,version=1.99.0 metrics_gathered=19i,gather_time_ns=442114i 1480682800000000000\ninternal_gather,input=http_listener,host=tyrion,version=1.99.0 metrics_gathered=0i,gather_time_ns=167285i 1480682800000000000\ninternal_http_listener,address=:8186,host=tyrion,version=1.99.0 queries_received=0i,writes_received=0i,requests_received=0i,buffers_created=0i,requests_served=0i,pings_received=0i,bytes_received=0i,not_founds_served=0i,pings_served=0i,queries_served=0i,writes_served=0i 1480682800000000000\n```\n",image:Rt.a},{id:"internet_speed",name:"Internet Speed",markdown:"# Internet Speed Monitor\n\nThe `Internet Speed Monitor` collects data about the internet speed on the system.\n\n## Configuration\n\n```toml\n# Monitors internet speed in the network\n[[inputs.internet_speed]]\n  ## Sets if runs file download test\n  ## Default: false\n  enable_file_download = false\n```\n\n## Metrics\n\nIt collects latency, download speed and upload speed\n\n\n| Name           | filed name | type    | Unit |\n| -------------- | ---------- | ------- | ---- |\n| Download Speed | download   | float64 | Mbps |\n| Upload Speed   | upload     | float64 | Mbps |\n| Latency        | latency    | float64 | ms   |\n\n## Example Output\n\n```sh\ninternet_speed,host=Sanyam-Ubuntu download=41.791,latency=28.518,upload=59.798 1631031183000000000\n```\n",image:po.a},{id:"interrupts",name:"Interrupts",markdown:'# Interrupts Input Plugin\n\nThe interrupts plugin gathers metrics about IRQs from `/proc/interrupts` and `/proc/softirqs`.\n\n### Configuration\n```toml\n[[inputs.interrupts]]\n  ## When set to true, cpu metrics are tagged with the cpu.  Otherwise cpu is\n  ## stored as a field.\n  ##\n  ## The default is false for backwards compatibility, and will be changed to\n  ## true in a future version.  It is recommended to set to true on new\n  ## deployments.\n  # cpu_as_tag = false\n\n  ## To filter which IRQs to collect, make use of tagpass / tagdrop, i.e.\n  # [inputs.interrupts.tagdrop]\n  #   irq = [ "NET_RX", "TASKLET" ]\n```\n\n### Metrics\n\nThere are two styles depending on the value of `cpu_as_tag`.\n\nWith `cpu_as_tag = false`:\n\n- interrupts\n  - tags:\n    - irq (IRQ name)\n    - type\n    - device (name of the device that is located at the IRQ)\n    - cpu\n  - fields:\n    - cpu (int, number of interrupts per cpu)\n    - total (int, total number of interrupts)\n\n- soft_interrupts\n  - tags:\n    - irq (IRQ name)\n    - type\n    - device (name of the device that is located at the IRQ)\n    - cpu\n  - fields:\n    - cpu (int, number of interrupts per cpu)\n    - total (int, total number of interrupts)\n\nWith `cpu_as_tag = true`:\n\n- interrupts\n  - tags:\n    - irq (IRQ name)\n    - type\n    - device (name of the device that is located at the IRQ)\n    - cpu\n  - fields:\n    - count (int, number of interrupts)\n\n- soft_interrupts\n  - tags:\n    - irq (IRQ name)\n    - type\n    - device (name of the device that is located at the IRQ)\n    - cpu\n  - fields:\n    - count (int, number of interrupts)\n\n### Example Output\n\nWith `cpu_as_tag = false`:\n```\ninterrupts,irq=0,type=IO-APIC,device=2-edge\\ timer,cpu=cpu0 count=23i 1489346531000000000\ninterrupts,irq=1,type=IO-APIC,device=1-edge\\ i8042,cpu=cpu0 count=9i 1489346531000000000\ninterrupts,irq=30,type=PCI-MSI,device=65537-edge\\ virtio1-input.0,cpu=cpu1 count=1i 1489346531000000000\nsoft_interrupts,irq=NET_RX,cpu=cpu0 count=280879i 1489346531000000000\n```\n\nWith `cpu_as_tag = true`:\n```\ninterrupts,cpu=cpu6,irq=PIW,type=Posted-interrupt\\ wakeup\\ event count=0i 1543539773000000000\ninterrupts,cpu=cpu7,irq=PIW,type=Posted-interrupt\\ wakeup\\ event count=0i 1543539773000000000\nsoft_interrupts,cpu=cpu0,irq=HI count=246441i 1543539773000000000\nsoft_interrupts,cpu=cpu1,irq=HI count=159154i 1543539773000000000\n```\n',image:zt.a},{id:"ipmi_sensor",name:"IPMI Sensor",markdown:'# IPMI Sensor Input Plugin\n\nGet bare metal metrics using the command line utility\n[`ipmitool`](https://github.com/ipmitool/ipmitool).\n\nIf no servers are specified, the plugin will query the local machine sensor stats via the following command:\n\n```\nipmitool sdr\n```\nor with the version 2 schema:\n```\nipmitool sdr elist\n```\n\nWhen one or more servers are specified, the plugin will use the following command to collect remote host sensor stats:\n\n```\nipmitool -I lan -H SERVER -U USERID -P PASSW0RD sdr\n```\n\nAny of the following parameters will be added to the aformentioned query if they\'re configured:\n```\n-y hex_key -L privilege\n```\n\n### Configuration\n\n```toml\n# Read metrics from the bare metal servers via IPMI\n[[inputs.ipmi_sensor]]\n  ## optionally specify the path to the ipmitool executable\n  # path = "/usr/bin/ipmitool"\n  ##\n  ## Setting \'use_sudo\' to true will make use of sudo to run ipmitool.\n  ## Sudo must be configured to allow the telegraf user to run ipmitool\n  ## without a password.\n  # use_sudo = false\n  ##\n  ## optionally force session privilege level. Can be CALLBACK, USER, OPERATOR, ADMINISTRATOR\n  # privilege = "ADMINISTRATOR"\n  ##\n  ## optionally specify one or more servers via a url matching\n  ##  [username[:password]@][protocol[(address)]]\n  ##  e.g.\n  ##    root:passwd@lan(127.0.0.1)\n  ##\n  ## if no servers are specified, local machine sensor stats will be queried\n  ##\n  # servers = ["USERID:PASSW0RD@lan(192.168.1.1)"]\n\n  ## Recommended: use metric \'interval\' that is a multiple of \'timeout\' to avoid\n  ## gaps or overlap in pulled data\n  interval = "30s"\n\n  ## Timeout for the ipmitool command to complete. Default is 20 seconds.\n  timeout = "20s"\n\n  ## Schema Version: (Optional, defaults to version 1)\n  metric_version = 2\n\n  ## Optionally provide the hex key for the IMPI connection.\n  # hex_key = ""\n\n  ## If ipmitool should use a cache\n  ## for me ipmitool runs about 2 to 10 times faster with cache enabled on HP G10 servers (when using ubuntu20.04)\n  ## the cache file may not work well for you if some sensors come up late\n  # use_cache = false\n\n  ## Path to the ipmitools cache file (defaults to OS temp dir)\n  ## The provided path must exist and must be writable\n  # cache_path = ""\n```\n\n### Measurements\n\nVersion 1 schema:\n- ipmi_sensor:\n  - tags:\n    - name\n    - unit\n    - host\n    - server (only when retrieving stats from remote servers)\n  - fields:\n    - status (int, 1=ok status_code/0=anything else)\n    - value (float)\n\nVersion 2 schema:\n- ipmi_sensor:\n  - tags:\n    - name\n    - entity_id (can help uniquify duplicate names)\n    - status_code (two letter code from IPMI documentation)\n    - status_desc (extended status description field)\n    - unit (only on analog values)\n    - host\n    - server (only when retrieving stats from remote)\n  - fields:\n    - value (float)\n\n#### Permissions\n\nWhen gathering from the local system, Telegraf will need permission to the\nipmi device node.  When using udev you can create the device node giving\n`rw` permissions to the `telegraf` user by adding the following rule to\n`/etc/udev/rules.d/52-telegraf-ipmi.rules`:\n\n```\nKERNEL=="ipmi*", MODE="660", GROUP="telegraf"\n```\nAlternatively, it is possible to use sudo. You will need the following in your telegraf config:\n```toml\n[[inputs.ipmi_sensor]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias IPMITOOL = /usr/bin/ipmitool *\ntelegraf  ALL=(root) NOPASSWD: IPMITOOL\nDefaults!IPMITOOL !logfile, !syslog, !pam_session\n```\n\n### Example Output\n\n#### Version 1 Schema\nWhen retrieving stats from a remote server:\n```\nipmi_sensor,server=10.20.2.203,name=uid_light value=0,status=1i 1517125513000000000\nipmi_sensor,server=10.20.2.203,name=sys._health_led status=1i,value=0 1517125513000000000\nipmi_sensor,server=10.20.2.203,name=power_supply_1,unit=watts status=1i,value=110 1517125513000000000\nipmi_sensor,server=10.20.2.203,name=power_supply_2,unit=watts status=1i,value=120 1517125513000000000\nipmi_sensor,server=10.20.2.203,name=power_supplies value=0,status=1i 1517125513000000000\nipmi_sensor,server=10.20.2.203,name=fan_1,unit=percent status=1i,value=43.12 1517125513000000000\n```\n\n\nWhen retrieving stats from the local machine (no server specified):\n```\nipmi_sensor,name=uid_light value=0,status=1i 1517125513000000000\nipmi_sensor,name=sys._health_led status=1i,value=0 1517125513000000000\nipmi_sensor,name=power_supply_1,unit=watts status=1i,value=110 1517125513000000000\nipmi_sensor,name=power_supply_2,unit=watts status=1i,value=120 1517125513000000000\nipmi_sensor,name=power_supplies value=0,status=1i 1517125513000000000\nipmi_sensor,name=fan_1,unit=percent status=1i,value=43.12 1517125513000000000\n```\n\n#### Version 2 Schema\n\nWhen retrieving stats from the local machine (no server specified):\n```\nipmi_sensor,name=uid_light,entity_id=23.1,status_code=ok,status_desc=ok value=0 1517125474000000000\nipmi_sensor,name=sys._health_led,entity_id=23.2,status_code=ok,status_desc=ok value=0 1517125474000000000\nipmi_sensor,entity_id=10.1,name=power_supply_1,status_code=ok,status_desc=presence_detected,unit=watts value=110 1517125474000000000\nipmi_sensor,name=power_supply_2,entity_id=10.2,status_code=ok,unit=watts,status_desc=presence_detected value=125 1517125474000000000\nipmi_sensor,name=power_supplies,entity_id=10.3,status_code=ok,status_desc=fully_redundant value=0 1517125474000000000\nipmi_sensor,entity_id=7.1,name=fan_1,status_code=ok,status_desc=transition_to_running,unit=percent value=43.12 1517125474000000000\n```\n',image:Ft.a},{id:"ipset",name:"Ipset",markdown:'# Ipset Input Plugin\n\nThe ipset plugin gathers packets and bytes counters from Linux ipset.\nIt uses the output of the command "ipset save".\nIpsets created without the "counters" option are ignored.\n\nResults are tagged with:\n- ipset name\n- ipset entry\n\nThere are 3 ways to grant telegraf the right to run ipset:\n* Run as root (strongly discouraged)\n* Use sudo\n* Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW capabilities.\n\n### Using systemd capabilities\n\nYou may run `systemctl edit telegraf.service` and add the following:\n\n```\n[Service]\nCapabilityBoundingSet=CAP_NET_RAW CAP_NET_ADMIN\nAmbientCapabilities=CAP_NET_RAW CAP_NET_ADMIN\n```\n\n### Using sudo\n\nYou will need the following in your telegraf config:\n```toml\n[[inputs.ipset]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias IPSETSAVE = /sbin/ipset save\ntelegraf  ALL=(root) NOPASSWD: IPSETSAVE\nDefaults!IPSETSAVE !logfile, !syslog, !pam_session\n```\n\n### Configuration\n\n```toml\n  [[inputs.ipset]]\n    ## By default, we only show sets which have already matched at least 1 packet.\n    ## set include_unmatched_sets = true to gather them all.\n    include_unmatched_sets = false\n    ## Adjust your sudo settings appropriately if using this option ("sudo ipset save")\n    ## You can avoid using sudo or root, by setting appropriate privileges for\n    ## the telegraf.service systemd service.\n    use_sudo = false\n    ## The default timeout of 1s for ipset execution can be overridden here:\n    # timeout = "1s"\n\n```\n\n### Example Output\n\n```\n$ sudo ipset save\ncreate myset hash:net family inet hashsize 1024 maxelem 65536 counters comment\nadd myset 10.69.152.1 packets 8 bytes 672 comment "machine A"\n```\n\n```\n$ telegraf --config telegraf.conf --input-filter ipset --test --debug\n* Plugin: inputs.ipset, Collection 1\n> ipset,rule=10.69.152.1,host=trashme,set=myset bytes_total=8i,packets_total=672i 1507615028000000000\n```\n',image:jt.a},{id:"iptables",name:"Iptables",markdown:'# Iptables Input Plugin\n\nThe iptables plugin gathers packets and bytes counters for rules within a set of table and chain from the Linux\'s iptables firewall.\n\nRules are identified through associated comment. **Rules without comment are ignored**.\nIndeed we need a unique ID for the rule and the rule number is not a constant: it may vary when rules are inserted/deleted at start-up or by automatic tools (interactive firewalls, fail2ban, ...).\nAlso when the rule set is becoming big (hundreds of lines) most people are interested in monitoring only a small part of the rule set.\n\nBefore using this plugin **you must ensure that the rules you want to monitor are named with a unique comment**. Comments are added using the `-m comment --comment "my comment"` iptables options.\n\nThe iptables command requires CAP_NET_ADMIN and CAP_NET_RAW capabilities. You have several options to grant telegraf to run iptables:\n\n* Run telegraf as root. This is strongly discouraged.\n* Configure systemd to run telegraf with CAP_NET_ADMIN and CAP_NET_RAW. This is the simplest and recommended option.\n* Configure sudo to grant telegraf to run iptables. This is the most restrictive option, but require sudo setup.\n\n### Using systemd capabilities\n\nYou may run `systemctl edit telegraf.service` and add the following:\n\n```\n[Service]\nCapabilityBoundingSet=CAP_NET_RAW CAP_NET_ADMIN\nAmbientCapabilities=CAP_NET_RAW CAP_NET_ADMIN\n```\n\nSince telegraf will fork a process to run iptables, `AmbientCapabilities` is required to transmit the capabilities bounding set to the forked process.\n\n### Using sudo\n\nYou will need the following in your telegraf config:\n```toml\n[[inputs.iptables]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias IPTABLESSHOW = /usr/bin/iptables -nvL *\ntelegraf  ALL=(root) NOPASSWD: IPTABLESSHOW\nDefaults!IPTABLESSHOW !logfile, !syslog, !pam_session\n```\n\n### Using IPtables lock feature\n\nDefining multiple instances of this plugin in telegraf.conf can lead to concurrent IPtables access resulting in "ERROR in input [inputs.iptables]: exit status 4" messages in telegraf.log and missing metrics. Setting \'use_lock = true\' in the plugin configuration will run IPtables with the \'-w\' switch, allowing a lock usage to prevent this error.\n\n### Configuration:\n\n```toml\n  # use sudo to run iptables\n  use_sudo = false\n  # run iptables with the lock option\n  use_lock = false\n  # Define an alternate executable, such as "ip6tables". Default is "iptables".\n  # binary = "ip6tables"\n  # defines the table to monitor:\n  table = "filter"\n  # defines the chains to monitor:\n  chains = [ "INPUT" ]\n```\n\n### Measurements & Fields:\n\n\n- iptables\n    - pkts (integer, count)\n    - bytes (integer, bytes)\n\n### Tags:\n\n- All measurements have the following tags:\n    - table\n    - chain\n    - ruleid\n\nThe `ruleid` is the comment associated to the rule.\n\n### Example Output:\n\n```\n$ iptables -nvL INPUT\nChain INPUT (policy DROP 0 packets, 0 bytes)\npkts bytes target     prot opt in     out     source               destination\n100   1024   ACCEPT     tcp  --  *      *       192.168.0.0/24       0.0.0.0/0            tcp dpt:22 /* ssh */\n 42   2048   ACCEPT     tcp  --  *      *       192.168.0.0/24       0.0.0.0/0            tcp dpt:80 /* httpd */\n```\n\n```\n$ ./telegraf --config telegraf.conf --input-filter iptables --test\niptables,table=filter,chain=INPUT,ruleid=ssh pkts=100i,bytes=1024i 1453831884664956455\niptables,table=filter,chain=INPUT,ruleid=httpd pkts=42i,bytes=2048i 1453831884664956455\n```\n',image:Wt.a},{id:"ipvs",name:"IPVS",markdown:"# IPVS Input Plugin\n\nThe IPVS input plugin uses the linux kernel netlink socket interface to gather\nmetrics about ipvs virtual and real servers.\n\n**Supported Platforms:** Linux\n\n### Configuration\n\n```toml\n[[inputs.ipvs]]\n  # no configuration\n```\n\n#### Permissions\n\nAssuming you installed the telegraf package via one of the published packages,\nthe process will be running as the `telegraf` user. However, in order for this\nplugin to communicate over netlink sockets it needs the telegraf process to be\nrunning as `root` (or some user with `CAP_NET_ADMIN` and `CAP_NET_RAW`). Be sure\nto ensure these permissions before running telegraf with this plugin included.\n\n### Metrics\n\nServer will contain tags identifying how it was configured, using one of\n`address` + `port` + `protocol` *OR* `fwmark`. This is how one would normally\nconfigure a virtual server using `ipvsadm`.\n\n- ipvs_virtual_server\n  - tags:\n    - sched (the scheduler in use)\n    - netmask (the mask used for determining affinity)\n    - address_family (inet/inet6)\n    - address\n    - port\n    - protocol\n    - fwmark\n  - fields:\n    - connections\n    - pkts_in\n    - pkts_out\n    - bytes_in\n    - bytes_out\n    - pps_in\n    - pps_out\n    - cps\n\n- ipvs_real_server\n  - tags:\n    - address\n    - port\n    - address_family (inet/inet6)\n    - virtual_address\n    - virtual_port\n    - virtual_protocol\n    - virtual_fwmark\n  - fields:\n    - active_connections\n    - inactive_connections\n    - connections\n    - pkts_in\n    - pkts_out\n    - bytes_in\n    - bytes_out\n    - pps_in\n    - pps_out\n    - cps\n\n### Example Output\n\nVirtual server is configured using `fwmark` and backed by 2 real servers:\n```\nipvs_virtual_server,address=172.18.64.234,address_family=inet,netmask=32,port=9000,protocol=tcp,sched=rr bytes_in=0i,bytes_out=0i,pps_in=0i,pps_out=0i,cps=0i,connections=0i,pkts_in=0i,pkts_out=0i 1541019340000000000\nipvs_real_server,address=172.18.64.220,address_family=inet,port=9000,virtual_address=172.18.64.234,virtual_port=9000,virtual_protocol=tcp active_connections=0i,inactive_connections=0i,pkts_in=0i,bytes_out=0i,pps_out=0i,connections=0i,pkts_out=0i,bytes_in=0i,pps_in=0i,cps=0i 1541019340000000000\nipvs_real_server,address=172.18.64.219,address_family=inet,port=9000,virtual_address=172.18.64.234,virtual_port=9000,virtual_protocol=tcp active_connections=0i,inactive_connections=0i,pps_in=0i,pps_out=0i,connections=0i,pkts_in=0i,pkts_out=0i,bytes_in=0i,bytes_out=0i,cps=0i 1541019340000000000\n```\n\nVirtual server is configured using `proto+addr+port` and backed by 2 real servers:\n```\nipvs_virtual_server,address_family=inet,fwmark=47,netmask=32,sched=rr cps=0i,connections=0i,pkts_in=0i,pkts_out=0i,bytes_in=0i,bytes_out=0i,pps_in=0i,pps_out=0i 1541019340000000000\nipvs_real_server,address=172.18.64.220,address_family=inet,port=9000,virtual_fwmark=47 inactive_connections=0i,pkts_out=0i,bytes_out=0i,pps_in=0i,cps=0i,active_connections=0i,pkts_in=0i,bytes_in=0i,pps_out=0i,connections=0i 1541019340000000000\nipvs_real_server,address=172.18.64.219,address_family=inet,port=9000,virtual_fwmark=47 cps=0i,active_connections=0i,inactive_connections=0i,connections=0i,pkts_in=0i,bytes_out=0i,pkts_out=0i,bytes_in=0i,pps_in=0i,pps_out=0i 1541019340000000000\n```\n",image:Qt.a},{id:"jenkins",name:"Jenkins",markdown:'# Jenkins Input Plugin\n\nThe jenkins plugin gathers information about the nodes and jobs running in a jenkins instance.\n\nThis plugin does not require a plugin on jenkins and it makes use of Jenkins API to retrieve all the information needed.\n\n### Configuration:\n\n```toml\n[[inputs.jenkins]]\n  ## The Jenkins URL in the format "schema://host:port"\n  url = "http://my-jenkins-instance:8080"\n  # username = "admin"\n  # password = "admin"\n\n  ## Set response_timeout\n  response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use SSL but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Optional Max Job Build Age filter\n  ## Default 1 hour, ignore builds older than max_build_age\n  # max_build_age = "1h"\n\n  ## Optional Sub Job Depth filter\n  ## Jenkins can have unlimited layer of sub jobs\n  ## This config will limit the layers of pulling, default value 0 means\n  ## unlimited pulling until no more sub jobs\n  # max_subjob_depth = 0\n\n  ## Optional Sub Job Per Layer\n  ## In workflow-multibranch-plugin, each branch will be created as a sub job.\n  ## This config will limit to call only the lasted branches in each layer,\n  ## empty will use default value 10\n  # max_subjob_per_layer = 10\n\n  ## Jobs to include or exclude from gathering\n  ## When using both lists, job_exclude has priority.\n  ## Wildcards are supported: [ "jobA/*", "jobB/subjob1/*"]\n  # job_include = [ "*" ]\n  # job_exclude = [ ]\n\n  ## Nodes to exclude from gathering\n  # node_exclude = [ ]\n\n  ## Worker pool for jenkins plugin only\n  ## Empty this field will use default value 5\n  # max_connections = 5\n```\n\n### Metrics:\n\n- jenkins_node\n  - tags:\n    - source\n    - port\n  - fields:\n    - busy_executors\n    - total_executors\n\n+ jenkins_node\n  - tags:\n    - arch\n    - disk_path\n    - temp_path\n    - node_name\n    - status ("online", "offline")\n    - source\n    - port\n  - fields:\n    - disk_available (Bytes)\n    - temp_available (Bytes)\n    - memory_available (Bytes)\n    - memory_total (Bytes)\n    - swap_available (Bytes)\n    - swap_total (Bytes)\n    - response_time (ms)\n    - num_executors\n\n- jenkins_job\n  - tags:\n    - name\n    - parents\n    - result\n    - source\n    - port\n  - fields:\n    - duration (ms)\n    - number\n    - result_code (0 = SUCCESS, 1 = FAILURE, 2 = NOT_BUILD, 3 = UNSTABLE, 4 = ABORTED)\n\n### Sample Queries:\n\n```\nSELECT mean("memory_available") AS "mean_memory_available", mean("memory_total") AS "mean_memory_total", mean("temp_available") AS "mean_temp_available" FROM "jenkins_node" WHERE time > now() - 15m GROUP BY time(:interval:) FILL(null)\n```\n\n```\nSELECT mean("duration") AS "mean_duration" FROM "jenkins_job" WHERE time > now() - 24h GROUP BY time(:interval:) FILL(null)\n```\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter jenkins --test\njenkins,host=myhost,port=80,source=my-jenkins-instance busy_executors=4i,total_executors=8i 1580418261000000000\njenkins_node,arch=Linux\\ (amd64),disk_path=/var/jenkins_home,temp_path=/tmp,host=myhost,node_name=master,source=my-jenkins-instance,port=8080 swap_total=4294963200,memory_available=586711040,memory_total=6089498624,status=online,response_time=1000i,disk_available=152392036352,temp_available=152392036352,swap_available=3503263744,num_executors=2i 1516031535000000000\njenkins_job,host=myhost,name=JOB1,parents=apps/br1,result=SUCCESS,source=my-jenkins-instance,port=8080 duration=2831i,result_code=0i 1516026630000000000\njenkins_job,host=myhost,name=JOB2,parents=apps/br2,result=SUCCESS,source=my-jenkins-instance,port=8080 duration=2285i,result_code=0i 1516027230000000000\n```\n\n',image:Vt.a},{id:"jolokia",name:"Jolokia",markdown:'# Jolokia Input Plugin\n\n**Deprecated in version 1.5:** Please use the [jolokia2](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2) plugin.\n\n#### Configuration\n\n```toml\n# Read JMX metrics through Jolokia\n[[inputs.jolokia]]\n  ## This is the context root used to compose the jolokia url\n  ## NOTE that Jolokia requires a trailing slash at the end of the context root\n  context = "/jolokia/"\n\n  ## This specifies the mode used\n  # mode = "proxy"\n  #\n  ## When in proxy mode this section is used to specify further\n  ## proxy address configurations.\n  ## Remember to change host address to fit your environment.\n  # [inputs.jolokia.proxy]\n  #   host = "127.0.0.1"\n  #   port = "8080"\n  \n  ## Optional http timeouts\n  ##\n  ## response_header_timeout, if non-zero, specifies the amount of time to wait\n  ## for a server\'s response headers after fully writing the request.\n  # response_header_timeout = "3s"\n  ##\n  ## client_timeout specifies a time limit for requests made by this client.\n  ## Includes connection time, any redirects, and reading the response body.\n  # client_timeout = "4s"\n\n  ## List of servers exposing jolokia read service\n  [[inputs.jolokia.servers]]\n    name = "as-server-01"\n    host = "127.0.0.1"\n    port = "8080"\n    # username = "myuser"\n    # password = "mypassword"\n\n  ## List of metrics collected on above servers\n  ## Each metric consists in a name, a jmx path and either\n  ## a pass or drop slice attribute.\n  ## This collect all heap memory usage metrics.\n  [[inputs.jolokia.metrics]]\n    name = "heap_memory_usage"\n    mbean  = "java.lang:type=Memory"\n    attribute = "HeapMemoryUsage"\n\n  ## This collect thread counts metrics.\n  [[inputs.jolokia.metrics]]\n    name = "thread_count"\n    mbean  = "java.lang:type=Threading"\n    attribute = "TotalStartedThreadCount,ThreadCount,DaemonThreadCount,PeakThreadCount"\n\n  ## This collect number of class loaded/unloaded counts metrics.\n  [[inputs.jolokia.metrics]]\n    name = "class_count"\n    mbean  = "java.lang:type=ClassLoading"\n    attribute = "LoadedClassCount,UnloadedClassCount,TotalLoadedClassCount"\n```\n\n#### Description\n\nThe Jolokia plugin collects JVM metrics exposed as MBean\'s attributes through\njolokia REST endpoint. All metrics are collected for each server configured.\n\nSee: https://jolokia.org/\n\n# Measurements:\nJolokia plugin produces one measure for each metric configured,\nadding Server\'s `jolokia_name`, `jolokia_host` and `jolokia_port` as tags.\n',image:Jt.a},{id:"jolokia2",name:"Jolokia2",markdown:'# Jolokia2 Input Plugin\n\nThe [Jolokia](http://jolokia.org) _agent_ and _proxy_ input plugins collect JMX metrics from an HTTP endpoint using Jolokia\'s [JSON-over-HTTP protocol](https://jolokia.org/reference/html/protocol.html).\n\n### Configuration:\n\n#### Jolokia Agent Configuration\n\nThe `jolokia2_agent` input plugin reads JMX metrics from one or more [Jolokia agent](https://jolokia.org/agent/jvm.html) REST endpoints.\n\n```toml\n[[inputs.jolokia2_agent]]\n  urls = ["http://agent:8080/jolokia"]\n\n  [[inputs.jolokia2_agent.metric]]\n    name  = "jvm_runtime"\n    mbean = "java.lang:type=Runtime"\n    paths = ["Uptime"]\n```\n\nOptionally, specify TLS options for communicating with agents:\n\n```toml\n[[inputs.jolokia2_agent]]\n  urls = ["https://agent:8080/jolokia"]\n  tls_ca   = "/var/private/ca.pem"\n  tls_cert = "/var/private/client.pem"\n  tls_key  = "/var/private/client-key.pem"\n  #insecure_skip_verify = false\n\n  [[inputs.jolokia2_agent.metric]]\n    name  = "jvm_runtime"\n    mbean = "java.lang:type=Runtime"\n    paths = ["Uptime"]\n```\n\n#### Jolokia Proxy Configuration\n\nThe `jolokia2_proxy` input plugin reads JMX metrics from one or more _targets_ by interacting with a [Jolokia proxy](https://jolokia.org/features/proxy.html) REST endpoint.\n\n```toml\n[[inputs.jolokia2_proxy]]\n  url = "http://proxy:8080/jolokia"\n\n  #default_target_username = ""\n  #default_target_password = ""\n  [[inputs.jolokia2_proxy.target]]\n    url = "service:jmx:rmi:///jndi/rmi://targethost:9999/jmxrmi"\n    # username = ""\n    # password = ""\n\n  [[inputs.jolokia2_proxy.metric]]\n    name  = "jvm_runtime"\n    mbean = "java.lang:type=Runtime"\n    paths = ["Uptime"]\n```\n\nOptionally, specify TLS options for communicating with proxies:\n\n```toml\n[[inputs.jolokia2_proxy]]\n  url = "https://proxy:8080/jolokia"\n\n  tls_ca   = "/var/private/ca.pem"\n  tls_cert = "/var/private/client.pem"\n  tls_key  = "/var/private/client-key.pem"\n  #insecure_skip_verify = false\n\n  #default_target_username = ""\n  #default_target_password = ""\n  [[inputs.jolokia2_proxy.target]]\n    url = "service:jmx:rmi:///jndi/rmi://targethost:9999/jmxrmi"\n    # username = ""\n    # password = ""\n\n  [[inputs.jolokia2_agent.metric]]\n    name  = "jvm_runtime"\n    mbean = "java.lang:type=Runtime"\n    paths = ["Uptime"]\n```\n\n#### Jolokia Metric Configuration\n\nEach `metric` declaration generates a Jolokia request to fetch telemetry from a JMX MBean.\n\n| Key            | Required | Description |\n|----------------|----------|-------------|\n| `mbean`        | yes      | The object name of a JMX MBean. MBean property-key values can contain a wildcard `*`, allowing you to fetch multiple MBeans with one declaration. |\n| `paths`        | no       | A list of MBean attributes to read. |\n| `tag_keys`     | no       | A list of MBean property-key names to convert into tags. The property-key name becomes the tag name, while the property-key value becomes the tag value. |\n| `tag_prefix`   | no       | A string to prepend to the tag names produced by this `metric` declaration. |\n| `field_name`   | no       | A string to set as the name of the field produced by this metric; can contain substitutions. |\n| `field_prefix` | no       | A string to prepend to the field names produced by this `metric` declaration; can contain substitutions. |\n\nUse `paths` to refine which fields to collect.\n\n```toml\n[[inputs.jolokia2_agent.metric]]\n  name  = "jvm_memory"\n  mbean = "java.lang:type=Memory"\n  paths = ["HeapMemoryUsage", "NonHeapMemoryUsage", "ObjectPendingFinalizationCount"]\n```\n\nThe preceeding `jvm_memory` `metric` declaration produces the following output:\n\n```\njvm_memory HeapMemoryUsage.committed=4294967296,HeapMemoryUsage.init=4294967296,HeapMemoryUsage.max=4294967296,HeapMemoryUsage.used=1750658992,NonHeapMemoryUsage.committed=67350528,NonHeapMemoryUsage.init=2555904,NonHeapMemoryUsage.max=-1,NonHeapMemoryUsage.used=65821352,ObjectPendingFinalizationCount=0 1503762436000000000\n```\n\nUse `*` wildcards against `mbean` property-key values to create distinct series by capturing values into `tag_keys`.\n\n```toml\n[[inputs.jolokia2_agent.metric]]\n  name     = "jvm_garbage_collector"\n  mbean    = "java.lang:name=*,type=GarbageCollector"\n  paths    = ["CollectionTime", "CollectionCount"]\n  tag_keys = ["name"]\n```\n\nSince `name=*` matches both `G1 Old Generation` and `G1 Young Generation`, and `name` is used as a tag, the preceeding `jvm_garbage_collector` `metric` declaration produces two metrics.\n\n```\njvm_garbage_collector,name=G1\\ Old\\ Generation CollectionCount=0,CollectionTime=0 1503762520000000000\njvm_garbage_collector,name=G1\\ Young\\ Generation CollectionTime=32,CollectionCount=2 1503762520000000000\n```\n\nUse `tag_prefix` along with `tag_keys` to add detail to tag names.\n\n```toml\n[[inputs.jolokia2_agent.metric]]\n  name       = "jvm_memory_pool"\n  mbean      = "java.lang:name=*,type=MemoryPool"\n  paths      = ["Usage", "PeakUsage", "CollectionUsage"]\n  tag_keys   = ["name"]\n  tag_prefix = "pool_"\n```\n\nThe preceeding `jvm_memory_pool` `metric` declaration produces six metrics, each with a distinct `pool_name` tag.\n\n```\njvm_memory_pool,pool_name=Compressed\\ Class\\ Space PeakUsage.max=1073741824,PeakUsage.committed=3145728,PeakUsage.init=0,Usage.committed=3145728,Usage.init=0,PeakUsage.used=3017976,Usage.max=1073741824,Usage.used=3017976 1503764025000000000\njvm_memory_pool,pool_name=Code\\ Cache PeakUsage.init=2555904,PeakUsage.committed=6291456,Usage.committed=6291456,PeakUsage.used=6202752,PeakUsage.max=251658240,Usage.used=6210368,Usage.max=251658240,Usage.init=2555904 1503764025000000000\njvm_memory_pool,pool_name=G1\\ Eden\\ Space CollectionUsage.max=-1,PeakUsage.committed=56623104,PeakUsage.init=56623104,PeakUsage.used=53477376,Usage.max=-1,Usage.committed=49283072,Usage.used=19922944,CollectionUsage.committed=49283072,CollectionUsage.init=56623104,CollectionUsage.used=0,PeakUsage.max=-1,Usage.init=56623104 1503764025000000000\njvm_memory_pool,pool_name=G1\\ Old\\ Gen CollectionUsage.max=1073741824,CollectionUsage.committed=0,PeakUsage.max=1073741824,PeakUsage.committed=1017118720,PeakUsage.init=1017118720,PeakUsage.used=137032208,Usage.max=1073741824,CollectionUsage.init=1017118720,Usage.committed=1017118720,Usage.init=1017118720,Usage.used=134708752,CollectionUsage.used=0 1503764025000000000\njvm_memory_pool,pool_name=G1\\ Survivor\\ Space Usage.max=-1,Usage.init=0,CollectionUsage.max=-1,CollectionUsage.committed=7340032,CollectionUsage.used=7340032,PeakUsage.committed=7340032,Usage.committed=7340032,Usage.used=7340032,CollectionUsage.init=0,PeakUsage.max=-1,PeakUsage.init=0,PeakUsage.used=7340032 1503764025000000000\njvm_memory_pool,pool_name=Metaspace PeakUsage.init=0,PeakUsage.used=21852224,PeakUsage.max=-1,Usage.max=-1,Usage.committed=22282240,Usage.init=0,Usage.used=21852224,PeakUsage.committed=22282240 1503764025000000000\n```\n\nUse substitutions to create fields and field prefixes with MBean property-keys captured by wildcards. In the following example, `$1` represents the value of the property-key `name`, and `$2` represents the value of the property-key `topic`.\n\n```toml\n[[inputs.jolokia2_agent.metric]]\n  name         = "kafka_topic"\n  mbean        = "kafka.server:name=*,topic=*,type=BrokerTopicMetrics"\n  field_prefix = "$1"\n  tag_keys     = ["topic"]\n```\n\nThe preceeding `kafka_topic` `metric` declaration produces a metric per Kafka topic. The `name` Mbean property-key is used as a field prefix to aid in gathering fields together into the single metric.\n\n```\nkafka_topic,topic=my-topic BytesOutPerSec.MeanRate=0,FailedProduceRequestsPerSec.MeanRate=0,BytesOutPerSec.EventType="bytes",BytesRejectedPerSec.Count=0,FailedProduceRequestsPerSec.RateUnit="SECONDS",FailedProduceRequestsPerSec.EventType="requests",MessagesInPerSec.RateUnit="SECONDS",BytesInPerSec.EventType="bytes",BytesOutPerSec.RateUnit="SECONDS",BytesInPerSec.OneMinuteRate=0,FailedFetchRequestsPerSec.EventType="requests",TotalFetchRequestsPerSec.MeanRate=146.301533938701,BytesOutPerSec.FifteenMinuteRate=0,TotalProduceRequestsPerSec.MeanRate=0,BytesRejectedPerSec.FifteenMinuteRate=0,MessagesInPerSec.FiveMinuteRate=0,BytesInPerSec.Count=0,BytesRejectedPerSec.MeanRate=0,FailedFetchRequestsPerSec.MeanRate=0,FailedFetchRequestsPerSec.FiveMinuteRate=0,FailedFetchRequestsPerSec.FifteenMinuteRate=0,FailedProduceRequestsPerSec.Count=0,TotalFetchRequestsPerSec.FifteenMinuteRate=128.59314292334466,TotalFetchRequestsPerSec.OneMinuteRate=126.71551273850747,TotalFetchRequestsPerSec.Count=1353483,TotalProduceRequestsPerSec.FifteenMinuteRate=0,FailedFetchRequestsPerSec.OneMinuteRate=0,FailedFetchRequestsPerSec.Count=0,FailedProduceRequestsPerSec.FifteenMinuteRate=0,TotalFetchRequestsPerSec.FiveMinuteRate=130.8516148751592,TotalFetchRequestsPerSec.RateUnit="SECONDS",BytesRejectedPerSec.RateUnit="SECONDS",BytesInPerSec.MeanRate=0,FailedFetchRequestsPerSec.RateUnit="SECONDS",BytesRejectedPerSec.OneMinuteRate=0,BytesOutPerSec.Count=0,BytesOutPerSec.OneMinuteRate=0,MessagesInPerSec.FifteenMinuteRate=0,MessagesInPerSec.MeanRate=0,BytesInPerSec.FiveMinuteRate=0,TotalProduceRequestsPerSec.RateUnit="SECONDS",FailedProduceRequestsPerSec.OneMinuteRate=0,TotalProduceRequestsPerSec.EventType="requests",BytesRejectedPerSec.FiveMinuteRate=0,BytesRejectedPerSec.EventType="bytes",BytesOutPerSec.FiveMinuteRate=0,FailedProduceRequestsPerSec.FiveMinuteRate=0,MessagesInPerSec.Count=0,TotalProduceRequestsPerSec.FiveMinuteRate=0,TotalProduceRequestsPerSec.OneMinuteRate=0,MessagesInPerSec.EventType="messages",MessagesInPerSec.OneMinuteRate=0,TotalFetchRequestsPerSec.EventType="requests",BytesInPerSec.RateUnit="SECONDS",BytesInPerSec.FifteenMinuteRate=0,TotalProduceRequestsPerSec.Count=0 1503767532000000000\n```\n\nBoth `jolokia2_agent` and `jolokia2_proxy` plugins support default configurations that apply to every `metric` declaration.\n\n| Key                       | Default Value | Description |\n|---------------------------|---------------|-------------|\n| `default_field_separator` | `.`           | A character to use to join Mbean attributes when creating fields. |\n| `default_field_prefix`    | _None_        | A string to prepend to the field names produced by all `metric` declarations. |\n| `default_tag_prefix`      | _None_        | A string to prepend to the tag names produced by all `metric` declarations. |\n\n### Example Configurations:\n\n- [ActiveMQ](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/activemq.conf)\n- [BitBucket](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/bitbucket.conf)\n- [Cassandra](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/cassandra.conf)\n- [Hadoop-HDFS](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/hadoop-hdfs.conf)\n- [Java JVM](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/java.conf)\n- [JBoss](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/jboss.conf)\n- [Kafka](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/kafka.conf)\n- [Kafka Connect](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/kafka-connect.conf)\n- [Tomcat](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/tomcat.conf)\n- [Weblogic](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/weblogic.conf)\n- [ZooKeeper](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2/examples/zookeeper.conf)\n\nPlease help improve this list and contribute new configuration files by opening an issue or pull request.\n',image:Yt.a},{id:"jti_openconfig_telemetry",name:"JTI OpenConfig Telemetry",markdown:'# JTI OpenConfig Telemetry Input Plugin\n\nThis plugin reads Juniper Networks implementation of OpenConfig telemetry data from listed sensors using Junos Telemetry Interface. Refer to\n[openconfig.net](http://openconfig.net/) for more details about OpenConfig and [Junos Telemetry Interface (JTI)](https://www.juniper.net/documentation/en_US/junos/topics/concept/junos-telemetry-interface-oveview.html).\n\n### Configuration:\n\n```toml\n# Subscribe and receive OpenConfig Telemetry data using JTI\n[[inputs.jti_openconfig_telemetry]]\n  ## List of device addresses to collect telemetry from\n  servers = ["localhost:1883"]\n\n  ## Authentication details. Username and password are must if device expects\n  ## authentication. Client ID must be unique when connecting from multiple instances\n  ## of telegraf to the same device\n  username = "user"\n  password = "pass"\n  client_id = "telegraf"\n\n  ## Frequency to get data\n  sample_frequency = "1000ms"\n\n  ## Sensors to subscribe for\n  ## A identifier for each sensor can be provided in path by separating with space\n  ## Else sensor path will be used as identifier\n  ## When identifier is used, we can provide a list of space separated sensors.\n  ## A single subscription will be created with all these sensors and data will\n  ## be saved to measurement with this identifier name\n  sensors = [\n   "/interfaces/",\n   "collection /components/ /lldp",\n  ]\n\n  ## We allow specifying sensor group level reporting rate. To do this, specify the\n  ## reporting rate in Duration at the beginning of sensor paths / collection\n  ## name. For entries without reporting rate, we use configured sample frequency\n  sensors = [\n   "1000ms customReporting /interfaces /lldp",\n   "2000ms collection /components",\n   "/interfaces",\n  ]\n\n  ## Optional TLS Config\n  # enable_tls = true\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Delay between retry attempts of failed RPC calls or streams. Defaults to 1000ms.\n  ## Failed streams/calls will not be retried if 0 is provided\n  retry_delay = "1000ms"\n\n  ## To treat all string values as tags, set this to true\n  str_as_tags = false\n```\n\n### Tags:\n\n- All measurements are tagged appropriately using the identifier information\n  in incoming data\n',image:en.a},{id:"kafka_consumer",name:"Kafka Consumer",markdown:'# Kafka Consumer Input Plugin\n\nThe [Kafka][kafka] consumer plugin reads from Kafka\nand creates metrics using one of the supported [input data formats][].\n\nFor old kafka version (< 0.8), please use the [kafka_consumer_legacy][] input plugin\nand use the old zookeeper connection method.\n\n### Configuration\n\n```toml\n[[inputs.kafka_consumer]]\n  ## Kafka brokers.\n  brokers = ["localhost:9092"]\n\n  ## Topics to consume.\n  topics = ["telegraf"]\n\n  ## When set this tag will be added to all metrics with the topic as the value.\n  # topic_tag = ""\n\n  ## Optional Client id\n  # client_id = "Telegraf"\n\n  ## Set the minimal supported Kafka version.  Setting this enables the use of new\n  ## Kafka features and APIs.  Must be 0.10.2.0 or greater.\n  ##   ex: version = "1.1.0"\n  # version = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## SASL authentication credentials.  These settings should typically be used\n  ## with TLS encryption enabled\n  # sasl_username = "kafka"\n  # sasl_password = "secret"\n\n  ## Optional SASL:\n  ## one of: OAUTHBEARER, PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, GSSAPI\n  ## (defaults to PLAIN)\n  # sasl_mechanism = ""\n\n  ## used if sasl_mechanism is GSSAPI (experimental)\n  # sasl_gssapi_service_name = ""\n  # ## One of: KRB5_USER_AUTH and KRB5_KEYTAB_AUTH\n  # sasl_gssapi_auth_type = "KRB5_USER_AUTH"\n  # sasl_gssapi_kerberos_config_path = "/"\n  # sasl_gssapi_realm = "realm"\n  # sasl_gssapi_key_tab_path = ""\n  # sasl_gssapi_disable_pafxfast = false\n\n  ## used if sasl_mechanism is OAUTHBEARER (experimental)\n  # sasl_access_token = ""\n\n  ## SASL protocol version.  When connecting to Azure EventHub set to 0.\n  # sasl_version = 1\n\n  ## Name of the consumer group.\n  # consumer_group = "telegraf_metrics_consumers"\n\n  ## Compression codec represents the various compression codecs recognized by\n  ## Kafka in messages.\n  ##  0 : None\n  ##  1 : Gzip\n  ##  2 : Snappy\n  ##  3 : LZ4\n  ##  4 : ZSTD\n  # compression_codec = 0\n  ## Initial offset position; one of "oldest" or "newest".\n  # offset = "oldest"\n\n  ## Consumer group partition assignment strategy; one of "range", "roundrobin" or "sticky".\n  # balance_strategy = "range"\n\n  ## Maximum length of a message to consume, in bytes (default 0/unlimited);\n  ## larger messages are dropped\n  max_message_len = 1000000\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n[kafka]: https://kafka.apache.org\n[kafka_consumer_legacy]: /plugins/inputs/kafka_consumer_legacy/README.md\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n',image:an.a},{id:"kafka_consumer_legacy",name:"Kafka Consumer Legacy",markdown:'# Kafka Consumer Legacy Input Plugin\n\nThe [Kafka](http://kafka.apache.org/) consumer plugin polls a specified Kafka\ntopic and adds messages to InfluxDB. The plugin assumes messages follow the\nline protocol. [Consumer Group](http://godoc.org/github.com/wvanbergen/kafka/consumergroup)\nis used to talk to the Kafka cluster so multiple instances of telegraf can read\nfrom the same topic in parallel.\n\n## Configuration\n\n```toml\n# Read metrics from Kafka topic(s)\n[[inputs.kafka_consumer]]\n  ## topic(s) to consume\n  topics = ["telegraf"]\n\n  ## an array of Zookeeper connection strings\n  zookeeper_peers = ["localhost:2181"]\n\n  ## Zookeeper Chroot\n  zookeeper_chroot = ""\n\n  ## the name of the consumer group\n  consumer_group = "telegraf_metrics_consumers"\n\n  ## Offset (must be either "oldest" or "newest")\n  offset = "oldest"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n\n  ## Maximum length of a message to consume, in bytes (default 0/unlimited);\n  ## larger messages are dropped\n  max_message_len = 65536\n```\n\n## Testing\n\nRunning integration tests requires running Zookeeper & Kafka. See Makefile\nfor kafka container command.\n',image:nn.a},{id:"kapacitor",name:"Kapacitor",markdown:'# Kapacitor Input Plugin\n\nThe Kapacitor plugin collects metrics from the given Kapacitor instances.\n\n### Configuration:\n\n```toml\n[[inputs.kapacitor]]\n  ## Multiple URLs from which to read Kapacitor-formatted JSON\n  ## Default is "http://localhost:9092/kapacitor/v1/debug/vars".\n  urls = [\n    "http://localhost:9092/kapacitor/v1/debug/vars"\n  ]\n\n  ## Time limit for http requests\n  timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Measurements and fields\n\n- [kapacitor](#kapacitor)\n    - [num_enabled_tasks](#num_enabled_tasks) _(integer)_\n    - [num_subscriptions](#num_subscriptions) _(integer)_\n    - [num_tasks](#num_tasks) _(integer)_\n- [kapacitor_alert](#kapacitor_alert)\n\t- [notification_dropped](#notification_dropped) _(integer)_\n\t- [primary-handle-count](#primary-handle-count) _(integer)_\n\t- [secondary-handle-count](#secondary-handle-count) _(integer)_\n- (Kapacitor Enterprise only) [kapacitor_cluster](#kapacitor_cluster) _(integer)_\n\t- [dropped_member_events](#dropped_member_events) _(integer)_\n\t- [dropped_user_events](#dropped_user_events) _(integer)_\n\t- [query_handler_errors](#query_handler_errors) _(integer)_\n- [kapacitor_edges](#kapacitor_edges)\n    - [collected](#collected) _(integer)_\n    - [emitted](#emitted) _(integer)_\n- [kapacitor_ingress](#kapacitor_ingress)\n    - [points_received](#points_received) _(integer)_\n- [kapacitor_load](#kapacitor_load)\n    - [errors](#errors) _(integer)_\n- [kapacitor_memstats](#kapacitor_memstats)\n    - [alloc_bytes](#alloc_bytes) _(integer)_\n    - [buck_hash_sys_bytes](#buck_hash_sys_bytes) _(integer)_\n    - [frees](#frees) _(integer)_\n    - [gc_sys_bytes](#gc_sys_bytes) _(integer)_\n    - [gc_cpu_fraction](#gc_cpu_fraction) _(float)_\n    - [heap_alloc_bytes](#heap_alloc_bytes) _(integer)_\n    - [heap_idle_bytes](#heap_idle_bytes) _(integer)_\n    - [heap_in_use_bytes](#heap_in_use_bytes) _(integer)_\n    - [heap_objects](#heap_objects) _(integer)_\n    - [heap_released_bytes](#heap_released_bytes) _(integer)_\n    - [heap_sys_bytes](#heap_sys_bytes) _(integer)_\n    - [last_gc_ns](#last_gc_ns) _(integer)_\n    - [lookups](#lookups) _(integer)_\n    - [mallocs](#mallocs) _(integer)_\n    - [mcache_in_use_bytes](#mcache_in_use_bytes) _(integer)_\n    - [mcache_sys_bytes](#mcache_sys_bytes) _(integer)_\n    - [mspan_in_use_bytes](#mspan_in_use_bytes) _(integer)_\n    - [mspan_sys_bytes](#mspan_sys_bytes) _(integer)_\n    - [next_gc_ns](#next_gc_ns) _(integer)_\n    - [num_gc](#num_gc) _(integer)_\n    - [other_sys_bytes](#other_sys_bytes) _(integer)_\n    - [pause_total_ns](#pause_total_ns) _(integer)_\n    - [stack_in_use_bytes](#stack_in_use_bytes) _(integer)_\n    - [stack_sys_bytes](#stack_sys_bytes) _(integer)_\n    - [sys_bytes](#sys_bytes) _(integer)_\n    - [total_alloc_bytes](#total_alloc_bytes) _(integer)_\n- [kapacitor_nodes](#kapacitor_nodes)\n    - [alerts_inhibited](#alerts_inhibited) _(integer)_\n    - [alerts_triggered](#alerts_triggered) _(integer)_\n    - [avg_exec_time_ns](#avg_exec_time_ns) _(integer)_\n    - [crits_triggered](#crits_triggered) _(integer)_\n    - [errors](#errors) _(integer)_\n    - [infos_triggered](#infos_triggered) _(integer)_\n    - [oks_triggered](#oks_triggered) _(integer)_\n    - [points_written](#points_written) _(integer)_\n    - [warns_triggered](#warns_triggered) _(integer)_\n    - [write_errors](#write_errors) _(integer)_\n- [kapacitor_topics](#kapacitor_topics)\n    - [collected](#collected) _(integer)_\n\n\n---\n\n### kapacitor\nThe `kapacitor` measurement stores fields with information related to\n[Kapacitor tasks](https://docs.influxdata.com/kapacitor/latest/introduction/getting-started/#kapacitor-tasks)\nand [subscriptions](https://docs.influxdata.com/kapacitor/latest/administration/subscription-management/).\n\n#### num_enabled_tasks\nThe number of enabled Kapacitor tasks.\n\n#### num_subscriptions\nThe number of Kapacitor/InfluxDB subscriptions.\n\n#### num_tasks\nThe total number of Kapacitor tasks.\n\n---\n\n### kapacitor_alert\nThe `kapacitor_alert` measurement stores fields with information related to\n[Kapacitor alerts](https://docs.influxdata.com/kapacitor/v1.5/working/alerts/).\n\n#### notification-dropped\nThe number of internal notifications dropped because they arrive too late from another Kapacitor node.\nIf this count is increasing, Kapacitor Enterprise nodes aren\'t able to communicate fast enough\nto keep up with the volume of alerts.\n\n#### primary-handle-count\nThe number of times this node handled an alert as the primary. This count should increase under normal conditions.\n\n#### secondary-handle-count\nThe number of times this node handled an alert as the secondary. An increase in this counter indicates that the primary is failing to handle alerts in a timely manner.\n\n---\n\n### kapacitor_cluster\nThe `kapacitor_cluster` measurement reflects the ability of [Kapacitor nodes to communicate](https://docs.influxdata.com/enterprise_kapacitor/v1.5/administration/configuration/#cluster-communications) with one another. Specifically, these metrics track the gossip communication between the Kapacitor nodes.\n\n#### dropped_member_events\nThe number of gossip member events that were dropped.\n\n#### dropped_user_events\nThe number of gossip user events that were dropped.\n\n---\n\n### kapacitor_edges\nThe `kapacitor_edges` measurement stores fields with information related to\n[edges](https://docs.influxdata.com/kapacitor/latest/tick/introduction/#pipelines)\nin Kapacitor TICKscripts.\n\n#### collected\nThe number of messages collected by TICKscript edges.\n\n#### emitted\nThe number of messages emitted by TICKscript edges.\n\n---\n\n### kapacitor_ingress\nThe `kapacitor_ingress` measurement stores fields with information related to data\ncoming into Kapacitor.\n\n#### points_received\nThe number of points received by Kapacitor.\n\n---\n\n### kapacitor_load\nThe `kapacitor_load` measurement stores fields with information related to the\n[Kapacitor Load Directory service](https://docs.influxdata.com/kapacitor/latest/guides/load_directory/).\n\n#### errors\nThe number of errors reported from the load directory service.\n\n---\n\n### kapacitor_memstats\nThe `kapacitor_memstats` measurement stores fields related to Kapacitor memory usage.\n\n#### alloc_bytes\nThe number of bytes of memory allocated by Kapacitor that are still in use.\n\n#### buck_hash_sys_bytes\nThe number of bytes of memory used by the profiling bucket hash table.\n\n#### frees\nThe number of heap objects freed.\n\n#### gc_sys_bytes\nThe number of bytes of memory used for garbage collection system metadata.\n\n#### gc_cpu_fraction\nThe fraction of Kapacitor\'s available CPU time used by garbage collection since\nKapacitor started.\n\n#### heap_alloc_bytes\nThe number of reachable and unreachable heap objects garbage collection has\nnot freed.\n\n#### heap_idle_bytes\nThe number of heap bytes waiting to be used.\n\n#### heap_in_use_bytes\nThe number of heap bytes in use.\n\n#### heap_objects\nThe number of allocated objects.\n\n#### heap_released_bytes\nThe number of heap bytes released to the operating system.\n\n#### heap_sys_bytes\nThe number of heap bytes obtained from `system`.\n\n#### last_gc_ns\nThe nanosecond epoch time of the last garbage collection.\n\n#### lookups\nThe total number of pointer lookups.\n\n#### mallocs\nThe total number of mallocs.\n\n#### mcache_in_use_bytes\nThe number of bytes in use by mcache structures.\n\n#### mcache_sys_bytes\nThe number of bytes used for mcache structures obtained from `system`.\n\n#### mspan_in_use_bytes\nThe number of bytes in use by mspan structures.\n\n#### mspan_sys_bytes\nThe number of bytes used for mspan structures obtained from `system`.\n\n#### next_gc_ns\nThe nanosecond epoch time of the next garbage collection.\n\n#### num_gc\nThe number of completed garbage collection cycles.\n\n#### other_sys_bytes\nThe number of bytes used for other system allocations.\n\n#### pause_total_ns\nThe total number of nanoseconds spent in garbage collection "stop-the-world"\npauses since Kapacitor started.\n\n#### stack_in_use_bytes\nThe number of bytes in use by the stack allocator.\n\n#### stack_sys_bytes\nThe number of bytes obtained from `system` for stack allocator.\n\n#### sys_bytes\nThe number of bytes of memory obtained from `system`.\n\n#### total_alloc_bytes\nThe total number of bytes allocated, even if freed.\n\n---\n\n### kapacitor_nodes\nThe `kapacitor_nodes` measurement stores fields related to events that occur in\n[TICKscript nodes](https://docs.influxdata.com/kapacitor/latest/nodes/).\n\n#### alerts_inhibited\nThe total number of alerts inhibited by TICKscripts.\n\n#### alerts_triggered\nThe total number of alerts triggered by TICKscripts.\n\n#### avg_exec_time_ns\nThe average execution time of TICKscripts in nanoseconds.\n\n#### crits_triggered\nThe number of critical (`crit`) alerts triggered by TICKscripts.\n\n#### errors\nThe number of errors caused caused by TICKscripts.\n\n#### infos_triggered\nThe number of info (`info`) alerts triggered by TICKscripts.\n\n#### oks_triggered\nThe number of ok (`ok`) alerts triggered by TICKscripts.\n\n#### points_written\nThe number of points written to InfluxDB or back to Kapacitor.\n\n#### warns_triggered\nThe number of warning (`warn`) alerts triggered by TICKscripts.\n\n#### working_cardinality\nThe total number of unique series processed.\n\n#### write_errors\nThe number of errors that occurred when writing to InfluxDB or other write endpoints.\n\n---\n\n### kapacitor_topics\nThe `kapacitor_topics` measurement stores fields related to\nKapacitor topics](https://docs.influxdata.com/kapacitor/latest/working/using_alert_topics/).\n\n#### collected\nThe number of events collected by Kapacitor topics.\n\n---\n\n*Note:* The Kapacitor variables `host`, `cluster_id`, and `server_id`\nare currently not recorded due to the potential high cardinality of\nthese values.\n\n## Example Output\n\n```\n$ telegraf --config /etc/telegraf.conf --input-filter kapacitor --test\n* Plugin: inputs.kapacitor, Collection 1\n> kapacitor_memstats,host=hostname.local,kap_version=1.1.0~rc2,url=http://localhost:9092/kapacitor/v1/debug/vars alloc_bytes=6974808i,buck_hash_sys_bytes=1452609i,frees=207281i,gc_sys_bytes=802816i,gc_cpu_fraction=0.00004693548939673313,heap_alloc_bytes=6974808i,heap_idle_bytes=6742016i,heap_in_use_bytes=9183232i,heap_objects=23216i,heap_released_bytes=0i,heap_sys_bytes=15925248i,last_gc_ns=1478791460012676997i,lookups=88i,mallocs=230497i,mcache_in_use_bytes=9600i,mcache_sys_bytes=16384i,mspan_in_use_bytes=98560i,mspan_sys_bytes=131072i,next_gc_ns=11467528i,num_gc=8i,other_sys_bytes=2236087i,pause_total_ns=2994110i,stack_in_use_bytes=1900544i,stack_sys_bytes=1900544i,sys_bytes=22464760i,total_alloc_bytes=35023600i 1478791462000000000\n> kapacitor,host=hostname.local,kap_version=1.1.0~rc2,url=http://localhost:9092/kapacitor/v1/debug/vars num_enabled_tasks=5i,num_subscriptions=5i,num_tasks=5i 1478791462000000000\n> kapacitor_edges,child=stream0,host=hostname.local,parent=stream,task=deadman-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=shard,retention_policy=monitor,task_master=main points_received=120 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=subscriber,retention_policy=monitor,task_master=main points_received=60 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=http_out,node=http_out3,task=sys-stats,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=window6,host=hostname.local,parent=derivative5,task=deadman-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=from,node=from1,task=sys-stats,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=stream,node=stream0,task=test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=window,node=window6,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=cq,retention_policy=monitor,task_master=main points_received=10 1478791462000000000\n> kapacitor_edges,child=http_out3,host=hostname.local,parent=window2,task=sys-stats,type=batch collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=mean4,host=hostname.local,parent=log3,task=deadman-test,type=batch collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_kapacitor,host=hostname.local,measurement=nodes,retention_policy=autogen,task_master=main points_received=207 1478791462000000000\n> kapacitor_edges,child=stream0,host=hostname.local,parent=stream,task=sys-stats,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=log6,host=hostname.local,parent=sum5,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=from1,host=hostname.local,parent=stream0,task=sys-stats,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=alert,node=alert2,task=test,type=stream alerts_triggered=0,avg_exec_time_ns=0i,crits_triggered=0,infos_triggered=0,oks_triggered=0,warns_triggered=0 1478791462000000000\n> kapacitor_edges,child=log3,host=hostname.local,parent=derivative2,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_kapacitor,host=hostname.local,measurement=runtime,retention_policy=autogen,task_master=main points_received=9 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=tsm1_filestore,retention_policy=monitor,task_master=main points_received=120 1478791462000000000\n> kapacitor_edges,child=derivative2,host=hostname.local,parent=from1,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=stream,node=stream0,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=queryExecutor,retention_policy=monitor,task_master=main points_received=10 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=tsm1_wal,retention_policy=monitor,task_master=main points_received=120 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=log,node=log6,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=stream,host=hostname.local,parent=stats,task=task_master:main,type=stream collected=598,emitted=598 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=write,retention_policy=monitor,task_master=main points_received=10 1478791462000000000\n> kapacitor_edges,child=stream0,host=hostname.local,parent=stream,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=log,node=log3,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=from,node=from1,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_kapacitor,host=hostname.local,measurement=ingress,retention_policy=autogen,task_master=main points_received=148 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=eval,node=eval4,task=derivative-test,type=stream avg_exec_time_ns=0i,eval_errors=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=derivative,node=derivative2,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=runtime,retention_policy=monitor,task_master=main points_received=10 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=httpd,retention_policy=monitor,task_master=main points_received=10 1478791462000000000\n> kapacitor_edges,child=sum5,host=hostname.local,parent=eval4,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_kapacitor,host=hostname.local,measurement=kapacitor,retention_policy=autogen,task_master=main points_received=9 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=from,node=from1,task=test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=tsm1_engine,retention_policy=monitor,task_master=main points_received=120 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=window,node=window2,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=stream,node=stream0,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=influxdb_out4,host=hostname.local,parent=http_out3,task=sys-stats,type=batch collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=window2,host=hostname.local,parent=from1,task=deadman-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=from,node=from1,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=from1,host=hostname.local,parent=stream0,task=deadman-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=database,retention_policy=monitor,task_master=main points_received=40 1478791462000000000\n> kapacitor_edges,child=stream,host=hostname.local,parent=write_points,task=task_master:main,type=stream collected=750,emitted=750 1478791462000000000\n> kapacitor_edges,child=log7,host=hostname.local,parent=window6,task=deadman-test,type=batch collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=window2,host=hostname.local,parent=from1,task=sys-stats,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=log,node=log7,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_ingress,database=_kapacitor,host=hostname.local,measurement=edges,retention_policy=autogen,task_master=main points_received=225 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=derivative,node=derivative5,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=from1,host=hostname.local,parent=stream0,task=test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=alert2,host=hostname.local,parent=from1,task=test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=log,node=log3,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=influxdb_out,node=influxdb_out4,task=sys-stats,type=stream avg_exec_time_ns=0i,points_written=0,write_errors=0 1478791462000000000\n> kapacitor_edges,child=stream0,host=hostname.local,parent=stream,task=test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=log3,host=hostname.local,parent=window2,task=deadman-test,type=batch collected=0,emitted=0 1478791462000000000\n> kapacitor_edges,child=derivative5,host=hostname.local,parent=mean4,task=deadman-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=stream,node=stream0,task=sys-stats,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=window,node=window2,task=sys-stats,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=mean,node=mean4,task=deadman-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=from1,host=hostname.local,parent=stream0,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n> kapacitor_ingress,database=_internal,host=hostname.local,measurement=tsm1_cache,retention_policy=monitor,task_master=main points_received=120 1478791462000000000\n> kapacitor_nodes,host=hostname.local,kind=sum,node=sum5,task=derivative-test,type=stream avg_exec_time_ns=0i 1478791462000000000\n> kapacitor_edges,child=eval4,host=hostname.local,parent=log3,task=derivative-test,type=stream collected=0,emitted=0 1478791462000000000\n```\n',image:rn.a},{id:"kernel",name:"Kernel",markdown:"# Kernel Input Plugin\n\nThis plugin is only available on Linux.\n\nThe kernel plugin gathers info about the kernel that doesn't fit into other\nplugins. In general, it is the statistics available in `/proc/stat` that are\nnot covered by other plugins as well as the value of `/proc/sys/kernel/random/entropy_avail`\n\nThe metrics are documented in `man proc` under the `/proc/stat` section.\nThe metrics are documented in `man 4 random` under the `/proc/stat` section.\n\n```\n\n\n/proc/sys/kernel/random/entropy_avail\nContains the value of available entropy\n\n/proc/stat\nkernel/system statistics. Varies with architecture. Common entries include:\n\npage 5741 1808\nThe number of pages the system paged in and the number that were paged out (from disk).\n\nswap 1 0\nThe number of swap pages that have been brought in and out.\n\nintr 1462898\nThis line shows counts of interrupts serviced since boot time, for each of\nthe possible system interrupts. The first column is the total of all\ninterrupts serviced; each subsequent column is the total for a particular interrupt.\n\nctxt 115315\nThe number of context switches that the system underwent.\n\nbtime 769041601\nboot time, in seconds since the Epoch, 1970-01-01 00:00:00 +0000 (UTC).\n\nprocesses 86031\nNumber of forks since boot.\n```\n\n### Configuration:\n\n```toml\n# Get kernel statistics from /proc/stat\n[[inputs.kernel]]\n  # no configuration\n```\n\n### Measurements & Fields:\n\n- kernel\n    - boot_time (integer, seconds since epoch, `btime`)\n    - context_switches (integer, `ctxt`)\n    - disk_pages_in (integer, `page (0)`)\n    - disk_pages_out (integer, `page (1)`)\n    - interrupts (integer, `intr`)\n    - processes_forked (integer, `processes`)\n    - entropy_avail (integer, `entropy_available`)\n\n### Tags:\n\nNone\n\n### Example Output:\n\n```\n$ telegraf --config ~/ws/telegraf.conf --input-filter kernel --test\n* Plugin: kernel, Collection 1\n> kernel entropy_available=2469i,boot_time=1457505775i,context_switches=2626618i,disk_pages_in=5741i,disk_pages_out=1808i,interrupts=1472736i,processes_forked=10673i 1457613402960879816\n```\n",image:un.a},{id:"kernel_vmstat",name:"Kernel VMStat",markdown:"# Kernel VMStat Input Plugin\n\nThe kernel_vmstat plugin gathers virtual memory statistics \nby reading /proc/vmstat. For a full list of available fields see the \n/proc/vmstat section of the [proc man page](http://man7.org/linux/man-pages/man5/proc.5.html).\nFor a better idea of what each field represents, see the \n[vmstat man page](http://linux.die.net/man/8/vmstat).\n\n\n```\n/proc/vmstat\nkernel/system statistics. Common entries include (from http://www.linuxinsight.com/proc_vmstat.html):\n\nNumber of pages that are dirty, under writeback or unstable:\n\nnr_dirty 1550\nnr_writeback 0\nnr_unstable 0\n\nNumber of pages allocated to page tables, mapped by files or allocated by the kernel slab allocator:\n\nnr_page_table_pages 699\nnr_mapped 139596\nnr_slab 42723\n\nNumber of pageins and pageouts (since the last boot):\n\npgpgin 33754195\npgpgout 38985992\n\nNumber of swapins and swapouts (since the last boot):\n\npswpin 2473\npswpout 2995\n\nNumber of page allocations per zone (since the last boot):\n\npgalloc_high 0\npgalloc_normal 110123213\npgalloc_dma32 0\npgalloc_dma 415219\n\nNumber of page frees, activations and deactivations (since the last boot):\n\npgfree 110549163\npgactivate 4509729\npgdeactivate 2136215\n\nNumber of minor and major page faults (since the last boot):\n\npgfault 80663722\npgmajfault 49813\n\nNumber of page refills (per zone, since the last boot):\n\npgrefill_high 0\npgrefill_normal 5817500\npgrefill_dma32 0\npgrefill_dma 149176\n\nNumber of page steals (per zone, since the last boot):\n\npgsteal_high 0\npgsteal_normal 10421346\npgsteal_dma32 0\npgsteal_dma 142196\n\nNumber of pages scanned by the kswapd daemon (per zone, since the last boot):\n\npgscan_kswapd_high 0\npgscan_kswapd_normal 10491424\npgscan_kswapd_dma32 0\npgscan_kswapd_dma 156130\n\nNumber of pages reclaimed directly (per zone, since the last boot):\n\npgscan_direct_high 0\npgscan_direct_normal 11904\npgscan_direct_dma32 0\npgscan_direct_dma 225\n\nNumber of pages reclaimed via inode freeing (since the last boot):\n\npginodesteal 11\n\nNumber of slab objects scanned (since the last boot):\n\nslabs_scanned 8926976\n\nNumber of pages reclaimed by kswapd (since the last boot):\n\nkswapd_steal 10551674\n\nNumber of pages reclaimed by kswapd via inode freeing (since the last boot):\n\nkswapd_inodesteal 338730\n\nNumber of kswapd's calls to page reclaim (since the last boot):\n\npageoutrun 181908\n\nNumber of direct reclaim calls (since the last boot):\n\nallocstall 160\n\nMiscellaneous statistics:\n\npgrotated 3781\nnr_bounce 0\n```\n\n### Configuration:\n\n```toml\n# Get kernel statistics from /proc/vmstat\n[[inputs.kernel_vmstat]]\n  # no configuration\n```\n\n### Measurements & Fields:\n\n- kernel_vmstat\n    - nr_free_pages (integer, `nr_free_pages`)\n    - nr_inactive_anon (integer, `nr_inactive_anon`)\n    - nr_active_anon (integer, `nr_active_anon`)\n    - nr_inactive_file (integer, `nr_inactive_file`)\n    - nr_active_file (integer, `nr_active_file`)\n    - nr_unevictable (integer, `nr_unevictable`)\n    - nr_mlock (integer, `nr_mlock`)\n    - nr_anon_pages (integer, `nr_anon_pages`)\n    - nr_mapped (integer, `nr_mapped`)\n    - nr_file_pages (integer, `nr_file_pages`)\n    - nr_dirty (integer, `nr_dirty`)\n    - nr_writeback (integer, `nr_writeback`)\n    - nr_slab_reclaimable (integer, `nr_slab_reclaimable`)\n    - nr_slab_unreclaimable (integer, `nr_slab_unreclaimable`)\n    - nr_page_table_pages (integer, `nr_page_table_pages`)\n    - nr_kernel_stack (integer, `nr_kernel_stack`)\n    - nr_unstable (integer, `nr_unstable`)\n    - nr_bounce (integer, `nr_bounce`)\n    - nr_vmscan_write (integer, `nr_vmscan_write`)\n    - nr_writeback_temp (integer, `nr_writeback_temp`)\n    - nr_isolated_anon (integer, `nr_isolated_anon`)\n    - nr_isolated_file (integer, `nr_isolated_file`)\n    - nr_shmem (integer, `nr_shmem`)\n    - numa_hit (integer, `numa_hit`)\n    - numa_miss (integer, `numa_miss`)\n    - numa_foreign (integer, `numa_foreign`)\n    - numa_interleave (integer, `numa_interleave`)\n    - numa_local (integer, `numa_local`)\n    - numa_other (integer, `numa_other`)\n    - nr_anon_transparent_hugepages (integer, `nr_anon_transparent_hugepages`)\n    - pgpgin (integer, `pgpgin`)\n    - pgpgout (integer, `pgpgout`)\n    - pswpin (integer, `pswpin`)\n    - pswpout (integer, `pswpout`)\n    - pgalloc_dma (integer, `pgalloc_dma`)\n    - pgalloc_dma32 (integer, `pgalloc_dma32`)\n    - pgalloc_normal (integer, `pgalloc_normal`)\n    - pgalloc_movable (integer, `pgalloc_movable`)\n    - pgfree (integer, `pgfree`)\n    - pgactivate (integer, `pgactivate`)\n    - pgdeactivate (integer, `pgdeactivate`)\n    - pgfault (integer, `pgfault`)\n    - pgmajfault (integer, `pgmajfault`)\n    - pgrefill_dma (integer, `pgrefill_dma`)\n    - pgrefill_dma32 (integer, `pgrefill_dma32`)\n    - pgrefill_normal (integer, `pgrefill_normal`)\n    - pgrefill_movable (integer, `pgrefill_movable`)\n    - pgsteal_dma (integer, `pgsteal_dma`)\n    - pgsteal_dma32 (integer, `pgsteal_dma32`)\n    - pgsteal_normal (integer, `pgsteal_normal`)\n    - pgsteal_movable (integer, `pgsteal_movable`)\n    - pgscan_kswapd_dma (integer, `pgscan_kswapd_dma`)\n    - pgscan_kswapd_dma32 (integer, `pgscan_kswapd_dma32`)\n    - pgscan_kswapd_normal (integer, `pgscan_kswapd_normal`)\n    - pgscan_kswapd_movable (integer, `pgscan_kswapd_movable`)\n    - pgscan_direct_dma (integer, `pgscan_direct_dma`)\n    - pgscan_direct_dma32 (integer, `pgscan_direct_dma32`)\n    - pgscan_direct_normal (integer, `pgscan_direct_normal`)\n    - pgscan_direct_movable (integer, `pgscan_direct_movable`)\n    - zone_reclaim_failed (integer, `zone_reclaim_failed`)\n    - pginodesteal (integer, `pginodesteal`)\n    - slabs_scanned (integer, `slabs_scanned`)\n    - kswapd_steal (integer, `kswapd_steal`)\n    - kswapd_inodesteal (integer, `kswapd_inodesteal`)\n    - kswapd_low_wmark_hit_quickly (integer, `kswapd_low_wmark_hit_quickly`)\n    - kswapd_high_wmark_hit_quickly (integer, `kswapd_high_wmark_hit_quickly`)\n    - kswapd_skip_congestion_wait (integer, `kswapd_skip_congestion_wait`)\n    - pageoutrun (integer, `pageoutrun`)\n    - allocstall (integer, `allocstall`)\n    - pgrotated (integer, `pgrotated`)\n    - compact_blocks_moved (integer, `compact_blocks_moved`)\n    - compact_pages_moved (integer, `compact_pages_moved`)\n    - compact_pagemigrate_failed (integer, `compact_pagemigrate_failed`)\n    - compact_stall (integer, `compact_stall`)\n    - compact_fail (integer, `compact_fail`)\n    - compact_success (integer, `compact_success`)\n    - htlb_buddy_alloc_success (integer, `htlb_buddy_alloc_success`)\n    - htlb_buddy_alloc_fail (integer, `htlb_buddy_alloc_fail`)\n    - unevictable_pgs_culled (integer, `unevictable_pgs_culled`)\n    - unevictable_pgs_scanned (integer, `unevictable_pgs_scanned`)\n    - unevictable_pgs_rescued (integer, `unevictable_pgs_rescued`)\n    - unevictable_pgs_mlocked (integer, `unevictable_pgs_mlocked`)\n    - unevictable_pgs_munlocked (integer, `unevictable_pgs_munlocked`)\n    - unevictable_pgs_cleared (integer, `unevictable_pgs_cleared`)\n    - unevictable_pgs_stranded (integer, `unevictable_pgs_stranded`)\n    - unevictable_pgs_mlockfreed (integer, `unevictable_pgs_mlockfreed`)\n    - thp_fault_alloc (integer, `thp_fault_alloc`)\n    - thp_fault_fallback (integer, `thp_fault_fallback`)\n    - thp_collapse_alloc (integer, `thp_collapse_alloc`)\n    - thp_collapse_alloc_failed (integer, `thp_collapse_alloc_failed`)\n    - thp_split (integer, `thp_split`)\n\n### Tags:\n\nNone\n\n### Example Output:\n\n```\n$ telegraf --config ~/ws/telegraf.conf --input-filter kernel_vmstat --test\n* Plugin: kernel_vmstat, Collection 1\n> kernel_vmstat allocstall=81496i,compact_blocks_moved=238196i,compact_fail=135220i,compact_pagemigrate_failed=0i,compact_pages_moved=6370588i,compact_stall=142092i,compact_success=6872i,htlb_buddy_alloc_fail=0i,htlb_buddy_alloc_success=0i,kswapd_high_wmark_hit_quickly=25439i,kswapd_inodesteal=29770874i,kswapd_low_wmark_hit_quickly=8756i,kswapd_skip_congestion_wait=0i,kswapd_steal=291534428i,nr_active_anon=2515657i,nr_active_file=2244914i,nr_anon_pages=1358675i,nr_anon_transparent_hugepages=2034i,nr_bounce=0i,nr_dirty=5690i,nr_file_pages=5153546i,nr_free_pages=78730i,nr_inactive_anon=426259i,nr_inactive_file=2366791i,nr_isolated_anon=0i,nr_isolated_file=0i,nr_kernel_stack=579i,nr_mapped=558821i,nr_mlock=0i,nr_page_table_pages=11115i,nr_shmem=541689i,nr_slab_reclaimable=459806i,nr_slab_unreclaimable=47859i,nr_unevictable=0i,nr_unstable=0i,nr_vmscan_write=6206i,nr_writeback=0i,nr_writeback_temp=0i,numa_foreign=0i,numa_hit=5113399878i,numa_interleave=35793i,numa_local=5113399878i,numa_miss=0i,numa_other=0i,pageoutrun=505006i,pgactivate=375664931i,pgalloc_dma=0i,pgalloc_dma32=122480220i,pgalloc_movable=0i,pgalloc_normal=5233176719i,pgdeactivate=122735906i,pgfault=8699921410i,pgfree=5359765021i,pginodesteal=9188431i,pgmajfault=122210i,pgpgin=219717626i,pgpgout=3495885510i,pgrefill_dma=0i,pgrefill_dma32=1180010i,pgrefill_movable=0i,pgrefill_normal=119866676i,pgrotated=60620i,pgscan_direct_dma=0i,pgscan_direct_dma32=12256i,pgscan_direct_movable=0i,pgscan_direct_normal=31501600i,pgscan_kswapd_dma=0i,pgscan_kswapd_dma32=4480608i,pgscan_kswapd_movable=0i,pgscan_kswapd_normal=287857984i,pgsteal_dma=0i,pgsteal_dma32=4466436i,pgsteal_movable=0i,pgsteal_normal=318463755i,pswpin=2092i,pswpout=6206i,slabs_scanned=93775616i,thp_collapse_alloc=24857i,thp_collapse_alloc_failed=102214i,thp_fault_alloc=346219i,thp_fault_fallback=895453i,thp_split=9817i,unevictable_pgs_cleared=0i,unevictable_pgs_culled=1531i,unevictable_pgs_mlocked=6988i,unevictable_pgs_mlockfreed=0i,unevictable_pgs_munlocked=6988i,unevictable_pgs_rescued=5426i,unevictable_pgs_scanned=0i,unevictable_pgs_stranded=0i,zone_reclaim_failed=0i 1459455200071462843 \n```\n",image:_n.a},{id:"kibana",name:"Kibana",markdown:'# Kibana Input Plugin\n\nThe `kibana` plugin queries the [Kibana][] API to obtain the service status.\n\n- Telegraf minimum version: 1.8\n- Kibana minimum tested version: 6.0\n\n[Kibana]: https://www.elastic.co/\n\n### Configuration\n\n```toml\n[[inputs.kibana]]\n  ## Specify a list of one or more Kibana servers\n  servers = ["http://localhost:5601"]\n\n  ## Timeout for HTTP requests\n  timeout = "5s"\n\n  ## HTTP Basic Auth credentials\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- kibana\n  - tags:\n    - name (Kibana reported name)\n    - source (Kibana server hostname or IP)\n    - status (Kibana health: green, yellow, red)\n    - version (Kibana version)\n  - fields:\n    - status_code (integer, green=1 yellow=2 red=3 unknown=0)\n    - heap_total_bytes (integer)\n    - heap_max_bytes (integer; deprecated in 1.13.3: use `heap_total_bytes` field)\n    - heap_used_bytes (integer)\n    - uptime_ms (integer)\n    - response_time_avg_ms (float)\n    - response_time_max_ms (integer)\n    - concurrent_connections (integer)\n    - requests_per_sec (float)\n\n### Example Output\n\n```\nkibana,host=myhost,name=my-kibana,source=localhost:5601,status=green,version=6.5.4 concurrent_connections=8i,heap_max_bytes=447778816i,heap_total_bytes=447778816i,heap_used_bytes=380603352i,requests_per_sec=1,response_time_avg_ms=57.6,response_time_max_ms=220i,status_code=1i,uptime_ms=6717489805i 1534864502000000000\n```\n\n## Run example environment\n\nRequires the following tools:\n\n* [Docker](https://docs.docker.com/get-docker/)\n* [Docker Compose](https://docs.docker.com/compose/install/)\n\nFrom the root of this project execute the following script: `./plugins/inputs/kibana/test_environment/run_test_env.sh`\n\nThis will build the latest Telegraf and then start up Kibana and Elasticsearch, Telegraf will begin monitoring Kibana\'s status and write its results to the file `/tmp/metrics.out` in the Telegraf container.\n\nThen you can attach to the telegraf container to inspect the file `/tmp/metrics.out` to see if the status is being reported.\n\nThe Visual Studio Code [Remote - Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) extension provides an easy user interface to attach to the running container.',image:mn.a},{id:"kinesis_consumer",name:"Kinesis Consumer",markdown:'# Kinesis Consumer Input Plugin\n\nThe [Kinesis][kinesis] consumer plugin reads from a Kinesis data stream\nand creates metrics using one of the supported [input data formats][].\n\n\n### Configuration\n\n```toml\n[[inputs.kinesis_consumer]]\n  ## Amazon REGION of kinesis endpoint.\n  region = "ap-southeast-2"\n\n  ## Amazon Credentials\n  ## Credentials are loaded in the following order\n  ## 1) Assumed credentials via STS if role_arn is specified\n  ## 2) explicit credentials from \'access_key\' and \'secret_key\'\n  ## 3) shared profile from \'profile\'\n  ## 4) environment variables\n  ## 5) shared credentials file\n  ## 6) EC2 Instance Profile\n  # access_key = ""\n  # secret_key = ""\n  # token = ""\n  # role_arn = ""\n  # profile = ""\n  # shared_credential_file = ""\n\n  ## Endpoint to make request against, the correct endpoint is automatically\n  ## determined and this option should only be set if you wish to override the\n  ## default.\n  ##   ex: endpoint_url = "http://localhost:8000"\n  # endpoint_url = ""\n\n  ## Kinesis StreamName must exist prior to starting telegraf.\n  streamname = "StreamName"\n\n  ## Shard iterator type (only \'TRIM_HORIZON\' and \'LATEST\' currently supported)\n  # shard_iterator_type = "TRIM_HORIZON"\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n\n  ##\n  ## The content encoding of the data from kinesis\n  ## If you are processing a cloudwatch logs kinesis stream then set this to "gzip"\n  ## as AWS compresses cloudwatch log data before it is sent to kinesis (aws\n  ## also base64 encodes the zip byte data before pushing to the stream.  The base64 decoding\n  ## is done automatically by the golang sdk, as data is read from kinesis)\n  ##\n  # content_encoding = "identity"\n\n  ## Optional\n  ## Configuration for a dynamodb checkpoint\n  [inputs.kinesis_consumer.checkpoint_dynamodb]\n    ## unique name for this consumer\n    app_name = "default"\n    table_name = "default"\n```\n\n\n#### Required AWS IAM permissions\n\nKinesis:\n - DescribeStream\n - GetRecords\n - GetShardIterator\n\nDynamoDB:\n - GetItem\n - PutItem\n\n\n#### DynamoDB Checkpoint\n\nThe DynamoDB checkpoint stores the last processed record in a DynamoDB. To leverage\nthis functionality, create a table with the following string type keys:\n\n```\nPartition key: namespace\nSort key: shard_id\n```\n\n\n[kinesis]: https://aws.amazon.com/kinesis/\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n',image:hn.a},{id:"KNXListener",name:"KNX",markdown:'# KNX Input Plugin\n\nThe KNX input plugin that listens for messages on the KNX home-automation bus.\nThis plugin connects to the KNX bus via a KNX-IP interface.\nInformation about supported KNX message datapoint types can be found at the\nunderlying "knx-go" project site (https://github.com/vapourismo/knx-go).\n\n### Configuration\n\nThis is a sample config for the plugin.\n\n```toml\n# Listener capable of handling KNX bus messages provided through a KNX-IP Interface.\n[[inputs.KNXListener]]\n  ## Type of KNX-IP interface.\n  ## Can be either "tunnel" or "router".\n  # service_type = "tunnel"\n\n  ## Address of the KNX-IP interface.\n  service_address = "localhost:3671"\n\n  ## Measurement definition(s)\n  # [[inputs.KNXListener.measurement]]\n  #   ## Name of the measurement\n  #   name = "temperature"\n  #   ## Datapoint-Type (DPT) of the KNX messages\n  #   dpt = "9.001"\n  #   ## List of Group-Addresses (GAs) assigned to the measurement\n  #   addresses = ["5/5/1"]\n\n  # [[inputs.KNXListener.measurement]]\n  #   name = "illumination"\n  #   dpt = "9.004"\n  #   addresses = ["5/5/3"]\n```\n\n#### Measurement configurations\n\nEach measurement contains only one datapoint-type (DPT) and assigns a list of\naddresses to this measurement. You can, for example group all temperature sensor\nmessages within a "temperature" measurement. However, you are free to split\nmessages of one datapoint-type to multiple measurements.\n\n**NOTE: You should not assign a group-address (GA) to multiple measurements!**\n\n### Metrics\n\nReceived KNX data is stored in the named measurement as configured above using\nthe "value" field. Additional to the value, there are the following tags added\nto the datapoint:\n  - "groupaddress": KNX group-address corresponding to the value\n  - "unit":         unit of the value\n  - "source":       KNX physical address sending the value\n\nTo find out about the datatype of the datapoint please check your KNX project,\nthe KNX-specification or the "knx-go" project for the corresponding DPT.\n\n### Example Output\n\nThis section shows example output in Line Protocol format.\n\n```\nillumination,groupaddress=5/5/4,host=Hugin,source=1.1.12,unit=lux value=17.889999389648438 1582132674999013274\ntemperature,groupaddress=5/5/1,host=Hugin,source=1.1.8,unit=°C value=17.799999237060547 1582132663427587361\nwindowopen,groupaddress=1/0/1,host=Hugin,source=1.1.3 value=true 1582132630425581320\n```\n',image:fn.a},{id:"kube_inventory",name:"Kubernetes Inventory",markdown:'# Kubernetes Inventory Input Plugin\n\nThis plugin generates metrics derived from the state of the following Kubernetes resources:\n\n- daemonsets\n- deployments\n- endpoints\n- ingress\n- nodes\n- persistentvolumes\n- persistentvolumeclaims\n- pods (containers)\n- services\n- statefulsets\n\nKubernetes is a fast moving project, with a new minor release every 3 months. As\nsuch, we will aim to maintain support only for versions that are supported by\nthe major cloud providers; this is roughly 4 release / 2 years.\n\n**This plugin supports Kubernetes 1.11 and later.**\n\n#### Series Cardinality Warning\n\nThis plugin may produce a high number of series which, when not controlled\nfor, will cause high load on your database. Use the following techniques to\navoid cardinality issues:\n\n- Use [metric filtering][] options to exclude unneeded measurements and tags.\n- Write to a database with an appropriate [retention policy][].\n- Consider using the [Time Series Index][tsi].\n- Monitor your databases [series cardinality][].\n- Consult the [InfluxDB documentation][influx-docs] for the most up-to-date techniques.\n\n### Configuration:\n\n```toml\n[[inputs.kube_inventory]]\n  ## URL for the Kubernetes API\n  url = "https://$HOSTIP:6443"\n\n  ## Namespace to use. Set to "" to use all namespaces.\n  # namespace = "default"\n\n  ## Use bearer token for authorization. (\'bearer_token\' takes priority)\n  ## If both of these are empty, we\'ll use the default serviceaccount:\n  ## at: /run/secrets/kubernetes.io/serviceaccount/token\n  # bearer_token = "/path/to/bearer/token"\n  ## OR\n  # bearer_token_string = "abc_123"\n\n  ## Set response_timeout (default 5 seconds)\n  # response_timeout = "5s"\n\n  ## Optional Resources to exclude from gathering\n  ## Leave them with blank with try to gather everything available.\n  ## Values can be - "daemonsets", deployments", "endpoints", "ingress", "nodes",\n  ## "persistentvolumes", "persistentvolumeclaims", "pods", "services", "statefulsets"\n  # resource_exclude = [ "deployments", "nodes", "statefulsets" ]\n\n  ## Optional Resources to include when gathering\n  ## Overrides resource_exclude if both set.\n  # resource_include = [ "deployments", "nodes", "statefulsets" ]\n\n  ## selectors to include and exclude as tags.  Globs accepted.\n  ## Note that an empty array for both will include all selectors as tags\n  ## selector_exclude overrides selector_include if both set.\n  selector_include = []\n  selector_exclude = ["*"]\n\n  ## Optional TLS Config\n  # tls_ca = "/path/to/cafile"\n  # tls_cert = "/path/to/certfile"\n  # tls_key = "/path/to/keyfile"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Uncomment to remove deprecated metrics.\n  # fielddrop = ["terminated_reason"]\n```\n\n#### Kubernetes Permissions\n\nIf using [RBAC authorization](https://kubernetes.io/docs/reference/access-authn-authz/rbac/), you will need to create a cluster role to list "persistentvolumes" and "nodes". You will then need to make an [aggregated ClusterRole](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles) that will eventually be bound to a user or group.\n\n```yaml\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: influx:cluster:viewer\n  labels:\n    rbac.authorization.k8s.io/aggregate-view-telegraf: "true"\nrules:\n  - apiGroups: [""]\n    resources: ["persistentvolumes", "nodes"]\n    verbs: ["get", "list"]\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: influx:telegraf\naggregationRule:\n  clusterRoleSelectors:\n    - matchLabels:\n        rbac.authorization.k8s.io/aggregate-view-telegraf: "true"\n    - matchLabels:\n        rbac.authorization.k8s.io/aggregate-to-view: "true"\nrules: [] # Rules are automatically filled in by the controller manager.\n```\n\nBind the newly created aggregated ClusterRole with the following config file, updating the subjects as needed.\n\n```yaml\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: influx:telegraf:viewer\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: influx:telegraf\nsubjects:\n  - kind: ServiceAccount\n    name: telegraf\n    namespace: default\n```\n\n### Metrics:\n\n- kubernetes_daemonset\n  - tags:\n    - daemonset_name\n    - namespace\n    - selector (\\*varies)\n  - fields:\n    - generation\n    - current_number_scheduled\n    - desired_number_scheduled\n    - number_available\n    - number_misscheduled\n    - number_ready\n    - number_unavailable\n    - updated_number_scheduled\n\n* kubernetes_deployment\n  - tags:\n    - deployment_name\n    - namespace\n    - selector (\\*varies)\n  - fields:\n    - replicas_available\n    - replicas_unavailable\n    - created\n\n- kubernetes_endpoints\n  - tags:\n    - endpoint_name\n    - namespace\n    - hostname\n    - node_name\n    - port_name\n    - port_protocol\n    - kind (\\*varies)\n  - fields:\n    - created\n    - generation\n    - ready\n    - port\n\n* kubernetes_ingress\n  - tags:\n    - ingress_name\n    - namespace\n    - hostname\n    - ip\n    - backend_service_name\n    - path\n    - host\n  - fields:\n    - created\n    - generation\n    - backend_service_port\n    - tls\n\n- kubernetes_node\n  - tags:\n    - node_name\n  - fields:\n    - capacity_cpu_cores\n    - capacity_millicpu_cores\n    - capacity_memory_bytes\n    - capacity_pods\n    - allocatable_cpu_cores\n    - allocatable_millicpu_cores\n    - allocatable_memory_bytes\n    - allocatable_pods\n\n* kubernetes_persistentvolume\n  - tags:\n    - pv_name\n    - phase\n    - storageclass\n  - fields:\n    - phase_type (int, [see below](#pv-phase_type))\n\n- kubernetes_persistentvolumeclaim\n  - tags:\n    - pvc_name\n    - namespace\n    - phase\n    - storageclass\n    - selector (\\*varies)\n  - fields:\n    - phase_type (int, [see below](#pvc-phase_type))\n\n* kubernetes_pod_container\n  - tags:\n    - container_name\n    - namespace\n    - node_name\n    - pod_name\n    - node_selector (\\*varies)\n    - phase\n    - state\n    - readiness\n  - fields:\n    - restarts_total\n    - state_code\n    - state_reason\n    - phase_reason\n    - terminated_reason (string, deprecated in 1.15: use `state_reason` instead)\n    - resource_requests_millicpu_units\n    - resource_requests_memory_bytes\n    - resource_limits_millicpu_units\n    - resource_limits_memory_bytes\n\n- kubernetes_service\n  - tags:\n    - service_name\n    - namespace\n    - port_name\n    - port_protocol\n    - external_name\n    - cluster_ip\n    - selector (\\*varies)\n  - fields\n    - created\n    - generation\n    - port\n    - target_port\n\n* kubernetes_statefulset\n  - tags:\n    - statefulset_name\n    - namespace\n    - selector (\\*varies)\n  - fields:\n    - created\n    - generation\n    - replicas\n    - replicas_current\n    - replicas_ready\n    - replicas_updated\n    - spec_replicas\n    - observed_generation\n\n#### pv `phase_type`\n\nThe persistentvolume "phase" is saved in the `phase` tag with a correlated numeric field called `phase_type` corresponding with that tag value.\n\n| Tag value | Corresponding field value |\n| --------- | ------------------------- |\n| bound     | 0                         |\n| failed    | 1                         |\n| pending   | 2                         |\n| released  | 3                         |\n| available | 4                         |\n| unknown   | 5                         |\n\n#### pvc `phase_type`\n\nThe persistentvolumeclaim "phase" is saved in the `phase` tag with a correlated numeric field called `phase_type` corresponding with that tag value.\n\n| Tag value | Corresponding field value |\n| --------- | ------------------------- |\n| bound     | 0                         |\n| lost      | 1                         |\n| pending   | 2                         |\n| unknown   | 3                         |\n\n### Example Output:\n\n```\nkubernetes_configmap,configmap_name=envoy-config,namespace=default,resource_version=56593031 created=1544103867000000000i 1547597616000000000\nkubernetes_daemonset,daemonset_name=telegraf,selector_select1=s1,namespace=logging number_unavailable=0i,desired_number_scheduled=11i,number_available=11i,number_misscheduled=8i,number_ready=11i,updated_number_scheduled=11i,created=1527758699000000000i,generation=16i,current_number_scheduled=11i 1547597616000000000\nkubernetes_deployment,deployment_name=deployd,selector_select1=s1,namespace=default replicas_unavailable=0i,created=1544103082000000000i,replicas_available=1i 1547597616000000000\nkubernetes_node,node_name=ip-172-17-0-2.internal allocatable_pods=110i,capacity_memory_bytes=128837533696,capacity_pods=110i,capacity_cpu_cores=16i,allocatable_cpu_cores=16i,allocatable_memory_bytes=128732676096 1547597616000000000\nkubernetes_persistentvolume,phase=Released,pv_name=pvc-aaaaaaaa-bbbb-cccc-1111-222222222222,storageclass=ebs-1-retain phase_type=3i 1547597616000000000\nkubernetes_persistentvolumeclaim,namespace=default,phase=Bound,pvc_name=data-etcd-0,selector_select1=s1,storageclass=ebs-1-retain phase_type=0i 1547597615000000000\nkubernetes_pod,namespace=default,node_name=ip-172-17-0-2.internal,pod_name=tick1 last_transition_time=1547578322000000000i,ready="false" 1547597616000000000\nkubernetes_service,cluster_ip=172.29.61.80,namespace=redis-cache-0001,port_name=redis,port_protocol=TCP,selector_app=myapp,selector_io.kompose.service=redis,selector_role=slave,service_name=redis-slave created=1588690034000000000i,generation=0i,port=6379i,target_port=0i 1547597616000000000\nkubernetes_pod_container,container_name=telegraf,namespace=default,node_name=ip-172-17-0-2.internal,node_selector_node-role.kubernetes.io/compute=true,pod_name=tick1,phase=Running,state=running,readiness=ready resource_requests_cpu_units=0.1,resource_limits_memory_bytes=524288000,resource_limits_cpu_units=0.5,restarts_total=0i,state_code=0i,state_reason="",phase_reason="",resource_requests_memory_bytes=524288000 1547597616000000000\nkubernetes_statefulset,namespace=default,selector_select1=s1,statefulset_name=etcd replicas_updated=3i,spec_replicas=3i,observed_generation=1i,created=1544101669000000000i,generation=1i,replicas=3i,replicas_current=3i,replicas_ready=3i 1547597616000000000\n```\n\n[metric filtering]: https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#metric-filtering\n[retention policy]: https://docs.influxdata.com/influxdb/latest/guides/downsampling_and_retention/\n[tsi]: https://docs.influxdata.com/influxdb/latest/concepts/time-series-index/\n[series cardinality]: https://docs.influxdata.com/influxdb/latest/query_language/spec/#show-cardinality\n[influx-docs]: https://docs.influxdata.com/influxdb/latest/\n[k8s-telegraf]: https://www.influxdata.com/blog/monitoring-kubernetes-architecture/\n',image:yn.a},{id:"kubernetes",name:"Kubernetes",markdown:'# Kubernetes Input Plugin\n\nThe Kubernetes plugin talks to the Kubelet API and gathers metrics about the\nrunning pods and containers for a single host. It is assumed that this plugin\nis running as part of a `daemonset` within a kubernetes installation. This\nmeans that telegraf is running on every node within the cluster. Therefore, you\nshould configure this plugin to talk to its locally running kubelet.\n\nTo find the ip address of the host you are running on you can issue a command like the following:\n\n```\n$ curl -s $API_URL/api/v1/namespaces/$POD_NAMESPACE/pods/$HOSTNAME --header "Authorization: Bearer $TOKEN" --insecure | jq -r \'.status.hostIP\'\n```\n\nIn this case we used the downward API to pass in the `$POD_NAMESPACE` and `$HOSTNAME` is the hostname of the pod which is set by the kubernetes API.\n\nKubernetes is a fast moving project, with a new minor release every 3 months. As\nsuch, we will aim to maintain support only for versions that are supported by\nthe major cloud providers; this is roughly 4 release / 2 years.\n\n**This plugin supports Kubernetes 1.11 and later.**\n\n#### Series Cardinality Warning\n\nThis plugin may produce a high number of series which, when not controlled\nfor, will cause high load on your database. Use the following techniques to\navoid cardinality issues:\n\n- Use [metric filtering][] options to exclude unneeded measurements and tags.\n- Write to a database with an appropriate [retention policy][].\n- Consider using the [Time Series Index][tsi].\n- Monitor your databases [series cardinality][].\n- Consult the [InfluxDB documentation][influx-docs] for the most up-to-date techniques.\n\n### Configuration\n\n```toml\n[[inputs.kubernetes]]\n  ## URL for the kubelet\n  url = "http://127.0.0.1:10255"\n\n  ## Use bearer token for authorization. (\'bearer_token\' takes priority)\n  ## If both of these are empty, we\'ll use the default serviceaccount:\n  ## at: /run/secrets/kubernetes.io/serviceaccount/token\n  # bearer_token = "/path/to/bearer/token"\n  ## OR\n  # bearer_token_string = "abc_123"\n\n  ## Pod labels to be added as tags.  An empty array for both include and\n  ## exclude will include all labels.\n  # label_include = []\n  # label_exclude = ["*"]\n\n  ## Set response_timeout (default 5 seconds)\n  # response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = /path/to/cafile\n  # tls_cert = /path/to/certfile\n  # tls_key = /path/to/keyfile\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### DaemonSet\n\nFor recommendations on running Telegraf as a DaemonSet see [Monitoring Kubernetes\nArchitecture][k8s-telegraf] or view the Helm charts:\n\n- [Telegraf][]\n- [InfluxDB][]\n- [Chronograf][]\n- [Kapacitor][]\n\n### Metrics\n\n- kubernetes_node\n  - tags:\n    - node_name\n  - fields:\n    - cpu_usage_nanocores\n    - cpu_usage_core_nanoseconds\n    - memory_available_bytes\n    - memory_usage_bytes\n    - memory_working_set_bytes\n    - memory_rss_bytes\n    - memory_page_faults\n    - memory_major_page_faults\n    - network_rx_bytes\n    - network_rx_errors\n    - network_tx_bytes\n    - network_tx_errors\n    - fs_available_bytes\n    - fs_capacity_bytes\n    - fs_used_bytes\n    - runtime_image_fs_available_bytes\n    - runtime_image_fs_capacity_bytes\n    - runtime_image_fs_used_bytes\n\n* kubernetes_pod_container\n  - tags:\n    - container_name\n    - namespace\n    - node_name\n    - pod_name\n  - fields:\n    - cpu_usage_nanocores\n    - cpu_usage_core_nanoseconds\n    - memory_usage_bytes\n    - memory_working_set_bytes\n    - memory_rss_bytes\n    - memory_page_faults\n    - memory_major_page_faults\n    - rootfs_available_bytes\n    - rootfs_capacity_bytes\n    - rootfs_used_bytes\n    - logsfs_available_bytes\n    - logsfs_capacity_bytes\n    - logsfs_used_bytes\n\n- kubernetes_pod_volume\n  - tags:\n    - volume_name\n    - namespace\n    - node_name\n    - pod_name\n  - fields:\n    - available_bytes\n    - capacity_bytes\n    - used_bytes\n\n* kubernetes_pod_network\n  - tags:\n    - namespace\n    - node_name\n    - pod_name\n  - fields:\n    - rx_bytes\n    - rx_errors\n    - tx_bytes\n    - tx_errors\n\n### Example Output\n\n```\nkubernetes_node\nkubernetes_pod_container,container_name=deis-controller,namespace=deis,node_name=ip-10-0-0-0.ec2.internal,pod_name=deis-controller-3058870187-xazsr cpu_usage_core_nanoseconds=2432835i,cpu_usage_nanocores=0i,logsfs_available_bytes=121128271872i,logsfs_capacity_bytes=153567944704i,logsfs_used_bytes=20787200i,memory_major_page_faults=0i,memory_page_faults=175i,memory_rss_bytes=0i,memory_usage_bytes=0i,memory_working_set_bytes=0i,rootfs_available_bytes=121128271872i,rootfs_capacity_bytes=153567944704i,rootfs_used_bytes=1110016i 1476477530000000000\nkubernetes_pod_network,namespace=deis,node_name=ip-10-0-0-0.ec2.internal,pod_name=deis-controller-3058870187-xazsr rx_bytes=120671099i,rx_errors=0i,tx_bytes=102451983i,tx_errors=0i 1476477530000000000\nkubernetes_pod_volume,volume_name=default-token-f7wts,namespace=default,node_name=ip-172-17-0-1.internal,pod_name=storage-7 available_bytes=8415240192i,capacity_bytes=8415252480i,used_bytes=12288i 1546910783000000000\nkubernetes_system_container\n```\n\n[metric filtering]: https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#metric-filtering\n[retention policy]: https://docs.influxdata.com/influxdb/latest/guides/downsampling_and_retention/\n[tsi]: https://docs.influxdata.com/influxdb/latest/concepts/time-series-index/\n[series cardinality]: https://docs.influxdata.com/influxdb/latest/query_language/spec/#show-cardinality\n[influx-docs]: https://docs.influxdata.com/influxdb/latest/\n[k8s-telegraf]: https://www.influxdata.com/blog/monitoring-kubernetes-architecture/\n[telegraf]: https://github.com/helm/charts/tree/master/stable/telegraf\n[influxdb]: https://github.com/helm/charts/tree/master/stable/influxdb\n[chronograf]: https://github.com/helm/charts/tree/master/stable/chronograf\n[kapacitor]: https://github.com/helm/charts/tree/master/stable/kapacitor\n',image:wn.a},{id:"lanz",name:"Arista LANZ Consumer",markdown:'# Arista LANZ Consumer Input Plugin\n\nThis plugin provides a consumer for use with Arista Networks’ Latency Analyzer (LANZ)\n\nMetrics are read from a stream of data via TCP through port 50001 on the\nswitches management IP. The data is in Protobuffers format. For more information on Arista LANZ\n\n- https://www.arista.com/en/um-eos/eos-latency-analyzer-lanz\n\nThis plugin uses Arista\'s sdk.\n\n- https://github.com/aristanetworks/goarista\n\n### Configuration\n\nYou will need to configure LANZ and enable streaming LANZ data.\n\n- https://www.arista.com/en/um-eos/eos-section-44-3-configuring-lanz\n- https://www.arista.com/en/um-eos/eos-section-44-3-configuring-lanz#ww1149292\n\n```toml\n[[inputs.lanz]]\n  servers = [\n    "tcp://switch1.int.example.com:50001",\n    "tcp://switch2.int.example.com:50001",\n  ]\n```\n\n### Metrics\n\nFor more details on the metrics see https://github.com/aristanetworks/goarista/blob/master/lanz/proto/lanz.proto\n\n- lanz_congestion_record:\n  - tags:\n    - intf_name\n    - switch_id\n    - port_id\n    - entry_type\n    - traffic_class\n    - fabric_peer_intf_name\n    - source\n    - port\n  - fields:\n    - timestamp        (integer)\n    - queue_size       (integer)\n    - time_of_max_qlen (integer)\n    - tx_latency       (integer)\n    - q_drop_count     (integer)\n\n+ lanz_global_buffer_usage_record\n  - tags:\n    - entry_type\n    - source\n    - port\n  - fields:\n    - timestamp   (integer)\n    - buffer_size (integer)\n    - duration    (integer)\n\n\n\n### Sample Queries\n\nGet the max tx_latency for the last hour for all interfaces on all switches.\n```sql\nSELECT max("tx_latency") AS "max_tx_latency" FROM "congestion_record" WHERE time > now() - 1h GROUP BY time(10s), "hostname", "intf_name"\n```\n\nGet the max tx_latency for the last hour for all interfaces on all switches.\n```sql\nSELECT max("queue_size") AS "max_queue_size" FROM "congestion_record" WHERE time > now() - 1h GROUP BY time(10s), "hostname", "intf_name"\n```\n\nGet the max buffer_size for over the last hour for all switches.\n```sql\nSELECT max("buffer_size") AS "max_buffer_size" FROM "global_buffer_usage_record" WHERE time > now() - 1h GROUP BY time(10s), "hostname"\n```\n\n### Example output\n```\nlanz_global_buffer_usage_record,entry_type=2,host=telegraf.int.example.com,port=50001,source=switch01.int.example.com timestamp=158334105824919i,buffer_size=505i,duration=0i 1583341058300643815\nlanz_congestion_record,entry_type=2,host=telegraf.int.example.com,intf_name=Ethernet36,port=50001,port_id=61,source=switch01.int.example.com,switch_id=0,traffic_class=1 time_of_max_qlen=0i,tx_latency=564480i,q_drop_count=0i,timestamp=158334105824919i,queue_size=225i 1583341058300636045\nlanz_global_buffer_usage_record,entry_type=2,host=telegraf.int.example.com,port=50001,source=switch01.int.example.com timestamp=158334105824919i,buffer_size=589i,duration=0i 1583341058300457464\nlanz_congestion_record,entry_type=1,host=telegraf.int.example.com,intf_name=Ethernet36,port=50001,port_id=61,source=switch01.int.example.com,switch_id=0,traffic_class=1 q_drop_count=0i,timestamp=158334105824919i,queue_size=232i,time_of_max_qlen=0i,tx_latency=584640i 1583341058300450302\n```\n\n\n',image:xn.a},{id:"leofs",name:"LeoFS",markdown:'# LeoFS Input Plugin\n\nThe LeoFS plugin gathers metrics of LeoGateway, LeoManager, and LeoStorage using SNMP. See [LeoFS Documentation / System Administration / System Monitoring](https://leo-project.net/leofs/docs/admin/system_admin/monitoring/).\n\n## Configuration:\n\n```toml\n# Sample Config:\n\n[[inputs.leofs]]\n        servers = ["127.0.0.1:4010"]\n```\n\n## Measurements & Fields:\n### Statistics specific to the internals of LeoManager\n#### Erlang VM\n\n- 1 min Statistics\n    - num_of_processes\n    - total_memory_usage\n    - system_memory_usage\n    - processes_memory_usage\n    - ets_memory_usage\n    - used_allocated_memory\n    - allocated_memory\n- 5 min Statistics\n    - num_of_processes_5min\n    - total_memory_usage_5min\n    - system_memory_usage_5min\n    - processes_memory_usage_5min\n    - ets_memory_usage_5min\n    - used_allocated_memory_5min\n    - allocated_memory_5min\n\n### Statistics specific to the internals of LeoStorage\n#### Erlang VM\n\n- 1 min Statistics\n    - num_of_processes\n    - total_memory_usage\n    - system_memory_usage\n    - processes_memory_usage\n    - ets_memory_usage\n    - used_allocated_memory\n    - allocated_memory\n- 5 min Statistics\n    - num_of_processes_5min\n    - total_memory_usage_5min\n    - system_memory_usage_5min\n    - processes_memory_usage_5min\n    - ets_memory_usage_5min\n    - used_allocated_memory_5min\n    - allocated_memory_5min\n\n#### Total Number of Requests\n\n- 1 min Statistics\n    - num_of_writes\n    - num_of_reads\n    - num_of_deletes\n- 5 min Statistics\n    - num_of_writes_5min\n    - num_of_reads_5min\n    - num_of_deletes_5min\n\n#### Total Number of Objects and Total Size of Objects\n\n- num_of_active_objects\n- total_objects\n- total_size_of_active_objects\n- total_size\n\n#### Total Number of MQ Messages\n\n- num_of_replication_messages,\n- num_of_sync-vnode_messages,\n- num_of_rebalance_messages,\n- mq_num_of_msg_recovery_node\n- mq_num_of_msg_deletion_dir\n- mq_num_of_msg_async_deletion_dir\n- mq_num_of_msg_req_deletion_dir\n- mq_mdcr_num_of_msg_req_comp_metadata\n- mq_mdcr_num_of_msg_req_sync_obj\n\nNote: The following items are available since LeoFS v1.4.0:\n\n- mq_num_of_msg_recovery_node\n- mq_num_of_msg_deletion_dir\n- mq_num_of_msg_async_deletion_dir\n- mq_num_of_msg_req_deletion_dir\n- mq_mdcr_num_of_msg_req_comp_metadata\n- mq_mdcr_num_of_msg_req_sync_obj\n\n#### Data Compaction\n\n- comp_state\n- comp_last_start_datetime\n- comp_last_end_datetime\n- comp_num_of_pending_targets\n- comp_num_of_ongoing_targets\n- comp_num_of_out_of_targets\n\nNote: The all items are available since LeoFS v1.4.0.\n\n### Statistics specific to the internals of LeoGateway\n#### Erlang VM\n\n- 1 min Statistics\n    - num_of_processes\n    - total_memory_usage\n    - system_memory_usage\n    - processes_memory_usage\n    - ets_memory_usage\n    - used_allocated_memory\n    - allocated_memory\n- 5 min Statistics\n    - num_of_processes_5min\n    - total_memory_usage_5min\n    - system_memory_usage_5min\n    - processes_memory_usage_5min\n    - ets_memory_usage_5min\n    - used_allocated_memory_5min\n    - allocated_memory_5min\n\n#### Total Number of Requests\n\n- 1 min Statistics\n    - num_of_writes\n    - num_of_reads\n    - num_of_deletes\n- 5 min Statistics\n    - num_of_writes_5min\n    - num_of_reads_5min\n    - num_of_deletes_5min\n\n#### Object Cache\n\n- count_of_cache-hit\n- count_of_cache-miss\n- total_of_files\n- total_cached_size\n\n\n### Tags:\n\nAll measurements have the following tags:\n\n- node\n\n\n### Example output:\n\n#### LeoManager\n\n```bash\n$ ./telegraf --config ./plugins/inputs/leofs/leo_manager.conf --input-filter leofs --test\n> leofs, host=manager_0, node=manager_0@127.0.0.1\n  allocated_memory=78255445,\n  allocated_memory_5min=78159025,\n  ets_memory_usage=4611900,\n  ets_memory_usage_5min=4632599,\n  num_of_processes=223,\n  num_of_processes_5min=223,\n  processes_memory_usage=20201316,\n  processes_memory_usage_5min=20186559,\n  system_memory_usage=37172701,\n  system_memory_usage_5min=37189213,\n  total_memory_usage=57373373,\n  total_memory_usage_5min=57374653,\n  used_allocated_memory=67,\n  used_allocated_memory_5min=67\n  1524105758000000000\n```\n\n#### LeoStorage\n\n```bash\n$ ./telegraf --config ./plugins/inputs/leofs/leo_storage.conf --input-filter leofs --test\n> leofs,host=storage_0,node=storage_0@127.0.0.1\n  allocated_memory=63504384,\n  allocated_memory_5min=0,\n  comp_last_end_datetime=0,\n  comp_last_start_datetime=0,\n  comp_num_of_ongoing_targets=0,\n  comp_num_of_out_of_targets=0,\n  comp_num_of_pending_targets=8,\n  comp_state=0,\n  ets_memory_usage=3877824,\n  ets_memory_usage_5min=0,\n  mq_mdcr_num_of_msg_req_comp_metadata=0,\n  mq_mdcr_num_of_msg_req_sync_obj=0,\n  mq_num_of_msg_async_deletion_dir=0,\n  mq_num_of_msg_deletion_dir=0,\n  mq_num_of_msg_recovery_node=0,\n  mq_num_of_msg_req_deletion_dir=0,\n  num_of_active_objects=70,\n  num_of_deletes=0,\n  num_of_deletes_5min=0,\n  num_of_processes=577,\n  num_of_processes_5min=0,\n  num_of_reads=1,\n  num_of_reads_5min=0,\n  num_of_rebalance_messages=0,\n  num_of_replication_messages=0,\n  num_of_sync-vnode_messages=0,\n  num_of_writes=70,\n  num_of_writes_5min=0,\n  processes_memory_usage=20029464,\n  processes_memory_usage_5min=0,\n  system_memory_usage=25900472,\n  system_memory_usage_5min=0,\n  total_memory_usage=45920987,\n  total_memory_usage_5min=0,\n  total_objects=70,\n  total_size=2,\n  total_size_of_active_objects=2,\n  used_allocated_memory=69,\n  used_allocated_memory_5min=0\n  1524529826000000000\n```\n\n#### LeoGateway\n\n```\n$ ./telegraf --config ./plugins/inputs/leofs/leo_gateway.conf --input-filter leofs --test\n> leofs, host=gateway_0, node=gateway_0@127.0.0.1\n  allocated_memory=87941120,\n  allocated_memory_5min=88067672,\n  count_of_cache-hit=0,\n  count_of_cache-miss=0,\n  ets_memory_usage=4843497,\n  ets_memory_usage_5min=4841574,\n  num_of_deletes=0,\n  num_of_deletes_5min=0,\n  num_of_processes=555,\n  num_of_processes_5min=555,\n  num_of_reads=0,\n  num_of_reads_5min=0,\n  num_of_writes=0,\n  num_of_writes_5min=0,\n  processes_memory_usage=17388052,\n  processes_memory_usage_5min=17413928,\n  system_memory_usage=49531263,\n  system_memory_usage_5min=49577819,\n  total_cached_size=0,\n  total_memory_usage=66917393,\n  total_memory_usage_5min=66989469,\n  total_of_files=0,\n  used_allocated_memory=69,\n  used_allocated_memory_5min=69 1524105894000000000\n```\n',image:Sn.a},{id:"linux_sysctl_fs",name:"Linux Sysctl FS",markdown:"# Linux Sysctl FS Input Plugin\n\nThe linux_sysctl_fs input provides Linux system level file metrics. The documentation on these fields can be found at https://www.kernel.org/doc/Documentation/sysctl/fs.txt.\n\nExample output:\n\n```\n> linux_sysctl_fs,host=foo dentry-want-pages=0i,file-max=44222i,aio-max-nr=65536i,inode-preshrink-nr=0i,dentry-nr=64340i,dentry-unused-nr=55274i,file-nr=1568i,aio-nr=0i,inode-nr=35952i,inode-free-nr=12957i,dentry-age-limit=45i 1490982022000000000\n```\n",image:Cn.a},{id:"logparser",name:"Logparser",markdown:'# Logparser Input Plugin\n\nThe `logparser` plugin streams and parses the given logfiles. Currently it\nhas the capability of parsing "grok" patterns from logfiles, which also supports\nregex patterns.\n\n**Deprecated in Telegraf 1.15**: Please use the [tail][] plugin along with the [`grok` data format][grok parser].\n\nThe `tail` plugin now provides all the functionality of the `logparser` plugin.\nMost options can be translated directly to the `tail` plugin:\n- For options in the `[inputs.logparser.grok]` section, the equivalent option\n  will have add the `grok_` prefix when using them in the `tail` input.\n- The grok `measurement` option can be replaced using the standard plugin\n  `name_override` option.\n\nMigration Example:\n```diff\n- [[inputs.logparser]]\n-   files = ["/var/log/apache/access.log"]\n-   from_beginning = false\n-   [inputs.logparser.grok]\n-     patterns = ["%{COMBINED_LOG_FORMAT}"]\n-     measurement = "apache_access_log"\n-     custom_pattern_files = []\n-     custom_patterns = \'\'\'\n-     \'\'\'\n-     timezone = "Canada/Eastern"\n\n+ [[inputs.tail]]\n+   files = ["/var/log/apache/access.log"]\n+   from_beginning = false\n+   grok_patterns = ["%{COMBINED_LOG_FORMAT}"]\n+   name_override = "apache_access_log"\n+   grok_custom_pattern_files = []\n+   grok_custom_patterns = \'\'\'\n+   \'\'\'\n+   grok_timezone = "Canada/Eastern"\n+   data_format = "grok"\n```\n\n### Configuration\n\n```toml\n[[inputs.logparser]]\n  ## Log files to parse.\n  ## These accept standard unix glob matching rules, but with the addition of\n  ## ** as a "super asterisk". ie:\n  ##   /var/log/**.log     -> recursively find all .log files in /var/log\n  ##   /var/log/*/*.log    -> find all .log files with a parent dir in /var/log\n  ##   /var/log/apache.log -> only tail the apache log file\n  files = ["/var/log/apache/access.log"]\n\n  ## Read files that currently exist from the beginning. Files that are created\n  ## while telegraf is running (and that match the "files" globs) will always\n  ## be read from the beginning.\n  from_beginning = false\n\n  ## Method used to watch for file updates.  Can be either "inotify" or "poll".\n  # watch_method = "inotify"\n\n  ## Parse logstash-style "grok" patterns:\n  [inputs.logparser.grok]\n    ## This is a list of patterns to check the given log file(s) for.\n    ## Note that adding patterns here increases processing time. The most\n    ## efficient configuration is to have one pattern per logparser.\n    ## Other common built-in patterns are:\n    ##   %{COMMON_LOG_FORMAT}   (plain apache & nginx access logs)\n    ##   %{COMBINED_LOG_FORMAT} (access logs + referrer & agent)\n    patterns = ["%{COMBINED_LOG_FORMAT}"]\n\n    ## Name of the outputted measurement name.\n    measurement = "apache_access_log"\n\n    ## Full path(s) to custom pattern files.\n    custom_pattern_files = []\n\n    ## Custom patterns can also be defined here. Put one pattern per line.\n    custom_patterns = \'\'\'\n    \'\'\'\n\n    ## Timezone allows you to provide an override for timestamps that\n    ## don\'t already include an offset\n    ## e.g. 04/06/2016 12:41:45 data one two 5.43µs\n    ##\n    ## Default: "" which renders UTC\n    ## Options are as follows:\n    ##   1. Local             -- interpret based on machine localtime\n    ##   2. "Canada/Eastern"  -- Unix TZ values like those found in https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\n    ##   3. UTC               -- or blank/unspecified, will return timestamp in UTC\n    # timezone = "Canada/Eastern"\n```\n\n### Grok Parser\n\nReference the [grok parser][] documentation to setup the grok section of the\nconfiguration.\n\n\n### Additional Resources\n\n- https://www.influxdata.com/telegraf-correlate-log-metrics-data-performance-bottlenecks/\n\n[tail]: /plugins/inputs/tail/README.md\n[grok parser]: /plugins/parsers/grok/README.md\n',image:Pn.a},{id:"logstash",name:"Logstash",markdown:'# Logstash Input Plugin\n\nThis plugin reads metrics exposed by\n[Logstash Monitoring API](https://www.elastic.co/guide/en/logstash/current/monitoring-logstash.html).\n\nLogstash 5 and later is supported.\n\n### Configuration\n\n```toml\n[[inputs.logstash]]\n  ## The URL of the exposed Logstash API endpoint.\n  url = "http://127.0.0.1:9600"\n\n  ## Use Logstash 5 single pipeline API, set to true when monitoring\n  ## Logstash 5.\n  # single_pipeline = false\n\n  ## Enable optional collection components.  Can contain\n  ## "pipelines", "process", and "jvm".\n  # collect = ["pipelines", "process", "jvm"]\n\n  ## Timeout for HTTP requests.\n  # timeout = "5s"\n\n  ## Optional HTTP Basic Auth credentials.\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional TLS Config.\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## Use TLS but skip chain & host verification.\n  # insecure_skip_verify = false\n\n  ## Optional HTTP headers.\n  # [inputs.logstash.headers]\n  #   "X-Special-Header" = "Special-Value"\n```\n\n### Metrics\n\n- logstash_jvm\n  - tags:\n    - node_id\n    - node_name\n    - node_host\n    - node_version\n  - fields:\n    - threads_peak_count\n    - mem_pools_survivor_peak_max_in_bytes\n    - mem_pools_survivor_max_in_bytes\n    - mem_pools_old_peak_used_in_bytes\n    - mem_pools_young_used_in_bytes\n    - mem_non_heap_committed_in_bytes\n    - threads_count\n    - mem_pools_old_committed_in_bytes\n    - mem_pools_young_peak_max_in_bytes\n    - mem_heap_used_percent\n    - gc_collectors_young_collection_time_in_millis\n    - mem_pools_survivor_peak_used_in_bytes\n    - mem_pools_young_committed_in_bytes\n    - gc_collectors_old_collection_time_in_millis\n    - gc_collectors_old_collection_count\n    - mem_pools_survivor_used_in_bytes\n    - mem_pools_old_used_in_bytes\n    - mem_pools_young_max_in_bytes\n    - mem_heap_max_in_bytes\n    - mem_non_heap_used_in_bytes\n    - mem_pools_survivor_committed_in_bytes\n    - mem_pools_old_max_in_bytes\n    - mem_heap_committed_in_bytes\n    - mem_pools_old_peak_max_in_bytes\n    - mem_pools_young_peak_used_in_bytes\n    - mem_heap_used_in_bytes\n    - gc_collectors_young_collection_count\n    - uptime_in_millis\n\n+ logstash_process\n  - tags:\n    - node_id\n    - node_name\n    - source\n    - node_version\n  - fields:\n    - open_file_descriptors\n    - cpu_load_average_1m\n    - cpu_load_average_5m\n    - cpu_load_average_15m\n    - cpu_total_in_millis\n    - cpu_percent\n    - peak_open_file_descriptors\n    - max_file_descriptors\n    - mem_total_virtual_in_bytes\n    - mem_total_virtual_in_bytes\n\n- logstash_events\n  - tags:\n    - node_id\n    - node_name\n    - source\n    - node_version\n    - pipeline (for Logstash 6+)\n  - fields:\n    - queue_push_duration_in_millis\n    - duration_in_millis\n    - in\n    - filtered\n    - out\n\n+ logstash_plugins\n  - tags:\n    - node_id\n    - node_name\n    - source\n    - node_version\n    - pipeline (for Logstash 6+)\n    - plugin_id\n    - plugin_name\n    - plugin_type\n  - fields:\n    - queue_push_duration_in_millis (for input plugins only)\n    - duration_in_millis\n    - in\n    - out\n\n- logstash_queue\n  - tags:\n    - node_id\n    - node_name\n    - source\n    - node_version\n    - pipeline (for Logstash 6+)\n    - queue_type\n  - fields:\n    - events\n    - free_space_in_bytes\n    - max_queue_size_in_bytes\n    - max_unread_events\n    - page_capacity_in_bytes\n    - queue_size_in_bytes\n\n### Example Output\n\n```\nlogstash_jvm,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,source=debian-stretch-logstash6.virt gc_collectors_old_collection_count=2,gc_collectors_old_collection_time_in_millis=100,gc_collectors_young_collection_count=26,gc_collectors_young_collection_time_in_millis=1028,mem_heap_committed_in_bytes=1056309248,mem_heap_max_in_bytes=1056309248,mem_heap_used_in_bytes=207216328,mem_heap_used_percent=19,mem_non_heap_committed_in_bytes=160878592,mem_non_heap_used_in_bytes=140838184,mem_pools_old_committed_in_bytes=899284992,mem_pools_old_max_in_bytes=899284992,mem_pools_old_peak_max_in_bytes=899284992,mem_pools_old_peak_used_in_bytes=189468088,mem_pools_old_used_in_bytes=189468088,mem_pools_survivor_committed_in_bytes=17432576,mem_pools_survivor_max_in_bytes=17432576,mem_pools_survivor_peak_max_in_bytes=17432576,mem_pools_survivor_peak_used_in_bytes=17432576,mem_pools_survivor_used_in_bytes=12572640,mem_pools_young_committed_in_bytes=139591680,mem_pools_young_max_in_bytes=139591680,mem_pools_young_peak_max_in_bytes=139591680,mem_pools_young_peak_used_in_bytes=139591680,mem_pools_young_used_in_bytes=5175600,threads_count=20,threads_peak_count=24,uptime_in_millis=739089 1566425244000000000\nlogstash_process,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,source=debian-stretch-logstash6.virt cpu_load_average_15m=0.03,cpu_load_average_1m=0.01,cpu_load_average_5m=0.04,cpu_percent=0,cpu_total_in_millis=83230,max_file_descriptors=16384,mem_total_virtual_in_bytes=3689132032,open_file_descriptors=118,peak_open_file_descriptors=118 1566425244000000000\nlogstash_events,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,pipeline=main,source=debian-stretch-logstash6.virt duration_in_millis=0,filtered=0,in=0,out=0,queue_push_duration_in_millis=0 1566425244000000000\nlogstash_plugins,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,pipeline=main,plugin_id=2807cb8610ba7854efa9159814fcf44c3dda762b43bd088403b30d42c88e69ab,plugin_name=beats,plugin_type=input,source=debian-stretch-logstash6.virt out=0,queue_push_duration_in_millis=0 1566425244000000000\nlogstash_plugins,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,pipeline=main,plugin_id=7a6c973366186a695727c73935634a00bccd52fceedf30d0746983fce572d50c,plugin_name=file,plugin_type=output,source=debian-stretch-logstash6.virt duration_in_millis=0,in=0,out=0 1566425244000000000\nlogstash_queue,node_id=3da53ed0-a946-4a33-9cdb-33013f2273f6,node_name=debian-stretch-logstash6.virt,node_version=6.8.1,pipeline=main,queue_type=memory,source=debian-stretch-logstash6.virt events=0 1566425244000000000\n```\n',image:Mn.a},{id:"lustre2",name:"Lustre",markdown:'# Lustre Input Plugin\n\nThe [Lustre][]® file system is an open-source, parallel file system that supports\nmany requirements of leadership class HPC simulation environments.\n\nThis plugin monitors the Lustre file system using its entries in the proc filesystem.\n\n### Configuration\n\n```toml\n# Read metrics from local Lustre service on OST, MDS\n[[inputs.lustre2]]\n  ## An array of /proc globs to search for Lustre stats\n  ## If not specified, the default will work on Lustre 2.5.x\n  ##\n  # ost_procfiles = [\n  #   "/proc/fs/lustre/obdfilter/*/stats",\n  #   "/proc/fs/lustre/osd-ldiskfs/*/stats",\n  #   "/proc/fs/lustre/obdfilter/*/job_stats",\n  # ]\n  # mds_procfiles = [\n  #   "/proc/fs/lustre/mdt/*/md_stats",\n  #   "/proc/fs/lustre/mdt/*/job_stats",\n  # ]\n```\n\n### Metrics\n\nFrom `/proc/fs/lustre/obdfilter/*/stats` and `/proc/fs/lustre/osd-ldiskfs/*/stats`:\n\n- lustre2\n  - tags:\n    - name\n  - fields:\n    - write_bytes\n    - write_calls\n    - read_bytes\n    - read_calls\n    - cache_hit\n    - cache_miss\n    - cache_access\n\nFrom `/proc/fs/lustre/obdfilter/*/job_stats`:\n\n- lustre2\n  - tags:\n    - name\n    - jobid\n  - fields:\n    - jobstats_ost_getattr\n    - jobstats_ost_setattr\n    - jobstats_ost_sync\n    - jobstats_punch\n    - jobstats_destroy\n    - jobstats_create\n    - jobstats_ost_statfs\n    - jobstats_get_info\n    - jobstats_set_info\n    - jobstats_quotactl\n    - jobstats_read_bytes\n    - jobstats_read_calls\n    - jobstats_read_max_size\n    - jobstats_read_min_size\n    - jobstats_write_bytes\n    - jobstats_write_calls\n    - jobstats_write_max_size\n    - jobstats_write_min_size\n\nFrom `/proc/fs/lustre/mdt/*/md_stats`:\n\n- lustre2\n  - tags:\n    - name\n  - fields:\n    - open\n    - close\n    - mknod\n    - link\n    - unlink\n    - mkdir\n    - rmdir\n    - rename\n    - getattr\n    - setattr\n    - getxattr\n    - setxattr\n    - statfs\n    - sync\n    - samedir_rename\n    - crossdir_rename\n\nFrom `/proc/fs/lustre/mdt/*/job_stats`:\n\n- lustre2\n  - tags:\n    - name\n    - jobid\n  - fields:\n    - jobstats_close\n    - jobstats_crossdir_rename\n    - jobstats_getattr\n    - jobstats_getxattr\n    - jobstats_link\n    - jobstats_mkdir\n    - jobstats_mknod\n    - jobstats_open\n    - jobstats_rename\n    - jobstats_rmdir\n    - jobstats_samedir_rename\n    - jobstats_setattr\n    - jobstats_setxattr\n    - jobstats_statfs\n    - jobstats_sync\n    - jobstats_unlink\n\n\n### Troubleshooting\n\nCheck for the default or custom procfiles in the proc filesystem, and reference\nthe [Lustre Monitoring and Statistics Guide][guide].  This plugin does not\nreport all information from these files, only a limited set of items\ncorresponding to the above metric fields.\n\n### Example Output\n\n```\nlustre2,host=oss2,jobid=42990218,name=wrk-OST0041 jobstats_ost_setattr=0i,jobstats_ost_sync=0i,jobstats_punch=0i,jobstats_read_bytes=4096i,jobstats_read_calls=1i,jobstats_read_max_size=4096i,jobstats_read_min_size=4096i,jobstats_write_bytes=310206488i,jobstats_write_calls=7423i,jobstats_write_max_size=53048i,jobstats_write_min_size=8820i 1556525847000000000\nlustre2,host=mds1,jobid=42992017,name=wrk-MDT0000 jobstats_close=31798i,jobstats_crossdir_rename=0i,jobstats_getattr=34146i,jobstats_getxattr=15i,jobstats_link=0i,jobstats_mkdir=658i,jobstats_mknod=0i,jobstats_open=31797i,jobstats_rename=0i,jobstats_rmdir=0i,jobstats_samedir_rename=0i,jobstats_setattr=1788i,jobstats_setxattr=0i,jobstats_statfs=0i,jobstats_sync=0i,jobstats_unlink=0i 1556525828000000000\n\n```\n\n[lustre]: http://lustre.org/\n[guide]: http://wiki.lustre.org/Lustre_Monitoring_and_Statistics_Guide\n',image:En.a},{id:"mailchimp",name:"Mailchimp",markdown:'# Mailchimp Input Plugin\n\nPulls campaign reports from the [Mailchimp API](https://developer.mailchimp.com/).\n\n### Configuration\n\nThis section contains the default TOML to configure the plugin.  You can\ngenerate it using `telegraf --usage mailchimp`.\n\n```toml\n[[inputs.mailchimp]]\n  ## MailChimp API key\n  ## get from https://admin.mailchimp.com/account/api/\n  api_key = "" # required\n  \n  ## Reports for campaigns sent more than days_old ago will not be collected.\n  ## 0 means collect all and is the default value.\n  days_old = 0\n  \n  ## Campaign ID to get, if empty gets all campaigns, this option overrides days_old\n  # campaign_id = ""\n```\n\n### Metrics\n\n- mailchimp\n  - tags:\n    - id\n    - campaign_title\n  - fields:\n    - emails_sent (integer, emails)\n    - abuse_reports (integer, reports)\n    - unsubscribed (integer, unsubscribes)\n    - hard_bounces (integer, emails)\n    - soft_bounces (integer, emails)\n    - syntax_errors (integer, errors)\n    - forwards_count (integer, emails)\n    - forwards_opens (integer, emails)\n    - opens_total (integer, emails)\n    - unique_opens (integer, emails)\n    - open_rate (double, percentage)\n    - clicks_total (integer, clicks)\n    - unique_clicks (integer, clicks)\n    - unique_subscriber_clicks (integer, clicks)\n    - click_rate (double, percentage)\n    - facebook_recipient_likes (integer, likes)\n    - facebook_unique_likes (integer, likes)\n    - facebook_likes (integer, likes)\n    - industry_type (string, type)\n    - industry_open_rate (double, percentage)\n    - industry_click_rate (double, percentage)\n    - industry_bounce_rate (double, percentage)\n    - industry_unopen_rate (double, percentage)\n    - industry_unsub_rate (double, percentage)\n    - industry_abuse_rate (double, percentage)\n    - list_stats_sub_rate (double, percentage)\n    - list_stats_unsub_rate (double, percentage)\n    - list_stats_open_rate (double, percentage)\n    - list_stats_click_rate (double, percentage)\n',image:Nn.a},{id:"marklogic",name:"MarkLogic",markdown:'# MarkLogic Input Plugin\n\nThe MarkLogic Telegraf plugin gathers health status metrics from one or more host.\n\n### Configuration:\n\n```toml\n[[inputs.marklogic]]\n  ## Base URL of the MarkLogic HTTP Server.\n  url = "http://localhost:8002"\n\n  ## List of specific hostnames to retrieve information. At least (1) required.\n  # hosts = ["hostname1", "hostname2"]\n\n  ## Using HTTP Basic Authentication. Management API requires \'manage-user\' role privileges\n  # username = "myuser"\n  # password = "mypassword"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- marklogic\n  - tags:\n    - source (the hostname of the server address, ex. `ml1.local`)\n    - id (the host node unique id ex. `2592913110757471141`)\n  - fields:\n    - online\n    - total_load\n    - total_rate\n    - ncpus\n    - ncores\n    - total_cpu_stat_user\n    - total_cpu_stat_system\n    - total_cpu_stat_idle\n    - total_cpu_stat_iowait\n    - memory_process_size\n    - memory_process_rss\n    - memory_system_total\n    - memory_system_free\n    - memory_process_swap_size\n    - memory_size\n    - host_size\n    - log_device_space\n    - data_dir_space\n    - query_read_bytes\n    - query_read_load\n    - merge_read_bytes\n    - merge_write_load\n    - http_server_receive_bytes\n    - http_server_send_bytes\n\n### Example Output:\n\n```\n$> marklogic,host=localhost,id=2592913110757471141,source=ml1.local total_cpu_stat_iowait=0.0125649003311992,memory_process_swap_size=0i,host_size=380i,data_dir_space=28216i,query_read_load=0i,ncpus=1i,log_device_space=28216i,query_read_bytes=13947332i,merge_write_load=0i,http_server_receive_bytes=225893i,online=true,ncores=4i,total_cpu_stat_user=0.150778993964195,total_cpu_stat_system=0.598927974700928,total_cpu_stat_idle=99.2210006713867,memory_system_total=3947i,memory_system_free=2669i,memory_size=4096i,total_rate=14.7697010040283,http_server_send_bytes=0i,memory_process_size=903i,memory_process_rss=486i,merge_read_load=0i,total_load=0.00502600101754069 1566373000000000000\n\n```\n',image:Ln.a},{id:"mcrouter",name:"Mcrouter",markdown:'# Mcrouter Input Plugin\n\nThis plugin gathers statistics data from a Mcrouter server.\n\n### Configuration:\n\n```toml\n# Read metrics from one or many mcrouter servers.\n[[inputs.mcrouter]]\n  ## An array of address to gather stats about. Specify an ip or hostname\n  ## with port. ie tcp://localhost:11211, tcp://10.0.0.1:11211, etc.\n  servers = ["tcp://localhost:11211", "unix:///var/run/mcrouter.sock"]\n\n  ## Timeout for metric collections from all servers.  Minimum timeout is "1s".\n  # timeout = "5s"\n```\n\n### Measurements & Fields:\n\nThe fields from this plugin are gathered in the *mcrouter* measurement.\n\nDescription of gathered fields can be found [here](https://github.com/facebook/mcrouter/wiki/Stats-list).\n\nFields:\n\n* uptime\n* num_servers\n* num_servers_new\n* num_servers_up\n* num_servers_down\n* num_servers_closed\n* num_clients\n* num_suspect_servers\n* destination_batches_sum\n* destination_requests_sum\n* outstanding_route_get_reqs_queued\n* outstanding_route_update_reqs_queued\n* outstanding_route_get_avg_queue_size\n* outstanding_route_update_avg_queue_size\n* outstanding_route_get_avg_wait_time_sec\n* outstanding_route_update_avg_wait_time_sec\n* retrans_closed_connections\n* destination_pending_reqs\n* destination_inflight_reqs\n* destination_batch_size\n* asynclog_requests\n* proxy_reqs_processing\n* proxy_reqs_waiting\n* client_queue_notify_period\n* rusage_system\n* rusage_user\n* ps_num_minor_faults\n* ps_num_major_faults\n* ps_user_time_sec\n* ps_system_time_sec\n* ps_vsize\n* ps_rss\n* fibers_allocated\n* fibers_pool_size\n* fibers_stack_high_watermark\n* successful_client_connections\n* duration_us\n* destination_max_pending_reqs\n* destination_max_inflight_reqs\n* retrans_per_kbyte_max\n* cmd_get_count\n* cmd_delete_out\n* cmd_lease_get\n* cmd_set\n* cmd_get_out_all\n* cmd_get_out\n* cmd_lease_set_count\n* cmd_other_out_all\n* cmd_lease_get_out\n* cmd_set_count\n* cmd_lease_set_out\n* cmd_delete_count\n* cmd_other\n* cmd_delete\n* cmd_get\n* cmd_lease_set\n* cmd_set_out\n* cmd_lease_get_count\n* cmd_other_out\n* cmd_lease_get_out_all\n* cmd_set_out_all\n* cmd_other_count\n* cmd_delete_out_all\n* cmd_lease_set_out_all\n\n### Tags:\n\n* Mcrouter measurements have the following tags:\n    - server (the host name from which metrics are gathered)\n\n\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter mcrouter --test\nmcrouter,server=localhost:11211 uptime=166,num_servers=1,num_servers_new=1,num_servers_up=0,num_servers_down=0,num_servers_closed=0,num_clients=1,num_suspect_servers=0,destination_batches_sum=0,destination_requests_sum=0,outstanding_route_get_reqs_queued=0,outstanding_route_update_reqs_queued=0,outstanding_route_get_avg_queue_size=0,outstanding_route_update_avg_queue_size=0,outstanding_route_get_avg_wait_time_sec=0,outstanding_route_update_avg_wait_time_sec=0,retrans_closed_connections=0,destination_pending_reqs=0,destination_inflight_reqs=0,destination_batch_size=0,asynclog_requests=0,proxy_reqs_processing=1,proxy_reqs_waiting=0,client_queue_notify_period=0,rusage_system=0.040966,rusage_user=0.020483,ps_num_minor_faults=2490,ps_num_major_faults=11,ps_user_time_sec=0.02,ps_system_time_sec=0.04,ps_vsize=697741312,ps_rss=10563584,fibers_allocated=0,fibers_pool_size=0,fibers_stack_high_watermark=0,successful_client_connections=18,duration_us=0,destination_max_pending_reqs=0,destination_max_inflight_reqs=0,retrans_per_kbyte_max=0,cmd_get_count=0,cmd_delete_out=0,cmd_lease_get=0,cmd_set=0,cmd_get_out_all=0,cmd_get_out=0,cmd_lease_set_count=0,cmd_other_out_all=0,cmd_lease_get_out=0,cmd_set_count=0,cmd_lease_set_out=0,cmd_delete_count=0,cmd_other=0,cmd_delete=0,cmd_get=0,cmd_lease_set=0,cmd_set_out=0,cmd_lease_get_count=0,cmd_other_out=0,cmd_lease_get_out_all=0,cmd_set_out_all=0,cmd_other_count=0,cmd_delete_out_all=0,cmd_lease_set_out_all=0 1453831884664956455\n```\n',image:Un.a},{id:"mdstat",name:"Mdstat",markdown:'# mdstat Input Plugin\n\nThe mdstat plugin gathers statistics about any Linux MD RAID arrays configured on the host\nby reading /proc/mdstat. For a full list of available fields see the \n/proc/mdstat section of the [proc man page](http://man7.org/linux/man-pages/man5/proc.5.html).\nFor a better idea of what each field represents, see the \n[mdstat man page](https://raid.wiki.kernel.org/index.php/Mdstat).\n\nStat collection based on Prometheus\' mdstat collection library at https://github.com/prometheus/procfs/blob/master/mdstat.go\n\n\n### Configuration:\n\n```toml\n# Get kernel statistics from /proc/mdstat\n[[inputs.mdstat]]\n  ## Sets file path\n  ## If not specified, then default is /proc/mdstat\n  # file_name = "/proc/mdstat"\n```\n\n### Measurements & Fields:\n\n- mdstat\n  - BlocksSynced (if the array is rebuilding/checking, this is the count of blocks that have been scanned)\n  - BlocksSyncedFinishTime (the expected finish time of the rebuild scan, listed in minutes remaining)\n  - BlocksSyncedPct (the percentage of the rebuild scan left)\n  - BlocksSyncedSpeed (the current speed the rebuild is running at, listed in K/sec)\n  - BlocksTotal (the total count of blocks in the array)\n  - DisksActive (the number of disks that are currently considered healthy in the array)\n  - DisksFailed (the current count of failed disks in the array)\n  - DisksSpare (the current count of "spare" disks in the array)\n  - DisksTotal (total count of disks in the array)\n\n### Tags:\n\n- mdstat\n  - ActivityState (`active` or `inactive`)\n  - Devices (comma separated list of devices that make up the array)\n  - Name (name of the array)\n\n### Example Output:\n\n```\n$ telegraf --config ~/ws/telegraf.conf --input-filter mdstat --test\n* Plugin: mdstat, Collection 1\n> mdstat,ActivityState=active,Devices=sdm1\\,sdn1,Name=md1 BlocksSynced=231299072i,BlocksSyncedFinishTime=0,BlocksSyncedPct=0,BlocksSyncedSpeed=0,BlocksTotal=231299072i,DisksActive=2i,DisksFailed=0i,DisksSpare=0i,DisksTotal=2i,DisksDown=0i 1617814276000000000\n> mdstat,ActivityState=active,Devices=sdm5\\,sdn5,Name=md2 BlocksSynced=2996224i,BlocksSyncedFinishTime=0,BlocksSyncedPct=0,BlocksSyncedSpeed=0,BlocksTotal=2996224i,DisksActive=2i,DisksFailed=0i,DisksSpare=0i,DisksTotal=2i,DisksDown=0i 1617814276000000000\n```\n',image:Cn.a},{id:"mem",name:"Memory",markdown:"# Memory Input Plugin\n\nThe mem plugin collects system memory metrics.\n\nFor a more complete explanation of the difference between *used* and\n*actual_used* RAM, see [Linux ate my ram](http://www.linuxatemyram.com/).\n\n### Configuration:\n```toml\n# Read metrics about memory usage\n[[inputs.mem]]\n  # no configuration\n```\n\n### Metrics:\n\nAvailable fields are dependent on platform.\n\n- mem\n  - fields:\n    - active (integer, Darwin, FreeBSD, Linux, OpenBSD)\n    - available (integer)\n    - available_percent (float)\n    - buffered (integer, FreeBSD, Linux)\n    - cached (integer, FreeBSD, Linux, OpenBSD)\n    - commit_limit (integer, Linux)\n    - committed_as (integer, Linux)\n    - dirty (integer, Linux)\n    - free (integer, Darwin, FreeBSD, Linux, OpenBSD)\n    - high_free (integer, Linux)\n    - high_total (integer, Linux)\n    - huge_pages_free (integer, Linux)\n    - huge_page_size (integer, Linux)\n    - huge_pages_total (integer, Linux)\n    - inactive (integer, Darwin, FreeBSD, Linux, OpenBSD)\n    - laundry (integer, FreeBSD)\n    - low_free (integer, Linux)\n    - low_total (integer, Linux)\n    - mapped (integer, Linux)\n    - page_tables (integer, Linux)\n    - shared (integer, Linux)\n    - slab (integer, Linux)\n    - sreclaimable (integer, Linux)\n    - sunreclaim (integer, Linux)\n    - swap_cached (integer, Linux)\n    - swap_free (integer, Linux)\n    - swap_total (integer, Linux)\n    - total (integer)\n    - used (integer)\n    - used_percent (float)\n    - vmalloc_chunk (integer, Linux)\n    - vmalloc_total (integer, Linux)\n    - vmalloc_used (integer, Linux)\n    - wired (integer, Darwin, FreeBSD, OpenBSD)\n    - write_back (integer, Linux)\n    - write_back_tmp (integer, Linux)\n\n### Example Output:\n```\nmem active=9299595264i,available=16818249728i,available_percent=80.41654254645131,buffered=2383761408i,cached=13316689920i,commit_limit=14751920128i,committed_as=11781156864i,dirty=122880i,free=1877688320i,high_free=0i,high_total=0i,huge_page_size=2097152i,huge_pages_free=0i,huge_pages_total=0i,inactive=7549939712i,low_free=0i,low_total=0i,mapped=416763904i,page_tables=19787776i,shared=670679040i,slab=2081071104i,sreclaimable=1923395584i,sunreclaim=157675520i,swap_cached=1302528i,swap_free=4286128128i,swap_total=4294963200i,total=20913917952i,used=3335778304i,used_percent=15.95004011996231,vmalloc_chunk=0i,vmalloc_total=35184372087808i,vmalloc_used=0i,wired=0i,write_back=0i,write_back_tmp=0i 1574712869000000000\n```\n",image:Hn.a},{id:"memcached",name:"Memcached",markdown:'# Memcached Input Plugin\n\nThis plugin gathers statistics data from a Memcached server.\n\n### Configuration:\n\n```toml\n# Read metrics from one or many memcached servers.\n[[inputs.memcached]]\n  # An array of address to gather stats about. Specify an ip on hostname\n  # with optional port. ie localhost, 10.0.0.1:11211, etc.\n  servers = ["localhost:11211"]\n  # An array of unix memcached sockets to gather stats about.\n  # unix_sockets = ["/var/run/memcached.sock"]\n```\n\n### Measurements & Fields:\n\nThe fields from this plugin are gathered in the *memcached* measurement.\n\nFields:\n\n* accepting_conns - Whether or not server is accepting conns\n* auth_cmds - Number of authentication commands handled, success or failure\n* auth_errors - Number of failed authentications\n* bytes - Current number of bytes used to store items\n* bytes_read - Total number of bytes read by this server from network\n* bytes_written - Total number of bytes sent by this server to network\n* cas_badval - Number of CAS reqs for which a key was found, but the CAS value did not match\n* cas_hits - Number of successful CAS reqs\n* cas_misses - Number of CAS reqs against missing keys\n* cmd_flush - Cumulative number of flush reqs\n* cmd_get - Cumulative number of retrieval reqs\n* cmd_set - Cumulative number of storage reqs\n* cmd_touch - Cumulative number of touch reqs\n* conn_yields - Number of times any connection yielded to another due to hitting the -R limit\n* connection_structures - Number of connection structures allocated by the server\n* curr_connections - Number of open connections\n* curr_items - Current number of items stored\n* decr_hits - Number of successful decr reqs\n* decr_misses - Number of decr reqs against missing keys\n* delete_hits - Number of deletion reqs resulting in an item being removed\n* delete_misses - umber of deletions reqs for missing keys\n* evicted_unfetched - Items evicted from LRU that were never touched by get/incr/append/etc\n* evictions - Number of valid items removed from cache to free memory for new items\n* expired_unfetched - Items pulled from LRU that were never touched by get/incr/append/etc before expiring\n* get_hits - Number of keys that have been requested and found present\n* get_misses - Number of items that have been requested and not found\n* hash_bytes - Bytes currently used by hash tables\n* hash_is_expanding - Indicates if the hash table is being grown to a new size\n* hash_power_level - Current size multiplier for hash table\n* incr_hits - Number of successful incr reqs\n* incr_misses - Number of incr reqs against missing keys\n* limit_maxbytes - Number of bytes this server is allowed to use for storage\n* listen_disabled_num - Number of times server has stopped accepting new connections (maxconns)\n* reclaimed - Number of times an entry was stored using memory from an expired entry\n* threads - Number of worker threads requested\n* total_connections - Total number of connections opened since the server started running\n* total_items - Total number of items stored since the server started\n* touch_hits - Number of keys that have been touched with a new expiration time\n* touch_misses - Number of items that have been touched and not found\n* uptime - Number of secs since the server started\n\nDescription of gathered fields taken from [here](https://github.com/memcached/memcached/blob/master/doc/protocol.txt).\n\n### Tags:\n\n* Memcached measurements have the following tags:\n    - server (the host name from which metrics are gathered)\n\n### Sample Queries:\n\nYou can use the following query to get the average get hit and miss ratio, as well as the total average size of cached items, number of cached items and average connection counts per server.\n\n```\nSELECT mean(get_hits) / mean(cmd_get) as get_ratio, mean(get_misses) / mean(cmd_get) as get_misses_ratio, mean(bytes), mean(curr_items), mean(curr_connections) FROM memcached WHERE time > now() - 1h GROUP BY server\n```\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter memcached --test\nmemcached,server=localhost:11211 get_hits=1,get_misses=2,evictions=0,limit_maxbytes=0,bytes=10,uptime=3600,curr_items=2,total_items=2,curr_connections=1,total_connections=2,connection_structures=1,cmd_get=2,cmd_set=1,delete_hits=0,delete_misses=0,incr_hits=0,incr_misses=0,decr_hits=0,decr_misses=0,cas_hits=0,cas_misses=0,bytes_read=10,bytes_written=10,threads=1,conn_yields=0 1453831884664956455\n```\n',image:Bn.a},{id:"mesos",name:"Mesos",markdown:'# Mesos Input Plugin\n\nThis input plugin gathers metrics from Mesos.\nFor more information, please check the [Mesos Observability Metrics](http://mesos.apache.org/documentation/latest/monitoring/) page.\n\n### Configuration:\n\n```toml\n# Telegraf plugin for gathering metrics from N Mesos masters\n[[inputs.mesos]]\n  ## Timeout, in ms.\n  timeout = 100\n\n  ## A list of Mesos masters.\n  masters = ["http://localhost:5050"]\n\n  ## Master metrics groups to be collected, by default, all enabled.\n  master_collections = [\n    "resources",\n    "master",\n    "system",\n    "agents",\n    "frameworks",\n    "framework_offers",\n    "tasks",\n    "messages",\n    "evqueue",\n    "registrar",\n    "allocator",\n  ]\n\n  ## A list of Mesos slaves, default is []\n  # slaves = []\n\n  ## Slave metrics groups to be collected, by default, all enabled.\n  # slave_collections = [\n  #   "resources",\n  #   "agent",\n  #   "system",\n  #   "executors",\n  #   "tasks",\n  #   "messages",\n  # ]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\nBy default this plugin is not configured to gather metrics from mesos. Since a mesos cluster can be deployed in numerous ways it does not provide any default\nvalues. User needs to specify master/slave nodes this plugin will gather metrics from.\n\n### Measurements & Fields:\n\nMesos master metric groups\n\n- resources\n    - master/cpus_percent\n    - master/cpus_used\n    - master/cpus_total\n    - master/cpus_revocable_percent\n    - master/cpus_revocable_total\n    - master/cpus_revocable_used\n    - master/disk_percent\n    - master/disk_used\n    - master/disk_total\n    - master/disk_revocable_percent\n    - master/disk_revocable_total\n    - master/disk_revocable_used\n    - master/gpus_percent\n    - master/gpus_used\n    - master/gpus_total\n    - master/gpus_revocable_percent\n    - master/gpus_revocable_total\n    - master/gpus_revocable_used\n    - master/mem_percent\n    - master/mem_used\n    - master/mem_total\n    - master/mem_revocable_percent\n    - master/mem_revocable_total\n    - master/mem_revocable_used\n\n- master\n    - master/elected\n    - master/uptime_secs\n\n- system\n    - system/cpus_total\n    - system/load_15min\n    - system/load_5min\n    - system/load_1min\n    - system/mem_free_bytes\n    - system/mem_total_bytes\n\n- slaves\n    - master/slave_registrations\n    - master/slave_removals\n    - master/slave_reregistrations\n    - master/slave_shutdowns_scheduled\n    - master/slave_shutdowns_canceled\n    - master/slave_shutdowns_completed\n    - master/slaves_active\n    - master/slaves_connected\n    - master/slaves_disconnected\n    - master/slaves_inactive\n    - master/slave_unreachable_canceled\n    - master/slave_unreachable_completed\n    - master/slave_unreachable_scheduled\n    - master/slaves_unreachable\n\n- frameworks\n    - master/frameworks_active\n    - master/frameworks_connected\n    - master/frameworks_disconnected\n    - master/frameworks_inactive\n    - master/outstanding_offers\n\n- framework offers\n    - master/frameworks/subscribed\n    - master/frameworks/calls_total\n    - master/frameworks/calls\n    - master/frameworks/events_total\n    - master/frameworks/events\n    - master/frameworks/operations_total\n    - master/frameworks/operations\n    - master/frameworks/tasks/active\n    - master/frameworks/tasks/terminal\n    - master/frameworks/offers/sent\n    - master/frameworks/offers/accepted\n    - master/frameworks/offers/declined\n    - master/frameworks/offers/rescinded\n    - master/frameworks/roles/suppressed\n\n- tasks\n    - master/tasks_error\n    - master/tasks_failed\n    - master/tasks_finished\n    - master/tasks_killed\n    - master/tasks_lost\n    - master/tasks_running\n    - master/tasks_staging\n    - master/tasks_starting\n    - master/tasks_dropped\n    - master/tasks_gone\n    - master/tasks_gone_by_operator\n    - master/tasks_killing\n    - master/tasks_unreachable\n\n- messages\n    - master/invalid_executor_to_framework_messages\n    - master/invalid_framework_to_executor_messages\n    - master/invalid_status_update_acknowledgements\n    - master/invalid_status_updates\n    - master/dropped_messages\n    - master/messages_authenticate\n    - master/messages_deactivate_framework\n    - master/messages_decline_offers\n    - master/messages_executor_to_framework\n    - master/messages_exited_executor\n    - master/messages_framework_to_executor\n    - master/messages_kill_task\n    - master/messages_launch_tasks\n    - master/messages_reconcile_tasks\n    - master/messages_register_framework\n    - master/messages_register_slave\n    - master/messages_reregister_framework\n    - master/messages_reregister_slave\n    - master/messages_resource_request\n    - master/messages_revive_offers\n    - master/messages_status_update\n    - master/messages_status_update_acknowledgement\n    - master/messages_unregister_framework\n    - master/messages_unregister_slave\n    - master/messages_update_slave\n    - master/recovery_slave_removals\n    - master/slave_removals/reason_registered\n    - master/slave_removals/reason_unhealthy\n    - master/slave_removals/reason_unregistered\n    - master/valid_framework_to_executor_messages\n    - master/valid_status_update_acknowledgements\n    - master/valid_status_updates\n    - master/task_lost/source_master/reason_invalid_offers\n    - master/task_lost/source_master/reason_slave_removed\n    - master/task_lost/source_slave/reason_executor_terminated\n    - master/valid_executor_to_framework_messages\n    - master/invalid_operation_status_update_acknowledgements\n    - master/messages_operation_status_update_acknowledgement\n    - master/messages_reconcile_operations\n    - master/messages_suppress_offers\n    - master/valid_operation_status_update_acknowledgements\n\n- evqueue\n    - master/event_queue_dispatches\n    - master/event_queue_http_requests\n    - master/event_queue_messages\n    - master/operator_event_stream_subscribers\n\n- registrar\n    - registrar/state_fetch_ms\n    - registrar/state_store_ms\n    - registrar/state_store_ms/max\n    - registrar/state_store_ms/min\n    - registrar/state_store_ms/p50\n    - registrar/state_store_ms/p90\n    - registrar/state_store_ms/p95\n    - registrar/state_store_ms/p99\n    - registrar/state_store_ms/p999\n    - registrar/state_store_ms/p9999\n    - registrar/state_store_ms/count\n    - registrar/log/ensemble_size\n    - registrar/log/recovered\n    - registrar/queued_operations\n    - registrar/registry_size_bytes\n\n- allocator\n    - allocator/allocation_run_ms\n    - allocator/allocation_run_ms/count\n    - allocator/allocation_run_ms/max\n    - allocator/allocation_run_ms/min\n    - allocator/allocation_run_ms/p50\n    - allocator/allocation_run_ms/p90\n    - allocator/allocation_run_ms/p95\n    - allocator/allocation_run_ms/p99\n    - allocator/allocation_run_ms/p999\n    - allocator/allocation_run_ms/p9999\n    - allocator/allocation_runs\n    - allocator/allocation_run_latency_ms\n    - allocator/allocation_run_latency_ms/count\n    - allocator/allocation_run_latency_ms/max\n    - allocator/allocation_run_latency_ms/min\n    - allocator/allocation_run_latency_ms/p50\n    - allocator/allocation_run_latency_ms/p90\n    - allocator/allocation_run_latency_ms/p95\n    - allocator/allocation_run_latency_ms/p99\n    - allocator/allocation_run_latency_ms/p999\n    - allocator/allocation_run_latency_ms/p9999\n    - allocator/roles/shares/dominant\n    - allocator/event_queue_dispatches\n    - allocator/offer_filters/roles/active\n    - allocator/quota/roles/resources/offered_or_allocated\n    - allocator/quota/roles/resources/guarantee\n    - allocator/resources/cpus/offered_or_allocated\n    - allocator/resources/cpus/total\n    - allocator/resources/disk/offered_or_allocated\n    - allocator/resources/disk/total\n    - allocator/resources/mem/offered_or_allocated\n    - allocator/resources/mem/total\n\nMesos slave metric groups\n- resources\n    - slave/cpus_percent\n    - slave/cpus_used\n    - slave/cpus_total\n    - slave/cpus_revocable_percent\n    - slave/cpus_revocable_total\n    - slave/cpus_revocable_used\n    - slave/disk_percent\n    - slave/disk_used\n    - slave/disk_total\n    - slave/disk_revocable_percent\n    - slave/disk_revocable_total\n    - slave/disk_revocable_used\n    - slave/gpus_percent\n    - slave/gpus_used\n    - slave/gpus_total,\n    - slave/gpus_revocable_percent\n    - slave/gpus_revocable_total\n    - slave/gpus_revocable_used\n    - slave/mem_percent\n    - slave/mem_used\n    - slave/mem_total\n    - slave/mem_revocable_percent\n    - slave/mem_revocable_total\n    - slave/mem_revocable_used\n\n- agent\n    - slave/registered\n    - slave/uptime_secs\n\n- system\n    - system/cpus_total\n    - system/load_15min\n    - system/load_5min\n    - system/load_1min\n    - system/mem_free_bytes\n    - system/mem_total_bytes\n\n- executors\n    - containerizer/mesos/container_destroy_errors\n    - slave/container_launch_errors\n    - slave/executors_preempted\n    - slave/frameworks_active\n    - slave/executor_directory_max_allowed_age_secs\n    - slave/executors_registering\n    - slave/executors_running\n    - slave/executors_terminated\n    - slave/executors_terminating\n    - slave/recovery_errors\n\n- tasks\n    - slave/tasks_failed\n    - slave/tasks_finished\n    - slave/tasks_killed\n    - slave/tasks_lost\n    - slave/tasks_running\n    - slave/tasks_staging\n    - slave/tasks_starting\n\n- messages\n    - slave/invalid_framework_messages\n    - slave/invalid_status_updates\n    - slave/valid_framework_messages\n    - slave/valid_status_updates\n\n### Tags:\n\n- All master/slave measurements have the following tags:\n    - server (network location of server: `host:port`)\n    - url (URL origin of server: `scheme://host:port`)\n    - role (master/slave)\n\n- All master measurements have the extra tags:\n\t- state (leader/follower)\n\n### Example Output:\n```\n$ telegraf --config ~/mesos.conf --input-filter mesos --test\n* Plugin: mesos, Collection 1\nmesos,role=master,state=leader,host=172.17.8.102,server=172.17.8.101\nallocator/event_queue_dispatches=0,master/cpus_percent=0,\nmaster/cpus_revocable_percent=0,master/cpus_revocable_total=0,\nmaster/cpus_revocable_used=0,master/cpus_total=2,\nmaster/cpus_used=0,master/disk_percent=0,master/disk_revocable_percent=0,\nmaster/disk_revocable_total=0,master/disk_revocable_used=0,master/disk_total=10823,\nmaster/disk_used=0,master/dropped_messages=2,master/elected=1,\nmaster/event_queue_dispatches=10,master/event_queue_http_requests=0,\nmaster/event_queue_messages=0,master/frameworks_active=2,master/frameworks_connected=2,\nmaster/frameworks_disconnected=0,master/frameworks_inactive=0,\nmaster/invalid_executor_to_framework_messages=0,\nmaster/invalid_framework_to_executor_messages=0,\nmaster/invalid_status_update_acknowledgements=0,master/invalid_status_updates=0,master/mem_percent=0,\nmaster/mem_revocable_percent=0,master/mem_revocable_total=0,\nmaster/mem_revocable_used=0,master/mem_total=1002,\nmaster/mem_used=0,master/messages_authenticate=0,\nmaster/messages_deactivate_framework=0 ...\n```\n\n',image:Gn.a},{id:"minecraft",name:"Minecraft",markdown:'# Minecraft Input Plugin\n\nThe `minecraft` plugin connects to a Minecraft server using the RCON protocol\nto collects scores from the server [scoreboard][].\n\nThis plugin is known to support Minecraft Java Edition versions 1.11 - 1.14.\nWhen using an version of Minecraft earlier than 1.13, be aware that the values\nfor some criterion has changed and may need to be modified.\n\n#### Server Setup\n\nEnable [RCON][] on the Minecraft server, add this to your server configuration\nin the [server.properties][] file:\n\n```conf\nenable-rcon=true\nrcon.password=<your password>\nrcon.port=<1-65535>\n```\n\nScoreboard [Objectives][] must be added using the server console for the\nplugin to collect.  These can be added in game by players with op status,\nfrom the server console, or over an RCON connection.\n\nWhen getting started pick an easy to test objective.  This command will add an\nobjective that counts the number of times a player has jumped:\n```\n/scoreboard objectives add jumps minecraft.custom:minecraft.jump\n```\n\nOnce a player has triggered the event they will be added to the scoreboard,\nyou can then list all players with recorded scores:\n```\n/scoreboard players list\n```\n\nView the current scores with a command, substituting your player name:\n```\n/scoreboard players list Etho\n```\n\n### Configuration\n\n```toml\n[[inputs.minecraft]]\n  ## Address of the Minecraft server.\n  # server = "localhost"\n\n  ## Server RCON Port.\n  # port = "25575"\n\n  ## Server RCON Password.\n  password = ""\n```\n\n### Metrics\n\n- minecraft\n  - tags:\n    - player\n    - port (port of the server)\n    - server (hostname:port, deprecated in 1.11; use `source` and `port` tags)\n    - source (hostname of the server)\n  - fields:\n    - `<objective_name>` (integer, count)\n\n### Sample Queries:\n\nGet the number of jumps per player in the last hour:\n```sql\nSELECT SPREAD("jumps") FROM "minecraft" WHERE time > now() - 1h GROUP BY "player"\n```\n\n### Example Output:\n```\nminecraft,player=notch,source=127.0.0.1,port=25575 jumps=178i 1498261397000000000\nminecraft,player=dinnerbone,source=127.0.0.1,port=25575 deaths=1i,jumps=1999i,cow_kills=1i 1498261397000000000\nminecraft,player=jeb,source=127.0.0.1,port=25575 d_pickaxe=1i,damage_dealt=80i,d_sword=2i,hunger=20i,health=20i,kills=1i,level=33i,jumps=264i,armor=15i 1498261397000000000\n```\n\n[server.properties]: https://minecraft.gamepedia.com/Server.properties\n[scoreboard]: http://minecraft.gamepedia.com/Scoreboard\n[objectives]: https://minecraft.gamepedia.com/Scoreboard#Objectives\n[rcon]: http://wiki.vg/RCON\n',image:Kn.a},{id:"modbus",name:"Modbus",markdown:'# Modbus Input Plugin\n\nThe Modbus plugin collects Discrete Inputs, Coils, Input Registers and Holding\nRegisters via Modbus TCP or Modbus RTU/ASCII.\n\n### Configuration\n\n```toml\n[[inputs.modbus]]\n  ## Connection Configuration\n  ##\n  ## The plugin supports connections to PLCs via MODBUS/TCP or\n  ## via serial line communication in binary (RTU) or readable (ASCII) encoding\n  ##\n  ## Device name\n  name = "Device"\n\n  ## Slave ID - addresses a MODBUS device on the bus\n  ## Range: 0 - 255 [0 = broadcast; 248 - 255 = reserved]\n  slave_id = 1\n\n  ## Timeout for each request\n  timeout = "1s"\n\n  ## Maximum number of retries and the time to wait between retries\n  ## when a slave-device is busy.\n  # busy_retries = 0\n  # busy_retries_wait = "100ms"\n\n  # TCP - connect via Modbus/TCP\n  controller = "tcp://localhost:502"\n\n  ## Serial (RS485; RS232)\n  # controller = "file:///dev/ttyUSB0"\n  # baud_rate = 9600\n  # data_bits = 8\n  # parity = "N"\n  # stop_bits = 1\n  # transmission_mode = "RTU"\n\n\n  ## Measurements\n  ##\n\n  ## Digital Variables, Discrete Inputs and Coils\n  ## measurement - the (optional) measurement name, defaults to "modbus"\n  ## name        - the variable name\n  ## address     - variable address\n\n  discrete_inputs = [\n    { name = "start",          address = [0]},\n    { name = "stop",           address = [1]},\n    { name = "reset",          address = [2]},\n    { name = "emergency_stop", address = [3]},\n  ]\n  coils = [\n    { name = "motor1_run",     address = [0]},\n    { name = "motor1_jog",     address = [1]},\n    { name = "motor1_stop",    address = [2]},\n  ]\n\n  ## Analog Variables, Input Registers and Holding Registers\n  ## measurement - the (optional) measurement name, defaults to "modbus"\n  ## name        - the variable name\n  ## byte_order  - the ordering of bytes\n  ##  |---AB, ABCD   - Big Endian\n  ##  |---BA, DCBA   - Little Endian\n  ##  |---BADC       - Mid-Big Endian\n  ##  |---CDAB       - Mid-Little Endian\n  ## data_type  - INT16, UINT16, INT32, UINT32, INT64, UINT64, FLOAT32-IEEE, FLOAT64-IEEE (the IEEE 754 binary representation)\n  ##              FLOAT32 (deprecated), FIXED, UFIXED (fixed-point representation on input)\n  ## scale      - the final numeric variable representation\n  ## address    - variable address\n\n  holding_registers = [\n    { name = "power_factor", byte_order = "AB",   data_type = "FIXED", scale=0.01,  address = [8]},\n    { name = "voltage",      byte_order = "AB",   data_type = "FIXED", scale=0.1,   address = [0]},\n    { name = "energy",       byte_order = "ABCD", data_type = "FIXED", scale=0.001, address = [5,6]},\n    { name = "current",      byte_order = "ABCD", data_type = "FIXED", scale=0.001, address = [1,2]},\n    { name = "frequency",    byte_order = "AB",   data_type = "UFIXED", scale=0.1,  address = [7]},\n    { name = "power",        byte_order = "ABCD", data_type = "UFIXED", scale=0.1,  address = [3,4]},\n  ]\n  input_registers = [\n    { name = "tank_level",   byte_order = "AB",   data_type = "INT16",   scale=1.0,     address = [0]},\n    { name = "tank_ph",      byte_order = "AB",   data_type = "INT16",   scale=1.0,     address = [1]},\n    { name = "pump1_speed",  byte_order = "ABCD", data_type = "INT32",   scale=1.0,     address = [3,4]},\n  ]\n```\n\n### Metrics\n\nMetric are custom and configured using the `discrete_inputs`, `coils`,\n`holding_register` and `input_registers` options.\n\n### Usage of `data_type`\n\nThe field `data_type` defines the representation of the data value on input from the modbus registers.\nThe input values are then converted from the given `data_type` to a type that is apropriate when\nsending the value to the output plugin. These output types are usually one of string,\ninteger or floating-point-number. The size of the output type is assumed to be large enough\nfor all supported input types. The mapping from the input type to the output type is fixed\nand cannot be configured.\n\n#### Integers: `INT16`, `UINT16`, `INT32`, `UINT32`, `INT64`, `UINT64`\n\nThese types are used for integer input values. Select the one that matches your modbus data source.\n\n#### Floating Point: `FLOAT32-IEEE`, `FLOAT64-IEEE`\n\nUse these types if your modbus registers contain a value that is encoded in this format. These types\nalways include the sign and therefore there exists no variant.\n\n#### Fixed Point: `FIXED`, `UFIXED` (`FLOAT32`)\n\nThese types are handled as an integer type on input, but are converted to floating point representation\nfor further processing (e.g. scaling). Use one of these types when the input value is a decimal fixed point\nrepresentation of a non-integer value.\n\nSelect the type `UFIXED` when the input type is declared to hold unsigned integer values, which cannot\nbe negative. The documentation of your modbus device should indicate this by a term like\n\'uint16 containing fixed-point representation with N decimal places\'.\n\nSelect the type `FIXED` when the input type is declared to hold signed integer values. Your documentation\nof the modbus device should indicate this with a term like \'int32 containing fixed-point representation\nwith N decimal places\'.\n\n(FLOAT32 is deprecated and should not be used any more. UFIXED provides the same conversion\nfrom unsigned values).\n\n### Trouble shooting\nModbus documentations are often a mess. People confuse memory-address (starts at one) and register address (starts at zero) or stay unclear about the used word-order. Furthermore, there are some non-standard implementations that also\nswap the bytes within the register word (16-bit).\n\nIf you get an error or don\'t get the expected values from your device, you can try the following steps (assuming a 32-bit value).\n\nIn case are using a serial device and get an `permission denied` error, please check the permissions of your serial device and change accordingly.\n\nIn case you get an `exception \'2\' (illegal data address)` error you might try to offset your `address` entries by minus one as it is very likely that there is a confusion between memory and register addresses.\n\nIn case you see strange values, the `byte_order` might be off. You can either probe all combinations (`ABCD`, `CDBA`, `BADC` or `DCBA`) or you set `byte_order="ABCD" data_type="UINT32"` and use the resulting value(s) in an online converter like [this](https://www.scadacore.com/tools/programming-calculators/online-hex-converter/). This makes especially sense if you don\'t want to mess with the device, deal with 64-bit values and/or don\'t know the `data_type` of your register (e.g. fix-point floating values vs. IEEE floating point).\n\nIf nothing helps, please post your configuration, error message and/or the output of `byte_order="ABCD" data_type="UINT32"` to one of the telegraf support channels (forum, slack or as issue).\n\n### Example Output\n\n```sh\n$ ./telegraf -config telegraf.conf -input-filter modbus -test\nmodbus.InputRegisters,host=orangepizero Current=0,Energy=0,Frecuency=60,Power=0,PowerFactor=0,Voltage=123.9000015258789 1554079521000000000\n```\n',image:Xn.a},{id:"mongodb",name:"MongoDB",markdown:'# MongoDB Input Plugin\n\n### Configuration:\n\n```toml\n[[inputs.mongodb]]\n  ## An array of URLs of the form:\n  ##   "mongodb://" [user ":" pass "@"] host [ ":" port]\n  ## For example:\n  ##   mongodb://user:auth_key@10.10.3.30:27017,\n  ##   mongodb://10.10.3.33:18832,\n  servers = ["mongodb://127.0.0.1:27017"]\n\n  ## When true, collect cluster status.\n  ## Note that the query that counts jumbo chunks triggers a COLLSCAN, which\n  ## may have an impact on performance.\n  # gather_cluster_status = true\n\n  ## When true, collect per database stats\n  # gather_perdb_stats = false\n\n  ## When true, collect per collection stats\n  # gather_col_stats = false\n  \n  ## When true, collect usage statistics for each collection\n  ## (insert, update, queries, remove, getmore, commands etc...).\n  # gather_top_stat = false\n\n  ## List of db where collections stats are collected\n  ## If empty, all db are concerned\n  # col_stats_dbs = ["local"]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n#### Permissions:\n\nIf your MongoDB instance has access control enabled you will need to connect\nas a user with sufficient rights.\n\nWith MongoDB 3.4 and higher, the `clusterMonitor` role can be used.  In\nversion 3.2 you may also need these additional permissions:\n```\n> db.grantRolesToUser("user", [{role: "read", actions: "find", db: "local"}])\n```\n\nIf the user is missing required privileges you may see an error in the\nTelegraf logs similar to:\n```\nError in input [mongodb]: not authorized on admin to execute command { serverStatus: 1, recordStats: 0 }\n```\n\nSome permission related errors are logged at debug level, you can check these\nmessages by setting `debug = true` in the agent section of the configuration or\nby running Telegraf with the `--debug` argument.\n\n### Metrics:\n\n- mongodb\n  - tags:\n    - hostname\n    - node_type\n    - rs_name\n  - fields:\n    - active_reads (integer)\n    - active_writes (integer)\n    - aggregate_command_failed (integer)\n    - aggregate_command_total (integer)\n    - assert_msg (integer)\n    - assert_regular (integer)\n    - assert_rollovers (integer)\n    - assert_user (integer)\n    - assert_warning (integer)\n    - available_reads (integer)\n    - available_writes (integer)\n    - commands (integer)\n    - connections_available (integer)\n    - connections_current (integer)\n    - connections_total_created (integer)\n    - count_command_failed (integer)\n    - count_command_total (integer)\n    - cursor_no_timeout_count (integer)\n    - cursor_pinned_count (integer)\n    - cursor_timed_out_count (integer)\n    - cursor_total_count (integer)\n    - delete_command_failed (integer)\n    - delete_command_total (integer)\n    - deletes (integer)\n    - distinct_command_failed (integer)\n    - distinct_command_total (integer)\n    - document_deleted (integer)\n    - document_inserted (integer)\n    - document_returned (integer)\n    - document_updated (integer)\n    - find_and_modify_command_failed (integer)\n    - find_and_modify_command_total (integer)\n    - find_command_failed (integer)\n    - find_command_total (integer)\n    - flushes (integer)\n    - flushes_total_time_ns (integer)\n    - get_more_command_failed (integer)\n    - get_more_command_total (integer)\n    - getmores (integer)\n    - insert_command_failed (integer)\n    - insert_command_total (integer)\n    - inserts (integer)\n    - jumbo_chunks (integer)\n    - latency_commands_count (integer)\n    - latency_commands (integer)\n    - latency_reads_count (integer)\n    - latency_reads (integer)\n    - latency_writes_count (integer)\n    - latency_writes (integer)\n    - member_status (string)\n    - net_in_bytes_count (integer)\n    - net_out_bytes_count (integer)\n    - open_connections (integer)\n    - operation_scan_and_order (integer)\n    - operation_write_conflicts (integer)\n    - page_faults (integer)\n    - percent_cache_dirty (float)\n    - percent_cache_used (float)\n    - queries (integer)\n    - queued_reads (integer)\n    - queued_writes (integer)\n    - repl_apply_batches_num (integer)\n    - repl_apply_batches_total_millis (integer)\n    - repl_apply_ops (integer)\n    - repl_buffer_count (integer)\n    - repl_buffer_size_bytes (integer)\n    - repl_commands (integer)\n    - repl_deletes (integer)\n    - repl_executor_pool_in_progress_count (integer)\n    - repl_executor_queues_network_in_progress (integer)\n    - repl_executor_queues_sleepers (integer)\n    - repl_executor_unsignaled_events (integer)\n    - repl_getmores (integer)\n    - repl_inserts (integer)\n    - repl_lag (integer)\n    - repl_network_bytes (integer)\n    - repl_network_getmores_num (integer)\n    - repl_network_getmores_total_millis (integer)\n    - repl_network_ops (integer)\n    - repl_queries (integer)\n    - repl_updates (integer)\n    - repl_oplog_window_sec (integer)\n    - repl_state (integer)\n    - resident_megabytes (integer)\n    - state (string)\n    - storage_freelist_search_bucket_exhausted (integer)\n    - storage_freelist_search_requests (integer)\n    - storage_freelist_search_scanned (integer)\n    - tcmalloc_central_cache_free_bytes (integer)\n    - tcmalloc_current_allocated_bytes (integer)\n    - tcmalloc_current_total_thread_cache_bytes (integer)\n    - tcmalloc_heap_size (integer)\n    - tcmalloc_max_total_thread_cache_bytes (integer)\n    - tcmalloc_pageheap_commit_count (integer)\n    - tcmalloc_pageheap_committed_bytes (integer)\n    - tcmalloc_pageheap_decommit_count (integer)\n    - tcmalloc_pageheap_free_bytes (integer)\n    - tcmalloc_pageheap_reserve_count (integer)\n    - tcmalloc_pageheap_scavenge_count (integer)\n    - tcmalloc_pageheap_total_commit_bytes (integer)\n    - tcmalloc_pageheap_total_decommit_bytes (integer)\n    - tcmalloc_pageheap_total_reserve_bytes (integer)\n    - tcmalloc_pageheap_unmapped_bytes (integer)\n    - tcmalloc_spinlock_total_delay_ns (integer)\n    - tcmalloc_thread_cache_free_bytes (integer)\n    - tcmalloc_total_free_bytes (integer)\n    - tcmalloc_transfer_cache_free_bytes (integer)\n    - total_available (integer)\n    - total_created (integer)\n    - total_docs_scanned (integer)\n    - total_in_use (integer)\n    - total_keys_scanned (integer)\n    - total_refreshing (integer)\n    - total_tickets_reads (integer)\n    - total_tickets_writes (integer)\n    - ttl_deletes (integer)\n    - ttl_passes (integer)\n    - update_command_failed (integer)\n    - update_command_total (integer)\n    - updates (integer)\n    - uptime_ns (integer)\n    - version (string)\n    - vsize_megabytes (integer)\n    - wtcache_app_threads_page_read_count (integer)\n    - wtcache_app_threads_page_read_time (integer)\n    - wtcache_app_threads_page_write_count (integer)\n    - wtcache_bytes_read_into (integer)\n    - wtcache_bytes_written_from (integer)\n    - wtcache_pages_read_into (integer)\n    - wtcache_pages_requested_from (integer)\n    - wtcache_current_bytes (integer)\n    - wtcache_max_bytes_configured (integer)\n    - wtcache_internal_pages_evicted (integer)\n    - wtcache_modified_pages_evicted (integer)\n    - wtcache_unmodified_pages_evicted (integer)\n    - wtcache_pages_evicted_by_app_thread (integer)\n    - wtcache_pages_queued_for_eviction (integer)\n    - wtcache_server_evicting_pages (integer)\n    - wtcache_tracked_dirty_bytes (integer)\n    - wtcache_worker_thread_evictingpages (integer)\n    - commands_per_sec (integer, deprecated in 1.10; use `commands`))\n    - cursor_no_timeout (integer, opened/sec, deprecated in 1.10; use `cursor_no_timeout_count`))\n    - cursor_pinned (integer, opened/sec, deprecated in 1.10; use `cursor_pinned_count`))\n    - cursor_timed_out (integer, opened/sec, deprecated in 1.10; use `cursor_timed_out_count`))\n    - cursor_total (integer, opened/sec, deprecated in 1.10; use `cursor_total_count`))\n    - deletes_per_sec (integer, deprecated in 1.10; use `deletes`))\n    - flushes_per_sec (integer, deprecated in 1.10; use `flushes`))\n    - getmores_per_sec (integer, deprecated in 1.10; use `getmores`))\n    - inserts_per_sec (integer, deprecated in 1.10; use `inserts`))\n    - net_in_bytes (integer, bytes/sec, deprecated in 1.10; use `net_out_bytes_count`))\n    - net_out_bytes (integer, bytes/sec, deprecated in 1.10; use `net_out_bytes_count`))\n    - queries_per_sec (integer, deprecated in 1.10; use `queries`))\n    - repl_commands_per_sec (integer, deprecated in 1.10; use `repl_commands`))\n    - repl_deletes_per_sec (integer, deprecated in 1.10; use `repl_deletes`)\n    - repl_getmores_per_sec (integer, deprecated in 1.10; use `repl_getmores`)\n    - repl_inserts_per_sec (integer, deprecated in 1.10; use `repl_inserts`))\n    - repl_queries_per_sec (integer, deprecated in 1.10; use `repl_queries`))\n    - repl_updates_per_sec (integer, deprecated in 1.10; use `repl_updates`))\n    - ttl_deletes_per_sec (integer, deprecated in 1.10; use `ttl_deletes`))\n    - ttl_passes_per_sec (integer, deprecated in 1.10; use `ttl_passes`))\n    - updates_per_sec (integer, deprecated in 1.10; use `updates`))\n\n+ mongodb_db_stats\n  - tags:\n    - db_name\n    - hostname\n  - fields:\n    - avg_obj_size (float)\n    - collections (integer)\n    - data_size (integer)\n    - index_size (integer)\n    - indexes (integer)\n    - num_extents (integer)\n    - objects (integer)\n    - ok (integer)\n    - storage_size (integer)\n    - type (string)\n\n- mongodb_col_stats\n  - tags:\n    - hostname\n    - collection\n    - db_name\n  - fields:\n    - size (integer)\n    - avg_obj_size (integer)\n    - storage_size (integer)\n    - total_index_size (integer)\n    - ok (integer)\n    - count (integer)\n    - type (string)\n\n- mongodb_shard_stats\n  - tags:\n    - hostname\n  - fields:\n    - in_use (integer)\n    - available (integer)\n    - created (integer)\n    - refreshing (integer)\n  \n- mongodb_top_stats\n  - tags:\n    - collection\n  - fields:\n    - total_time (integer)\n    - total_count (integer)\n    - read_lock_time (integer)\n    - read_lock_count (integer)\n    - write_lock_time (integer)\n    - write_lock_count (integer)\n    - queries_time (integer)\n    - queries_count (integer)\n    - get_more_time (integer)\n    - get_more_count (integer)\n    - insert_time (integer)\n    - insert_count (integer)\n    - update_time (integer)\n    - update_count (integer)\n    - remove_time (integer)\n    - remove_count (integer)\n    - commands_time (integer)\n    - commands_count (integer)\n\n### Example Output:\n```\nmongodb,hostname=127.0.0.1:27017 active_reads=3i,active_writes=0i,aggregate_command_failed=0i,aggregate_command_total=87210i,assert_msg=0i,assert_regular=0i,assert_rollovers=0i,assert_user=0i,assert_warning=0i,available_reads=125i,available_writes=128i,commands=218126i,commands_per_sec=1876i,connections_available=838853i,connections_current=7i,connections_total_created=8i,count_command_failed=0i,count_command_total=7i,cursor_no_timeout=0i,cursor_no_timeout_count=0i,cursor_pinned=0i,cursor_pinned_count=0i,cursor_timed_out=0i,cursor_timed_out_count=0i,cursor_total=0i,cursor_total_count=0i,delete_command_failed=0i,delete_command_total=0i,deletes=0i,deletes_per_sec=0i,distinct_command_failed=0i,distinct_command_total=87190i,document_deleted=0i,document_inserted=0i,document_returned=7i,document_updated=43595i,find_and_modify_command_failed=0i,find_and_modify_command_total=43595i,find_command_failed=0i,find_command_total=348819i,flushes=1i,flushes_per_sec=0i,flushes_total_time_ns=5000000i,get_more_command_failed=0i,get_more_command_total=0i,getmores=7i,getmores_per_sec=1i,insert_command_failed=0i,insert_command_total=0i,inserts=0i,inserts_per_sec=0i,jumbo_chunks=0i,latency_commands=44179i,latency_commands_count=122i,latency_reads=36662189i,latency_reads_count=523229i,latency_writes=6768713i,latency_writes_count=87190i,net_in_bytes=837378i,net_in_bytes_count=97692502i,net_out_bytes=690836i,net_out_bytes_count=75377383i,open_connections=7i,operation_scan_and_order=87193i,operation_write_conflicts=7i,page_faults=0i,percent_cache_dirty=0.9,percent_cache_used=1,queries=348816i,queries_per_sec=2988i,queued_reads=0i,queued_writes=0i,resident_megabytes=77i,storage_freelist_search_bucket_exhausted=0i,storage_freelist_search_requests=0i,storage_freelist_search_scanned=0i,tcmalloc_central_cache_free_bytes=280136i,tcmalloc_current_allocated_bytes=77677288i,tcmalloc_current_total_thread_cache_bytes=1222608i,tcmalloc_heap_size=142659584i,tcmalloc_max_total_thread_cache_bytes=260046848i,tcmalloc_pageheap_commit_count=1898i,tcmalloc_pageheap_committed_bytes=130084864i,tcmalloc_pageheap_decommit_count=889i,tcmalloc_pageheap_free_bytes=50610176i,tcmalloc_pageheap_reserve_count=50i,tcmalloc_pageheap_scavenge_count=884i,tcmalloc_pageheap_total_commit_bytes=13021937664i,tcmalloc_pageheap_total_decommit_bytes=12891852800i,tcmalloc_pageheap_total_reserve_bytes=142659584i,tcmalloc_pageheap_unmapped_bytes=12574720i,tcmalloc_spinlock_total_delay_ns=9767500i,tcmalloc_thread_cache_free_bytes=1222608i,tcmalloc_total_free_bytes=1797400i,tcmalloc_transfer_cache_free_bytes=294656i,total_available=0i,total_created=0i,total_docs_scanned=43595i,total_in_use=0i,total_keys_scanned=130805i,total_refreshing=0i,total_tickets_reads=128i,total_tickets_writes=128i,ttl_deletes=0i,ttl_deletes_per_sec=0i,ttl_passes=0i,ttl_passes_per_sec=0i,update_command_failed=0i,update_command_total=43595i,updates=43595i,updates_per_sec=372i,uptime_ns=60023000000i,version="3.6.17",vsize_megabytes=1048i,wtcache_app_threads_page_read_count=108i,wtcache_app_threads_page_read_time=25995i,wtcache_app_threads_page_write_count=0i,wtcache_bytes_read_into=2487250i,wtcache_bytes_written_from=74i,wtcache_current_bytes=5014530i,wtcache_internal_pages_evicted=0i,wtcache_max_bytes_configured=505413632i,wtcache_modified_pages_evicted=0i,wtcache_pages_evicted_by_app_thread=0i,wtcache_pages_queued_for_eviction=0i,wtcache_pages_read_into=139i,wtcache_pages_requested_from=699135i,wtcache_server_evicting_pages=0i,wtcache_tracked_dirty_bytes=4797426i,wtcache_unmodified_pages_evicted=0i,wtcache_worker_thread_evictingpages=0i 1586379818000000000\nmongodb,hostname=127.0.0.1:27017,node_type=SEC,rs_name=rs0 active_reads=1i,active_writes=0i,aggregate_command_failed=0i,aggregate_command_total=1i,assert_msg=0i,assert_regular=0i,assert_rollovers=0i,assert_user=79i,assert_warning=0i,available_reads=127i,available_writes=128i,commands=1121855i,commands_per_sec=10i,connections_available=51183i,connections_current=17i,connections_total_created=557i,count_command_failed=0i,count_command_total=46307i,cursor_no_timeout=0i,cursor_no_timeout_count=0i,cursor_pinned=0i,cursor_pinned_count=0i,cursor_timed_out=0i,cursor_timed_out_count=28i,cursor_total=0i,cursor_total_count=0i,delete_command_failed=0i,delete_command_total=0i,deletes=0i,deletes_per_sec=0i,distinct_command_failed=0i,distinct_command_total=0i,document_deleted=0i,document_inserted=0i,document_returned=2248129i,document_updated=0i,find_and_modify_command_failed=0i,find_and_modify_command_total=0i,find_command_failed=2i,find_command_total=8764i,flushes=7850i,flushes_per_sec=0i,flushes_total_time_ns=4535446000000i,get_more_command_failed=0i,get_more_command_total=1993i,getmores=2018i,getmores_per_sec=0i,insert_command_failed=0i,insert_command_total=0i,inserts=0i,inserts_per_sec=0i,jumbo_chunks=0i,latency_commands=112011949i,latency_commands_count=1072472i,latency_reads=1877142443i,latency_reads_count=57086i,latency_writes=0i,latency_writes_count=0i,member_status="SEC",net_in_bytes=1212i,net_in_bytes_count=263928689i,net_out_bytes=41051i,net_out_bytes_count=2475389483i,open_connections=17i,operation_scan_and_order=34i,operation_write_conflicts=0i,page_faults=317i,percent_cache_dirty=1.6,percent_cache_used=73,queries=8764i,queries_per_sec=0i,queued_reads=0i,queued_writes=0i,repl_apply_batches_num=17839419i,repl_apply_batches_total_millis=399929i,repl_apply_ops=23355263i,repl_buffer_count=0i,repl_buffer_size_bytes=0i,repl_commands=11i,repl_commands_per_sec=0i,repl_deletes=440608i,repl_deletes_per_sec=0i,repl_executor_pool_in_progress_count=0i,repl_executor_queues_network_in_progress=0i,repl_executor_queues_sleepers=4i,repl_executor_unsignaled_events=0i,repl_getmores=0i,repl_getmores_per_sec=0i,repl_inserts=1875729i,repl_inserts_per_sec=0i,repl_lag=0i,repl_network_bytes=39122199371i,repl_network_getmores_num=34908797i,repl_network_getmores_total_millis=434805356i,repl_network_ops=23199086i,repl_oplog_window_sec=619292i,repl_queries=0i,repl_queries_per_sec=0i,repl_updates=21034729i,repl_updates_per_sec=38i,repl_state=2,resident_megabytes=6721i,state="SECONDARY",storage_freelist_search_bucket_exhausted=0i,storage_freelist_search_requests=0i,storage_freelist_search_scanned=0i,tcmalloc_central_cache_free_bytes=358512400i,tcmalloc_current_allocated_bytes=5427379424i,tcmalloc_current_total_thread_cache_bytes=70349552i,tcmalloc_heap_size=10199310336i,tcmalloc_max_total_thread_cache_bytes=1073741824i,tcmalloc_pageheap_commit_count=790819i,tcmalloc_pageheap_committed_bytes=7064821760i,tcmalloc_pageheap_decommit_count=533347i,tcmalloc_pageheap_free_bytes=1207816192i,tcmalloc_pageheap_reserve_count=7706i,tcmalloc_pageheap_scavenge_count=426235i,tcmalloc_pageheap_total_commit_bytes=116127649792i,tcmalloc_pageheap_total_decommit_bytes=109062828032i,tcmalloc_pageheap_total_reserve_bytes=10199310336i,tcmalloc_pageheap_unmapped_bytes=3134488576i,tcmalloc_spinlock_total_delay_ns=2518474348i,tcmalloc_thread_cache_free_bytes=70349552i,tcmalloc_total_free_bytes=429626144i,tcmalloc_transfer_cache_free_bytes=764192i,total_available=0i,total_created=0i,total_docs_scanned=735004782i,total_in_use=0i,total_keys_scanned=6188216i,total_refreshing=0i,total_tickets_reads=128i,total_tickets_writes=128i,ttl_deletes=0i,ttl_deletes_per_sec=0i,ttl_passes=7892i,ttl_passes_per_sec=0i,update_command_failed=0i,update_command_total=0i,updates=0i,updates_per_sec=0i,uptime_ns=473590288000000i,version="3.6.17",vsize_megabytes=11136i,wtcache_app_threads_page_read_count=11467625i,wtcache_app_threads_page_read_time=1700336840i,wtcache_app_threads_page_write_count=13268184i,wtcache_bytes_read_into=348022587843i,wtcache_bytes_written_from=322571702254i,wtcache_current_bytes=5509459274i,wtcache_internal_pages_evicted=109108i,wtcache_max_bytes_configured=7547650048i,wtcache_modified_pages_evicted=911196i,wtcache_pages_evicted_by_app_thread=17366i,wtcache_pages_queued_for_eviction=16572754i,wtcache_pages_read_into=11689764i,wtcache_pages_requested_from=499825861i,wtcache_server_evicting_pages=0i,wtcache_tracked_dirty_bytes=117487510i,wtcache_unmodified_pages_evicted=11058458i,wtcache_worker_thread_evictingpages=11907226i 1586379707000000000\nmongodb_db_stats,db_name=admin,hostname=127.0.0.1:27017 avg_obj_size=241,collections=2i,data_size=723i,index_size=49152i,indexes=3i,num_extents=0i,objects=3i,ok=1i,storage_size=53248i,type="db_stat" 1547159491000000000\nmongodb_db_stats,db_name=local,hostname=127.0.0.1:27017 avg_obj_size=813.9705882352941,collections=6i,data_size=55350i,index_size=102400i,indexes=5i,num_extents=0i,objects=68i,ok=1i,storage_size=204800i,type="db_stat" 1547159491000000000\nmongodb_col_stats,collection=foo,db_name=local,hostname=127.0.0.1:27017 size=375005928i,avg_obj_size=5494,type="col_stat",storage_size=249307136i,total_index_size=2138112i,ok=1i,count=68251i 1547159491000000000\nmongodb_shard_stats,hostname=127.0.0.1:27017,in_use=3i,available=3i,created=4i,refreshing=0i 1522799074000000000\nmongodb_top_stats,collection=foo,total_time=1471,total_count=158,read_lock_time=49614,read_lock_count=657,write_lock_time=49125456,write_lock_count=9841,queries_time=174,queries_count=495,get_more_time=498,get_more_count=46,insert_time=2651,insert_count=1265,update_time=0,update_count=0,remove_time=0,remove_count=0,commands_time=498611,commands_count=4615\n```\n',image:$n.a},{id:"monit",name:"Monit",markdown:'# Monit Input Plugin\n\nThe `monit` plugin gathers metrics and status information about local processes,\nremote hosts, file, file systems, directories and network interfaces managed\nand watched over by [Monit][monit].\n\nThe use this plugin you should first enable the [HTTPD TCP port][httpd] in\nMonit.\n\nMinimum Version of Monit tested with is 5.16.\n\n[monit]: https://mmonit.com/\n[httpd]: https://mmonit.com/monit/documentation/monit.html#TCP-PORT\n\n### Configuration\n\n```toml\n[[inputs.monit]]\n  ## Monit HTTPD address\n  address = "http://127.0.0.1:2812"\n\n  ## Username and Password for Monit\n  # username = ""\n  # password = ""\n\n  ## Amount of time allowed to complete the HTTP request\n  # timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- monit_filesystem\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - mode\n    - block_percent\n    - block_usage\n    - block_total\n    - inode_percent\n    - inode_usage\n    - inode_total\n\n+ monit_directory\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - permissions\n\n- monit_file\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - size\n    - permissions\n\n+ monit_process\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - cpu_percent\n    - cpu_percent_total\n    - mem_kb\n    - mem_kb_total\n    - mem_percent\n    - mem_percent_total\n    - pid\n    - parent_pid\n    - threads\n    - children\n\n- monit_remote_host\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - hostname\n    - port_number\n    - request\n    - response_time\n    - protocol\n    - type\n\n+ monit_system\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n    - cpu_system\n    - cpu_user\n    - cpu_wait\n    - cpu_load_avg_1m\n    - cpu_load_avg_5m\n    - cpu_load_avg_15m\n    - mem_kb\n    - mem_percent\n    - swap_kb\n    - swap_percent\n\n- monit_fifo\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n\t- permissions\n\n+ monit_program\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n\n- monit_network\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n\n+ monit_program\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n\n- monit_network\n  - tags:\n    - address\n    - version\n    - service\n    - platform_name\n    - status\n    - monitoring_status\n    - monitoring_mode\n  - fields:\n    - status_code\n    - monitoring_status_code\n    - monitoring_mode_code\n\n### Example Output\n```\nmonit_file,monitoring_mode=active,monitoring_status=monitored,pending_action=none,platform_name=Linux,service=rsyslog_pid,source=xyzzy.local,status=running,version=5.20.0 mode=644i,monitoring_mode_code=0i,monitoring_status_code=1i,pending_action_code=0i,size=3i,status_code=0i 1579735047000000000\nmonit_process,monitoring_mode=active,monitoring_status=monitored,pending_action=none,platform_name=Linux,service=rsyslog,source=xyzzy.local,status=running,version=5.20.0 children=0i,cpu_percent=0,cpu_percent_total=0,mem_kb=3148i,mem_kb_total=3148i,mem_percent=0.2,mem_percent_total=0.2,monitoring_mode_code=0i,monitoring_status_code=1i,parent_pid=1i,pending_action_code=0i,pid=318i,status_code=0i,threads=4i 1579735047000000000\nmonit_program,monitoring_mode=active,monitoring_status=initializing,pending_action=none,platform_name=Linux,service=echo,source=xyzzy.local,status=running,version=5.20.0 monitoring_mode_code=0i,monitoring_status_code=2i,pending_action_code=0i,program_started=0i,program_status=0i,status_code=0i 1579735047000000000\nmonit_system,monitoring_mode=active,monitoring_status=monitored,pending_action=none,platform_name=Linux,service=debian-stretch-monit.virt,source=xyzzy.local,status=running,version=5.20.0 cpu_load_avg_15m=0,cpu_load_avg_1m=0,cpu_load_avg_5m=0,cpu_system=0,cpu_user=0,cpu_wait=0,mem_kb=42852i,mem_percent=2.1,monitoring_mode_code=0i,monitoring_status_code=1i,pending_action_code=0i,status_code=0i,swap_kb=0,swap_percent=0 1579735047000000000\nmonit_remote_host,dc=new-12,host=palladium,monitoring_mode=active,monitoring_status=monitored,pending_action=none,platform_name=Linux,rack=rack-0,service=blog.kalvad.com,source=palladium,status=running,version=5.27.0 monitoring_status_code=1i,monitoring_mode_code=0i,response_time=0.664412,type="TCP",pending_action_code=0i,remote_hostname="blog.kalvad.com",port_number=443i,request="/",protocol="HTTP",status_code=0i 1599138990000000000\n```\n',image:Zn.a},{id:"mqtt_consumer",name:"MQTT Consumer",markdown:'# MQTT Consumer Input Plugin\n\nThe [MQTT](https://mqtt.org) consumer plugin reads from the specified MQTT topics\nand creates metrics using one of the supported [input data formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).\n\n### Configuration\n\n```toml\n[[inputs.mqtt_consumer]]\n  ## Broker URLs for the MQTT server or cluster.  To connect to multiple\n  ## clusters or standalone servers, use a seperate plugin instance.\n  ##   example: servers = ["tcp://localhost:1883"]\n  ##            servers = ["ssl://localhost:1883"]\n  ##            servers = ["ws://localhost:1883"]\n  servers = ["tcp://127.0.0.1:1883"]\n\n  ## Topics that will be subscribed to.\n  topics = [\n    "telegraf/host01/cpu",\n    "telegraf/+/mem",\n    "sensors/#",\n  ]\n\n  ## The message topic will be stored in a tag specified by this value.  If set\n  ## to the empty string no topic tag will be created.\n  # topic_tag = "topic"\n\n  ## QoS policy for messages\n  ##   0 = at most once\n  ##   1 = at least once\n  ##   2 = exactly once\n  ##\n  ## When using a QoS of 1 or 2, you should enable persistent_session to allow\n  ## resuming unacknowledged messages.\n  # qos = 0\n\n  ## Connection timeout for initial connection in seconds\n  # connection_timeout = "30s"\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Persistent session disables clearing of the client session on connection.\n  ## In order for this option to work you must also set client_id to identify\n  ## the client.  To receive messages that arrived while the client is offline,\n  ## also set the qos option to 1 or 2 and don\'t forget to also set the QoS when\n  ## publishing.\n  # persistent_session = false\n\n  ## If unset, a random client ID will be generated.\n  # client_id = ""\n\n  ## Username and password to connect MQTT server.\n  # username = "telegraf"\n  # password = "metricsmetricsmetricsmetrics"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n### Metrics\n\n- All measurements are tagged with the incoming topic, ie\n`topic=telegraf/host01/cpu`\n',image:ts.a},{id:"multifile",name:"Multifile",markdown:'# Multifile Input Plugin\n\nThe multifile input plugin allows Telegraf to combine data from multiple files\ninto a single metric, creating one field or tag per file.  This is often\nuseful creating custom metrics from the `/sys` or `/proc` filesystems.\n\n> Note: If you wish to parse metrics from a single file formatted in one of the supported\n> [input data formats][], you should use the [file][] input plugin instead.\n\n### Configuration\n```toml\n[[inputs.multifile]]\n  ## Base directory where telegraf will look for files.\n  ## Omit this option to use absolute paths.\n  base_dir = "/sys/bus/i2c/devices/1-0076/iio:device0"\n\n  ## If true discard all data when a single file can\'t be read.\n  ## Else, Telegraf omits the field generated from this file.\n  # fail_early = true\n\n  ## Files to parse each interval.\n  [[inputs.multifile.file]]\n    file = "in_pressure_input"\n    dest = "pressure"\n    conversion = "float"\n  [[inputs.multifile.file]]\n    file = "in_temp_input"\n    dest = "temperature"\n    conversion = "float(3)"\n  [[inputs.multifile.file]]\n    file = "in_humidityrelative_input"\n    dest = "humidityrelative"\n    conversion = "float(3)"\n```\n\nEach file table can contain the following options:\n* `file`:\nPath of the file to be parsed, relative to the `base_dir`.\n* `dest`:\nName of the field/tag key, defaults to `$(basename file)`.\n* `conversion`:\nData format used to parse the file contents:\n\t* `float(X)`: Converts the input value into a float and divides by the Xth power of 10. Effectively just moves the decimal left X places. For example a value of `123` with `float(2)` will result in `1.23`.\n\t* `float`: Converts the value into a float with no adjustment. Same as `float(0)`.\n\t* `int`: Converts the value into an integer.\n\t* `string`, `""`: No conversion.\n\t* `bool`: Converts the value into a boolean.\n\t* `tag`: File content is used as a tag.\n\n### Example Output\nThis example shows a BME280 connected to a Raspberry Pi, using the sample config.\n```\nmultifile pressure=101.343285156,temperature=20.4,humidityrelative=48.9 1547202076000000000\n```\n\nTo reproduce this, connect a BMP280 to the board\'s GPIO pins and register the BME280 device driver\n```\ncd /sys/bus/i2c/devices/i2c-1\necho bme280 0x76 > new_device\n```\n\nThe kernel driver provides the following files in `/sys/bus/i2c/devices/1-0076/iio:device0`:\n* `in_humidityrelative_input`: `48900`\n* `in_pressure_input`: `101.343285156`\n* `in_temp_input`: `20400`\n\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n[file]: /plugins/inputs/file/README.md\n',image:ss.a},{id:"mysql",name:"MySQL",markdown:'# MySQL Input Plugin\n\nThis plugin gathers the statistic data from MySQL server\n\n* Global statuses\n* Global variables\n* Slave statuses\n* Binlog size\n* Process list\n* User Statistics\n* Info schema auto increment columns\n* InnoDB metrics\n* Table I/O waits\n* Index I/O waits\n* Perf Schema table lock waits\n* Perf Schema event waits\n* Perf Schema events statements\n* File events statistics\n* Table schema statistics\n\n### Configuration\n\n```toml\n[[inputs.mysql]]\n  ## specify servers via a url matching:\n  ##  [username[:password]@][protocol[(address)]]/[?tls=[true|false|skip-verify|custom]]\n  ##  see https://github.com/go-sql-driver/mysql#dsn-data-source-name\n  ##  e.g.\n  ##    servers = ["user:passwd@tcp(127.0.0.1:3306)/?tls=false"]\n  ##    servers = ["user@tcp(127.0.0.1:3306)/?tls=false"]\n  #\n  ## If no servers are specified, then localhost is used as the host.\n  servers = ["tcp(127.0.0.1:3306)/"]\n\n  ## Selects the metric output format.\n  ##\n  ## This option exists to maintain backwards compatibility, if you have\n  ## existing metrics do not set or change this value until you are ready to\n  ## migrate to the new format.\n  ##\n  ## If you do not have existing metrics from this plugin set to the latest\n  ## version.\n  ##\n  ## Telegraf >=1.6: metric_version = 2\n  ##           <1.6: metric_version = 1 (or unset)\n  metric_version = 2\n\n  ## if the list is empty, then metrics are gathered from all database tables\n  # table_schema_databases = []\n\n  ## gather metrics from INFORMATION_SCHEMA.TABLES for databases provided above list\n  # gather_table_schema = false\n\n  ## gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST\n  # gather_process_list = false\n\n  ## gather user statistics from INFORMATION_SCHEMA.USER_STATISTICS\n  # gather_user_statistics = false\n\n  ## gather auto_increment columns and max values from information schema\n  # gather_info_schema_auto_inc = false\n\n  ## gather metrics from INFORMATION_SCHEMA.INNODB_METRICS\n  # gather_innodb_metrics = false\n\n  ## gather metrics from all channels from SHOW SLAVE STATUS command output\n  # gather_all_slave_channels = false\n  \n  ## gather metrics from SHOW SLAVE STATUS command output\n  # gather_slave_status = false\n\n  ## use SHOW ALL SLAVES STATUS command output for MariaDB\n  # mariadb_dialect = false\n\n  ## gather metrics from SHOW BINARY LOGS command output\n  # gather_binary_logs = false\n\n  ## gather metrics from SHOW GLOBAL VARIABLES command output\n  # gather_global_variables = true\n\n  ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE\n  # gather_table_io_waits = false\n\n  ## gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS\n  # gather_table_lock_waits = false\n\n  ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE\n  # gather_index_io_waits = false\n\n  ## gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS\n  # gather_event_waits = false\n\n  ## gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME\n  # gather_file_events_stats = false\n\n  ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST\n  # gather_perf_events_statements             = false\n  #\n  ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_ACCOUNT_BY_EVENT_NAME\n  # gather_perf_sum_per_acc_per_event         = false\n  #\n  ## list of events to be gathered for gather_perf_sum_per_acc_per_event\n  ## in case of empty list all events will be gathered\n  # perf_summary_events                       = []\n  #\n  # gather_perf_events_statements = false\n\n  ## the limits for metrics form perf_events_statements\n  # perf_events_statements_digest_text_limit = 120\n  # perf_events_statements_limit = 250\n  # perf_events_statements_time_limit = 86400\n\n  ## Some queries we may want to run less often (such as SHOW GLOBAL VARIABLES)\n  ##   example: interval_slow = "30m"\n  # interval_slow = ""\n\n  ## Optional TLS Config (will be used if tls=custom parameter specified in server uri)\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n#### Metric Version\n\nWhen `metric_version = 2`, a variety of field type issues are corrected as well\nas naming inconsistencies.  If you have existing data on the original version\nenabling this feature will cause a `field type error` when inserted into\nInfluxDB due to the change of types.  For this reason, you should keep the\n`metric_version` unset until you are ready to migrate to the new format.\n\nIf preserving your old data is not required you may wish to drop conflicting\nmeasurements:\n```sql\nDROP SERIES from mysql\nDROP SERIES from mysql_variables\nDROP SERIES from mysql_innodb\n```\n\nOtherwise, migration can be performed using the following steps:\n\n1. Duplicate your `mysql` plugin configuration and add a `name_suffix` and\n`metric_version = 2`, this will result in collection using both the old and new\nstyle concurrently:\n   ```toml\n   [[inputs.mysql]]\n     servers = ["tcp(127.0.0.1:3306)/"]\n\n   [[inputs.mysql]]\n     name_suffix = "_v2"\n     metric_version = 2\n\n     servers = ["tcp(127.0.0.1:3306)/"]\n   ```\n\n2. Upgrade all affected Telegraf clients to version >=1.6.\n\n   New measurements will be created with the `name_suffix`, for example::\n   - `mysql_v2`\n   - `mysql_variables_v2`\n\n3. Update charts, alerts, and other supporting code to the new format.\n4. You can now remove the old `mysql` plugin configuration and remove old\n   measurements.\n\nIf you wish to remove the `name_suffix` you may use Kapacitor to copy the\nhistorical data to the default name.  Do this only after retiring the old\nmeasurement name.\n\n1. Use the technique described above to write to multiple locations:\n   ```toml\n   [[inputs.mysql]]\n     servers = ["tcp(127.0.0.1:3306)/"]\n     metric_version = 2\n\n   [[inputs.mysql]]\n     name_suffix = "_v2"\n     metric_version = 2\n\n     servers = ["tcp(127.0.0.1:3306)/"]\n   ```\n2. Create a TICKScript to copy the historical data:\n   ```\n   dbrp "telegraf"."autogen"\n\n   batch\n       |query(\'\'\'\n           SELECT * FROM "telegraf"."autogen"."mysql_v2"\n       \'\'\')\n           .period(5m)\n           .every(5m)\n           |influxDBOut()\n                   .database(\'telegraf\')\n                   .retentionPolicy(\'autogen\')\n                   .measurement(\'mysql\')\n   ```\n3. Define a task for your script:\n   ```sh\n   kapacitor define copy-measurement -tick copy-measurement.task\n   ```\n4. Run the task over the data you would like to migrate:\n   ```sh\n   kapacitor replay-live batch -start 2018-03-30T20:00:00Z -stop 2018-04-01T12:00:00Z -rec-time -task copy-measurement\n   ```\n5. Verify copied data and repeat for other measurements.\n\n### Metrics:\n* Global statuses - all numeric and boolean values of `SHOW GLOBAL STATUSES`\n* Global variables - all numeric and boolean values of `SHOW GLOBAL VARIABLES`\n* Slave status - metrics from `SHOW SLAVE STATUS` the metrics are gathered when\nthe single-source replication is on. If the multi-source replication is set,\nthen everything works differently, this metric does not work with multi-source\nreplication, unless you set `gather_all_slave_channels = true`. For MariaDB,\n`mariadb_dialect = true` should be set to address the field names and commands\ndifferences.\n    * slave_[column name]()\n* Binary logs - all metrics including size and count of all binary files.\nRequires to be turned on in configuration.\n    * binary_size_bytes(int, number)\n    * binary_files_count(int, number)\n* Process list - connection metrics from processlist for each user. It has the following tags\n    * connections(int, number)\n* User Statistics - connection metrics from user statistics for each user. It has the following fields\n    * access_denied\n    * binlog_bytes_written\n    * busy_time\n    * bytes_received\n    * bytes_sent\n    * commit_transactions\n    * concurrent_connections\n    * connected_time\n    * cpu_time\n    * denied_connections\n    * empty_queries\n    * hostlost_connections\n    * other_commands\n    * rollback_transactions\n    * rows_fetched\n    * rows_updated\n    * select_commands\n    * server\n    * table_rows_read\n    * total_connections\n    * total_ssl_connections\n    * update_commands\n    * user\n* Perf Table IO waits - total count and time of I/O waits event for each table\nand process. It has following fields:\n    * table_io_waits_total_fetch(float, number)\n    * table_io_waits_total_insert(float, number)\n    * table_io_waits_total_update(float, number)\n    * table_io_waits_total_delete(float, number)\n    * table_io_waits_seconds_total_fetch(float, milliseconds)\n    * table_io_waits_seconds_total_insert(float, milliseconds)\n    * table_io_waits_seconds_total_update(float, milliseconds)\n    * table_io_waits_seconds_total_delete(float, milliseconds)\n* Perf index IO waits - total count and time of I/O waits event for each index\nand process. It has following fields:\n    * index_io_waits_total_fetch(float, number)\n    * index_io_waits_seconds_total_fetch(float, milliseconds)\n    * index_io_waits_total_insert(float, number)\n    * index_io_waits_total_update(float, number)\n    * index_io_waits_total_delete(float, number)\n    * index_io_waits_seconds_total_insert(float, milliseconds)\n    * index_io_waits_seconds_total_update(float, milliseconds)\n    * index_io_waits_seconds_total_delete(float, milliseconds)\n* Info schema autoincrement statuses - autoincrement fields and max values\nfor them. It has following fields:\n    * auto_increment_column(int, number)\n    * auto_increment_column_max(int, number)\n* InnoDB metrics - all metrics of information_schema.INNODB_METRICS with a status "enabled"\n* Perf table lock waits - gathers total number and time for SQL and external\nlock waits events for each table and operation. It has following fields.\nThe unit of fields varies by the tags.\n    * read_normal(float, number/milliseconds)\n    * read_with_shared_locks(float, number/milliseconds)\n    * read_high_priority(float, number/milliseconds)\n    * read_no_insert(float, number/milliseconds)\n    * write_normal(float, number/milliseconds)\n    * write_allow_write(float, number/milliseconds)\n    * write_concurrent_insert(float, number/milliseconds)\n    * write_low_priority(float, number/milliseconds)\n    * read(float, number/milliseconds)\n    * write(float, number/milliseconds)\n* Perf events waits - gathers total time and number of event waits\n    * events_waits_total(float, number)\n    * events_waits_seconds_total(float, milliseconds)\n* Perf file events statuses - gathers file events statuses\n    * file_events_total(float,number)\n    * file_events_seconds_total(float, milliseconds)\n    * file_events_bytes_total(float, bytes)\n* Perf events statements - gathers attributes of each event\n    * events_statements_total(float, number)\n    * events_statements_seconds_total(float, millieconds)\n    * events_statements_errors_total(float, number)\n    * events_statements_warnings_total(float, number)\n    * events_statements_rows_affected_total(float, number)\n    * events_statements_rows_sent_total(float, number)\n    * events_statements_rows_examined_total(float, number)\n    * events_statements_tmp_tables_total(float, number)\n    * events_statements_tmp_disk_tables_total(float, number)\n    * events_statements_sort_merge_passes_totals(float, number)\n    * events_statements_sort_rows_total(float, number)\n    * events_statements_no_index_used_total(float, number)\n* Table schema - gathers statistics of each schema. It has following measurements\n    * info_schema_table_rows(float, number)\n    * info_schema_table_size_data_length(float, number)\n    * info_schema_table_size_index_length(float, number)\n    * info_schema_table_size_data_free(float, number)\n    * info_schema_table_version(float, number)\n\n## Tags\n* All measurements has following tags\n    * server (the host name from which the metrics are gathered)\n* Process list measurement has following tags\n    * user (username for whom the metrics are gathered)\n* User Statistics measurement has following tags\n    * user (username for whom the metrics are gathered)\n* Perf table IO waits measurement has following tags\n    * schema\n    * name (object name for event or process)\n* Perf index IO waits has following tags\n    * schema\n    * name\n    * index\n* Info schema autoincrement statuses has following tags\n    * schema\n    * table\n    * column\n* Perf table lock waits has following tags\n    * schema\n    * table\n    * sql_lock_waits_total(fields including this tag have numeric unit)\n    * external_lock_waits_total(fields including this tag have numeric unit)\n    * sql_lock_waits_seconds_total(fields including this tag have millisecond unit)\n    * external_lock_waits_seconds_total(fields including this tag have millisecond unit)\n* Perf events statements has following tags\n    * event_name\n* Perf file events statuses has following tags\n    * event_name\n    * mode\n* Perf file events statements has following tags\n    * schema\n    * digest\n    * digest_text\n* Table schema has following tags\n    * schema\n    * table\n    * component\n    * type\n    * engine\n    * row_format\n    * create_options\n',image:is.a},{id:"nats",name:"NATS",markdown:'# NATS Input Plugin\n\nThe [NATS](http://www.nats.io/about/) monitoring plugin gathers metrics from\nthe NATS [monitoring http server](https://www.nats.io/documentation/server/gnatsd-monitoring/).\n\n### Configuration\n\n```toml\n[[inputs.nats]]\n  ## The address of the monitoring endpoint of the NATS server\n  server = "http://localhost:8222"\n\n  ## Maximum time to receive response\n  # response_timeout = "5s"\n```\n\n### Metrics:\n\n- nats\n  - tags\n    - server\n  - fields:\n    - uptime (integer, nanoseconds)\n    - mem (integer, bytes)\n    - subscriptions (integer, count)\n    - out_bytes (integer, bytes)\n    - connections (integer, count)\n    - in_msgs (integer, bytes)\n    - total_connections (integer, count)\n    - cores (integer, count)\n    - cpu (integer, count)\n    - slow_consumers (integer, count)\n    - routes (integer, count)\n    - remotes (integer, count)\n    - out_msgs (integer, count)\n    - in_bytes (integer, bytes)\n\n### Example Output:\n\n```\nnats,server=http://localhost:8222 uptime=117158348682i,mem=6647808i,subscriptions=0i,out_bytes=0i,connections=0i,in_msgs=0i,total_connections=0i,cores=2i,cpu=0,slow_consumers=0i,routes=0i,remotes=0i,out_msgs=0i,in_bytes=0i 1517015107000000000\n```\n',image:_s.a},{id:"nats_consumer",name:"NATS Consumer",markdown:'# NATS Consumer Input Plugin\n\nThe [NATS][nats] consumer plugin reads from the specified NATS subjects and\ncreates metrics using one of the supported [input data formats][].\n\nA [Queue Group][queue group] is used when subscribing to subjects so multiple\ninstances of telegraf can read from a NATS cluster in parallel.\n\n### Configuration:\n\n```toml\n[[inputs.nats_consumer]]\n  ## urls of NATS servers\n  servers = ["nats://localhost:4222"]\n\n  ## subject(s) to consume\n  subjects = ["telegraf"]\n\n  ## name a queue group\n  queue_group = "telegraf_consumers"\n\n  ## Optional credentials\n  # username = ""\n  # password = ""\n\n  ## Optional NATS 2.0 and NATS NGS compatible user credentials\n  # credentials = "/etc/telegraf/nats.creds"\n\n  ## Use Transport Layer Security\n  # secure = false\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Sets the limits for pending msgs and bytes for each subscription\n  ## These shouldn\'t need to be adjusted except in very high throughput scenarios\n  # pending_message_limit = 65536\n  # pending_bytes_limit = 67108864\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n[nats]: https://www.nats.io/about/\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n[queue group]: https://www.nats.io/documentation/concepts/nats-queueing/\n',image:rs.a},{id:"neptune_apex",name:"Neptune Apex",markdown:'# Neptune Apex Input Plugin\n\nThe Neptune Apex controller family allows an aquarium hobbyist to monitor and control\ntheir tanks based on various probes. The data is taken directly from the `/cgi-bin/status.xml` at the interval specified\nin the telegraf.conf configuration file.\n\nThe [Neptune Apex](https://www.neptunesystems.com/) input plugin collects real-time data from the Apex\'s status.xml page.\n\n\n### Configuration\n\n```toml\n[[inputs.neptune_apex]]\n  ## The Neptune Apex plugin reads the publicly available status.xml data from a local Apex.\n  ## Measurements will be logged under "apex".\n\n  ## The base URL of the local Apex(es). If you specify more than one server, they will\n  ## be differentiated by the "source" tag.\n  servers = [\n    "http://apex.local",\n  ]\n\n  ## The response_timeout specifies how long to wait for a reply from the Apex.\n  #response_timeout = "5s"\n\n```\n\n### Metrics\n\nThe Neptune Apex controller family allows an aquarium hobbyist to monitor and control\ntheir tanks based on various probes. The data is taken directly from the /cgi-bin/status.xml at the interval specified\nin the telegraf.conf configuration file.\n\nNo manipulation is done on any of the fields to ensure future changes to the status.xml do not introduce conversion bugs\nto this plugin. When reasonable and predictable, some tags are derived to make graphing easier and without front-end\nprogramming. These tags are clearly marked in the list below and should be considered a convenience rather than authoritative.\n\n- neptune_apex (All metrics have this measurement name)\n  - tags:\n    - host (mandatory, string) is the host on which telegraf runs.\n    - source (mandatory, string) contains the hostname of the apex device. This can be used to differentiate between\n    different units. By using the source instead of the serial number, replacements units won\'t disturb graphs.\n    - type (mandatory, string) maps to the different types of data. Values can be "controller" (The Apex controller\n    itself), "probe" for the different input probes, or "output" for any physical or virtual outputs. The Watt and Amp\n    probes attached to the physical 120V outlets are aggregated under the output type.\n    - hardware (mandatory, string) controller hardware version\n    - software (mandatory, string) software version\n    - probe_type (optional, string) contains the probe type as reported by the Apex.\n    - name (optional, string) contains the name of the probe or output.\n    - output_id (optional, string) represents the internal unique output ID. This is different from the device_id.\n    - device_id (optional, string) maps to either the aquabus address or the internal reference.\n    - output_type (optional, string) categorizes the output into different categories. This tag is DERIVED from the\n    device_id. Possible values are: "variable" for the 0-10V signal ports, "outlet" for physical 120V sockets, "alert"\n    for alarms (email, sound), "virtual" for user-defined outputs, and "unknown" for everything else.\n  - fields:\n    - value (float, various unit) represents the probe reading.\n    - state (string) represents the output state as defined by the Apex. Examples include "AOF" for Auto (OFF), "TBL"\n    for operating according to a table, and "PF*" for different programs.\n    - amp (float, Ampere) is the amount of current flowing through the 120V outlet.\n    - watt (float, Watt) represents the amount of energy flowing through the 120V outlet.\n    - xstatus (string) indicates the xstatus of an outlet. Found on wireless Vortech devices.\n    - power_failed (int64, Unix epoch in ns) when the controller last lost power. Omitted if the apex reports it as "none"\n    - power_restored (int64, Unix epoch in ns) when the controller last powered on. Omitted if the apex reports it as "none"\n    - serial (string, serial number)\n   - time:\n     - The time used for the metric is parsed from the status.xml page. This helps when cross-referencing events with\n     the local system of Apex Fusion. Since the Apex uses NTP, this should not matter in most scenarios.\n\n\n### Sample Queries\n\n\nGet the max, mean, and min for the temperature in the last hour:\n```sql\nSELECT mean("value") FROM "neptune_apex" WHERE ("probe_type" = \'Temp\') AND time >= now() - 6h GROUP BY time(20s)\n```\n\n### Troubleshooting\n\n#### sendRequest failure\nThis indicates a problem communicating with the local Apex controller. If on Mac/Linux, try curl:\n```sh\n$ curl apex.local/cgi-bin/status.xml\n```\nto isolate the problem.\n\n#### parseXML errors\nEnsure the XML being returned is valid. If you get valid XML back, open a bug request.\n\n#### Missing fields/data\nThe neptune_apex plugin is strict on its input to prevent any conversion errors. If you have fields in the status.xml\noutput that are not converted to a metric, open a feature request and paste your whole status.xml\n\n### Example Output\n\n```\nneptune_apex,hardware=1.0,host=ubuntu,software=5.04_7A18,source=apex,type=controller power_failed=1544814000000000000i,power_restored=1544833875000000000i,serial="AC5:12345" 1545978278000000000\nneptune_apex,device_id=base_Var1,hardware=1.0,host=ubuntu,name=VarSpd1_I1,output_id=0,output_type=variable,software=5.04_7A18,source=apex,type=output state="PF1" 1545978278000000000\nneptune_apex,device_id=base_Var2,hardware=1.0,host=ubuntu,name=VarSpd2_I2,output_id=1,output_type=variable,software=5.04_7A18,source=apex,type=output state="PF2" 1545978278000000000\nneptune_apex,device_id=base_Var3,hardware=1.0,host=ubuntu,name=VarSpd3_I3,output_id=2,output_type=variable,software=5.04_7A18,source=apex,type=output state="PF3" 1545978278000000000\nneptune_apex,device_id=base_Var4,hardware=1.0,host=ubuntu,name=VarSpd4_I4,output_id=3,output_type=variable,software=5.04_7A18,source=apex,type=output state="PF4" 1545978278000000000\nneptune_apex,device_id=base_Alarm,hardware=1.0,host=ubuntu,name=SndAlm_I6,output_id=4,output_type=alert,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=base_Warn,hardware=1.0,host=ubuntu,name=SndWrn_I7,output_id=5,output_type=alert,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=base_email,hardware=1.0,host=ubuntu,name=EmailAlm_I5,output_id=6,output_type=alert,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=base_email2,hardware=1.0,host=ubuntu,name=Email2Alm_I9,output_id=7,output_type=alert,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=2_1,hardware=1.0,host=ubuntu,name=RETURN_2_1,output_id=8,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0.3,state="AON",watt=34 1545978278000000000\nneptune_apex,device_id=2_2,hardware=1.0,host=ubuntu,name=Heater1_2_2,output_id=9,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AOF",watt=0 1545978278000000000\nneptune_apex,device_id=2_3,hardware=1.0,host=ubuntu,name=FREE_2_3,output_id=10,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="OFF",watt=1 1545978278000000000\nneptune_apex,device_id=2_4,hardware=1.0,host=ubuntu,name=LIGHT_2_4,output_id=11,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="OFF",watt=1 1545978278000000000\nneptune_apex,device_id=2_5,hardware=1.0,host=ubuntu,name=LHead_2_5,output_id=12,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=4 1545978278000000000\nneptune_apex,device_id=2_6,hardware=1.0,host=ubuntu,name=SKIMMER_2_6,output_id=13,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0.1,state="AON",watt=12 1545978278000000000\nneptune_apex,device_id=2_7,hardware=1.0,host=ubuntu,name=FREE_2_7,output_id=14,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="OFF",watt=1 1545978278000000000\nneptune_apex,device_id=2_8,hardware=1.0,host=ubuntu,name=CABLIGHT_2_8,output_id=15,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=1 1545978278000000000\nneptune_apex,device_id=2_9,hardware=1.0,host=ubuntu,name=LinkA_2_9,output_id=16,output_type=unknown,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=2_10,hardware=1.0,host=ubuntu,name=LinkB_2_10,output_id=17,output_type=unknown,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=3_1,hardware=1.0,host=ubuntu,name=RVortech_3_1,output_id=18,output_type=unknown,software=5.04_7A18,source=apex,type=output state="TBL",xstatus="OK" 1545978278000000000\nneptune_apex,device_id=3_2,hardware=1.0,host=ubuntu,name=LVortech_3_2,output_id=19,output_type=unknown,software=5.04_7A18,source=apex,type=output state="TBL",xstatus="OK" 1545978278000000000\nneptune_apex,device_id=4_1,hardware=1.0,host=ubuntu,name=OSMOLATO_4_1,output_id=20,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AOF",watt=0 1545978278000000000\nneptune_apex,device_id=4_2,hardware=1.0,host=ubuntu,name=HEATER2_4_2,output_id=21,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AOF",watt=0 1545978278000000000\nneptune_apex,device_id=4_3,hardware=1.0,host=ubuntu,name=NUC_4_3,output_id=22,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0.1,state="AON",watt=8 1545978278000000000\nneptune_apex,device_id=4_4,hardware=1.0,host=ubuntu,name=CABFAN_4_4,output_id=23,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=1 1545978278000000000\nneptune_apex,device_id=4_5,hardware=1.0,host=ubuntu,name=RHEAD_4_5,output_id=24,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=3 1545978278000000000\nneptune_apex,device_id=4_6,hardware=1.0,host=ubuntu,name=FIRE_4_6,output_id=25,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=3 1545978278000000000\nneptune_apex,device_id=4_7,hardware=1.0,host=ubuntu,name=LightGW_4_7,output_id=26,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=1 1545978278000000000\nneptune_apex,device_id=4_8,hardware=1.0,host=ubuntu,name=GBSWITCH_4_8,output_id=27,output_type=outlet,software=5.04_7A18,source=apex,type=output amp=0,state="AON",watt=0 1545978278000000000\nneptune_apex,device_id=4_9,hardware=1.0,host=ubuntu,name=LinkA_4_9,output_id=28,output_type=unknown,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=4_10,hardware=1.0,host=ubuntu,name=LinkB_4_10,output_id=29,output_type=unknown,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=5_1,hardware=1.0,host=ubuntu,name=LinkA_5_1,output_id=30,output_type=unknown,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=Cntl_A1,hardware=1.0,host=ubuntu,name=ATO_EMPTY,output_id=31,output_type=virtual,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=Cntl_A2,hardware=1.0,host=ubuntu,name=LEAK,output_id=32,output_type=virtual,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,device_id=Cntl_A3,hardware=1.0,host=ubuntu,name=SKMR_NOPWR,output_id=33,output_type=virtual,software=5.04_7A18,source=apex,type=output state="AOF" 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=Tmp,probe_type=Temp,software=5.04_7A18,source=apex,type=probe value=78.1 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=pH,probe_type=pH,software=5.04_7A18,source=apex,type=probe value=7.93 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=ORP,probe_type=ORP,software=5.04_7A18,source=apex,type=probe value=191 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=Salt,probe_type=Cond,software=5.04_7A18,source=apex,type=probe value=29.4 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=Volt_2,software=5.04_7A18,source=apex,type=probe value=117 1545978278000000000\nneptune_apex,hardware=1.0,host=ubuntu,name=Volt_4,software=5.04_7A18,source=apex,type=probe value=118 1545978278000000000\n\n```\n\n### Contributing\n\nThis plugin is used for mission-critical aquatic life support. A bug could very well result in the death of animals.\nNeptune does not publish a schema file and as such, we have made this plugin very strict on input with no provisions for\nautomatically adding fields. We are also careful to not add default values when none are presented to prevent automation\nerrors.\n\nWhen writing unit tests, use actual Apex output to run tests. It\'s acceptable to abridge the number of repeated fields\nbut never inner fields or parameters.\n',image:us.a},{id:"net_response",name:"Network Response",markdown:'# Network Response Input Plugin\n\nThe input plugin test UDP/TCP connections response time and can optional\nverify text in the response.\n\n### Configuration:\n\n```toml\n# Collect response time of a TCP or UDP connection\n[[inputs.net_response]]\n  ## Protocol, must be "tcp" or "udp"\n  ## NOTE: because the "udp" protocol does not respond to requests, it requires\n  ## a send/expect string pair (see below).\n  protocol = "tcp"\n  ## Server address (default localhost)\n  address = "localhost:80"\n\n  ## Set timeout\n  # timeout = "1s"\n\n  ## Set read timeout (only used if expecting a response)\n  # read_timeout = "1s"\n\n  ## The following options are required for UDP checks. For TCP, they are\n  ## optional. The plugin will send the given string to the server and then\n  ## expect to receive the given \'expect\' string back.\n  ## string sent to the server\n  # send = "ssh"\n  ## expected string in answer\n  # expect = "ssh"\n\n  ## Uncomment to remove deprecated fields; recommended for new deploys\n  # fielddrop = ["result_type", "string_found"]\n```\n\n### Metrics:\n\n- net_response\n  - tags:\n    - server\n    - port\n    - protocol\n    - result\n  - fields:\n    - response_time (float, seconds)\n    - result_code (int, success = 0, timeout = 1, connection_failed = 2, read_failed = 3, string_mismatch = 4)\n    - result_type (string) **DEPRECATED in 1.7; use result tag**\n    - string_found (boolean) **DEPRECATED in 1.4; use result tag**\n\n### Example Output:\n\n```\nnet_response,port=8086,protocol=tcp,result=success,server=localhost response_time=0.000092948,result_code=0i,result_type="success" 1525820185000000000\nnet_response,port=8080,protocol=tcp,result=connection_failed,server=localhost result_code=2i,result_type="connection_failed" 1525820088000000000\nnet_response,port=8080,protocol=udp,result=read_failed,server=localhost result_code=3i,result_type="read_failed",string_found=false 1525820088000000000\n```\n',image:ms.a},{id:"net_stat",name:"Net Stat",markdown:"# Netstat Input Plugin\n\nThis plugin collects TCP connections state and UDP socket counts by using `lsof`.\n\n### Configuration:\n\n``` toml\n# Collect TCP connections state and UDP socket counts\n[[inputs.netstat]]\n  # no configuration\n```\n\n# Measurements:\n\nSupported TCP Connection states are follows.\n\n- established\n- syn_sent\n- syn_recv\n- fin_wait1\n- fin_wait2\n- time_wait\n- close\n- close_wait\n- last_ack\n- listen\n- closing\n- none\n\n### TCP Connection State measurements:\n\nMeta:\n- units: counts\n\nMeasurement names:\n- tcp_established\n- tcp_syn_sent\n- tcp_syn_recv\n- tcp_fin_wait1\n- tcp_fin_wait2\n- tcp_time_wait\n- tcp_close\n- tcp_close_wait\n- tcp_last_ack\n- tcp_listen\n- tcp_closing\n- tcp_none\n\nIf there are no connection on the state, the metric is not counted.\n\n### UDP socket counts measurements:\n\nMeta:\n- units: counts\n\nMeasurement names:\n- udp_socket\n",image:ms.a},{id:"net",name:"Net",markdown:'# Net Input Plugin\n\nThis plugin gathers metrics about network interface and protocol usage (Linux only).\n\n### Configuration:\n\n```toml\n# Gather metrics about network interfaces\n[[inputs.net]]\n  ## By default, telegraf gathers stats from any up interface (excluding loopback)\n  ## Setting interfaces will tell it to gather these explicit interfaces,\n  ## regardless of status. When specifying an interface, glob-style\n  ## patterns are also supported.\n  ##\n  # interfaces = ["eth*", "enp0s[0-1]", "lo"]\n  ##\n  ## On linux systems telegraf also collects protocol stats.\n  ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.\n  ##\n  # ignore_protocol_stats = false\n  ##\n```\n\n### Measurements & Fields:\n\nThe fields from this plugin are gathered in the _net_ measurement.\n\nFields (all platforms):\n\n* bytes_sent - The total number of bytes sent by the interface\n* bytes_recv - The total number of bytes received by the interface\n* packets_sent - The total number of packets sent by the interface\n* packets_recv - The total number of packets received by the interface\n* err_in - The total number of receive errors detected by the interface\n* err_out - The total number of transmit errors detected by the interface\n* drop_in - The total number of received packets dropped by the interface\n* drop_out - The total number of transmitted packets dropped by the interface\n\nDifferent platforms gather the data above with different mechanisms. Telegraf uses the ([gopsutil](https://github.com/shirou/gopsutil)) package, which under Linux reads the /proc/net/dev file.\nUnder freebsd/openbsd and darwin the plugin uses netstat.\n\nAdditionally, for the time being _only under Linux_, the plugin gathers system wide stats for different network protocols using /proc/net/snmp (tcp, udp, icmp, etc.).\nExplanation of the different metrics exposed by snmp is out of the scope of this document. The best way to find information would be tracing the constants in the Linux kernel source [here](https://elixir.bootlin.com/linux/latest/source/net/ipv4/proc.c) and their usage. If /proc/net/snmp cannot be read for some reason, telegraf ignores the error silently.\n\n### Tags:\n\n* Net measurements have the following tags:\n    - interface (the interface from which metrics are gathered)\n\nUnder Linux the system wide protocol metrics have the interface=all tag.\n\n### Sample Queries:\n\nYou can use the following query to get the upload/download traffic rate per second for all interfaces in the last hour. The query uses the [derivative function](https://docs.influxdata.com/influxdb/v1.2/query_language/functions#derivative) which calculates the rate of change between subsequent field values.\n\n```sql\nSELECT derivative(first(bytes_recv), 1s) as "download bytes/sec", derivative(first(bytes_sent), 1s) as "upload bytes/sec" FROM net WHERE time > now() - 1h AND interface != \'all\' GROUP BY time(10s), interface fill(0);\n```\n\n### Example Output:\n\n```\n# All platforms\n$ ./telegraf --config telegraf.conf --input-filter net --test\nnet,interface=eth0,host=HOST bytes_sent=451838509i,bytes_recv=3284081640i,packets_sent=2663590i,packets_recv=3585442i,err_in=0i,err_out=0i,drop_in=4i,drop_out=0i 1492834180000000000\n```\n\n```\n# Linux\n$ ./telegraf --config telegraf.conf --input-filter net --test\nnet,interface=eth0,host=HOST bytes_sent=451838509i,bytes_recv=3284081640i,packets_sent=2663590i,packets_recv=3585442i,err_in=0i,err_out=0i,drop_in=4i,drop_out=0i 1492834180000000000\nnet,interface=all,host=HOST ip_reasmfails=0i,icmp_insrcquenchs=0i,icmp_outtimestamps=0i,ip_inhdrerrors=0i,ip_inunknownprotos=0i,icmp_intimeexcds=10i,icmp_outaddrmasks=0i,icmp_indestunreachs=11005i,icmpmsg_outtype0=6i,tcp_retranssegs=14669i,udplite_outdatagrams=0i,ip_reasmtimeout=0i,ip_outnoroutes=2577i,ip_inaddrerrors=186i,icmp_outaddrmaskreps=0i,tcp_incsumerrors=0i,tcp_activeopens=55965i,ip_reasmoks=0i,icmp_inechos=6i,icmp_outdestunreachs=9417i,ip_reasmreqds=0i,icmp_outtimestampreps=0i,tcp_rtoalgorithm=1i,icmpmsg_intype3=11005i,icmpmsg_outtype69=129i,tcp_outsegs=2777459i,udplite_rcvbuferrors=0i,ip_fragoks=0i,icmp_inmsgs=13398i,icmp_outerrors=0i,tcp_outrsts=14951i,udplite_noports=0i,icmp_outmsgs=11517i,icmp_outechoreps=6i,icmpmsg_intype11=10i,icmp_inparmprobs=0i,ip_forwdatagrams=0i,icmp_inechoreps=1909i,icmp_outredirects=0i,icmp_intimestampreps=0i,icmpmsg_intype5=468i,tcp_rtomax=120000i,tcp_maxconn=-1i,ip_fragcreates=0i,ip_fragfails=0i,icmp_inredirects=468i,icmp_outtimeexcds=0i,icmp_outechos=1965i,icmp_inaddrmasks=0i,tcp_inerrs=389i,tcp_rtomin=200i,ip_defaultttl=64i,ip_outrequests=3366408i,ip_forwarding=2i,udp_incsumerrors=0i,udp_indatagrams=522136i,udplite_incsumerrors=0i,ip_outdiscards=871i,icmp_inerrors=958i,icmp_outsrcquenchs=0i,icmpmsg_intype0=1909i,tcp_insegs=3580226i,udp_outdatagrams=577265i,udp_rcvbuferrors=0i,udplite_sndbuferrors=0i,icmp_incsumerrors=0i,icmp_outparmprobs=0i,icmpmsg_outtype3=9417i,tcp_attemptfails=2652i,udplite_inerrors=0i,udplite_indatagrams=0i,ip_inreceives=4172969i,icmpmsg_outtype8=1965i,tcp_currestab=59i,udp_noports=5961i,ip_indelivers=4099279i,ip_indiscards=0i,tcp_estabresets=5818i,udp_sndbuferrors=3i,icmp_intimestamps=0i,icmpmsg_intype8=6i,udp_inerrors=0i,icmp_inaddrmaskreps=0i,tcp_passiveopens=452i 1492831540000000000\n```\n',image:ms.a},{id:"nfsclient",name:"NFS Client",markdown:"# NFS Client Input Plugin\n\nThe NFS Client input plugin collects data from /proc/self/mountstats. By default, only a limited number of general system-level metrics are collected, including basic read/write counts.\nIf `fullstat` is set, a great deal of additional metrics are collected, detailed below.\n\n**NOTE** Many of the metrics, even if tagged with a mount point, are really _per-server_.  Thus, if you mount these two shares:  `nfs01:/vol/foo/bar` and `nfs01:/vol/foo/baz`, there will be two near identical entries in /proc/self/mountstats.  This is a limitation of the metrics exposed by the kernel, not the telegraf plugin.\n\n### Configuration\n\n```toml\n[[inputs.nfsclient]]\n  ## Read more low-level metrics (optional, defaults to false)\n  # fullstat = false\n\n  ## List of mounts to explictly include or exclude (optional)\n  ## The pattern (Go regexp) is matched against the mount point (not the\n  ## device being mounted).  If include_mounts is set, all mounts are ignored\n  ## unless present in the list. If a mount is listed in both include_mounts\n  ## and exclude_mounts, it is excluded.  Go regexp patterns can be used.\n  # include_mounts = []\n  # exclude_mounts = []\n\n  ## List of operations to include or exclude from collecting.  This applies\n  ## only when fullstat=true.  Symantics are similar to {include,exclude}_mounts:\n  ## the default is to collect everything; when include_operations is set, only\n  ## those OPs are collected; when exclude_operations is set, all are collected\n  ## except those listed.  If include and exclude are set, the OP is excluded.\n  ## See /proc/self/mountstats for a list of valid operations; note that\n  ## NFSv3 and NFSv4 have different lists.  While it is not possible to\n  ## have different include/exclude lists for NFSv3/4, unused elements\n  ## in the list should be okay.  It is possible to have different lists\n  ## for different mountpoints:  use mulitple [[input.nfsclient]] stanzas,\n  ## with their own lists.  See \"include_mounts\" above, and be careful of\n  ## duplicate metrics.\n  # include_operations = []\n  # exclude_operations = []\n```\n#### Configuration Options\n- **fullstat** bool: Collect per-operation type metrics.  Defaults to false.\n- **include_mounts** list(string): gather metrics for only these mounts.  Default is to watch all mounts.\n- **exclude_mounts** list(string): gather metrics for all mounts, except those listed in this option. Excludes take precedence over includes.\n- **include_operations** list(string): List of specific NFS operations to track.  See /proc/self/mountstats (the \"per-op statistics\" section) for complete lists of valid options for NFSv3 and NFSV4.  The default is to gather all metrics, but this is almost certainly *not* what you want (there are 22 operations for NFSv3, and well over 50 for NFSv4).  A suggested 'minimal' list of operations to collect for basic usage:  `['READ','WRITE','ACCESS','GETATTR','READDIR','LOOKUP','LOOKUP']`\n- **exclude_operations** list(string): Gather all metrics, except those listed.  Excludes take precedence over includes.\n\n*N.B.* the `include_mounts` and `exclude_mounts` arguments are both applied to the local mount location (e.g. /mnt/NFS), not the server export (e.g. nfsserver:/vol/NFS).  Go regexp patterns can be used in either.\n\n#### References\n1. [nfsiostat](http://git.linux-nfs.org/?p=steved/nfs-utils.git;a=summary)\n2. [net/sunrpc/stats.c - Linux source code](https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/net/sunrpc/stats.c)\n3. [What is in /proc/self/mountstats for NFS mounts: an introduction](https://utcc.utoronto.ca/~cks/space/blog/linux/NFSMountstatsIndex)\n4. [The xprt: data for NFS mounts in /proc/self/mountstats](https://utcc.utoronto.ca/~cks/space/blog/linux/NFSMountstatsXprt)\n\n\n\n### Metrics\n\n#### Fields\n\n- nfsstat\n    - bytes (integer, bytes) - The total number of bytes exchanged doing this operation. This is bytes sent *and* received, including overhead *and* payload.  (bytes = OP_bytes_sent + OP_bytes_recv.  See nfs_ops below)\n    - ops (integer, count) - The number of operations of this type executed.\n    - retrans (integer, count) - The number of times an operation had to be retried (retrans = OP_trans - OP_ops.  See nfs_ops below)\n    - exe (integer, miliseconds) - The number of miliseconds it took to process the operations.\n    - rtt (integer, miliseconds) - The round-trip time for operations.\n\nIn addition enabling `fullstat` will make many more metrics available.\n\n#### Tags\n\n- All measurements have the following tags:\n    - mountpoint - The local mountpoint, for instance: \"/var/www\"\n    - serverexport - The full server export, for instance: \"nfsserver.example.org:/export\"\n\n- Measurements nfsstat and nfs_ops will also include:\n    - operation - the NFS operation in question.  `READ` or `WRITE` for nfsstat, but potentially one of ~20 or ~50, depending on NFS version.  A complete list of operations supported is visible in `/proc/self/mountstats`.\n\n\n\n### Additional metrics\n\nWhen `fullstat` is true, additional measurements are collected.  Tags are the same as above.\n\n#### NFS Operations\n\nMost descriptions come from Reference [[3](https://utcc.utoronto.ca/~cks/space/blog/linux/NFSMountstatsIndex)] and `nfs_iostat.h`.  Field order and names are the same as in `/proc/self/mountstats` and the Kernel source.\n\nPlease refer to `/proc/self/mountstats` for a list of supported NFS operations, as it changes occasionally.\n\n- nfs_bytes\n    - fields:\n        - normalreadbytes (int, bytes): Bytes read from the server via `read()`\n        - normalwritebytes (int, bytes): Bytes written to the server via `write()`\n        - directreadbytes (int, bytes): Bytes read with O_DIRECT set\n        - directwritebytes (int, bytes): Bytes written with O_DIRECT set   \n        - serverreadbytes (int, bytes): Bytes read via NFS READ (via `mmap()`)\n        - serverwritebytes (int, bytes): Bytes written via NFS WRITE (via `mmap()`)\n        - readpages (int, count): Number of pages read\n        - writepages (int, count): Number of pages written\n\n- nfs_events (Per-event metrics)\n    - fields:\n        - inoderevalidates (int, count): How many times cached inode attributes have to be re-validated from the server.\n        - dentryrevalidates (int, count): How many times cached dentry nodes have to be re-validated.\n        - datainvalidates (int, count): How many times an inode had its cached data thrown out.\n        - attrinvalidates (int, count): How many times an inode has had cached inode attributes invalidated.\n        - vfsopen (int, count): How many times files or directories have been `open()`'d.\n        - vfslookup (int, count): How many name lookups in directories there have been.\n        - vfsaccess (int, count): Number of calls to `access()`. (formerly called \"vfspermission\")\n        - vfsupdatepage (int, count): Count of updates (and potential writes) to pages.\n        - vfsreadpage (int, count): Number of pages read.\n        - vfsreadpages (int, count): Count of how many times a _group_ of pages was read (possibly via `mmap()`?).\n        - vfswritepage (int, count): Number of pages written.\n        - vfswritepages (int, count): Count of how many times a _group_ of pages was written (possibly via `mmap()`?)\n        - vfsgetdents (int, count): Count of directory entry reads with getdents(). These reads can be served from cache and don't necessarily imply actual NFS requests. (formerly called \"vfsreaddir\")\n        - vfssetattr (int, count): How many times we've set attributes on inodes.\n        - vfsflush (int, count): Count of times pending writes have been forcibly flushed to the server.\n        - vfsfsync (int, count): Count of calls to `fsync()` on directories and files.\n        - vfslock (int, count): Number of times a lock was attempted on a file (regardless of success or not).\n        - vfsrelease (int, count): Number of calls to `close()`.\n        - congestionwait (int, count): Believe unused by the Linux kernel, but it is part of the NFS spec.\n        - setattrtrunc (int, count): How many times files have had their size truncated.\n        - extendwrite (int, count): How many times a file has been grown because you're writing beyond the existing end of the file.\n        - sillyrenames (int, count): Number of times an in-use file was removed (thus creating a temporary \".nfsXXXXXX\" file)\n        - shortreads (int, count): Number of times the NFS server returned less data than requested.\n        - shortwrites (int, count): Number of times NFS server reports it wrote less data than requested.\n        - delay (int, count): Occurances of EJUKEBOX (\"Jukebox Delay\", probably unused)\n        - pnfsreads (int, count): Count of NFS v4.1+ pNFS reads.\n        - pnfswrites (int, count): Count of NFS v4.1+ pNFS writes.\n\n- nfs_xprt_tcp\n    - fields:\n        - bind_count (int, count): Number of _completely new_ mounts to this server (sometimes 0?)\n        - connect_count (int, count): How many times the client has connected to the server in question\n        - connect_time (int, jiffies): How long the NFS client has spent waiting for its connection(s) to the server to be established.\n        - idle_time (int, seconds): How long (in seconds) since the NFS mount saw any RPC traffic.\n        - rpcsends (int, count): How many RPC requests this mount has sent to the server.\n        - rpcreceives (int, count): How many RPC replies this mount has received from the server.\n        - badxids (int, count): Count of XIDs sent by the server that the client doesn't know about.\n        - inflightsends (int, count): Number of outstanding requests; always >1. (See reference #4 for comment on this field)\n        - backlogutil (int, count): Cumulative backlog count\n\n- nfs_xprt_udp\n    - fields:\n        - [same as nfs_xprt_tcp, except for connect_count, connect_time, and idle_time]\n\n- nfs_ops\n    - fields (In all cases, the `operations` tag is set to the uppercase name of the NFS operation, _e.g._ \"READ\", \"FSINFO\", _etc_.  See /proc/self/mountstats for a full list):\n        - ops (int, count): Total operations of this type.\n        - trans (int, count): Total transmissions of this type, including retransmissions: `OP_ops - OP_trans = total_retransmissions` (lower is better).\n        - timeouts (int, count): Number of major timeouts.\n        - bytes_sent (int, count): Bytes received, including headers (should also be close to on-wire size).\n        - bytes_recv (int, count): Bytes sent, including headers (should be close to on-wire size).\n        - queue_time (int, milliseconds): Cumulative time a request waited in the queue before sending this OP type.\n        - response_time (int, milliseconds): Cumulative time waiting for a response for this OP type.\n        - total_time (int, milliseconds): Cumulative time a request waited in the queue before sending.\n        - errors (int, count): Total number operations that complete with tk_status < 0 (usually errors).  This is a new field, present in kernel >=5.3, mountstats version 1.1\n\n\n### Example Output\nFor basic metrics showing server-wise read and write data.\n```\nnfsstat,mountpoint=/NFS,operation=READ,serverexport=1.2.3.4:/storage/NFS ops=600i,retrans=1i,bytes=1207i,rtt=606i,exe=607i 1612651512000000000\nnfsstat,mountpoint=/NFS,operation=WRITE,serverexport=1.2.3.4:/storage/NFS bytes=1407i,rtt=706i,exe=707i,ops=700i,retrans=1i 1612651512000000000\n\n```\n\nFor `fullstat=true` metrics, which includes additional measurements for `nfs_bytes`, `nfs_events`, and `nfs_xprt_tcp` (and `nfs_xprt_udp` if present).\nAdditionally, per-OP metrics are collected, with examples for READ, LOOKUP, and NULL shown.\nPlease refer to `/proc/self/mountstats` for a list of supported NFS operations, as it changes as it changes periodically.\n\n```\nnfs_bytes,mountpoint=/home,serverexport=nfs01:/vol/home directreadbytes=0i,directwritebytes=0i,normalreadbytes=42648757667i,normalwritebytes=0i,readpages=10404603i,serverreadbytes=42617098139i,serverwritebytes=0i,writepages=0i 1608787697000000000\nnfs_events,mountpoint=/home,serverexport=nfs01:/vol/home attrinvalidates=116i,congestionwait=0i,datainvalidates=65i,delay=0i,dentryrevalidates=5911243i,extendwrite=0i,inoderevalidates=200378i,pnfsreads=0i,pnfswrites=0i,setattrtrunc=0i,shortreads=0i,shortwrites=0i,sillyrenames=0i,vfsaccess=7203852i,vfsflush=117405i,vfsfsync=0i,vfsgetdents=3368i,vfslock=0i,vfslookup=740i,vfsopen=157281i,vfsreadpage=16i,vfsreadpages=86874i,vfsrelease=155526i,vfssetattr=0i,vfsupdatepage=0i,vfswritepage=0i,vfswritepages=215514i 1608787697000000000\nnfs_xprt_tcp,mountpoint=/home,serverexport=nfs01:/vol/home backlogutil=0i,badxids=0i,bind_count=1i,connect_count=1i,connect_time=0i,idle_time=0i,inflightsends=15659826i,rpcreceives=2173896i,rpcsends=2173896i 1608787697000000000\n\nnfs_ops,mountpoint=/NFS,operation=NULL,serverexport=1.2.3.4:/storage/NFS trans=0i,timeouts=0i,bytes_sent=0i,bytes_recv=0i,queue_time=0i,response_time=0i,total_time=0i,ops=0i 1612651512000000000\nnfs_ops,mountpoint=/NFS,operation=READ,serverexport=1.2.3.4:/storage/NFS bytes=1207i,timeouts=602i,total_time=607i,exe=607i,trans=601i,bytes_sent=603i,bytes_recv=604i,queue_time=605i,ops=600i,retrans=1i,rtt=606i,response_time=606i 1612651512000000000\nnfs_ops,mountpoint=/NFS,operation=WRITE,serverexport=1.2.3.4:/storage/NFS ops=700i,bytes=1407i,exe=707i,trans=701i,timeouts=702i,response_time=706i,total_time=707i,retrans=1i,rtt=706i,bytes_sent=703i,bytes_recv=704i,queue_time=705i 1612651512000000000\n```\n\n\n",image:hs.a},{id:"nginx",name:"Nginx",markdown:'# Nginx Input Plugin\n\n### Configuration:\n\n```toml\n# Read Nginx\'s basic status information (ngx_http_stub_status_module)\n[[inputs.nginx]]\n  ## An array of Nginx stub_status URI to gather stats.\n  urls = ["http://localhost/server_status"]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## HTTP response timeout (default: 5s)\n  response_timeout = "5s"\n```\n\n### Measurements & Fields:\n\n- Measurement\n    - accepts\n    - active\n    - handled\n    - reading\n    - requests\n    - waiting\n    - writing\n\n### Tags:\n\n- All measurements have the following tags:\n    - port\n    - server\n\n### Example Output:\n\nUsing this configuration:\n```toml\n[[inputs.nginx]]\n  ## An array of Nginx stub_status URI to gather stats.\n  urls = ["http://localhost/status"]\n```\n\nWhen run with:\n```sh\n./telegraf --config telegraf.conf --input-filter nginx --test\n```\n\nIt produces:\n```\n* Plugin: nginx, Collection 1\n> nginx,port=80,server=localhost accepts=605i,active=2i,handled=605i,reading=0i,requests=12132i,waiting=1i,writing=1i 1456690994701784331\n```\n',image:Ps.a},{id:"nginx_plus",name:"Nginx Plus",markdown:'# Nginx Plus Input Plugin\n\nNginx Plus is a commercial version of the open source web server Nginx. The use this plugin you will need a license. For more information about the differences between Nginx (F/OSS) and Nginx Plus, [click here](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).\n\nStructures for Nginx Plus have been built based on history of\n[status module documentation](http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n### Configuration:\n\n```toml\n# Read Nginx Plus\' advanced status information\n[[inputs.nginx_plus]]\n  ## An array of Nginx status URIs to gather stats.\n  urls = ["http://localhost/status"]\n```\n\n### Measurements & Fields:\n\n- nginx_plus_processes\n  - respawned\n- nginx_plus_connections\n  - accepted\n  - dropped\n  - active\n  - idle\n- nginx_plus_ssl\n  - handshakes\n  - handshakes_failed\n  - session_reuses\n- nginx_plus_requests\n  - total\n  - current\n- nginx_plus_upstream, nginx_plus_stream_upstream\n  - keepalive\n  - zombies\n- nginx_plus_upstream_peer, nginx_plus_stream_upstream_peer\n  - requests\n  - unavail\n  - healthchecks_checks\n  - header_time\n  - response_time\n  - state\n  - active\n  - downstart\n  - healthchecks_last_passed\n  - weight\n  - responses_1xx\n  - responses_2xx\n  - responses_3xx\n  - responses_4xx\n  - responses_5xx\n  - received\n  - selected\n  - healthchecks_fails\n  - healthchecks_unhealthy\n  - backup\n  - responses_total\n  - sent\n  - fails\n  - downtime\n\n\n### Tags:\n\n- nginx_plus_processes, nginx_plus_connections, nginx_plus_ssl, nginx_plus_requests\n  - server\n  - port\n\n- nginx_plus_upstream, nginx_plus_stream_upstream\n  - upstream\n  - server\n  - port\n\n- nginx_plus_upstream_peer, nginx_plus_stream_upstream_peer\n  - id\n  - upstream\n  - server\n  - port\n  - upstream_address\n\n### Example Output:\n\nUsing this configuration:\n```toml\n[[inputs.nginx_plus]]\n  ## An array of Nginx Plus status URIs to gather stats.\n  urls = ["http://localhost/status"]\n```\n\nWhen run with:\n```sh\n./telegraf -config telegraf.conf -input-filter nginx_plus -test\n```\n\nIt produces:\n```\n* Plugin: inputs.nginx_plus, Collection 1\n> nginx_plus_processes,server=localhost,port=12021,host=word.local respawned=0i 1505782513000000000\n> nginx_plus_connections,server=localhost,port=12021,host=word.local accepted=5535735212i,dropped=10140186i,active=9541i,idle=67540i 1505782513000000000\n> nginx_plus_ssl,server=localhost,port=12021,host=word.local handshakes=0i,handshakes_failed=0i,session_reuses=0i 1505782513000000000\n> nginx_plus_requests,server=localhost,port=12021,host=word.local total=186780541173i,current=9037i 1505782513000000000\n> nginx_plus_upstream,port=12021,host=word.local,upstream=dataserver80,server=localhost keepalive=0i,zombies=0i 1505782513000000000\n> nginx_plus_upstream_peer,upstream=dataserver80,upstream_address=10.10.102.181:80,id=0,server=localhost,port=12021,host=word.local sent=53806910399i,received=7516943964i,fails=207i,downtime=2325979i,selected=1505782512000i,backup=false,active=6i,responses_4xx=6935i,header_time=80i,response_time=80i,healthchecks_last_passed=true,responses_1xx=0i,responses_2xx=36299890i,responses_5xx=360450i,responses_total=36667275i,unavail=154i,downstart=0i,state="up",requests=36673741i,responses_3xx=0i,healthchecks_unhealthy=5i,weight=1i,healthchecks_checks=177209i,healthchecks_fails=29i 1505782513000000000\n> nginx_plus_stream_upstream,server=localhost,port=12021,host=word.local,upstream=dataserver443 zombies=0i 1505782513000000000\n> nginx_plus_stream_upstream_peer,server=localhost,upstream_address=10.10.102.181:443,id=0,port=12021,host=word.local,upstream=dataserver443 active=1i,healthchecks_unhealthy=1i,weight=1i,unavail=0i,connect_time=24i,first_byte_time=78i,healthchecks_last_passed=true,state="up",sent=4457713140i,received=698065272i,fails=0i,healthchecks_checks=178421i,downstart=0i,selected=1505782512000i,response_time=5156i,backup=false,connections=56251i,healthchecks_fails=20i,downtime=391017i 1505782513000000000\n```\n\n### Reference material\n\nSubsequent versions of status response structure available here:\n\n- [version 1](http://web.archive.org/web/20130805111222/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n- [version 2](http://web.archive.org/web/20131218101504/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n- version 3 - not available\n\n- [version 4](http://web.archive.org/web/20141218170938/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n- [version 5](http://web.archive.org/web/20150414043916/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n- [version 6](http://web.archive.org/web/20150918163811/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n\n- [version 7](http://web.archive.org/web/20161107221028/http://nginx.org/en/docs/http/ngx_http_status_module.html)\n',image:ys.a},{id:"nginx_plus_api",name:"Nginx Plus API",markdown:'# Nginx Plus API Input Plugin\n\nNginx Plus is a commercial version of the open source web server Nginx. The use this plugin you will need a license. For more information about the differences between Nginx (F/OSS) and Nginx Plus, [click here](https://www.nginx.com/blog/whats-difference-nginx-foss-nginx-plus/).\n\n### Configuration:\n\n```toml\n# Read Nginx Plus API advanced status information\n[[inputs.nginx_plus_api]]\n  ## An array of Nginx API URIs to gather stats.\n  urls = ["http://localhost/api"]\n  # Nginx API version, default: 3\n  # api_version = 3\n```\n\n### Migration from Nginx Plus (Status) input plugin\n\n| Nginx Plus                      | Nginx Plus API                       |\n|---------------------------------|--------------------------------------|\n| nginx_plus_processes            | nginx_plus_api_processes             |\n| nginx_plus_connections          | nginx_plus_api_connections           |\n| nginx_plus_ssl                  | nginx_plus_api_ssl                   |\n| nginx_plus_requests             | nginx_plus_api_http_requests         |\n| nginx_plus_zone                 | nginx_plus_api_http_server_zones     |\n| nginx_plus_upstream             | nginx_plus_api_http_upstreams        |\n| nginx_plus_upstream_peer        | nginx_plus_api_http_upstream_peers   |\n| nginx_plus_cache                | nginx_plus_api_http_caches           |\n| nginx_plus_stream_upstream      | nginx_plus_api_stream_upstreams      |\n| nginx_plus_stream_upstream_peer | nginx_plus_api_stream_upstream_peers |\n| nginx.stream.zone               | nginx_plus_api_stream_server_zones   |\n\n### Measurements by API version\n\n| Measurement                          | API version (api_version) |\n|--------------------------------------|---------------------------|\n| nginx_plus_api_processes             | >= 3                      |\n| nginx_plus_api_connections           | >= 3                      |\n| nginx_plus_api_ssl                   | >= 3                      |\n| nginx_plus_api_http_requests         | >= 3                      |\n| nginx_plus_api_http_server_zones     | >= 3                      |\n| nginx_plus_api_http_upstreams        | >= 3                      |\n| nginx_plus_api_http_upstream_peers   | >= 3                      |\n| nginx_plus_api_http_caches           | >= 3                      |\n| nginx_plus_api_stream_upstreams      | >= 3                      |\n| nginx_plus_api_stream_upstream_peers | >= 3                      |\n| nginx_plus_api_stream_server_zones   | >= 3                      |\n| nginx_plus_api_http_location_zones   | >= 5                      |\n| nginx_plus_api_resolver_zones        | >= 5                      |\n\n### Measurements & Fields:\n\n- nginx_plus_api_processes\n  - respawned\n- nginx_plus_api_connections\n  - accepted\n  - dropped\n  - active\n  - idle\n- nginx_plus_api_ssl\n  - handshakes\n  - handshakes_failed\n  - session_reuses\n- nginx_plus_api_http_requests\n  - total\n  - current\n- nginx_plus_api_http_server_zones\n  - processing\n  - requests\n  - responses_1xx\n  - responses_2xx\n  - responses_3xx\n  - responses_4xx\n  - responses_5xx\n  - responses_total\n  - received\n  - sent\n  - discarded\n- nginx_plus_api_http_upstreams\n  - keepalive\n  - zombies\n- nginx_plus_api_http_upstream_peers\n  - requests\n  - unavail\n  - healthchecks_checks\n  - header_time\n  - state\n  - response_time\n  - active\n  - healthchecks_last_passed\n  - weight\n  - responses_1xx\n  - responses_2xx\n  - responses_3xx\n  - responses_4xx\n  - responses_5xx\n  - received\n  - healthchecks_fails\n  - healthchecks_unhealthy\n  - backup\n  - responses_total\n  - sent\n  - fails\n  - downtime\n- nginx_plus_api_http_caches\n  - size\n  - max_size\n  - cold\n  - hit_responses\n  - hit_bytes\n  - stale_responses\n  - stale_bytes\n  - updating_responses\n  - updating_bytes\n  - revalidated_responses\n  - revalidated_bytes\n  - miss_responses\n  - miss_bytes\n  - miss_responses_written\n  - miss_bytes_written\n  - expired_responses\n  - expired_bytes\n  - expired_responses_written\n  - expired_bytes_written\n  - bypass_responses\n  - bypass_bytes\n  - bypass_responses_written\n  - bypass_bytes_written\n- nginx_plus_api_stream_upstreams\n  - zombies\n- nginx_plus_api_stream_upstream_peers\n  - unavail\n  - healthchecks_checks\n  - healthchecks_fails\n  - healthchecks_unhealthy\n  - healthchecks_last_passed\n  - response_time\n  - state\n  - active\n  - weight\n  - received\n  - backup\n  - sent\n  - fails\n  - downtime\n- nginx_plus_api_stream_server_zones\n  - processing\n  - connections\n  - received\n  - sent\n- nginx_plus_api_location_zones\n  - requests\n  - responses_1xx\n  - responses_2xx\n  - responses_3xx\n  - responses_4xx\n  - responses_5xx\n  - responses_total\n  - received\n  - sent\n  - discarded\n- nginx_plus_api_resolver_zones\n  - name\n  - srv\n  - addr\n  - noerror\n  - formerr\n  - servfail\n  - nxdomain\n  - notimp\n  - refused\n  - timedout\n  - unknown\n\n### Tags:\n\n- nginx_plus_api_processes, nginx_plus_api_connections, nginx_plus_api_ssl, nginx_plus_api_http_requests\n  - source\n  - port\n\n- nginx_plus_api_http_upstreams, nginx_plus_api_stream_upstreams\n  - upstream\n  - source\n  - port\n\n- nginx_plus_api_http_server_zones, nginx_plus_api_upstream_server_zones, nginx_plus_api_http_location_zones, nginx_plus_api_resolver_zones\n  - source\n  - port\n  - zone\n\n- nginx_plus_api_upstream_peers, nginx_plus_api_stream_upstream_peers\n  - id\n  - upstream\n  - source\n  - port\n  - upstream_address\n\n- nginx_plus_api_http_caches\n  - source\n  - port\n\n### Example Output:\n\nUsing this configuration:\n```toml\n[[inputs.nginx_plus_api]]\n  ## An array of Nginx Plus API URIs to gather stats.\n  urls = ["http://localhost/api"]\n```\n\nWhen run with:\n```sh\n./telegraf -config telegraf.conf -input-filter nginx_plus_api -test\n```\n\nIt produces:\n```\n> nginx_plus_api_processes,port=80,source=demo.nginx.com respawned=0i 1570696321000000000\n> nginx_plus_api_connections,port=80,source=demo.nginx.com accepted=68998606i,active=7i,dropped=0i,idle=57i 1570696322000000000\n> nginx_plus_api_ssl,port=80,source=demo.nginx.com handshakes=9398978i,handshakes_failed=289353i,session_reuses=1004389i 1570696322000000000\n> nginx_plus_api_http_requests,port=80,source=demo.nginx.com current=51i,total=264649353i 1570696322000000000\n> nginx_plus_api_http_server_zones,port=80,source=demo.nginx.com,zone=hg.nginx.org discarded=5i,processing=0i,received=24123604i,requests=60138i,responses_1xx=0i,responses_2xx=59353i,responses_3xx=531i,responses_4xx=249i,responses_5xx=0i,responses_total=60133i,sent=830165221i 1570696322000000000\n> nginx_plus_api_http_server_zones,port=80,source=demo.nginx.com,zone=trac.nginx.org discarded=250i,processing=0i,received=2184618i,requests=12404i,responses_1xx=0i,responses_2xx=8579i,responses_3xx=2513i,responses_4xx=583i,responses_5xx=479i,responses_total=12154i,sent=139384159i 1570696322000000000\n> nginx_plus_api_http_server_zones,port=80,source=demo.nginx.com,zone=lxr.nginx.org discarded=1i,processing=0i,received=1011701i,requests=4523i,responses_1xx=0i,responses_2xx=4332i,responses_3xx=28i,responses_4xx=39i,responses_5xx=123i,responses_total=4522i,sent=72631354i 1570696322000000000\n> nginx_plus_api_http_upstreams,port=80,source=demo.nginx.com,upstream=trac-backend keepalive=0i,zombies=0i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=trac-backend,upstream_address=10.0.0.1:8080 active=0i,backup=false,downtime=0i,fails=0i,header_time=235i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=88581178i,requests=3180i,response_time=235i,responses_1xx=0i,responses_2xx=3168i,responses_3xx=5i,responses_4xx=6i,responses_5xx=0i,responses_total=3179i,sent=1321720i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=1,port=80,source=demo.nginx.com,upstream=trac-backend,upstream_address=10.0.0.1:8081 active=0i,backup=true,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,requests=0i,responses_1xx=0i,responses_2xx=0i,responses_3xx=0i,responses_4xx=0i,responses_5xx=0i,responses_total=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_upstreams,port=80,source=demo.nginx.com,upstream=hg-backend keepalive=0i,zombies=0i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=hg-backend,upstream_address=10.0.0.1:8088 active=0i,backup=false,downtime=0i,fails=0i,header_time=22i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=909402572i,requests=18514i,response_time=88i,responses_1xx=0i,responses_2xx=17799i,responses_3xx=531i,responses_4xx=179i,responses_5xx=0i,responses_total=18509i,sent=10608107i,state="up",unavail=0i,weight=5i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=1,port=80,source=demo.nginx.com,upstream=hg-backend,upstream_address=10.0.0.1:8089 active=0i,backup=true,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,requests=0i,responses_1xx=0i,responses_2xx=0i,responses_3xx=0i,responses_4xx=0i,responses_5xx=0i,responses_total=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_upstreams,port=80,source=demo.nginx.com,upstream=lxr-backend keepalive=0i,zombies=0i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=lxr-backend,upstream_address=unix:/tmp/cgi.sock active=0i,backup=false,downtime=0i,fails=123i,header_time=91i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=71782888i,requests=4354i,response_time=91i,responses_1xx=0i,responses_2xx=4230i,responses_3xx=0i,responses_4xx=0i,responses_5xx=0i,responses_total=4230i,sent=3088656i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=1,port=80,source=demo.nginx.com,upstream=lxr-backend,upstream_address=unix:/tmp/cgib.sock active=0i,backup=true,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,max_conns=42i,received=0i,requests=0i,responses_1xx=0i,responses_2xx=0i,responses_3xx=0i,responses_4xx=0i,responses_5xx=0i,responses_total=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_upstreams,port=80,source=demo.nginx.com,upstream=demo-backend keepalive=0i,zombies=0i 1570696322000000000\n> nginx_plus_api_http_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=demo-backend,upstream_address=10.0.0.2:15431 active=0i,backup=false,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,requests=0i,responses_1xx=0i,responses_2xx=0i,responses_3xx=0i,responses_4xx=0i,responses_5xx=0i,responses_total=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696322000000000\n> nginx_plus_api_http_caches,cache=http_cache,port=80,source=demo.nginx.com bypass_bytes=0i,bypass_bytes_written=0i,bypass_responses=0i,bypass_responses_written=0i,cold=false,expired_bytes=381518640i,expired_bytes_written=363449785i,expired_responses=42114i,expired_responses_written=39954i,hit_bytes=6321885979i,hit_responses=596730i,max_size=536870912i,miss_bytes=48512185i,miss_bytes_written=155600i,miss_responses=6052i,miss_responses_written=136i,revalidated_bytes=0i,revalidated_responses=0i,size=765952i,stale_bytes=0i,stale_responses=0i,updating_bytes=0i,updating_responses=0i 1570696323000000000\n> nginx_plus_api_stream_server_zones,port=80,source=demo.nginx.com,zone=postgresql_loadbalancer connections=0i,processing=0i,received=0i,sent=0i 1570696323000000000\n> nginx_plus_api_stream_server_zones,port=80,source=demo.nginx.com,zone=dns_loadbalancer connections=0i,processing=0i,received=0i,sent=0i 1570696323000000000\n> nginx_plus_api_stream_upstreams,port=80,source=demo.nginx.com,upstream=postgresql_backends zombies=0i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=postgresql_backends,upstream_address=10.0.0.2:15432 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=1,port=80,source=demo.nginx.com,upstream=postgresql_backends,upstream_address=10.0.0.2:15433 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=2,port=80,source=demo.nginx.com,upstream=postgresql_backends,upstream_address=10.0.0.2:15434 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=3,port=80,source=demo.nginx.com,upstream=postgresql_backends,upstream_address=10.0.0.2:15435 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="down",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstreams,port=80,source=demo.nginx.com,upstream=dns_udp_backends zombies=0i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=0,port=80,source=demo.nginx.com,upstream=dns_udp_backends,upstream_address=10.0.0.5:53 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="up",unavail=0i,weight=2i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=1,port=80,source=demo.nginx.com,upstream=dns_udp_backends,upstream_address=10.0.0.2:53 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="up",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstream_peers,id=2,port=80,source=demo.nginx.com,upstream=dns_udp_backends,upstream_address=10.0.0.7:53 active=0i,backup=false,connections=0i,downtime=0i,fails=0i,healthchecks_checks=0i,healthchecks_fails=0i,healthchecks_unhealthy=0i,received=0i,sent=0i,state="down",unavail=0i,weight=1i 1570696323000000000\n> nginx_plus_api_stream_upstreams,port=80,source=demo.nginx.com,upstream=unused_tcp_backends zombies=0i 1570696323000000000\n> nginx_plus_api_http_location_zones,port=80,source=demo.nginx.com,zone=swagger discarded=0i,received=1622i,requests=8i,responses_1xx=0i,responses_2xx=7i,responses_3xx=0i,responses_4xx=1i,responses_5xx=0i,responses_total=8i,sent=638333i 1570696323000000000\n> nginx_plus_api_http_location_zones,port=80,source=demo.nginx.com,zone=api-calls discarded=64i,received=337530181i,requests=1726513i,responses_1xx=0i,responses_2xx=1726428i,responses_3xx=0i,responses_4xx=21i,responses_5xx=0i,responses_total=1726449i,sent=1902577668i 1570696323000000000\n> nginx_plus_api_resolver_zones,port=80,source=demo.nginx.com,zone=resolver1 addr=0i,formerr=0i,name=0i,noerror=0i,notimp=0i,nxdomain=0i,refused=0i,servfail=0i,srv=0i,timedout=0i,unknown=0i 1570696324000000000\n```\n\n### Reference material\n\n[api documentation](http://demo.nginx.com/swagger-ui/#/)\n',image:fs.a},{id:"nginx_sts",name:"Nginx Stream STS",markdown:'# Nginx Stream STS Input Plugin\n\nThis plugin gathers Nginx status using external virtual host traffic status\nmodule -  https://github.com/vozlt/nginx-module-sts. This is an Nginx module\nthat provides access to stream host status information. It contains the current\nstatus such as servers, upstreams, caches. This is similar to the live activity\nmonitoring of Nginx plus.  For module configuration details please see its\n[documentation](https://github.com/vozlt/nginx-module-sts#synopsis).\n\nTelegraf minimum version: Telegraf 1.15.0\n\n### Configuration\n\n```toml\n[[inputs.nginx_sts]]\n  ## An array of ngx_http_status_module or status URI to gather stats.\n  urls = ["http://localhost/status"]\n\n  ## HTTP response timeout (default: 5s)\n  response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- nginx_sts_connections\n  - tags:\n    - source\n    - port\n  - fields:\n    - active\n    - reading\n    - writing\n    - waiting\n    - accepted\n    - handled\n    - requests\n\n+ nginx_sts_server\n  - tags:\n    - source\n    - port\n    - zone\n  - fields:\n    - connects\n    - in_bytes\n    - out_bytes\n    - response_1xx_count\n    - response_2xx_count\n    - response_3xx_count\n    - response_4xx_count\n    - response_5xx_count\n    - session_msec_counter\n    - session_msec\n\n- nginx_sts_filter\n  - tags:\n    - source\n    - port\n    - filter_name\n    - filter_key\n  - fields:\n    - connects\n    - in_bytes\n    - out_bytes\n    - response_1xx_count\n    - response_2xx_count\n    - response_3xx_count\n    - response_4xx_count\n    - response_5xx_count\n    - session_msec_counter\n    - session_msec\n\n+ nginx_sts_upstream\n  - tags:\n    - source\n    - port\n    - upstream\n    - upstream_address\n  - fields:\n    - connects\n    - in_bytes\n    - out_bytes\n    - response_1xx_count\n    - response_2xx_count\n    - response_3xx_count\n    - response_4xx_count\n    - response_5xx_count\n    - session_msec_counter\n    - session_msec\n    - upstream_session_msec_counter\n    - upstream_session_msec\n    - upstream_connect_msec_counter\n    - upstream_connect_msec\n    - upstream_firstbyte_msec_counter\n    - upstream_firstbyte_msec\n    - weight\n    - max_fails\n    - fail_timeout\n    - backup\n    - down\n\n### Example Output:\n\n```\nnginx_sts_upstream,host=localhost,port=80,source=127.0.0.1,upstream=backend_cluster,upstream_address=1.2.3.4:8080 upstream_connect_msec_counter=0i,out_bytes=0i,down=false,connects=0i,session_msec=0i,upstream_session_msec=0i,upstream_session_msec_counter=0i,upstream_connect_msec=0i,upstream_firstbyte_msec_counter=0i,response_3xx_count=0i,session_msec_counter=0i,weight=1i,max_fails=1i,backup=false,upstream_firstbyte_msec=0i,in_bytes=0i,response_1xx_count=0i,response_2xx_count=0i,response_4xx_count=0i,response_5xx_count=0i,fail_timeout=10i 1584699180000000000\nnginx_sts_upstream,host=localhost,port=80,source=127.0.0.1,upstream=backend_cluster,upstream_address=9.8.7.6:8080 upstream_firstbyte_msec_counter=0i,response_2xx_count=0i,down=false,upstream_session_msec_counter=0i,out_bytes=0i,response_5xx_count=0i,weight=1i,max_fails=1i,fail_timeout=10i,connects=0i,session_msec_counter=0i,upstream_session_msec=0i,in_bytes=0i,response_1xx_count=0i,response_3xx_count=0i,response_4xx_count=0i,session_msec=0i,upstream_connect_msec=0i,upstream_connect_msec_counter=0i,upstream_firstbyte_msec=0i,backup=false 1584699180000000000\nnginx_sts_server,host=localhost,port=80,source=127.0.0.1,zone=* response_2xx_count=0i,response_4xx_count=0i,response_5xx_count=0i,session_msec_counter=0i,in_bytes=0i,out_bytes=0i,session_msec=0i,response_1xx_count=0i,response_3xx_count=0i,connects=0i 1584699180000000000\nnginx_sts_connections,host=localhost,port=80,source=127.0.0.1 waiting=1i,accepted=146i,handled=146i,requests=13421i,active=3i,reading=0i,writing=2i 1584699180000000000\n```\n',image:ws.a},{id:"nginx_upstream_check",name:"Nginx Upstream Check",markdown:'# Nginx Upstream Check Input Plugin\n\nRead the status output of the nginx_upstream_check (https://github.com/yaoweibin/nginx_upstream_check_module).\nThis module can periodically check the servers in the Nginx\'s upstream with configured request and interval to determine\nif the server is still available. If checks are failed the server is marked as "down" and will not receive any requests\nuntil the check will pass and a server will be marked as "up" again.\n\nThe status page displays the current status of all upstreams and servers as well as number of the failed and successful\nchecks. This information can be exported in JSON format and parsed by this input.\n\n### Configuration:\n\n```toml\n  ## An URL where Nginx Upstream check module is enabled\n  ## It should be set to return a JSON formatted response\n  url = "http://127.0.0.1/status?format=json"\n\n  ## HTTP method\n  # method = "GET"\n\n  ## Optional HTTP headers\n  # headers = {"X-Special-Header" = "Special-Value"}\n\n  ## Override HTTP "Host" header\n  # host_header = "check.example.com"\n\n  ## Timeout for HTTP requests\n  timeout = "5s"\n\n  ## Optional HTTP Basic Auth credentials\n  # username = "username"\n  # password = "pa$$word"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Measurements & Fields:\n\n- Measurement\n    - fall (The number of failed server check attempts, counter)\n    - rise (The number of successful server check attempts, counter)\n    - status (The reporter server status as a string)\n    - status_code (The server status code. 1 - up, 2 - down, 0 - other)\n\nThe "status_code" field most likely will be the most useful one because it allows you to determine the current\nstate of every server and, possible, add some monitoring to watch over it. InfluxDB can use string values and the\n"status" field can be used instead, but for most other monitoring solutions the integer code will be appropriate.\n\n### Tags:\n\n- All measurements have the following tags:\n    - name (The hostname or IP of the upstream server)\n    - port (The alternative check port, 0 if the default one is used)\n    - type (The check type, http/tcp)\n    - upstream (The name of the upstream block in the Nginx configuration)\n    - url (The status url used by telegraf)\n\n### Example Output:\n\nWhen run with:\n```sh\n./telegraf --config telegraf.conf --input-filter nginx_upstream_check --test\n```\n\nIt produces:\n```\n* Plugin: nginx_upstream_check, Collection 1\n> nginx_upstream_check,host=node1,name=192.168.0.1:8080,port=0,type=http,upstream=my_backends,url=http://127.0.0.1:80/status?format\\=json fall=0i,rise=100i,status="up",status_code=1i 1529088524000000000\n> nginx_upstream_check,host=node2,name=192.168.0.2:8080,port=0,type=http,upstream=my_backends,url=http://127.0.0.1:80/status?format\\=json fall=100i,rise=0i,status="down",status_code=2i 1529088524000000000\n```\n',image:xs.a},{id:"nginx_vts",name:"Nginx Virtual Host Traffic (VTS)",markdown:'# Nginx Virtual Host Traffic (VTS) Input Plugin\n\nThis plugin gathers Nginx status using external virtual host traffic status module -  https://github.com/vozlt/nginx-module-vts. This is an Nginx module that provides access to virtual host status information. It contains the current status such as servers, upstreams, caches. This is similar to the live activity monitoring of Nginx plus.\nFor module configuration details please see its [documentation](https://github.com/vozlt/nginx-module-vts#synopsis).\n\n### Configuration:\n\n```toml\n# Read nginx status information using nginx-module-vts module\n[[inputs.nginx_vts]]\n  ## An array of Nginx status URIs to gather stats.\n  urls = ["http://localhost/status"]\n```\n\n### Measurements & Fields:\n\n- nginx_vts_connections\n  - active\n  - reading\n  - writing\n  - waiting\n  - accepted\n  - handled\n  - requests\n- nginx_vts_server, nginx_vts_filter\n  - requests\n  - request_time\n  - in_bytes\n  - out_bytes\n  - response_1xx_count\n  - response_2xx_count\n  - response_3xx_count\n  - response_4xx_count\n  - response_5xx_count\n  - cache_miss\n  - cache_bypass\n  - cache_expired\n  - cache_stale\n  - cache_updating\n  - cache_revalidated\n  - cache_hit\n  - cache_scarce\n- nginx_vts_upstream\n  - requests\n  - request_time\n  - response_time\n  - in_bytes\n  - out_bytes\n  - response_1xx_count\n  - response_2xx_count\n  - response_3xx_count\n  - response_4xx_count\n  - response_5xx_count\n  - weight\n  - max_fails\n  - fail_timeout\n  - backup\n  - down\n- nginx_vts_cache\n  - max_bytes\n  - used_bytes\n  - in_bytes\n  - out_bytes\n  - miss\n  - bypass\n  - expired\n  - stale\n  - updating\n  - revalidated\n  - hit\n  - scarce\n\n\n### Tags:\n\n- nginx_vts_connections\n  - source\n  - port\n- nginx_vts_server\n  - source\n  - port\n  - zone\n- nginx_vts_filter\n  - source\n  - port\n  - filter_name\n  - filter_key\n- nginx_vts_upstream\n  - source\n  - port\n  - upstream\n  - upstream_address\n- nginx_vts_cache\n  - source\n  - port\n  - zone\n\n\n### Example Output:\n\nUsing this configuration:\n```toml\n[[inputs.nginx_vts]]\n  ## An array of Nginx status URIs to gather stats.\n  urls = ["http://localhost/status"]\n```\n\nWhen run with:\n```sh\n./telegraf -config telegraf.conf -input-filter nginx_vts -test\n```\n\nIt produces:\n```\nnginx_vts_connections,source=localhost,port=80,host=localhost waiting=30i,accepted=295333i,handled=295333i,requests=6833487i,active=33i,reading=0i,writing=3i 1518341521000000000\nnginx_vts_server,zone=example.com,port=80,host=localhost,source=localhost cache_hit=158915i,in_bytes=1935528964i,out_bytes=6531366419i,response_2xx_count=809994i,response_4xx_count=16664i,cache_bypass=0i,cache_stale=0i,cache_revalidated=0i,requests=2187977i,response_1xx_count=0i,response_3xx_count=1360390i,cache_miss=2249i,cache_updating=0i,cache_scarce=0i,request_time=13i,response_5xx_count=929i,cache_expired=0i 1518341521000000000\nnginx_vts_server,host=localhost,source=localhost,port=80,zone=* requests=6775284i,in_bytes=5003242389i,out_bytes=36858233827i,cache_expired=318881i,cache_updating=0i,request_time=51i,response_1xx_count=0i,response_2xx_count=4385916i,response_4xx_count=83680i,response_5xx_count=1186i,cache_bypass=0i,cache_revalidated=0i,cache_hit=1972222i,cache_scarce=0i,response_3xx_count=2304502i,cache_miss=408251i,cache_stale=0i 1518341521000000000\nnginx_vts_filter,filter_key=FI,filter_name=country,port=80,host=localhost,source=localhost request_time=0i,in_bytes=139701i,response_3xx_count=0i,out_bytes=2644495i,response_1xx_count=0i,cache_expired=0i,cache_scarce=0i,requests=179i,cache_miss=0i,cache_bypass=0i,cache_stale=0i,cache_updating=0i,cache_revalidated=0i,cache_hit=0i,response_2xx_count=177i,response_4xx_count=2i,response_5xx_count=0i 1518341521000000000\nnginx_vts_upstream,port=80,host=localhost,upstream=backend_cluster,upstream_address=127.0.0.1:6000,source=localhost fail_timeout=10i,backup=false,request_time=31i,response_5xx_count=1081i,response_2xx_count=1877498i,max_fails=1i,in_bytes=2763336289i,out_bytes=19470265071i,weight=1i,down=false,response_time=31i,response_1xx_count=0i,response_4xx_count=76125i,requests=3379232i,response_3xx_count=1424528i 1518341521000000000\nnginx_vts_cache,source=localhost,port=80,host=localhost,zone=example stale=0i,used_bytes=64334336i,miss=394573i,bypass=0i,expired=318788i,updating=0i,revalidated=0i,hit=689883i,scarce=0i,max_bytes=9223372036854775296i,in_bytes=1111161581i,out_bytes=19175548290i 1518341521000000000\n```\n',image:Ss.a},{id:"nsd",name:"NSD",markdown:'# NSD Input Plugin\n\nThis plugin gathers stats from\n[NSD](https://www.nlnetlabs.nl/projects/nsd/about) - an authoritative DNS name\nserver.\n\n### Configuration:\n\n```toml\n# A plugin to collect stats from the NSD DNS resolver\n[[inputs.nsd]]\n  ## Address of server to connect to, optionally \':port\'. Defaults to the\n  ## address in the nsd config file.\n  server = "127.0.0.1:8953"\n\n  ## If running as a restricted user you can prepend sudo for additional access:\n  # use_sudo = false\n\n  ## The default location of the nsd-control binary can be overridden with:\n  # binary = "/usr/sbin/nsd-control"\n\n  ## The default location of the nsd config file can be overridden with:\n  # config_file = "/etc/nsd/nsd.conf"\n\n  ## The default timeout of 1s can be overridden with:\n  # timeout = "1s"\n```\n\n#### Permissions:\n\nIt\'s important to note that this plugin references nsd-control, which may\nrequire additional permissions to execute successfully.  Depending on the\nuser/group permissions of the telegraf user executing this plugin, you may\nneed to alter the group membership, set facls, or use sudo.\n\n**Group membership (Recommended)**:\n```bash\n$ groups telegraf\ntelegraf : telegraf\n\n$ usermod -a -G nsd telegraf\n\n$ groups telegraf\ntelegraf : telegraf nsd\n```\n\n**Sudo privileges**:\nIf you use this method, you will need the following in your telegraf config:\n```toml\n[[inputs.nsd]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias NSDCONTROLCTL = /usr/sbin/nsd-control\ntelegraf  ALL=(ALL) NOPASSWD: NSDCONTROLCTL\nDefaults!NSDCONTROLCTL !logfile, !syslog, !pam_session\n```\n\nPlease use the solution you see as most appropriate.\n\n### Metrics:\n\nThis is the full list of stats provided by nsd-control. In the output, the\ndots in the nsd-control stat name are replaced by underscores (see\nhttps://www.nlnetlabs.nl/documentation/nsd/nsd-control/ for details).\n\n- nsd\n  - fields:\n    - num_queries\n    - time_boot\n    - time_elapsed\n    - size_db_disk\n    - size_db_mem\n    - size_xfrd_mem\n    - size_config_disk\n    - size_config_mem\n    - num_type_TYPE0\n    - num_type_A\n    - num_type_NS\n    - num_type_MD\n    - num_type_MF\n    - num_type_CNAME\n    - num_type_SOA\n    - num_type_MB\n    - num_type_MG\n    - num_type_MR\n    - num_type_NULL\n    - num_type_WKS\n    - num_type_PTR\n    - num_type_HINFO\n    - num_type_MINFO\n    - num_type_MX\n    - num_type_TXT\n    - num_type_RP\n    - num_type_AFSDB\n    - num_type_X25\n    - num_type_ISDN\n    - num_type_RT\n    - num_type_NSAP\n    - num_type_SIG\n    - num_type_KEY\n    - num_type_PX\n    - num_type_AAAA\n    - num_type_LOC\n    - num_type_NXT\n    - num_type_SRV\n    - num_type_NAPTR\n    - num_type_KX\n    - num_type_CERT\n    - num_type_DNAME\n    - num_type_OPT\n    - num_type_APL\n    - num_type_DS\n    - num_type_SSHFP\n    - num_type_IPSECKEY\n    - num_type_RRSIG\n    - num_type_NSEC\n    - num_type_DNSKEY\n    - num_type_DHCID\n    - num_type_NSEC3\n    - num_type_NSEC3PARAM\n    - num_type_TLSA\n    - num_type_SMIMEA\n    - num_type_CDS\n    - num_type_CDNSKEY\n    - num_type_OPENPGPKEY\n    - num_type_CSYNC\n    - num_type_SPF\n    - num_type_NID\n    - num_type_L32\n    - num_type_L64\n    - num_type_LP\n    - num_type_EUI48\n    - num_type_EUI64\n    - num_type_TYPE252\n    - num_type_TYPE253\n    - num_type_TYPE255\n    - num_opcode_QUERY\n    - num_opcode_NOTIFY\n    - num_class_CLASS0\n    - num_class_IN\n    - num_class_CH\n    - num_rcode_NOERROR\n    - num_rcode_FORMERR\n    - num_rcode_SERVFAIL\n    - num_rcode_NXDOMAIN\n    - num_rcode_NOTIMP\n    - num_rcode_REFUSED\n    - num_rcode_YXDOMAIN\n    - num_rcode_NOTAUTH\n    - num_edns\n    - num_ednserr\n    - num_udp\n    - num_udp6\n    - num_tcp\n    - num_tcp6\n    - num_tls\n    - num_tls6\n    - num_answer_wo_aa\n    - num_rxerr\n    - num_txerr\n    - num_raxfr\n    - num_truncated\n    - num_dropped\n    - zone_master\n    - zone_slave\n\n- nsd_servers\n  - tags:\n    - server\n  - fields:\n    - queries\n',image:Cs.a},{id:"nsq",name:"NSQ",markdown:'# NSQ Input Plugin\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.nsq]]\n  ## An array of NSQD HTTP API endpoints\n  endpoints  = ["http://localhost:4151"]\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n',image:Es.a},{id:"nsq_consumer",name:"NSQ Consumer",markdown:'# NSQ Consumer Input Plugin\n\nThe [NSQ][nsq] consumer plugin reads from NSQD and creates metrics using one\nof the supported [input data formats][].\n\n### Configuration:\n\n```toml\n# Read metrics from NSQD topic(s)\n[[inputs.nsq_consumer]]\n  ## Server option still works but is deprecated, we just prepend it to the nsqd array.\n  # server = "localhost:4150"\n\n  ## An array representing the NSQD TCP HTTP Endpoints\n  nsqd = ["localhost:4150"]\n\n  ## An array representing the NSQLookupd HTTP Endpoints\n  nsqlookupd = ["localhost:4161"]\n  topic = "telegraf"\n  channel = "consumer"\n  max_in_flight = 100\n\n  ## Maximum messages to read from the broker that have not been written by an\n  ## output.  For best throughput set based on the number of metrics within\n  ## each message and the size of the output\'s metric_batch_size.\n  ##\n  ## For example, if each message from the queue contains 10 metrics and the\n  ## output metric_batch_size is 1000, setting this to 100 will ensure that a\n  ## full batch is collected and the write is triggered immediately without\n  ## waiting until the next flush_interval.\n  # max_undelivered_messages = 1000\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n```\n\n[nsq]: https://nsq.io\n[input data formats]: /docs/DATA_FORMATS_INPUT.md\n',image:Ms.a},{id:"nstat",name:"Nstat",markdown:'# Nstat Input Plugin\n\nPlugin collects network metrics from `/proc/net/netstat`, `/proc/net/snmp` and `/proc/net/snmp6` files\n\n### Configuration\n\nThe plugin firstly tries to read file paths from config values\nif it is empty, then it reads from env variables.\n* `PROC_NET_NETSTAT`\n* `PROC_NET_SNMP`\n* `PROC_NET_SNMP6`\n\nIf these variables are also not set,\nthen it tries to read the proc root from env - `PROC_ROOT`,\nand sets `/proc` as a root path if `PROC_ROOT` is also empty.\n\nThen appends default file paths:\n* `/net/netstat`\n* `/net/snmp`\n* `/net/snmp6`\n\nSo if nothing is given, no paths in config and in env vars, the plugin takes the default paths.\n* `/proc/net/netstat`\n* `/proc/net/snmp`\n* `/proc/net/snmp6`\n\nThe sample config file\n```toml\n[[inputs.nstat]]\n  ## file paths\n  ## e.g: /proc/net/netstat, /proc/net/snmp, /proc/net/snmp6\n  # proc_net_netstat    = \t""\n  # proc_net_snmp \t\t= \t""\n  # proc_net_snmp6 \t\t= \t""\n  ## dump metrics with 0 values too\n  # dump_zeros\t\t\t= \ttrue\n```\n\nIn case that `proc_net_snmp6` path doesn\'t exist (e.g. IPv6 is not enabled) no error would be raised.\n\n### Measurements & Fields\n\n- nstat\n    - Icmp6InCsumErrors\n    - Icmp6InDestUnreachs\n    - Icmp6InEchoReplies\n    - Icmp6InEchos\n    - Icmp6InErrors\n    - Icmp6InGroupMembQueries\n    - Icmp6InGroupMembReductions\n    - Icmp6InGroupMembResponses\n    - Icmp6InMLDv2Reports\n    - Icmp6InMsgs\n    - Icmp6InNeighborAdvertisements\n    - Icmp6InNeighborSolicits\n    - Icmp6InParmProblems\n    - Icmp6InPktTooBigs\n    - Icmp6InRedirects\n    - Icmp6InRouterAdvertisements\n    - Icmp6InRouterSolicits\n    - Icmp6InTimeExcds\n    - Icmp6OutDestUnreachs\n    - Icmp6OutEchoReplies\n    - Icmp6OutEchos\n    - Icmp6OutErrors\n    - Icmp6OutGroupMembQueries\n    - Icmp6OutGroupMembReductions\n    - Icmp6OutGroupMembResponses\n    - Icmp6OutMLDv2Reports\n    - Icmp6OutMsgs\n    - Icmp6OutNeighborAdvertisements\n    - Icmp6OutNeighborSolicits\n    - Icmp6OutParmProblems\n    - Icmp6OutPktTooBigs\n    - Icmp6OutRedirects\n    - Icmp6OutRouterAdvertisements\n    - Icmp6OutRouterSolicits\n    - Icmp6OutTimeExcds\n    - Icmp6OutType133\n    - Icmp6OutType135\n    - Icmp6OutType143\n    - IcmpInAddrMaskReps\n    - IcmpInAddrMasks\n    - IcmpInCsumErrors\n    - IcmpInDestUnreachs\n    - IcmpInEchoReps\n    - IcmpInEchos\n    - IcmpInErrors\n    - IcmpInMsgs\n    - IcmpInParmProbs\n    - IcmpInRedirects\n    - IcmpInSrcQuenchs\n    - IcmpInTimeExcds\n    - IcmpInTimestampReps\n    - IcmpInTimestamps\n    - IcmpMsgInType3\n    - IcmpMsgOutType3\n    - IcmpOutAddrMaskReps\n    - IcmpOutAddrMasks\n    - IcmpOutDestUnreachs\n    - IcmpOutEchoReps\n    - IcmpOutEchos\n    - IcmpOutErrors\n    - IcmpOutMsgs\n    - IcmpOutParmProbs\n    - IcmpOutRedirects\n    - IcmpOutSrcQuenchs\n    - IcmpOutTimeExcds\n    - IcmpOutTimestampReps\n    - IcmpOutTimestamps\n    - Ip6FragCreates\n    - Ip6FragFails\n    - Ip6FragOKs\n    - Ip6InAddrErrors\n    - Ip6InBcastOctets\n    - Ip6InCEPkts\n    - Ip6InDelivers\n    - Ip6InDiscards\n    - Ip6InECT0Pkts\n    - Ip6InECT1Pkts\n    - Ip6InHdrErrors\n    - Ip6InMcastOctets\n    - Ip6InMcastPkts\n    - Ip6InNoECTPkts\n    - Ip6InNoRoutes\n    - Ip6InOctets\n    - Ip6InReceives\n    - Ip6InTooBigErrors\n    - Ip6InTruncatedPkts\n    - Ip6InUnknownProtos\n    - Ip6OutBcastOctets\n    - Ip6OutDiscards\n    - Ip6OutForwDatagrams\n    - Ip6OutMcastOctets\n    - Ip6OutMcastPkts\n    - Ip6OutNoRoutes\n    - Ip6OutOctets\n    - Ip6OutRequests\n    - Ip6ReasmFails\n    - Ip6ReasmOKs\n    - Ip6ReasmReqds\n    - Ip6ReasmTimeout\n    - IpDefaultTTL\n    - IpExtInBcastOctets\n    - IpExtInBcastPkts\n    - IpExtInCEPkts\n    - IpExtInCsumErrors\n    - IpExtInECT0Pkts\n    - IpExtInECT1Pkts\n    - IpExtInMcastOctets\n    - IpExtInMcastPkts\n    - IpExtInNoECTPkts\n    - IpExtInNoRoutes\n    - IpExtInOctets\n    - IpExtInTruncatedPkts\n    - IpExtOutBcastOctets\n    - IpExtOutBcastPkts\n    - IpExtOutMcastOctets\n    - IpExtOutMcastPkts\n    - IpExtOutOctets\n    - IpForwDatagrams\n    - IpForwarding\n    - IpFragCreates\n    - IpFragFails\n    - IpFragOKs\n    - IpInAddrErrors\n    - IpInDelivers\n    - IpInDiscards\n    - IpInHdrErrors\n    - IpInReceives\n    - IpInUnknownProtos\n    - IpOutDiscards\n    - IpOutNoRoutes\n    - IpOutRequests\n    - IpReasmFails\n    - IpReasmOKs\n    - IpReasmReqds\n    - IpReasmTimeout\n    - TcpActiveOpens\n    - TcpAttemptFails\n    - TcpCurrEstab\n    - TcpEstabResets\n    - TcpExtArpFilter\n    - TcpExtBusyPollRxPackets\n    - TcpExtDelayedACKLocked\n    - TcpExtDelayedACKLost\n    - TcpExtDelayedACKs\n    - TcpExtEmbryonicRsts\n    - TcpExtIPReversePathFilter\n    - TcpExtListenDrops\n    - TcpExtListenOverflows\n    - TcpExtLockDroppedIcmps\n    - TcpExtOfoPruned\n    - TcpExtOutOfWindowIcmps\n    - TcpExtPAWSActive\n    - TcpExtPAWSEstab\n    - TcpExtPAWSPassive\n    - TcpExtPruneCalled\n    - TcpExtRcvPruned\n    - TcpExtSyncookiesFailed\n    - TcpExtSyncookiesRecv\n    - TcpExtSyncookiesSent\n    - TcpExtTCPACKSkippedChallenge\n    - TcpExtTCPACKSkippedFinWait2\n    - TcpExtTCPACKSkippedPAWS\n    - TcpExtTCPACKSkippedSeq\n    - TcpExtTCPACKSkippedSynRecv\n    - TcpExtTCPACKSkippedTimeWait\n    - TcpExtTCPAbortFailed\n    - TcpExtTCPAbortOnClose\n    - TcpExtTCPAbortOnData\n    - TcpExtTCPAbortOnLinger\n    - TcpExtTCPAbortOnMemory\n    - TcpExtTCPAbortOnTimeout\n    - TcpExtTCPAutoCorking\n    - TcpExtTCPBacklogDrop\n    - TcpExtTCPChallengeACK\n    - TcpExtTCPDSACKIgnoredNoUndo\n    - TcpExtTCPDSACKIgnoredOld\n    - TcpExtTCPDSACKOfoRecv\n    - TcpExtTCPDSACKOfoSent\n    - TcpExtTCPDSACKOldSent\n    - TcpExtTCPDSACKRecv\n    - TcpExtTCPDSACKUndo\n    - TcpExtTCPDeferAcceptDrop\n    - TcpExtTCPDirectCopyFromBacklog\n    - TcpExtTCPDirectCopyFromPrequeue\n    - TcpExtTCPFACKReorder\n    - TcpExtTCPFastOpenActive\n    - TcpExtTCPFastOpenActiveFail\n    - TcpExtTCPFastOpenCookieReqd\n    - TcpExtTCPFastOpenListenOverflow\n    - TcpExtTCPFastOpenPassive\n    - TcpExtTCPFastOpenPassiveFail\n    - TcpExtTCPFastRetrans\n    - TcpExtTCPForwardRetrans\n    - TcpExtTCPFromZeroWindowAdv\n    - TcpExtTCPFullUndo\n    - TcpExtTCPHPAcks\n    - TcpExtTCPHPHits\n    - TcpExtTCPHPHitsToUser\n    - TcpExtTCPHystartDelayCwnd\n    - TcpExtTCPHystartDelayDetect\n    - TcpExtTCPHystartTrainCwnd\n    - TcpExtTCPHystartTrainDetect\n    - TcpExtTCPKeepAlive\n    - TcpExtTCPLossFailures\n    - TcpExtTCPLossProbeRecovery\n    - TcpExtTCPLossProbes\n    - TcpExtTCPLossUndo\n    - TcpExtTCPLostRetransmit\n    - TcpExtTCPMD5NotFound\n    - TcpExtTCPMD5Unexpected\n    - TcpExtTCPMTUPFail\n    - TcpExtTCPMTUPSuccess\n    - TcpExtTCPMemoryPressures\n    - TcpExtTCPMinTTLDrop\n    - TcpExtTCPOFODrop\n    - TcpExtTCPOFOMerge\n    - TcpExtTCPOFOQueue\n    - TcpExtTCPOrigDataSent\n    - TcpExtTCPPartialUndo\n    - TcpExtTCPPrequeueDropped\n    - TcpExtTCPPrequeued\n    - TcpExtTCPPureAcks\n    - TcpExtTCPRcvCoalesce\n    - TcpExtTCPRcvCollapsed\n    - TcpExtTCPRenoFailures\n    - TcpExtTCPRenoRecovery\n    - TcpExtTCPRenoRecoveryFail\n    - TcpExtTCPRenoReorder\n    - TcpExtTCPReqQFullDoCookies\n    - TcpExtTCPReqQFullDrop\n    - TcpExtTCPRetransFail\n    - TcpExtTCPSACKDiscard\n    - TcpExtTCPSACKReneging\n    - TcpExtTCPSACKReorder\n    - TcpExtTCPSYNChallenge\n    - TcpExtTCPSackFailures\n    - TcpExtTCPSackMerged\n    - TcpExtTCPSackRecovery\n    - TcpExtTCPSackRecoveryFail\n    - TcpExtTCPSackShiftFallback\n    - TcpExtTCPSackShifted\n    - TcpExtTCPSchedulerFailed\n    - TcpExtTCPSlowStartRetrans\n    - TcpExtTCPSpuriousRTOs\n    - TcpExtTCPSpuriousRtxHostQueues\n    - TcpExtTCPSynRetrans\n    - TcpExtTCPTSReorder\n    - TcpExtTCPTimeWaitOverflow\n    - TcpExtTCPTimeouts\n    - TcpExtTCPToZeroWindowAdv\n    - TcpExtTCPWantZeroWindowAdv\n    - TcpExtTCPWinProbe\n    - TcpExtTW\n    - TcpExtTWKilled\n    - TcpExtTWRecycled\n    - TcpInCsumErrors\n    - TcpInErrs\n    - TcpInSegs\n    - TcpMaxConn\n    - TcpOutRsts\n    - TcpOutSegs\n    - TcpPassiveOpens\n    - TcpRetransSegs\n    - TcpRtoAlgorithm\n    - TcpRtoMax\n    - TcpRtoMin\n    - Udp6IgnoredMulti\n    - Udp6InCsumErrors\n    - Udp6InDatagrams\n    - Udp6InErrors\n    - Udp6NoPorts\n    - Udp6OutDatagrams\n    - Udp6RcvbufErrors\n    - Udp6SndbufErrors\n    - UdpIgnoredMulti\n    - UdpInCsumErrors\n    - UdpInDatagrams\n    - UdpInErrors\n    - UdpLite6InCsumErrors\n    - UdpLite6InDatagrams\n    - UdpLite6InErrors\n    - UdpLite6NoPorts\n    - UdpLite6OutDatagrams\n    - UdpLite6RcvbufErrors\n    - UdpLite6SndbufErrors\n    - UdpLiteIgnoredMulti\n    - UdpLiteInCsumErrors\n    - UdpLiteInDatagrams\n    - UdpLiteInErrors\n    - UdpLiteNoPorts\n    - UdpLiteOutDatagrams\n    - UdpLiteRcvbufErrors\n    - UdpLiteSndbufErrors\n    - UdpNoPorts\n    - UdpOutDatagrams\n    - UdpRcvbufErrors\n    - UdpSndbufErrors\n\n### Tags\n- All measurements have the following tags\n    - host (host of the system)\n    - name (the type of the metric: snmp, snmp6 or netstat)\n',image:Ns.a},{id:"ntpq",name:"ntpq",markdown:"# ntpq Input Plugin\n\nGet standard NTP query metrics, requires ntpq executable.\n\nBelow is the documentation of the various headers returned from the NTP query\ncommand when running `ntpq -p`.\n\n- remote – The remote peer or server being synced to. “LOCAL” is this local host\n(included in case there are no remote peers or servers available);\n- refid – Where or what the remote peer or server is itself synchronised to;\n- st (stratum) – The remote peer or server Stratum\n- t (type) – Type (u: unicast or manycast client, b: broadcast or multicast client,\nl: local reference clock, s: symmetric peer, A: manycast server,\nB: broadcast server, M: multicast server, see “Automatic Server Discovery“);\n- when – When last polled (seconds ago, “h” hours ago, or “d” days ago);\n- poll – Polling frequency: rfc5905 suggests this ranges in NTPv4 from 4 (16s)\nto 17 (36h) (log2 seconds), however observation suggests the actual displayed\nvalue is seconds for a much smaller range of 64 (26) to 1024 (210) seconds;\n- reach – An 8-bit left-shift shift register value recording polls (bit set =\nsuccessful, bit reset = fail) displayed in octal;\n- delay – Round trip communication delay to the remote peer or server (milliseconds);\n- offset – Mean offset (phase) in the times reported between this local host and\nthe remote peer or server (RMS, milliseconds);\n- jitter – Mean deviation (jitter) in the time reported for that remote peer or\nserver (RMS of difference of multiple time samples, milliseconds);\n\n### Configuration:\n\n```toml\n# Get standard NTP query metrics, requires ntpq executable\n[[inputs.ntpq]]\n  ## If false, add -n for ntpq command. Can reduce metric gather times.\n  dns_lookup = true\n```\n\n### Measurements & Fields:\n\n- ntpq\n    - delay (float, milliseconds)\n    - jitter (float, milliseconds)\n    - offset (float, milliseconds)\n    - poll (int, seconds)\n    - reach (int)\n    - when (int, seconds)\n\n### Tags:\n\n- All measurements have the following tags:\n    - refid\n    - remote\n    - type\n    - stratum\n\n### Example Output:\n\n```\n$ telegraf --config ~/ws/telegraf.conf --input-filter ntpq --test\n* Plugin: ntpq, Collection 1\n> ntpq,refid=.GPSs.,remote=*time.apple.com,stratum=1,type=u delay=91.797,jitter=3.735,offset=12.841,poll=64i,reach=377i,when=35i 1457960478909556134\n```\n",image:Ls.a},{id:"nvidia_smi",name:"Nvidia System Management Interface (SMI)",markdown:'# Nvidia System Management Interface (SMI) Input Plugin\n\nThis plugin uses a query on the [`nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface) binary to pull GPU stats including memory and GPU usage, temp and other.\n\n### Configuration\n\n```toml\n# Pulls statistics from nvidia GPUs attached to the host\n[[inputs.nvidia_smi]]\n  ## Optional: path to nvidia-smi binary, defaults to $PATH via exec.LookPath\n  # bin_path = "/usr/bin/nvidia-smi"\n\n  ## Optional: timeout for GPU polling\n  # timeout = "5s"\n```\n\n#### Windows\n\nOn Windows, `nvidia-smi` is generally located at `C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvidia-smi.exe`\nOn Windows 10, you may also find this located here `C:\\Windows\\System32\\nvidia-smi.exe`\n\nYou\'ll need to escape the `\\` within the `telegraf.conf` like this: `C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVSMI\\\\nvidia-smi.exe`\n\n### Metrics\n- measurement: `nvidia_smi`\n  - tags\n    - `name` (type of GPU e.g. `GeForce GTX 1070 Ti`)\n    - `compute_mode` (The compute mode of the GPU e.g. `Default`)\n    - `index` (The port index where the GPU is connected to the motherboard e.g. `1`)\n    - `pstate` (Overclocking state for the GPU e.g. `P0`)\n    - `uuid` (A unique identifier for the GPU e.g. `GPU-f9ba66fc-a7f5-94c5-da19-019ef2f9c665`)\n  - fields\n    - `fan_speed` (integer, percentage)\n    - `fbc_stats_session_count` (integer)\n    - `fbc_stats_average_fps` (integer)\n    - `fbc_stats_average_latency` (integer)\n    - `memory_free` (integer, MiB)\n    - `memory_used` (integer, MiB)\n    - `memory_total` (integer, MiB)\n    - `power_draw` (float, W)\n    - `temperature_gpu` (integer, degrees C)\n    - `utilization_gpu` (integer, percentage)\n    - `utilization_memory` (integer, percentage)\n    - `utilization_encoder` (integer, percentage)\n    - `utilization_decoder` (integer, percentage)\n    - `pcie_link_gen_current` (integer)\n    - `pcie_link_width_current` (integer)\n    - `encoder_stats_session_count` (integer)\n    - `encoder_stats_average_fps` (integer)\n    - `encoder_stats_average_latency` (integer)\n    - `clocks_current_graphics` (integer, MHz)\n    - `clocks_current_sm` (integer, MHz)\n    - `clocks_current_memory` (integer, MHz)\n    - `clocks_current_video` (integer, MHz)\n    - `driver_version` (string)\n    - `cuda_version` (string)\n\n### Sample Query\n\nThe below query could be used to alert on the average temperature of the your GPUs over the last minute\n\n```sql\nSELECT mean("temperature_gpu") FROM "nvidia_smi" WHERE time > now() - 5m GROUP BY time(1m), "index", "name", "host"\n```\n\n### Troubleshooting\n\nCheck the full output by running `nvidia-smi` binary manually.\n\nLinux:\n```sh\nsudo -u telegraf -- /usr/bin/nvidia-smi -q -x\n```\n\nWindows:\n```\n"C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvidia-smi.exe" -q -x\n```\n\nPlease include the output of this command if opening an GitHub issue.\n\n### Example Output\n```\nnvidia_smi,compute_mode=Default,host=8218cf,index=0,name=GeForce\\ GTX\\ 1070,pstate=P2,uuid=GPU-823bc202-6279-6f2c-d729-868a30f14d96 fan_speed=100i,memory_free=7563i,memory_total=8112i,memory_used=549i,temperature_gpu=53i,utilization_gpu=100i,utilization_memory=90i 1523991122000000000\nnvidia_smi,compute_mode=Default,host=8218cf,index=1,name=GeForce\\ GTX\\ 1080,pstate=P2,uuid=GPU-f9ba66fc-a7f5-94c5-da19-019ef2f9c665 fan_speed=100i,memory_free=7557i,memory_total=8114i,memory_used=557i,temperature_gpu=50i,utilization_gpu=100i,utilization_memory=85i 1523991122000000000\nnvidia_smi,compute_mode=Default,host=8218cf,index=2,name=GeForce\\ GTX\\ 1080,pstate=P2,uuid=GPU-d4cfc28d-0481-8d07-b81a-ddfc63d74adf fan_speed=100i,memory_free=7557i,memory_total=8114i,memory_used=557i,temperature_gpu=58i,utilization_gpu=100i,utilization_memory=86i 1523991122000000000\n```\n\n### Limitations\nNote that there seems to be an issue with getting current memory clock values when the memory is overclocked.\nThis may or may not apply to everyone but it\'s confirmed to be an issue on an EVGA 2080 Ti.\n\n**NOTE:** For use with docker either generate your own custom docker image based on nvidia/cuda which also installs a telegraf package or use [volume mount binding](https://docs.docker.com/storage/bind-mounts/) to inject the required binary into the docker container.\n',image:Us.a},{id:"opcua",name:"OPC UA Client",markdown:'# OPC UA Client Input Plugin\n\nThe `opcua` plugin retrieves data from OPC UA client devices.\n\nTelegraf minimum version: Telegraf 1.16\nPlugin minimum tested version: 1.16\n\n### Configuration:\n\n```toml\n[[inputs.opcua]]\n  ## Metric name\n  # name = "opcua"\n  #\n  ## OPC UA Endpoint URL\n  # endpoint = "opc.tcp://localhost:4840"\n  #\n  ## Maximum time allowed to establish a connect to the endpoint.\n  # connect_timeout = "10s"\n  #\n  ## Maximum time allowed for a request over the estabilished connection.\n  # request_timeout = "5s"\n  #\n  ## Security policy, one of "None", "Basic128Rsa15", "Basic256",\n  ## "Basic256Sha256", or "auto"\n  # security_policy = "auto"\n  #\n  ## Security mode, one of "None", "Sign", "SignAndEncrypt", or "auto"\n  # security_mode = "auto"\n  #\n  ## Path to cert.pem. Required when security mode or policy isn\'t "None".\n  ## If cert path is not supplied, self-signed cert and key will be generated.\n  # certificate = "/etc/telegraf/cert.pem"\n  #\n  ## Path to private key.pem. Required when security mode or policy isn\'t "None".\n  ## If key path is not supplied, self-signed cert and key will be generated.\n  # private_key = "/etc/telegraf/key.pem"\n  #\n  ## Authentication Method, one of "Certificate", "UserName", or "Anonymous".  To\n  ## authenticate using a specific ID, select \'Certificate\' or \'UserName\'\n  # auth_method = "Anonymous"\n  #\n  ## Username. Required for auth_method = "UserName"\n  # username = ""\n  #\n  ## Password. Required for auth_method = "UserName"\n  # password = ""\n  #\n  ## Node ID configuration\n  ## name              - field name to use in the output\n  ## namespace         - OPC UA namespace of the node (integer value 0 thru 3)\n  ## identifier_type   - OPC UA ID type (s=string, i=numeric, g=guid, b=opaque)\n  ## identifier        - OPC UA ID (tag as shown in opcua browser)\n  ## tags              - extra tags to be added to the output metric (optional)\n  ## Example:\n  ## {name="ProductUri", namespace="0", identifier_type="i", identifier="2262", tags=[["tag1","value1"],["tag2","value2]]}\n  # nodes = [\n  #  {name="", namespace="", identifier_type="", identifier=""},\n  #  {name="", namespace="", identifier_type="", identifier=""},\n  #]\n  #\n  ## Node Group\n  ## Sets defaults for OPC UA namespace and ID type so they aren\'t required in\n  ## every node.  A group can also have a metric name that overrides the main\n  ## plugin metric name.\n  ##\n  ## Multiple node groups are allowed\n  #[[inputs.opcua.group]]\n  ## Group Metric name. Overrides the top level name.  If unset, the\n  ## top level name is used.\n  # name =\n  #\n  ## Group default namespace. If a node in the group doesn\'t set its\n  ## namespace, this is used.\n  # namespace =\n  #\n  ## Group default identifier type. If a node in the group doesn\'t set its\n  ## namespace, this is used.\n  # identifier_type =\n  #\n  ## Node ID Configuration.  Array of nodes with the same settings as above.\n  # nodes = [\n  #  {name="", namespace="", identifier_type="", identifier=""},\n  #  {name="", namespace="", identifier_type="", identifier=""},\n  #]\n```\n\n### Node Configuration\nAn OPC UA node ID may resemble: "n=3;s=Temperature". In this example:\n- n=3 is indicating the `namespace` is 3\n- s=Temperature is indicting that the `identifier_type` is a string and `identifier` value is \'Temperature\'\n- This example temperature node has a value of 79.0\nTo gather data from this node enter the following line into the \'nodes\' property above:\n```\n{field_name="temp", namespace="3", identifier_type="s", identifier="Temperature"},\n```\n\nThis node configuration produces a metric like this:\n```\nopcua,id=n\\=3;s\\=Temperature temp=79.0,quality="OK (0x0)" 1597820490000000000\n\n```\n\n### Group Configuration\nGroups can set default values for the namespace, identifier type, and\ntags settings.  The default values apply to all the nodes in the\ngroup.  If a default is set, a node may omit the setting altogether.\nThis simplifies node configuration, especially when many nodes share\nthe same namespace or identifier type.\n\nThe output metric will include tags set in the group and the node.  If\na tag with the same name is set in both places, the tag value from the\nnode is used.\n\nThis example group configuration has two groups with two nodes each:\n```\n  [[inputs.opcua.group]]\n  name="group1_metric_name"\n  namespace="3"\n  identifier_type="i"\n  tags=[["group1_tag", "val1"]]\n  nodes = [\n    {name="name", identifier="1001", tags=[["node1_tag", "val2"]]},\n    {name="name", identifier="1002", tags=[["node1_tag", "val3"]]},\n  ]\n  [[inputs.opcua.group]]\n  name="group2_metric_name"\n  namespace="3"\n  identifier_type="i"\n  tags=[["group2_tag", "val3"]]\n  nodes = [\n    {name="saw", identifier="1003", tags=[["node2_tag", "val4"]]},\n    {name="sin", identifier="1004"},\n  ]\n```\n\nIt produces metrics like these:\n```\ngroup1_metric_name,group1_tag=val1,id=ns\\=3;i\\=1001,node1_tag=val2 name=0,Quality="OK (0x0)" 1606893246000000000\ngroup1_metric_name,group1_tag=val1,id=ns\\=3;i\\=1002,node1_tag=val3 name=-1.389117,Quality="OK (0x0)" 1606893246000000000\ngroup2_metric_name,group2_tag=val3,id=ns\\=3;i\\=1003,node2_tag=val4 Quality="OK (0x0)",saw=-1.6 1606893246000000000\ngroup2_metric_name,group2_tag=val3,id=ns\\=3;i\\=1004 sin=1.902113,Quality="OK (0x0)" 1606893246000000000\n```\n',image:Bs.a},{id:"openldap",name:"OpenLDAP",markdown:'# OpenLDAP Input Plugin\n\nThis plugin gathers metrics from OpenLDAP\'s cn=Monitor backend.\n\n### Configuration:\n\nTo use this plugin you must enable the [slapd monitoring](https://www.openldap.org/devel/admin/monitoringslapd.html) backend.\n\n```toml\n[[inputs.openldap]]\n  host = "localhost"\n  port = 389\n\n  # ldaps, starttls, or no encryption. default is an empty string, disabling all encryption.\n  # note that port will likely need to be changed to 636 for ldaps\n  # valid options: "" | "starttls" | "ldaps"\n  tls = ""\n\n  # skip peer certificate verification. Default is false.\n  insecure_skip_verify = false\n\n  # Path to PEM-encoded Root certificate to use to verify server certificate\n  tls_ca = "/etc/ssl/certs.pem"\n\n  # dn/password to bind with. If bind_dn is empty, an anonymous bind is performed.\n  bind_dn = ""\n  bind_password = ""\n  \n  # reverse metric names so they sort more naturally\n  # Defaults to false if unset, but is set to true when generating a new config\n  reverse_metric_names = true\n```\n\n### Measurements & Fields:\n\nAll **monitorCounter**, **monitoredInfo**, **monitorOpInitiated**, and **monitorOpCompleted** attributes are gathered based on this LDAP query:\n\n```\n(|(objectClass=monitorCounterObject)(objectClass=monitorOperation)(objectClass=monitoredObject))\n```\n\nMetric names are based on their entry DN with the cn=Monitor base removed. If `reverse_metric_names` is not set, metrics are based on their DN. If `reverse_metric_names` is set to `true`, the names are reversed. This is recommended as it allows the names to sort more naturally.\n\nMetrics for the **monitorOp*** attributes have **_initiated** and **_completed** added to the base name as appropriate.\n\nAn OpenLDAP 2.4 server will provide these metrics:\n\n- openldap\n\t- connections_current\n\t- connections_max_file_descriptors\n\t- connections_total\n\t- operations_abandon_completed\n\t- operations_abandon_initiated\n\t- operations_add_completed\n\t- operations_add_initiated\n\t- operations_bind_completed\n\t- operations_bind_initiated\n\t- operations_compare_completed\n\t- operations_compare_initiated\n\t- operations_delete_completed\n\t- operations_delete_initiated\n\t- operations_extended_completed\n\t- operations_extended_initiated\n\t- operations_modify_completed\n\t- operations_modify_initiated\n\t- operations_modrdn_completed\n\t- operations_modrdn_initiated\n\t- operations_search_completed\n\t- operations_search_initiated\n\t- operations_unbind_completed\n\t- operations_unbind_initiated\n\t- statistics_bytes\n\t- statistics_entries\n\t- statistics_pdu\n\t- statistics_referrals\n\t- threads_active\n\t- threads_backload\n\t- threads_max\n\t- threads_max_pending\n\t- threads_open\n\t- threads_pending\n\t- threads_starting\n\t- time_uptime\n\t- waiters_read\n\t- waiters_write\n\n### Tags:\n\n- server= # value from config\n- port= # value from config\n\n### Example Output:\n\n```\n$ telegraf -config telegraf.conf -input-filter openldap -test --debug\n* Plugin: inputs.openldap, Collection 1\n> openldap,server=localhost,port=389,host=niska.ait.psu.edu operations_bind_initiated=10i,operations_unbind_initiated=6i,operations_modrdn_completed=0i,operations_delete_initiated=0i,operations_add_completed=2i,operations_delete_completed=0i,operations_abandon_completed=0i,statistics_entries=1516i,threads_open=2i,threads_active=1i,waiters_read=1i,operations_modify_completed=0i,operations_extended_initiated=4i,threads_pending=0i,operations_search_initiated=36i,operations_compare_initiated=0i,connections_max_file_descriptors=4096i,operations_modify_initiated=0i,operations_modrdn_initiated=0i,threads_max=16i,time_uptime=6017i,connections_total=1037i,connections_current=1i,operations_add_initiated=2i,statistics_bytes=162071i,operations_unbind_completed=6i,operations_abandon_initiated=0i,statistics_pdu=1566i,threads_max_pending=0i,threads_backload=1i,waiters_write=0i,operations_bind_completed=10i,operations_search_completed=35i,operations_compare_completed=0i,operations_extended_completed=4i,statistics_referrals=0i,threads_starting=0i 1516912070000000000\n```\n',image:Hs.a},{id:"openntpd",name:"OpenNTPD",markdown:'# OpenNTPD Input Plugin\n\nGet standard NTP query metrics from [OpenNTPD][] using the ntpctl command.\n\n[OpenNTPD]: http://www.openntpd.org/\n\nBelow is the documentation of the various headers returned from the NTP query\ncommand when running `ntpctl -s peers`.\n\n- remote – The remote peer or server being synced to.\n- wt – the peer weight\n- tl – the peer trust level\n- st (stratum) – The remote peer or server Stratum\n- next – number of seconds until the next poll\n- poll – polling interval in seconds\n- delay – Round trip communication delay to the remote peer\nor server (milliseconds);\n- offset – Mean offset (phase) in the times reported between this local host and\nthe remote peer or server (RMS, milliseconds);\n- jitter – Mean deviation (jitter) in the time reported for that remote peer or\nserver (RMS of difference of multiple time samples, milliseconds);\n\n### Configuration\n\n```toml\n[[inputs.openntpd]]\n  ## Run ntpctl binary with sudo.\n  # use_sudo = false\n\n  ## Location of the ntpctl binary.\n  # binary = "/usr/sbin/ntpctl"\n\n  ## Maximum time the ntpctl binary is allowed to run.\n  # timeout = "5ms"\n```\n\n### Metrics\n\n- ntpctl\n  - tags:\n    - remote\n    - stratum\n  - fields:\n    - delay (float, milliseconds)\n    - jitter (float, milliseconds)\n    - offset (float, milliseconds)\n    - poll (int, seconds)\n    - next (int, seconds)\n    - wt (int)\n    - tl (int)\n\n### Permissions\n\nIt\'s important to note that this plugin references ntpctl, which may require\nadditional permissions to execute successfully.\nDepending on the user/group permissions of the telegraf user executing this\nplugin, you may need to alter the group membership, set facls, or use sudo.\n\n**Group membership (Recommended)**:\n```bash\n$ groups telegraf\ntelegraf : telegraf\n\n$ usermod -a -G ntpd telegraf\n\n$ groups telegraf\ntelegraf : telegraf ntpd\n```\n\n**Sudo privileges**:\nIf you use this method, you will need the following in your telegraf config:\n```toml\n[[inputs.openntpd]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following lines:\nCmnd_Alias NTPCTL = /usr/sbin/ntpctl\ntelegraf ALL=(ALL) NOPASSWD: NTPCTL\nDefaults!NTPCTL !logfile, !syslog, !pam_session\n```\n\nPlease use the solution you see as most appropriate.\n\n### Example Output\n\n```\nopenntpd,remote=194.57.169.1,stratum=2,host=localhost tl=10i,poll=1007i,\noffset=2.295,jitter=3.896,delay=53.766,next=266i,wt=1i 1514454299000000000\n```\n',image:Gs.a},{id:"opensmtpd",name:"OpenSMTPD",markdown:'# OpenSMTPD Input Plugin\n\nThis plugin gathers stats from [OpenSMTPD - a FREE implementation of the server-side SMTP protocol](https://www.opensmtpd.org/)\n\n### Configuration:\n\n```toml\n [[inputs.opensmtpd]]\n   ## If running as a restricted user you can prepend sudo for additional access:\n   #use_sudo = false\n\n   ## The default location of the smtpctl binary can be overridden with:\n   binary = "/usr/sbin/smtpctl"\n\n   # The default timeout of 1s can be overridden with:\n   #timeout = "1s"\n```\n\n### Measurements & Fields:\n\nThis is the full list of stats provided by smtpctl and potentially collected by telegram\ndepending of your smtpctl configuration.\n\n- smtpctl\n    bounce_envelope\n    bounce_message\n    bounce_session\n    control_session\n    mda_envelope\n    mda_pending\n    mda_running\n    mda_user\n    mta_connector\n    mta_domain\n    mta_envelope\n    mta_host\n    mta_relay\n    mta_route\n    mta_session\n    mta_source\n    mta_task\n    mta_task_running\n    queue_bounce\n    queue_evpcache_load_hit\n    queue_evpcache_size\n    queue_evpcache_update_hit\n    scheduler_delivery_ok\n    scheduler_delivery_permfail\n    scheduler_delivery_tempfail\n    scheduler_envelope\n    scheduler_envelope_expired\n    scheduler_envelope_incoming\n    scheduler_envelope_inflight\n    scheduler_ramqueue_envelope\n    scheduler_ramqueue_message\n    scheduler_ramqueue_update\n    smtp_session\n    smtp_session_inet4\n    smtp_session_local\n    uptime\n\n### Permissions:\n\nIt\'s important to note that this plugin references smtpctl, which may require additional permissions to execute successfully.\nDepending on the user/group permissions of the telegraf user executing this plugin, you may need to alter the group membership, set facls, or use sudo.\n\n**Group membership (Recommended)**:\n```bash\n$ groups telegraf\ntelegraf : telegraf\n\n$ usermod -a -G opensmtpd telegraf\n\n$ groups telegraf\ntelegraf : telegraf opensmtpd\n```\n\n**Sudo privileges**:\nIf you use this method, you will need the following in your telegraf config:\n```toml\n[[inputs.opensmtpd]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias SMTPCTL = /usr/sbin/smtpctl\ntelegraf  ALL=(ALL) NOPASSWD: SMTPCTL\nDefaults!SMTPCTL !logfile, !syslog, !pam_session\n```\n\nPlease use the solution you see as most appropriate.\n\n### Example Output:\n\n```\n telegraf --config etc/telegraf.conf --input-filter opensmtpd --test\n* Plugin: inputs.opensmtpd, Collection 1\n> opensmtpd,host=localhost scheduler_delivery_tempfail=822,mta_host=10,mta_task_running=4,queue_bounce=13017,scheduler_delivery_permfail=51022,mta_relay=7,queue_evpcache_size=2,scheduler_envelope_expired=26,bounce_message=0,mta_domain=7,queue_evpcache_update_hit=848,smtp_session_local=12294,bounce_envelope=0,queue_evpcache_load_hit=4389703,scheduler_ramqueue_update=0,mta_route=3,scheduler_delivery_ok=2149489,smtp_session_inet4=2131997,control_session=1,scheduler_envelope_incoming=0,uptime=10346728,scheduler_ramqueue_envelope=2,smtp_session=0,bounce_session=0,mta_envelope=2,mta_session=6,mta_task=2,scheduler_ramqueue_message=2,mta_connector=7,mta_source=1,scheduler_envelope=2,scheduler_envelope_inflight=2 1510220300000000000\n\n```\n',image:Ks.a},{id:"opentelemetry",name:"OpenTelemetry",markdown:'# OpenTelemetry Input Plugin\n\nThis plugin receives traces, metrics and logs from [OpenTelemetry](https://opentelemetry.io) clients and agents via gRPC.\n\n### Configuration\n\n```toml\n[[inputs.opentelemetry]]\n  ## Override the OpenTelemetry gRPC service address:port \n  # service_address = "0.0.0.0:4317"\n  \n  ## Override the default request timeout\n  # timeout = "5s"\n  \n  ## Select a schema for metrics: "prometheus-v1" or "prometheus-v2"\n  ## For more information about the alternatives, read the Prometheus input\n  ## plugin notes.\n  # metrics_schema = "prometheus-v1"\n```\n\n#### Schema\n\nThe OpenTelemetry->InfluxDB conversion [schema](https://github.com/influxdata/influxdb-observability/blob/main/docs/index.md)\nand [implementation](https://github.com/influxdata/influxdb-observability/tree/main/otel2influx)\nare hosted at https://github.com/influxdata/influxdb-observability .\n\nSpans are stored in measurement `spans`.\nLogs are stored in measurement `logs`.\n\nFor metrics, two output schemata exist.\nMetrics received with `metrics_schema=prometheus-v1` are assigned measurement from the OTel field `Metric.name`.\nMetrics received with `metrics_schema=prometheus-v2` are stored in measurement `prometheus`.\n\n### Example Output\n\n#### Tracing Spans\n```\nspans end_time_unix_nano="2021-02-19 20:50:25.6893952 +0000 UTC",instrumentation_library_name="tracegen",kind="SPAN_KIND_INTERNAL",name="okey-dokey",net.peer.ip="1.2.3.4",parent_span_id="d5270e78d85f570f",peer.service="tracegen-client",service.name="tracegen",span.kind="server",span_id="4c28227be6a010e1",status_code="STATUS_CODE_OK",trace_id="7d4854815225332c9834e6dbf85b9380" 1613767825689169000\nspans end_time_unix_nano="2021-02-19 20:50:25.6893952 +0000 UTC",instrumentation_library_name="tracegen",kind="SPAN_KIND_INTERNAL",name="lets-go",net.peer.ip="1.2.3.4",peer.service="tracegen-server",service.name="tracegen",span.kind="client",span_id="d5270e78d85f570f",status_code="STATUS_CODE_OK",trace_id="7d4854815225332c9834e6dbf85b9380" 1613767825689135000\nspans end_time_unix_nano="2021-02-19 20:50:25.6895667 +0000 UTC",instrumentation_library_name="tracegen",kind="SPAN_KIND_INTERNAL",name="okey-dokey",net.peer.ip="1.2.3.4",parent_span_id="b57e98af78c3399b",peer.service="tracegen-client",service.name="tracegen",span.kind="server",span_id="a0643a156d7f9f7f",status_code="STATUS_CODE_OK",trace_id="fd6b8bb5965e726c94978c644962cdc8" 1613767825689388000\nspans end_time_unix_nano="2021-02-19 20:50:25.6895667 +0000 UTC",instrumentation_library_name="tracegen",kind="SPAN_KIND_INTERNAL",name="lets-go",net.peer.ip="1.2.3.4",peer.service="tracegen-server",service.name="tracegen",span.kind="client",span_id="b57e98af78c3399b",status_code="STATUS_CODE_OK",trace_id="fd6b8bb5965e726c94978c644962cdc8" 1613767825689303300\nspans end_time_unix_nano="2021-02-19 20:50:25.6896741 +0000 UTC",instrumentation_library_name="tracegen",kind="SPAN_KIND_INTERNAL",name="okey-dokey",net.peer.ip="1.2.3.4",parent_span_id="6a8e6a0edcc1c966",peer.service="tracegen-client",service.name="tracegen",span.kind="server",span_id="d68f7f3b41eb8075",status_code="STATUS_CODE_OK",trace_id="651dadde186b7834c52b13a28fc27bea" 1613767825689480300\n```\n\n### Metrics - `prometheus-v1`\n```\ncpu_temp,foo=bar gauge=87.332\nhttp_requests_total,method=post,code=200 counter=1027\nhttp_requests_total,method=post,code=400 counter=3\nhttp_request_duration_seconds 0.05=24054,0.1=33444,0.2=100392,0.5=129389,1=133988,sum=53423,count=144320\nrpc_duration_seconds 0.01=3102,0.05=3272,0.5=4773,0.9=9001,0.99=76656,sum=1.7560473e+07,count=2693\n```\n\n### Metrics - `prometheus-v2`\n```\nprometheus,foo=bar cpu_temp=87.332\nprometheus,method=post,code=200 http_requests_total=1027\nprometheus,method=post,code=400 http_requests_total=3\nprometheus,le=0.05 http_request_duration_seconds_bucket=24054\nprometheus,le=0.1  http_request_duration_seconds_bucket=33444\nprometheus,le=0.2  http_request_duration_seconds_bucket=100392\nprometheus,le=0.5  http_request_duration_seconds_bucket=129389\nprometheus,le=1    http_request_duration_seconds_bucket=133988\nprometheus         http_request_duration_seconds_count=144320,http_request_duration_seconds_sum=53423\nprometheus,quantile=0.01 rpc_duration_seconds=3102\nprometheus,quantile=0.05 rpc_duration_seconds=3272\nprometheus,quantile=0.5  rpc_duration_seconds=4773\nprometheus,quantile=0.9  rpc_duration_seconds=9001\nprometheus,quantile=0.99 rpc_duration_seconds=76656\nprometheus               rpc_duration_seconds_count=1.7560473e+07,rpc_duration_seconds_sum=2693\n```\n\n### Logs\n```\nlogs fluent.tag="fluent.info",pid=18i,ppid=9i,worker=0i 1613769568895331700\nlogs fluent.tag="fluent.debug",instance=1720i,queue_size=0i,stage_size=0i 1613769568895697200\nlogs fluent.tag="fluent.info",worker=0i 1613769568896515100\n```\n',image:Xs.a},{id:"openweathermap",name:"OpenWeatherMap",markdown:'# OpenWeatherMap Input Plugin\n\nCollect current weather and forecast data from OpenWeatherMap.\n\nTo use this plugin you will need an [api key][] (app_id).\n\nCity identifiers can be found in the [city list][]. Alternately you\ncan [search][] by name; the `city_id` can be found as the last digits\nof the URL: https://openweathermap.org/city/2643743. Language\nidentifiers can be found in the [lang list][]. Documentation for\ncondition ID, icon, and main is at [weather conditions][].\n\n### Configuration\n\n```toml\n[[inputs.openweathermap]]\n  ## OpenWeatherMap API key.\n  app_id = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"\n\n  ## City ID\'s to collect weather data from.\n  city_id = ["5391959"]\n\n  ## Language of the description field. Can be one of "ar", "bg",\n  ## "ca", "cz", "de", "el", "en", "fa", "fi", "fr", "gl", "hr", "hu",\n  ## "it", "ja", "kr", "la", "lt", "mk", "nl", "pl", "pt", "ro", "ru",\n  ## "se", "sk", "sl", "es", "tr", "ua", "vi", "zh_cn", "zh_tw"\n  # lang = "en"\n\n  ## APIs to fetch; can contain "weather" or "forecast".\n  fetch = ["weather", "forecast"]\n\n  ## OpenWeatherMap base URL\n  # base_url = "https://api.openweathermap.org/"\n\n  ## Timeout for HTTP response.\n  # response_timeout = "5s"\n\n  ## Preferred unit system for temperature and wind speed. Can be one of\n  ## "metric", "imperial", or "standard".\n  # units = "metric"\n\n  ## Query interval; OpenWeatherMap weather data is updated every 10\n  ## minutes.\n  interval = "10m"\n```\n\n### Metrics\n\n- weather\n  - tags:\n    - city_id\n    - forecast\n    - condition_id\n    - condition_main\n  - fields:\n    - cloudiness (int, percent)\n    - humidity (int, percent)\n    - pressure (float, atmospheric pressure hPa)\n    - rain (float, rain volume for the last 1-3 hours (depending on API response) in mm)\n    - sunrise (int, nanoseconds since unix epoch)\n    - sunset (int, nanoseconds since unix epoch)\n    - temperature (float, degrees)\n    - visibility (int, meters, not available on forecast data)\n    - wind_degrees (float, wind direction in degrees)\n    - wind_speed (float, wind speed in meters/sec or miles/sec)\n    - condition_description (string, localized long description)\n    - condition_icon\n\n\n### Example Output\n\n```\n> weather,city=San\\ Francisco,city_id=5391959,condition_id=800,condition_main=Clear,country=US,forecast=* cloudiness=1i,condition_description="clear sky",condition_icon="01d",humidity=35i,pressure=1012,rain=0,sunrise=1570630329000000000i,sunset=1570671689000000000i,temperature=21.52,visibility=16093i,wind_degrees=280,wind_speed=5.7 1570659256000000000\n> weather,city=San\\ Francisco,city_id=5391959,condition_id=800,condition_main=Clear,country=US,forecast=3h cloudiness=0i,condition_description="clear sky",condition_icon="01n",humidity=41i,pressure=1010,rain=0,temperature=22.34,wind_degrees=249.393,wind_speed=2.085 1570665600000000000\n> weather,city=San\\ Francisco,city_id=5391959,condition_id=800,condition_main=Clear,country=US,forecast=6h cloudiness=0i,condition_description="clear sky",condition_icon="01n",humidity=50i,pressure=1012,rain=0,temperature=17.09,wind_degrees=310.754,wind_speed=3.009 1570676400000000000\n```\n\n[api key]: https://openweathermap.org/appid\n[city list]: http://bulk.openweathermap.org/sample/city.list.json.gz\n[search]: https://openweathermap.org/find\n[lang list]: https://openweathermap.org/current#multi\n[weather conditions]: https://openweathermap.org/weather-conditions\n',image:$s.a},{id:"passenger",name:"Passenger",markdown:'# Passenger Input Plugin\n\nGather [Phusion Passenger](https://www.phusionpassenger.com/) metrics using the `passenger-status` command line utility.\n\n**Series Cardinality Warning**\n\nDepending on your environment, this `passenger_process` measurement of this\nplugin can quickly create a high number of series which, when unchecked, can\ncause high load on your database.  You can use the following techniques to\nmanage your series cardinality:\n\n- Use the\n  [measurement filtering](https://docs.influxdata.com/telegraf/latest/administration/configuration/#measurement-filtering)\n  options to exclude unneeded tags.  In some environments, you may wish to use\n  `tagexclude` to remove the `pid` and `process_group_id` tags.\n- Write to a database with an appropriate\n  [retention policy](https://docs.influxdata.com/influxdb/latest/guides/downsampling_and_retention/).\n- Consider using the\n  [Time Series Index](https://docs.influxdata.com/influxdb/latest/concepts/time-series-index/).\n- Monitor your databases\n  [series cardinality](https://docs.influxdata.com/influxdb/latest/query_language/spec/#show-cardinality).\n\n### Configuration\n\n```toml\n# Read metrics of passenger using passenger-status\n[[inputs.passenger]]\n  ## Path of passenger-status.\n  ##\n  ## Plugin gather metric via parsing XML output of passenger-status\n  ## More information about the tool:\n  ##   https://www.phusionpassenger.com/library/admin/apache/overall_status_report.html\n  ##\n  ## If no path is specified, then the plugin simply execute passenger-status\n  ## hopefully it can be found in your PATH\n  command = "passenger-status -v --show=xml"\n```\n\n#### Permissions:\n\nTelegraf must have permission to execute the `passenger-status` command.  On most systems, Telegraf runs as the `telegraf` user.\n\n### Metrics:\n\n- passenger\n  - tags:\n    - passenger_version\n  - fields:\n    - process_count\n    - max\n    - capacity_used\n    - get_wait_list_size\n\n- passenger_supergroup\n  - tags:\n    - name\n  - fields:\n    - get_wait_list_size\n    - capacity_used\n\n- passenger_group\n  - tags:\n    - name\n    - app_root\n    - app_type\n  - fields:\n    - get_wait_list_size\n    - capacity_used\n    - processes_being_spawned\n\n- passenger_process\n  - tags:\n    - group_name\n    - app_root\n    - supergroup_name\n    - pid\n    - code_revision\n    - life_status\n    - process_group_id\n  - fields:\n    - concurrency\n    - sessions\n    - busyness\n    - processed\n    - spawner_creation_time\n    - spawn_start_time\n    - spawn_end_time\n    - last_used\n    - uptime\n    - cpu\n    - rss\n    - pss\n    - private_dirty\n    - swap\n    - real_memory\n    - vmsize\n\n### Example Output:\n```\npassenger,passenger_version=5.0.17 capacity_used=23i,get_wait_list_size=0i,max=23i,process_count=23i 1452984112799414257\npassenger_supergroup,name=/var/app/current/public capacity_used=23i,get_wait_list_size=0i 1452984112799496977\npassenger_group,app_root=/var/app/current,app_type=rack,name=/var/app/current/public capacity_used=23i,get_wait_list_size=0i,processes_being_spawned=0i 1452984112799527021\npassenger_process,app_root=/var/app/current,code_revision=899ac7f,group_name=/var/app/current/public,life_status=ALIVE,pid=11553,process_group_id=13608,supergroup_name=/var/app/current/public busyness=0i,concurrency=1i,cpu=58i,last_used=1452747071764940i,private_dirty=314900i,processed=951i,pss=319391i,real_memory=314900i,rss=418548i,sessions=0i,spawn_end_time=1452746845013365i,spawn_start_time=1452746844946982i,spawner_creation_time=1452746835922747i,swap=0i,uptime=226i,vmsize=1563580i 1452984112799571490\npassenger_process,app_root=/var/app/current,code_revision=899ac7f,group_name=/var/app/current/public,life_status=ALIVE,pid=11563,process_group_id=13608,supergroup_name=/var/app/current/public busyness=2147483647i,concurrency=1i,cpu=47i,last_used=1452747071709179i,private_dirty=309240i,processed=756i,pss=314036i,real_memory=309240i,rss=418296i,sessions=1i,spawn_end_time=1452746845172460i,spawn_start_time=1452746845136882i,spawner_creation_time=1452746835922747i,swap=0i,uptime=226i,vmsize=1563608i 1452984112799638581\n```\n',image:Zs.a},{id:"pf",name:"PF",markdown:'# PF Input Plugin\n\nThe pf plugin gathers information from the FreeBSD/OpenBSD pf firewall. Currently it can retrieve information about the state table: the number of current entries in the table, and counters for the number of searches, inserts, and removals to the table.\n\nThe pf plugin retrieves this information by invoking the `pfstat` command. The `pfstat` command requires read access to the device file `/dev/pf`. You have several options to permit telegraf to run `pfctl`:\n\n* Run telegraf as root. This is strongly discouraged.\n* Change the ownership and permissions for /dev/pf such that the user telegraf runs at can read the /dev/pf device file. This is probably not that good of an idea either.\n* Configure sudo to grant telegraf to run `pfctl` as root. This is the most restrictive option, but require sudo setup.\n* Add "telegraf" to the "proxy" group as /dev/pf is owned by root:proxy. \n\n### Using sudo\n\nYou may edit your sudo configuration with the following:\n\n```sudo\ntelegraf ALL=(root) NOPASSWD: /sbin/pfctl -s info\n```\n\n### Configuration:\n\n```toml\n  # use sudo to run pfctl\n  use_sudo = false\n```\n\n### Measurements & Fields:\n\n\n- pf\n    - entries (integer, count)\n    - searches (integer, count)\n    - inserts (integer, count)\n    - removals (integer, count)\n    - match (integer, count)\n    - bad-offset (integer, count)\n    - fragment (integer, count)\n    - short (integer, count)\n    - normalize (integer, count)\n    - memory (integer, count)\n    - bad-timestamp (integer, count)\n    - congestion (integer, count)\n    - ip-option (integer, count)\n    - proto-cksum (integer, count)\n    - state-mismatch (integer, count)\n    - state-insert (integer, count)\n    - state-limit (integer, count)\n    - src-limit (integer, count)\n    - synproxy (integer, count)\n\n### Example Output:\n\n```\n> pfctl -s info\nStatus: Enabled for 0 days 00:26:05           Debug: Urgent\n\nState Table                          Total             Rate\n  current entries                        2               \n  searches                           11325            7.2/s\n  inserts                                5            0.0/s\n  removals                               3            0.0/s\nCounters\n  match                              11226            7.2/s\n  bad-offset                             0            0.0/s\n  fragment                               0            0.0/s\n  short                                  0            0.0/s\n  normalize                              0            0.0/s\n  memory                                 0            0.0/s\n  bad-timestamp                          0            0.0/s\n  congestion                             0            0.0/s\n  ip-option                              0            0.0/s\n  proto-cksum                            0            0.0/s\n  state-mismatch                         0            0.0/s\n  state-insert                           0            0.0/s\n  state-limit                            0            0.0/s\n  src-limit                              0            0.0/s\n  synproxy                               0            0.0/s\n```\n\n```\n> ./telegraf --config telegraf.conf --input-filter pf --test\n* Plugin: inputs.pf, Collection 1\n> pf,host=columbia entries=3i,searches=2668i,inserts=12i,removals=9i 1510941775000000000\n```\n',image:ta.a},{id:"pgbouncer",name:"PgBouncer",markdown:'# PgBouncer Input Plugin\n\nThe `pgbouncer` plugin provides metrics for your PgBouncer load balancer.\n\nMore information about the meaning of these metrics can be found in the\n[PgBouncer Documentation](https://pgbouncer.github.io/usage.html).\n\n- PgBouncer minimum tested version: 1.5\n\n### Configuration example\n\n```toml\n[[inputs.pgbouncer]]\n  ## specify address via a url matching:\n  ##   postgres://[pqgotest[:password]]@host:port[/dbname]\\\n  ##       ?sslmode=[disable|verify-ca|verify-full]\n  ## or a simple string:\n  ##   host=localhost port=5432 user=pqgotest password=... sslmode=... dbname=app_production\n  ##\n  ## All connection parameters are optional.\n  ##\n  address = "host=localhost user=pgbouncer sslmode=disable"\n```\n\n#### `address`\n\nSpecify address via a postgresql connection string:\n\n  `host=/run/postgresql port=6432 user=telegraf database=pgbouncer`\n\nOr via an url matching:\n\n  `postgres://[pqgotest[:password]]@host:port[/dbname]?sslmode=[disable|verify-ca|verify-full]`\n\nAll connection parameters are optional.\n\nWithout the dbname parameter, the driver will default to a database with the same name as the user.\nThis dbname is just for instantiating a connection with the server and doesn\'t restrict the databases we are trying to grab metrics for.\n\n### Metrics\n\n- pgbouncer\n  - tags:\n    - db\n    - server\n  - fields:\n    - avg_query_count\n    - avg_query_time\n    - avg_wait_time\n    - avg_xact_count\n    - avg_xact_time\n    - total_query_count\n    - total_query_time\n    - total_received\n    - total_sent\n    - total_wait_time\n    - total_xact_count\n    - total_xact_time\n\n+ pgbouncer_pools\n  - tags:\n    - db\n    - pool_mode\n    - server\n    - user\n  - fields:\n    - cl_active\n    - cl_waiting\n    - maxwait\n    - maxwait_us\n    - sv_active\n    - sv_idle\n    - sv_login\n    - sv_tested\n    - sv_used\n\n### Example Output\n\n```\npgbouncer,db=pgbouncer,server=host\\=debian-buster-postgres\\ user\\=dbn\\ port\\=6432\\ dbname\\=pgbouncer\\  avg_query_count=0i,avg_query_time=0i,avg_wait_time=0i,avg_xact_count=0i,avg_xact_time=0i,total_query_count=26i,total_query_time=0i,total_received=0i,total_sent=0i,total_wait_time=0i,total_xact_count=26i,total_xact_time=0i 1581569936000000000\npgbouncer_pools,db=pgbouncer,pool_mode=statement,server=host\\=debian-buster-postgres\\ user\\=dbn\\ port\\=6432\\ dbname\\=pgbouncer\\ ,user=pgbouncer cl_active=1i,cl_waiting=0i,maxwait=0i,maxwait_us=0i,sv_active=0i,sv_idle=0i,sv_login=0i,sv_tested=0i,sv_used=0i 1581569936000000000\n```\n',image:sa.a},{id:"phpfpm",name:"PHP-FPM",markdown:'# PHP-FPM Input Plugin\n\nGet phpfpm stats using either HTTP status page or fpm socket.\n\n### Configuration:\n\n```toml\n# Read metrics of phpfpm, via HTTP status page or socket\n[[inputs.phpfpm]]\n  ## An array of addresses to gather stats about. Specify an ip or hostname\n  ## with optional port and path\n  ##\n  ## Plugin can be configured in three modes (either can be used):\n  ##   - http: the URL must start with http:// or https://, ie:\n  ##       "http://localhost/status"\n  ##       "http://192.168.130.1/status?full"\n  ##\n  ##   - unixsocket: path to fpm socket, ie:\n  ##       "/var/run/php5-fpm.sock"\n  ##      or using a custom fpm status path:\n  ##       "/var/run/php5-fpm.sock:fpm-custom-status-path"\n  ##      glob patterns are also supported:\n  ##       "/var/run/php*.sock"\n  ##\n  ##   - fcgi: the URL must start with fcgi:// or cgi://, and port must be present, ie:\n  ##       "fcgi://10.0.0.12:9000/status"\n  ##       "cgi://10.0.10.12:9001/status"\n  ##\n  ## Example of multiple gathering from local socket and remote host\n  ## urls = ["http://192.168.1.20/status", "/tmp/fpm.sock"]\n  urls = ["http://localhost/status"]\n\n  ## Duration allowed to complete HTTP requests.\n  # timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\nWhen using `unixsocket`, you have to ensure that telegraf runs on same\nhost, and socket path is accessible to telegraf user.\n\n### Metrics:\n\n- phpfpm\n  - tags:\n    - pool\n    - url\n  - fields:\n    - accepted_conn\n    - listen_queue\n    - max_listen_queue\n    - listen_queue_len\n    - idle_processes\n    - active_processes\n    - total_processes\n    - max_active_processes\n    - max_children_reached\n    - slow_requests\n\n# Example Output\n\n```\nphpfpm,pool=www accepted_conn=13i,active_processes=2i,idle_processes=1i,listen_queue=0i,listen_queue_len=0i,max_active_processes=2i,max_children_reached=0i,max_listen_queue=0i,slow_requests=0i,total_processes=3i 1453011293083331187\nphpfpm,pool=www2 accepted_conn=12i,active_processes=1i,idle_processes=2i,listen_queue=0i,listen_queue_len=0i,max_active_processes=2i,max_children_reached=0i,max_listen_queue=0i,slow_requests=0i,total_processes=3i 1453011293083691422\nphpfpm,pool=www3 accepted_conn=11i,active_processes=1i,idle_processes=2i,listen_queue=0i,listen_queue_len=0i,max_active_processes=2i,max_children_reached=0i,max_listen_queue=0i,slow_requests=0i,total_processes=3i 1453011293083691658\n```\n',image:ia.a},{id:"ping",name:"Ping",markdown:'# Ping Input Plugin\n\nSends a ping message by executing the system ping command and reports the results.\n\nThis plugin has two main methods of operation: `exec` and `native`.  The\nrecommended method is `native`, which has greater system compatibility and\nperformance.  However, for backwards compatibility the `exec` method is the\ndefault.\n\nWhen using `method = "exec"`, the systems ping utility is executed to send the\nping packets.\n\nMost ping command implementations are supported, one notable exception being\nthat there is currently no support for GNU Inetutils ping.  You may instead use\nthe iputils-ping implementation:\n```\napt-get install iputils-ping\n```\n\nWhen using `method = "native"` a ping is sent and the results are reported in\nnative Go by the Telegraf process, eliminating the need to execute the system\n`ping` command.\n\n### Configuration:\n\n```toml\n[[inputs.ping]]\n  ## Hosts to send ping packets to.\n  urls = ["example.org"]\n\n  ## Method used for sending pings, can be either "exec" or "native".  When set\n  ## to "exec" the systems ping command will be executed.  When set to "native"\n  ## the plugin will send pings directly.\n  ##\n  ## While the default is "exec" for backwards compatibility, new deployments\n  ## are encouraged to use the "native" method for improved compatibility and\n  ## performance.\n  # method = "exec"\n\n  ## Number of ping packets to send per interval.  Corresponds to the "-c"\n  ## option of the ping command.\n  # count = 1\n\n  ## Time to wait between sending ping packets in seconds.  Operates like the\n  ## "-i" option of the ping command.\n  # ping_interval = 1.0\n\n  ## If set, the time to wait for a ping response in seconds.  Operates like\n  ## the "-W" option of the ping command.\n  # timeout = 1.0\n\n  ## If set, the total ping deadline, in seconds.  Operates like the -w option\n  ## of the ping command.\n  # deadline = 10\n\n  ## Interface or source address to send ping from.  Operates like the -I or -S\n  ## option of the ping command.\n  # interface = ""\n\n  ## Percentiles to calculate. This only works with the native method.\n  # percentiles = [50, 95, 99]\n\n  ## Specify the ping executable binary.\n  # binary = "ping"\n\n  ## Arguments for ping command. When arguments is not empty, the command from\n  ## the binary option will be used and other options (ping_interval, timeout,\n  ## etc) will be ignored.\n  # arguments = ["-c", "3"]\n\n  ## Use only IPv6 addresses when resolving a hostname.\n  # ipv6 = false\n\n  ## Number of data bytes to be sent. Corresponds to the "-s"\n  ## option of the ping command. This only works with the native method.\n  # size = 56\n```\n\n#### File Limit\n\nSince this plugin runs the ping command, it may need to open multiple files per\nhost.  The number of files used is lessened with the `native` option but still\nmany files are used.  With a large host list you may receive a `too many open\nfiles` error.\n\nTo increase this limit on platforms using systemd the recommended method is to\nuse the "drop-in directory", usually located at\n`/etc/systemd/system/telegraf.service.d`.\n\nYou can create or edit a drop-in file in the correct location using:\n```sh\n$ systemctl edit telegraf\n```\n\nIncrease the number of open files:\n```ini\n[Service]\nLimitNOFILE=8192\n```\n\nRestart Telegraf:\n```sh\n$ systemctl edit telegraf\n```\n\n#### Linux Permissions\n\nWhen using `method = "native"`, Telegraf will attempt to use privileged raw\nICMP sockets.  On most systems, doing so requires `CAP_NET_RAW` capabilities or for Telegraf to be run as root.\n\nWith systemd:\n```sh\n$ systemctl edit telegraf\n```\n```ini\n[Service]\nCapabilityBoundingSet=CAP_NET_RAW\nAmbientCapabilities=CAP_NET_RAW\n```\n```sh\n$ systemctl restart telegraf\n```\n\nWithout systemd:\n```sh\n$ setcap cap_net_raw=eip /usr/bin/telegraf\n```\n\nReference [`man 7 capabilities`][man 7 capabilities] for more information about\nsetting capabilities.\n\n[man 7 capabilities]: http://man7.org/linux/man-pages/man7/capabilities.7.html\n\n#### Other OS Permissions\n\nWhen using `method = "native"`, you will need permissions similar to the executable ping program for your OS. \n\n### Metrics\n\n- ping\n  - tags:\n    - url\n  - fields:\n    - packets_transmitted (integer)\n    - packets_received (integer)\n    - percent_packet_loss (float)\n    - ttl (integer, Not available on Windows)\n    - average_response_ms (float)\n    - minimum_response_ms (float)\n    - maximum_response_ms (float)\n    - standard_deviation_ms (float, Available on Windows only with method = "native")\n    - percentile\\<N\\>_ms (float, Where `<N>` is the percentile specified in `percentiles`. Available with method = "native" only)\n    - errors (float, Windows only)\n    - reply_received (integer, Windows with method = "exec" only)\n    - percent_reply_loss (float, Windows with method = "exec" only)\n    - result_code (int, success = 0, no such host = 1, ping error = 2)\n\n##### reply_received vs packets_received\n\nOn Windows systems with `method = "exec"`, the "Destination net unreachable" reply will increment `packets_received` but not `reply_received`*.\n\n##### ttl\n\nThere is currently no support for TTL on windows with `"native"`; track\nprogress at https://github.com/golang/go/issues/7175 and\nhttps://github.com/golang/go/issues/7174\n\n\n### Example Output\n\n```\nping,url=example.org average_response_ms=23.066,ttl=63,maximum_response_ms=24.64,minimum_response_ms=22.451,packets_received=5i,packets_transmitted=5i,percent_packet_loss=0,result_code=0i,standard_deviation_ms=0.809 1535747258000000000\n```\n',image:ra.a},{id:"postfix",name:"Postfix",markdown:"# Postfix Input Plugin\n\nThe postfix plugin reports metrics on the postfix queues.\n\nFor each of the active, hold, incoming, maildrop, and deferred queues\n(http://www.postfix.org/QSHAPE_README.html#queues), it will report the queue\nlength (number of items), size (bytes used by items), and age (age of oldest\nitem in seconds).\n\n### Configuration\n\n```toml\n[[inputs.postfix]]\n  ## Postfix queue directory. If not provided, telegraf will try to use\n  ## 'postconf -h queue_directory' to determine it.\n  # queue_directory = \"/var/spool/postfix\"\n```\n\n#### Permissions\n\nTelegraf will need read access to the files in the queue directory.  You may\nneed to alter the permissions of these directories to provide access to the\ntelegraf user.\n\nThis can be setup either using standard unix permissions or with Posix ACLs,\nyou will only need to use one method:\n\nUnix permissions:\n```sh\n$ sudo chgrp -R telegraf /var/spool/postfix/{active,hold,incoming,deferred}\n$ sudo chmod -R g+rXs /var/spool/postfix/{active,hold,incoming,deferred}\n$ sudo usermod -a -G postdrop telegraf\n$ sudo chmod g+r /var/spool/postfix/maildrop\n```\n\nPosix ACL:\n```sh\n$ sudo setfacl -Rm g:telegraf:rX /var/spool/postfix/\n$ sudo setfacl -dm g:telegraf:rX /var/spool/postfix/\n```\n\n### Metrics\n\n- postfix_queue\n  - tags:\n    - queue\n  - fields:\n    - length (integer)\n    - size (integer, bytes)\n    - age (integer, seconds)\n\n\n### Example Output\n\n```\npostfix_queue,queue=active length=3,size=12345,age=9\npostfix_queue,queue=hold length=0,size=0,age=0\npostfix_queue,queue=maildrop length=1,size=2000,age=2\npostfix_queue,queue=incoming length=1,size=1020,age=0\npostfix_queue,queue=deferred length=400,size=76543210,age=3600\n```\n",image:_a.a},{id:"postgresql",name:"PostgreSQL",markdown:'# PostgreSQL Input Plugin\n\nThis postgresql plugin provides metrics for your postgres database. It currently works with postgres versions 8.1+. It uses data from the built in _pg_stat_database_ and pg_stat_bgwriter views. The metrics recorded depend on your version of postgres. See table:\n```\npg version      9.2+   9.1   8.3-9.0   8.1-8.2   7.4-8.0(unsupported)\n---             ---    ---   -------   -------   -------\ndatid            x      x       x         x\ndatname          x      x       x         x\nnumbackends      x      x       x         x         x\nxact_commit      x      x       x         x         x\nxact_rollback    x      x       x         x         x\nblks_read        x      x       x         x         x\nblks_hit         x      x       x         x         x\ntup_returned     x      x       x\ntup_fetched      x      x       x\ntup_inserted     x      x       x\ntup_updated      x      x       x\ntup_deleted      x      x       x\nconflicts        x      x\ntemp_files       x\ntemp_bytes       x\ndeadlocks        x\nblk_read_time    x\nblk_write_time   x\nstats_reset*     x      x\n```\n\n_* value ignored and therefore not recorded._\n\n\nMore information about the meaning of these metrics can be found in the [PostgreSQL Documentation](http://www.postgresql.org/docs/9.2/static/monitoring-stats.html#PG-STAT-DATABASE-VIEW)\n\n## Configuration\nSpecify address via a postgresql connection string:\n\n  `host=localhost port=5432 user=telegraf database=telegraf`\n\nOr via an url matching:\n\n  `postgres://[pqgotest[:password]]@host:port[/dbname]?sslmode=[disable|verify-ca|verify-full]`\n\nAll connection parameters are optional. Without the dbname parameter, the driver will default to a database with the same name as the user. This dbname is just for instantiating a connection with the server and doesn\'t restrict the databases we are trying to grab metrics for.\n\nA  list of databases to explicitly ignore.  If not specified, metrics for all databases are gathered.  Do NOT use with the \'databases\' option.\n\n  `ignored_databases = ["postgres", "template0", "template1"]`\n\nA list of databases to pull metrics about. If not specified, metrics for all databases are gathered.  Do NOT use with the \'ignored_databases\' option.\n\n  `databases = ["app_production", "testing"]`\n\n### TLS Configuration\n\nAdd the `sslkey`, `sslcert` and `sslrootcert` options to your DSN:\n```\nhost=localhost user=pgotest dbname=app_production sslmode=require sslkey=/etc/telegraf/key.pem sslcert=/etc/telegraf/cert.pem sslrootcert=/etc/telegraf/ca.pem\n```\n\n### Configuration example\n```toml\n[[inputs.postgresql]]\n  address = "postgres://telegraf@localhost/someDB"\n  ignored_databases = ["template0", "template1"]\n```\n',image:ma.a},{id:"postgresql_extensible",name:"PostgreSQL Extensible",markdown:"# PostgreSQL Extensible Input Plugin\n\nThis postgresql plugin provides metrics for your postgres database. It has been\ndesigned to parse SQL queries in the plugin section of your `telegraf.conf`.\n\nThe example below has two queries are specified, with the following parameters:\n\n* The SQL query itself\n* The minimum PostgreSQL version supported (the numeric display visible in pg_settings)\n* A boolean to define if the query has to be run against some specific database (defined in the `databases` variable of the plugin section)\n* The name of the measurement\n* A list of the columns to be defined as tags\n\n```toml\n[[inputs.postgresql_extensible]]\n  # specify address via a url matching:\n  # postgres://[pqgotest[:password]]@host:port[/dbname]?sslmode=...\n  # or a simple string:\n  #   host=localhost port=5432 user=pqgotest password=... sslmode=... dbname=app_production\n  #\n  # All connection parameters are optional.\n  # Without the dbname parameter, the driver will default to a database\n  # with the same name as the user. This dbname is just for instantiating a\n  # connection with the server and doesn't restrict the databases we are trying\n  # to grab metrics for.\n  #\n  address = \"host=localhost user=postgres sslmode=disable\"\n  # A list of databases to pull metrics about. If not specified, metrics for all\n  # databases are gathered.\n  # databases = [\"app_production\", \"testing\"]\n  #\n  # Define the toml config where the sql queries are stored\n  # New queries can be added, if the withdbname is set to true and there is no\n  # databases defined in the 'databases field', the sql query is ended by a 'is\n  # not null' in order to make the query succeed.\n  # Be careful that the sqlquery must contain the where clause with a part of\n  # the filtering, the plugin will add a 'IN (dbname list)' clause if the\n  # withdbname is set to true\n  # Example :\n  # The sqlquery : \"SELECT * FROM pg_stat_database where datname\" become\n  # \"SELECT * FROM pg_stat_database where datname IN ('postgres', 'pgbench')\"\n  # because the databases variable was set to ['postgres', 'pgbench' ] and the\n  # withdbname was true.\n  # Be careful that if the withdbname is set to false you don't have to define\n  # the where clause (aka with the dbname)\n  #\n  # The script option can be used to specify the .sql file path.\n  # If script and sqlquery options specified at same time, sqlquery will be used\n  #\n  # the tagvalue field is used to define custom tags (separated by comas).\n  # the query is expected to return columns which match the names of the\n  # defined tags. The values in these columns must be of a string-type,\n  # a number-type or a blob-type.\n  #\n  # The timestamp field is used to override the data points timestamp value. By\n  # default, all rows inserted with current time. By setting a timestamp column,\n  # the row will be inserted with that column's value. \n  #\n  # Structure :\n  # [[inputs.postgresql_extensible.query]]\n  #   sqlquery string\n  #   version string\n  #   withdbname boolean\n  #   tagvalue string (coma separated)\n  #   timestamp string\n  [[inputs.postgresql_extensible.query]]\n    sqlquery=\"SELECT * FROM pg_stat_database where datname\"\n    version=901\n    withdbname=false\n    tagvalue=\"\"\n  [[inputs.postgresql_extensible.query]]\n    script=\"your_sql-filepath.sql\"\n    version=901\n    withdbname=false\n    tagvalue=\"\"\n```\n\nThe system can be easily extended using homemade metrics collection tools or\nusing postgresql extensions ([pg_stat_statements](http://www.postgresql.org/docs/current/static/pgstatstatements.html), [pg_proctab](https://github.com/markwkm/pg_proctab) or [powa](http://dalibo.github.io/powa/))\n\n# Sample Queries :\n- telegraf.conf postgresql_extensible queries (assuming that you have configured\n correctly your connection)\n```toml\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"SELECT * FROM pg_stat_database\"\n  version=901\n  withdbname=false\n  tagvalue=\"\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"SELECT * FROM pg_stat_bgwriter\"\n  version=901\n  withdbname=false\n  tagvalue=\"\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"select * from sessions\"\n  version=901\n  withdbname=false\n  tagvalue=\"db,username,state\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"select setting as max_connections from pg_settings where \\\n  name='max_connections'\"\n  version=801\n  withdbname=false\n  tagvalue=\"\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"select * from pg_stat_kcache\"\n  version=901\n  withdbname=false\n  tagvalue=\"\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"select setting as shared_buffers from pg_settings where \\\n  name='shared_buffers'\"\n  version=801\n  withdbname=false\n  tagvalue=\"\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"SELECT db, count( distinct blocking_pid ) AS num_blocking_sessions,\\\n  count( distinct blocked_pid) AS num_blocked_sessions FROM \\\n  public.blocking_procs group by db\"\n  version=901\n  withdbname=false\n  tagvalue=\"db\"\n[[inputs.postgresql_extensible.query]]\n  sqlquery=\"\"\"\n    SELECT type, (enabled || '') AS enabled, COUNT(*)\n      FROM application_users\n      GROUP BY type, enabled\n  \"\"\"\n  version=901\n  withdbname=false\n  tagvalue=\"type,enabled\"\n```\n\n# Postgresql Side\npostgresql.conf :\n```\nshared_preload_libraries = 'pg_stat_statements,pg_stat_kcache'\n```\n\nPlease follow the requirements to setup those extensions.\n\nIn the database (can be a specific monitoring db)\n```\ncreate extension pg_stat_statements;\ncreate extension pg_stat_kcache;\ncreate extension pg_proctab;\n```\n(assuming that the extension is installed on the OS Layer)\n\n - pg_stat_kcache is available on the postgresql.org yum repo\n - pg_proctab is available at : https://github.com/markwkm/pg_proctab\n\n ## Views\n - Blocking sessions\n```sql\nCREATE OR REPLACE VIEW public.blocking_procs AS\n SELECT a.datname AS db,\n    kl.pid AS blocking_pid,\n    ka.usename AS blocking_user,\n    ka.query AS blocking_query,\n    bl.pid AS blocked_pid,\n    a.usename AS blocked_user,\n    a.query AS blocked_query,\n    to_char(age(now(), a.query_start), 'HH24h:MIm:SSs'::text) AS age\n   FROM pg_locks bl\n     JOIN pg_stat_activity a ON bl.pid = a.pid\n     JOIN pg_locks kl ON bl.locktype = kl.locktype AND NOT bl.database IS\n     DISTINCT FROM kl.database AND NOT bl.relation IS DISTINCT FROM kl.relation\n     AND NOT bl.page IS DISTINCT FROM kl.page AND NOT bl.tuple IS DISTINCT FROM\n     kl.tuple AND NOT bl.virtualxid IS DISTINCT FROM kl.virtualxid AND NOT\n     bl.transactionid IS DISTINCT FROM kl.transactionid AND NOT bl.classid IS\n     DISTINCT FROM kl.classid AND NOT bl.objid IS DISTINCT FROM kl.objid AND\n      NOT bl.objsubid IS DISTINCT FROM kl.objsubid AND bl.pid <> kl.pid\n     JOIN pg_stat_activity ka ON kl.pid = ka.pid\n  WHERE kl.granted AND NOT bl.granted\n  ORDER BY a.query_start;\n```\n  - Sessions Statistics\n```sql\nCREATE OR REPLACE VIEW public.sessions AS\n WITH proctab AS (\n         SELECT pg_proctab.pid,\n                CASE\n                    WHEN pg_proctab.state::text = 'R'::bpchar::text\n                      THEN 'running'::text\n                    WHEN pg_proctab.state::text = 'D'::bpchar::text\n                      THEN 'sleep-io'::text\n                    WHEN pg_proctab.state::text = 'S'::bpchar::text\n                      THEN 'sleep-waiting'::text\n                    WHEN pg_proctab.state::text = 'Z'::bpchar::text\n                      THEN 'zombie'::text\n                    WHEN pg_proctab.state::text = 'T'::bpchar::text\n                      THEN 'stopped'::text\n                    ELSE NULL::text\n                END AS proc_state,\n            pg_proctab.ppid,\n            pg_proctab.utime,\n            pg_proctab.stime,\n            pg_proctab.vsize,\n            pg_proctab.rss,\n            pg_proctab.processor,\n            pg_proctab.rchar,\n            pg_proctab.wchar,\n            pg_proctab.syscr,\n            pg_proctab.syscw,\n            pg_proctab.reads,\n            pg_proctab.writes,\n            pg_proctab.cwrites\n           FROM pg_proctab() pg_proctab(pid, comm, fullcomm, state, ppid, pgrp,\n             session, tty_nr, tpgid, flags, minflt, cminflt, majflt, cmajflt,\n             utime, stime, cutime, cstime, priority, nice, num_threads,\n             itrealvalue, starttime, vsize, rss, exit_signal, processor,\n             rt_priority, policy, delayacct_blkio_ticks, uid, username, rchar,\n             wchar, syscr, syscw, reads, writes, cwrites)\n        ), stat_activity AS (\n         SELECT pg_stat_activity.datname,\n            pg_stat_activity.pid,\n            pg_stat_activity.usename,\n                CASE\n                    WHEN pg_stat_activity.query IS NULL THEN 'no query'::text\n                    WHEN pg_stat_activity.query IS NOT NULL AND\n                    pg_stat_activity.state = 'idle'::text THEN 'no query'::text\n                    ELSE regexp_replace(pg_stat_activity.query, '[\\n\\r]+'::text,\n                       ' '::text, 'g'::text)\n                END AS query\n           FROM pg_stat_activity\n        )\n SELECT stat.datname::name AS db,\n    stat.usename::name AS username,\n    stat.pid,\n    proc.proc_state::text AS state,\n('\"'::text || stat.query) || '\"'::text AS query,\n    (proc.utime/1000)::bigint AS session_usertime,\n    (proc.stime/1000)::bigint AS session_systemtime,\n    proc.vsize AS session_virtual_memory_size,\n    proc.rss AS session_resident_memory_size,\n    proc.processor AS session_processor_number,\n    proc.rchar AS session_bytes_read,\n    proc.rchar-proc.reads AS session_logical_bytes_read,\n    proc.wchar AS session_bytes_written,\n    proc.wchar-proc.writes AS session_logical_bytes_writes,\n    proc.syscr AS session_read_io,\n    proc.syscw AS session_write_io,\n    proc.reads AS session_physical_reads,\n    proc.writes AS session_physical_writes,\n    proc.cwrites AS session_cancel_writes\n   FROM proctab proc,\n    stat_activity stat\n  WHERE proc.pid = stat.pid;\n```\n",image:ua.a},{id:"powerdns",name:"PowerDNS",markdown:"# PowerDNS Input Plugin\n\nThe powerdns plugin gathers metrics about PowerDNS using unix socket.\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.powerdns]]\n  # An array of sockets to gather stats about.\n  # Specify a path to unix socket.\n  #\n  # If no servers are specified, then '/var/run/pdns.controlsocket' is used as the path.\n  unix_sockets = [\"/var/run/pdns.controlsocket\"]\n```\n\n#### Permissions\n\nTelegraf will need read access to the powerdns control socket.\n\nOn many systems this can be accomplished by adding the `telegraf` user to the\n`pdns` group:\n```\nusermod telegraf -a -G pdns\n```\n\n### Measurements & Fields:\n\n- powerdns\n  - corrupt-packets\n  - deferred-cache-inserts\n  - deferred-cache-lookup\n  - dnsupdate-answers\n  - dnsupdate-changes\n  - dnsupdate-queries\n  - dnsupdate-refused\n  - packetcache-hit\n  - packetcache-miss\n  - packetcache-size\n  - query-cache-hit\n  - query-cache-miss\n  - rd-queries\n  - recursing-answers\n  - recursing-questions\n  - recursion-unanswered\n  - security-status\n  - servfail-packets\n  - signatures\n  - tcp-answers\n  - tcp-queries\n  - timedout-packets\n  - udp-answers\n  - udp-answers-bytes\n  - udp-do-queries\n  - udp-queries\n  - udp4-answers\n  - udp4-queries\n  - udp6-answers\n  - udp6-queries\n  - key-cache-size\n  - latency\n  - meta-cache-size\n  - qsize-q\n  - signature-cache-size\n  - sys-msec\n  - uptime\n  - user-msec\n\n### Tags:\n\n- tags: `server=socket`\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter powerdns --test\n> powerdns,server=/var/run/pdns.controlsocket corrupt-packets=0i,deferred-cache-inserts=0i,deferred-cache-lookup=0i,dnsupdate-answers=0i,dnsupdate-changes=0i,dnsupdate-queries=0i,dnsupdate-refused=0i,key-cache-size=0i,latency=26i,meta-cache-size=0i,packetcache-hit=0i,packetcache-miss=1i,packetcache-size=0i,qsize-q=0i,query-cache-hit=0i,query-cache-miss=6i,rd-queries=1i,recursing-answers=0i,recursing-questions=0i,recursion-unanswered=0i,security-status=3i,servfail-packets=0i,signature-cache-size=0i,signatures=0i,sys-msec=4349i,tcp-answers=0i,tcp-queries=0i,timedout-packets=0i,udp-answers=1i,udp-answers-bytes=50i,udp-do-queries=0i,udp-queries=0i,udp4-answers=1i,udp4-queries=1i,udp6-answers=0i,udp6-queries=0i,uptime=166738i,user-msec=3036i 1454078624932715706\n```\n",image:fa.a},{id:"powerdns_recursor",name:"PowerDNS Recursor",markdown:'# PowerDNS Recursor Input Plugin\n\nThe `powerdns_recursor` plugin gathers metrics about PowerDNS Recursor using\nthe unix controlsocket.\n\n### Configuration\n\n```toml\n[[inputs.powerdns_recursor]]\n  ## Path to the Recursor control socket.\n  unix_sockets = ["/var/run/pdns_recursor.controlsocket"]\n\n  ## Directory to create receive socket.  This default is likely not writable,\n  ## please reference the full plugin documentation for a recommended setup.\n  # socket_dir = "/var/run/"\n  ## Socket permissions for the receive socket.\n  # socket_mode = "0666"\n```\n\n#### Permissions\n\nTelegraf will need read/write access to the control socket and to the\n`socket_dir`.  PowerDNS will need to be able to write to the `socket_dir`.\n\nThe setup described below was tested on a Debian Stretch system and may need\nadapted for other systems.\n\nFirst change permissions on the controlsocket in the PowerDNS recursor\nconfiguration, usually in `/etc/powerdns/recursor.conf`:\n```\nsocket-mode = 660\n```\n\nThen place the `telegraf` user into the `pdns` group:\n```\nusermod telegraf -a -G pdns\n```\n\nSince `telegraf` cannot write to to the default `/var/run` socket directory,\ncreate a subdirectory and adjust permissions for this directory so that both\nusers can access it.\n```sh\n$ mkdir /var/run/pdns\n$ chown root:pdns /var/run/pdns\n$ chmod 770 /var/run/pdns\n```\n\n### Metrics\n\n- powerdns_recursor\n  - tags:\n    - server\n  - fields:\n    - all-outqueries\n    - answers-slow\n    - answers0-1\n    - answers1-10\n    - answers10-100\n    - answers100-1000\n    - auth-zone-queries\n    - auth4-answers-slow\n    - auth4-answers0-1\n    - auth4-answers1-10\n    - auth4-answers10-100\n    - auth4-answers100-1000\n    - auth6-answers-slow\n    - auth6-answers0-1\n    - auth6-answers1-10\n    - auth6-answers10-100\n    - auth6-answers100-1000\n    - cache-entries\n    - cache-hits\n    - cache-misses\n    - case-mismatches\n    - chain-resends\n    - client-parse-errors\n    - concurrent-queries\n    - dlg-only-drops\n    - dnssec-queries\n    - dnssec-result-bogus\n    - dnssec-result-indeterminate\n    - dnssec-result-insecure\n    - dnssec-result-nta\n    - dnssec-result-secure\n    - dnssec-validations\n    - dont-outqueries\n    - ecs-queries\n    - ecs-responses\n    - edns-ping-matches\n    - edns-ping-mismatches\n    - failed-host-entries\n    - fd-usage\n    - ignored-packets\n    - ipv6-outqueries\n    - ipv6-questions\n    - malloc-bytes\n    - max-cache-entries\n    - max-mthread-stack\n    - max-packetcache-entries\n    - negcache-entries\n    - no-packet-error\n    - noedns-outqueries\n    - noerror-answers\n    - noping-outqueries\n    - nsset-invalidations\n    - nsspeeds-entries\n    - nxdomain-answers\n    - outgoing-timeouts\n    - outgoing4-timeouts\n    - outgoing6-timeouts\n    - over-capacity-drops\n    - packetcache-entries\n    - packetcache-hits\n    - packetcache-misses\n    - policy-drops\n    - policy-result-custom\n    - policy-result-drop\n    - policy-result-noaction\n    - policy-result-nodata\n    - policy-result-nxdomain\n    - policy-result-truncate\n    - qa-latency\n    - query-pipe-full-drops\n    - questions\n    - real-memory-usage\n    - resource-limits\n    - security-status\n    - server-parse-errors\n    - servfail-answers\n    - spoof-prevents\n    - sys-msec\n    - tcp-client-overflow\n    - tcp-clients\n    - tcp-outqueries\n    - tcp-questions\n    - throttle-entries\n    - throttled-out\n    - throttled-outqueries\n    - too-old-drops\n    - udp-in-errors\n    - udp-noport-errors\n    - udp-recvbuf-errors\n    - udp-sndbuf-errors\n    - unauthorized-tcp\n    - unauthorized-udp\n    - unexpected-packets\n    - unreachables\n    - uptime\n    - user-msec\n    - x-our-latency\n    - x-ourtime-slow\n    - x-ourtime0-1\n    - x-ourtime1-2\n    - x-ourtime16-32\n    - x-ourtime2-4\n    - x-ourtime4-8\n    - x-ourtime8-16\n\n### Example Output\n\n```\npowerdns_recursor,server=/var/run/pdns_recursor.controlsocket all-outqueries=3631810i,answers-slow=36863i,answers0-1=179612i,answers1-10=1223305i,answers10-100=1252199i,answers100-1000=408357i,auth-zone-queries=4i,auth4-answers-slow=44758i,auth4-answers0-1=59721i,auth4-answers1-10=1766787i,auth4-answers10-100=1329638i,auth4-answers100-1000=430372i,auth6-answers-slow=0i,auth6-answers0-1=0i,auth6-answers1-10=0i,auth6-answers10-100=0i,auth6-answers100-1000=0i,cache-entries=296689i,cache-hits=150654i,cache-misses=2949682i,case-mismatches=0i,chain-resends=420004i,client-parse-errors=0i,concurrent-queries=0i,dlg-only-drops=0i,dnssec-queries=152970i,dnssec-result-bogus=0i,dnssec-result-indeterminate=0i,dnssec-result-insecure=0i,dnssec-result-nta=0i,dnssec-result-secure=47i,dnssec-validations=47i,dont-outqueries=62i,ecs-queries=0i,ecs-responses=0i,edns-ping-matches=0i,edns-ping-mismatches=0i,failed-host-entries=21i,fd-usage=32i,ignored-packets=0i,ipv6-outqueries=0i,ipv6-questions=0i,malloc-bytes=0i,max-cache-entries=1000000i,max-mthread-stack=33747i,max-packetcache-entries=500000i,negcache-entries=100019i,no-packet-error=0i,noedns-outqueries=73341i,noerror-answers=25453808i,noping-outqueries=0i,nsset-invalidations=2398i,nsspeeds-entries=3966i,nxdomain-answers=3341302i,outgoing-timeouts=44384i,outgoing4-timeouts=44384i,outgoing6-timeouts=0i,over-capacity-drops=0i,packetcache-entries=78258i,packetcache-hits=25999027i,packetcache-misses=3100179i,policy-drops=0i,policy-result-custom=0i,policy-result-drop=0i,policy-result-noaction=3100336i,policy-result-nodata=0i,policy-result-nxdomain=0i,policy-result-truncate=0i,qa-latency=6553i,query-pipe-full-drops=0i,questions=29099363i,real-memory-usage=280494080i,resource-limits=0i,security-status=1i,server-parse-errors=0i,servfail-answers=304253i,spoof-prevents=0i,sys-msec=1312600i,tcp-client-overflow=0i,tcp-clients=0i,tcp-outqueries=116i,tcp-questions=133i,throttle-entries=21i,throttled-out=13296i,throttled-outqueries=13296i,too-old-drops=2i,udp-in-errors=4i,udp-noport-errors=2918i,udp-recvbuf-errors=0i,udp-sndbuf-errors=0i,unauthorized-tcp=0i,unauthorized-udp=0i,unexpected-packets=0i,unreachables=1708i,uptime=167482i,user-msec=1282640i,x-our-latency=19i,x-ourtime-slow=642i,x-ourtime0-1=3095566i,x-ourtime1-2=3401i,x-ourtime16-32=201i,x-ourtime2-4=304i,x-ourtime4-8=198i,x-ourtime8-16=24i 1533903879000000000\n```\n',image:ha.a},{id:"processes",name:"Processes",markdown:"# Processes Input Plugin\n\nThis plugin gathers info about the total number of processes and groups\nthem by status (zombie, sleeping, running, etc.)\n\nOn linux this plugin requires access to procfs (/proc), on other OSes\nit requires access to execute `ps`.\n\n**Supported Platforms**: Linux, FreeBSD, Darwin\n\n### Configuration\n\n```toml\n# Get the number of processes and group them by status\n[[inputs.processes]]\n  # no configuration\n```\n\nAnother possible configuration is to define an alternative path for resolving the /proc location.\nUsing the environment variable `HOST_PROC` the plugin will retrieve process information from the specified location.\n\n`docker run -v /proc:/rootfs/proc:ro -e HOST_PROC=/rootfs/proc`\n\n### Metrics\n\n- processes\n  - fields:\n    - blocked (aka disk sleep or uninterruptible sleep)\n    - running\n    - sleeping\n    - stopped\n    - total\n    - zombie\n    - dead\n    - wait (freebsd only)\n    - idle (bsd and Linux 4+ only)\n    - paging (linux only)\n    - parked (linux only)\n    - total_threads (linux only)\n\n### Process State Mappings\n\nDifferent OSes use slightly different State codes for their processes, these\nstate codes are documented in `man ps`, and I will give a mapping of what major\nOS state codes correspond to in telegraf metrics:\n\n```\nLinux  FreeBSD  Darwin  meaning\n  R       R       R     running\n  S       S       S     sleeping\n  Z       Z       Z     zombie\n  X      none    none   dead\n  T       T       T     stopped\n  I       I       I     idle (sleeping for longer than about 20 seconds)\n  D      D,L      U     blocked (waiting in uninterruptible sleep, or locked)\n  W       W      none   paging (linux kernel < 2.6 only), wait (freebsd)\n```\n\n### Example Output\n\n```\nprocesses blocked=8i,running=1i,sleeping=265i,stopped=0i,total=274i,zombie=0i,dead=0i,paging=0i,total_threads=687i 1457478636980905042\n```\n",image:ya.a},{id:"procstat",name:"Procstat",markdown:'# Procstat Input Plugin\n\nThe procstat plugin can be used to monitor the system resource usage of one or more processes.\nThe procstat_lookup metric displays the query information,\nspecifically the number of PIDs returned on a search\n\nProcesses can be selected for monitoring using one of several methods:\n- pidfile\n- exe\n- pattern\n- user\n- systemd_unit\n- cgroup\n- win_service\n\n### Configuration:\n\n```toml\n# Monitor process cpu and memory usage\n[[inputs.procstat]]\n  ## PID file to monitor process\n  pid_file = "/var/run/nginx.pid"\n  ## executable name (ie, pgrep <exe>)\n  # exe = "nginx"\n  ## pattern as argument for pgrep (ie, pgrep -f <pattern>)\n  # pattern = "nginx"\n  ## user as argument for pgrep (ie, pgrep -u <user>)\n  # user = "nginx"\n  ## Systemd unit name\n  # systemd_unit = "nginx.service"\n  ## CGroup name or path\n  # cgroup = "systemd/system.slice/nginx.service"\n\n  ## Windows service name\n  # win_service = ""\n\n  ## override for process_name\n  ## This is optional; default is sourced from /proc/<pid>/status\n  # process_name = "bar"\n\n  ## Field name prefix\n  # prefix = ""\n\n  ## When true add the full cmdline as a tag.\n  # cmdline_tag = false\n\n  ## Mode to use when calculating CPU usage. Can be one of \'solaris\' or \'irix\'.\n  # mode = "irix"\n\n  ## Add the PID as a tag instead of as a field.  When collecting multiple\n  ## processes with otherwise matching tags this setting should be enabled to\n  ## ensure each process has a unique identity.\n  ##\n  ## Enabling this option may result in a large number of series, especially\n  ## when processes have a short lifetime.\n  # pid_tag = false\n\n  ## Method to use when finding process IDs.  Can be one of \'pgrep\', or\n  ## \'native\'.  The pgrep finder calls the pgrep executable in the PATH while\n  ## the native finder performs the search directly in a manor dependent on the\n  ## platform.  Default is \'pgrep\'\n  # pid_finder = "pgrep"\n```\n\n#### Windows support\n\nPreliminary support for Windows has been added, however you may prefer using\nthe `win_perf_counters` input plugin as a more mature alternative.\n\n### Metrics:\n\n- procstat\n  - tags:\n    - pid (when `pid_tag` is true)\n    - cmdline (when \'cmdline_tag\' is true)\n    - process_name\n    - pidfile (when defined)\n    - exe (when defined)\n    - pattern (when defined)\n    - user (when selected)\n    - systemd_unit (when defined)\n    - cgroup (when defined)\n    - win_service (when defined)\n  - fields:\n    - child_major_faults (int)\n    - child_minor_faults (int)\n    - created_at (int) [epoch in nanoseconds]\n    - cpu_time (int)\n    - cpu_time_guest (float)\n    - cpu_time_guest_nice (float)\n    - cpu_time_idle (float)\n    - cpu_time_iowait (float)\n    - cpu_time_irq (float)\n    - cpu_time_nice (float)\n    - cpu_time_soft_irq (float)\n    - cpu_time_steal (float)\n    - cpu_time_system (float)\n    - cpu_time_user (float)\n    - cpu_usage (float)\n    - involuntary_context_switches (int)\n    - major_faults (int)\n    - memory_data (int)\n    - memory_locked (int)\n    - memory_rss (int)\n    - memory_stack (int)\n    - memory_swap (int)\n    - memory_usage (float)\n    - memory_vms (int)\n    - minor_faults (int)\n    - nice_priority (int)\n    - num_fds (int, *telegraf* may need to be ran as **root**)\n    - num_threads (int)\n    - pid (int)\n    - read_bytes (int, *telegraf* may need to be ran as **root**)\n    - read_count (int, *telegraf* may need to be ran as **root**)\n    - realtime_priority (int)\n    - rlimit_cpu_time_hard (int)\n    - rlimit_cpu_time_soft (int)\n    - rlimit_file_locks_hard (int)\n    - rlimit_file_locks_soft (int)\n    - rlimit_memory_data_hard (int)\n    - rlimit_memory_data_soft (int)\n    - rlimit_memory_locked_hard (int)\n    - rlimit_memory_locked_soft (int)\n    - rlimit_memory_rss_hard (int)\n    - rlimit_memory_rss_soft (int)\n    - rlimit_memory_stack_hard (int)\n    - rlimit_memory_stack_soft (int)\n    - rlimit_memory_vms_hard (int)\n    - rlimit_memory_vms_soft (int)\n    - rlimit_nice_priority_hard (int)\n    - rlimit_nice_priority_soft (int)\n    - rlimit_num_fds_hard (int)\n    - rlimit_num_fds_soft (int)\n    - rlimit_realtime_priority_hard (int)\n    - rlimit_realtime_priority_soft (int)\n    - rlimit_signals_pending_hard (int)\n    - rlimit_signals_pending_soft (int)\n    - signals_pending (int)\n    - voluntary_context_switches (int)\n    - write_bytes (int, *telegraf* may need to be ran as **root**)\n    - write_count (int, *telegraf* may need to be ran as **root**)\n- procstat_lookup\n  - tags:\n    - exe\n    - pid_finder\n    - pid_file\n    - pattern\n    - prefix\n    - user\n    - systemd_unit\n    - cgroup\n    - win_service\n    - result\n  - fields:\n    - pid_count (int)\n    - running (int)\n    - result_code (int, success = 0, lookup_error = 1)\n\n*NOTE: Resource limit > 2147483647 will be reported as 2147483647.*\n\n### Example Output:\n\n```\nprocstat_lookup,host=prash-laptop,pattern=influxd,pid_finder=pgrep,result=success pid_count=1i,running=1i,result_code=0i 1582089700000000000\nprocstat,host=prash-laptop,pattern=influxd,process_name=influxd,user=root involuntary_context_switches=151496i,child_minor_faults=1061i,child_major_faults=8i,cpu_time_user=2564.81,cpu_time_idle=0,cpu_time_irq=0,cpu_time_guest=0,pid=32025i,major_faults=8609i,created_at=1580107536000000000i,voluntary_context_switches=1058996i,cpu_time_system=616.98,cpu_time_steal=0,cpu_time_guest_nice=0,memory_swap=0i,memory_locked=0i,memory_usage=1.7797634601593018,num_threads=18i,cpu_time_nice=0,cpu_time_iowait=0,cpu_time_soft_irq=0,memory_rss=148643840i,memory_vms=1435688960i,memory_data=0i,memory_stack=0i,minor_faults=1856550i 1582089700000000000\n```\n',image:wa.a},{id:"prometheus",name:"Prometheus",markdown:'# Prometheus Input Plugin\n\nThe prometheus input plugin gathers metrics from HTTP servers exposing metrics\nin Prometheus format.\n\n### Configuration:\n\n```toml\n# Read metrics from one or many prometheus clients\n[[inputs.prometheus]]\n  ## An array of urls to scrape metrics from.\n  urls = ["http://localhost:9100/metrics"]\n  \n  ## Metric version controls the mapping from Prometheus metrics into\n  ## Telegraf metrics.  When using the prometheus_client output, use the same\n  ## value in both plugins to ensure metrics are round-tripped without\n  ## modification.\n  ##\n  ##   example: metric_version = 1; \n  ##            metric_version = 2; recommended version\n  # metric_version = 1\n  \n  ## Url tag name (tag containing scrapped url. optional, default is "url")\n  # url_tag = "url"\n  \n  ## An array of Kubernetes services to scrape metrics from.\n  # kubernetes_services = ["http://my-service-dns.my-namespace:9100/metrics"]\n  \n  ## Kubernetes config file to create client from.\n  # kube_config = "/path/to/kubernetes.config"\n  \n  ## Scrape Kubernetes pods for the following prometheus annotations:\n  ## - prometheus.io/scrape: Enable scraping for this pod\n  ## - prometheus.io/scheme: If the metrics endpoint is secured then you will need to\n  ##     set this to \'https\' & most likely set the tls config.\n  ## - prometheus.io/path: If the metrics path is not /metrics, define it with this annotation.\n  ## - prometheus.io/port: If port is not 9102 use this annotation\n  # monitor_kubernetes_pods = true\n  \n  ## Get the list of pods to scrape with either the scope of\n  ## - cluster: the kubernetes watch api (default, no need to specify)\n  ## - node: the local cadvisor api; for scalability. Note that the config node_ip or the environment variable NODE_IP must be set to the host IP.\n  # pod_scrape_scope = "cluster"\n  \n  ## Only for node scrape scope: node IP of the node that telegraf is running on.\n  ## Either this config or the environment variable NODE_IP must be set.\n  # node_ip = "10.180.1.1"\n\t\n  ## Only for node scrape scope: interval in seconds for how often to get updated pod list for scraping.\n  ## Default is 60 seconds.\n  # pod_scrape_interval = 60\n  \n  ## Restricts Kubernetes monitoring to a single namespace\n  ##   ex: monitor_kubernetes_pods_namespace = "default"\n  # monitor_kubernetes_pods_namespace = ""\n  # label selector to target pods which have the label\n  # kubernetes_label_selector = "env=dev,app=nginx"\n  # field selector to target pods\n  # eg. To scrape pods on a specific node\n  # kubernetes_field_selector = "spec.nodeName=$HOSTNAME"\n  \n  ## Use bearer token for authorization. (\'bearer_token\' takes priority)\n  # bearer_token = "/path/to/bearer/token"\n  ## OR\n  # bearer_token_string = "abc_123"\n  \n  ## HTTP Basic Authentication username and password. (\'bearer_token\' and\n  ## \'bearer_token_string\' take priority)\n  # username = ""\n  # password = ""\n  \n  ## Specify timeout duration for slower prometheus clients (default is 3s)\n  # response_timeout = "3s"\n  \n  ## Optional TLS Config\n  # tls_ca = /path/to/cafile\n  # tls_cert = /path/to/certfile\n  # tls_key = /path/to/keyfile\n  \n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n`urls` can contain a unix socket as well. If a different path is required (default is `/metrics` for both http[s] and unix) for a unix socket, add `path` as a query parameter as follows: `unix:///var/run/prometheus.sock?path=/custom/metrics`\n\n#### Kubernetes Service Discovery\n\nURLs listed in the `kubernetes_services` parameter will be expanded\nby looking up all A records assigned to the hostname as described in\n[Kubernetes DNS service discovery](https://kubernetes.io/docs/concepts/services-networking/service/#dns).\n\nThis method can be used to locate all\n[Kubernetes headless services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services).\n\n#### Kubernetes scraping\n\nEnabling this option will allow the plugin to scrape for prometheus annotation on Kubernetes\npods. Currently, you can run this plugin in your kubernetes cluster, or we use the kubeconfig\nfile to determine where to monitor.\nCurrently the following annotation are supported:\n\n* `prometheus.io/scrape` Enable scraping for this pod.\n* `prometheus.io/scheme` If the metrics endpoint is secured then you will need to set this to `https` & most likely set the tls config. (default \'http\')\n* `prometheus.io/path` Override the path for the metrics endpoint on the service. (default \'/metrics\')\n* `prometheus.io/port` Used to override the port. (default 9102)\n\nUsing the `monitor_kubernetes_pods_namespace` option allows you to limit which pods you are scraping.\n\nUsing `pod_scrape_scope = "node"` allows more scalable scraping for pods which will scrape pods only in the node that telegraf is running. It will fetch the pod list locally from the node\'s kubelet. This will require running Telegraf in every node of the cluster. Note that either `node_ip` must be specified in the config or the environment variable `NODE_IP` must be set to the host IP. ThisThe latter can be done in the yaml of the pod running telegraf:\n```\nenv:\n  - name: NODE_IP\n    valueFrom:\n      fieldRef:\n        fieldPath: status.hostIP\n ```\n\nIf using node level scrape scope, `pod_scrape_interval` specifies how often (in seconds) the pod list for scraping should updated. If not specified, the default is 60 seconds.\n\n#### Bearer Token\n\nIf set, the file specified by the `bearer_token` parameter will be read on\neach interval and its contents will be appended to the Bearer string in the\nAuthorization header.\n\n### Usage for Caddy HTTP server\n\nIf you want to monitor Caddy, you need to use Caddy with its Prometheus plugin:\n\n* Download Caddy+Prometheus plugin [here](https://caddyserver.com/download/linux/amd64?plugins=http.prometheus)\n* Add the `prometheus` directive in your `CaddyFile`\n* Restart Caddy\n* Configure Telegraf to fetch metrics on it:\n\n```toml\n[[inputs.prometheus]]\n#   ## An array of urls to scrape metrics from.\n  urls = ["http://localhost:9180/metrics"]\n```\n\n> This is the default URL where Caddy Prometheus plugin will send data.\n> For more details, please read the [Caddy Prometheus documentation](https://github.com/miekg/caddy-prometheus/blob/master/README.md).\n\n### Metrics:\n\nMeasurement names are based on the Metric Family and tags are created for each\nlabel.  The value is added to a field named based on the metric type.\n\nAll metrics receive the `url` tag indicating the related URL specified in the\nTelegraf configuration. If using Kubernetes service discovery the `address`\ntag is also added indicating the discovered ip address.\n\n### Example Output:\n\n**Source**\n```\n# HELP go_gc_duration_seconds A summary of the GC invocation durations.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile="0"} 7.4545e-05\ngo_gc_duration_seconds{quantile="0.25"} 7.6999e-05\ngo_gc_duration_seconds{quantile="0.5"} 0.000277935\ngo_gc_duration_seconds{quantile="0.75"} 0.000706591\ngo_gc_duration_seconds{quantile="1"} 0.000706591\ngo_gc_duration_seconds_sum 0.00113607\ngo_gc_duration_seconds_count 4\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 15\n# HELP cpu_usage_user Telegraf collected metric\n# TYPE cpu_usage_user gauge\ncpu_usage_user{cpu="cpu0"} 1.4112903225816156\ncpu_usage_user{cpu="cpu1"} 0.702106318955865\ncpu_usage_user{cpu="cpu2"} 2.0161290322588776\ncpu_usage_user{cpu="cpu3"} 1.5045135406226022\n```\n\n**Output**\n```\ngo_gc_duration_seconds,url=http://example.org:9273/metrics 1=0.001336611,count=14,sum=0.004527551,0=0.000057965,0.25=0.000083812,0.5=0.000286537,0.75=0.000365303 1505776733000000000\ngo_goroutines,url=http://example.org:9273/metrics gauge=21 1505776695000000000\ncpu_usage_user,cpu=cpu0,url=http://example.org:9273/metrics gauge=1.513622603430151 1505776751000000000\ncpu_usage_user,cpu=cpu1,url=http://example.org:9273/metrics gauge=5.829145728641773 1505776751000000000\ncpu_usage_user,cpu=cpu2,url=http://example.org:9273/metrics gauge=2.119071644805144 1505776751000000000\ncpu_usage_user,cpu=cpu3,url=http://example.org:9273/metrics gauge=1.5228426395944945 1505776751000000000\n```\n\n**Output (when metric_version = 2)**\n```\nprometheus,quantile=1,url=http://example.org:9273/metrics go_gc_duration_seconds=0.005574303 1556075100000000000\nprometheus,quantile=0.75,url=http://example.org:9273/metrics go_gc_duration_seconds=0.0001046 1556075100000000000\nprometheus,quantile=0.5,url=http://example.org:9273/metrics go_gc_duration_seconds=0.0000719 1556075100000000000\nprometheus,quantile=0.25,url=http://example.org:9273/metrics go_gc_duration_seconds=0.0000579 1556075100000000000\nprometheus,quantile=0,url=http://example.org:9273/metrics go_gc_duration_seconds=0.0000349 1556075100000000000\nprometheus,url=http://example.org:9273/metrics go_gc_duration_seconds_count=324,go_gc_duration_seconds_sum=0.091340353 1556075100000000000\nprometheus,url=http://example.org:9273/metrics go_goroutines=15 1556075100000000000\nprometheus,cpu=cpu0,url=http://example.org:9273/metrics cpu_usage_user=1.513622603430151 1505776751000000000\nprometheus,cpu=cpu1,url=http://example.org:9273/metrics cpu_usage_user=5.829145728641773 1505776751000000000\nprometheus,cpu=cpu2,url=http://example.org:9273/metrics cpu_usage_user=2.119071644805144 1505776751000000000\nprometheus,cpu=cpu3,url=http://example.org:9273/metrics cpu_usage_user=1.5228426395944945 1505776751000000000\n```\n',image:xa.a},{id:"proxmox",name:"Proxmox",markdown:'# Proxmox Input Plugin\n\nThe proxmox plugin gathers metrics about containers and VMs using the Proxmox API.\n\nTelegraf minimum version: Telegraf 1.16.0\n\n### Configuration:\n\n```toml\n[[inputs.proxmox]]\n  ## API connection configuration. The API token was introduced in Proxmox v6.2. Required permissions for user and token: PVEAuditor role on /.\n  base_url = "https://localhost:8006/api2/json"\n  api_token = "USER@REALM!TOKENID=UUID"\n  ## Node name, defaults to OS hostname\n  # node_name = ""\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  insecure_skip_verify = false\n\n  # HTTP response timeout (default: 5s)\n  response_timeout = "5s"\n```\n\n#### Permissions\n\nThe plugin will need to have access to the Proxmox API. An API token\nmust be provided with the corresponding user being assigned at least the PVEAuditor\nrole on /.\n\n### Measurements & Fields:\n\n- proxmox\n  - status\n  - uptime\n  - cpuload\n  - mem_used\n  - mem_total\n  - mem_free\n  - mem_used_percentage\n  - swap_used\n  - swap_total\n  - swap_free\n  - swap_used_percentage\n  - disk_used\n  - disk_total\n  - disk_free\n  - disk_used_percentage\n\n### Tags:\n\n  - node_fqdn - FQDN of the node telegraf is running on\n  - vm_name - Name of the VM/container\n  - vm_fqdn - FQDN of the VM/container\n  - vm_type - Type of the VM/container (lxc, qemu)\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter proxmox --test\n> proxmox,host=pxnode,node_fqdn=pxnode.example.com,vm_fqdn=vm1.example.com,vm_name=vm1,vm_type=lxc cpuload=0.147998116735236,disk_free=4461129728i,disk_total=5217320960i,disk_used=756191232i,disk_used_percentage=14,mem_free=1046827008i,mem_total=1073741824i,mem_used=26914816i,mem_used_percentage=2,status="running",swap_free=536698880i,swap_total=536870912i,swap_used=172032i,swap_used_percentage=0,uptime=1643793i 1595457277000000000\n> ...\n```\n',image:Sa.a},{id:"puppetagent",name:"PuppetAgent",markdown:"# PuppetAgent Input Plugin\n\n#### Description\n\nThe puppetagent plugin collects variables outputted from the 'last_run_summary.yaml' file\nusually located in `/var/lib/puppet/state/`\n[PuppetAgent Runs](https://puppet.com/blog/puppet-monitoring-how-to-monitor-success-or-failure-of-puppet-runs/).\n\n```\ncat /var/lib/puppet/state/last_run_summary.yaml\n\n---\n  events:\n    failure: 0\n    total: 0\n    success: 0\n  resources:\n    failed: 0\n    scheduled: 0\n    changed: 0\n    skipped: 0\n    total: 109\n    failed_to_restart: 0\n    restarted: 0\n    out_of_sync: 0\n  changes:\n    total: 0\n  time:\n    user: 0.004331\n    schedule: 0.001123\n    filebucket: 0.000353\n    file: 0.441472\n    exec: 0.508123\n    anchor: 0.000555\n    yumrepo: 0.006989\n    ssh_authorized_key: 0.000764\n    service: 1.807795\n    package: 1.325788\n    total: 8.85354707064819\n    config_retrieval: 4.75567007064819\n    last_run: 1444936531\n    cron: 0.000584\n  version:\n    config: 1444936521\n    puppet: \"3.7.5\"\n```\n\n```\njcross@pit-devops-02 ~ >sudo ./telegraf_linux_amd64 --input-filter puppetagent --config tele.conf --test\n* Plugin: puppetagent, Collection 1\n> [] puppetagent_events_failure value=0\n> [] puppetagent_events_total value=0\n> [] puppetagent_events_success value=0\n> [] puppetagent_resources_failed value=0\n> [] puppetagent_resources_scheduled value=0\n> [] puppetagent_resources_changed value=0\n> [] puppetagent_resources_skipped value=0\n> [] puppetagent_resources_total value=109\n> [] puppetagent_resources_failedtorestart value=0\n> [] puppetagent_resources_restarted value=0\n> [] puppetagent_resources_outofsync value=0\n> [] puppetagent_changes_total value=0\n> [] puppetagent_time_user value=0.00393\n> [] puppetagent_time_schedule value=0.001234\n> [] puppetagent_time_filebucket value=0.000244\n> [] puppetagent_time_file value=0.587734\n> [] puppetagent_time_exec value=0.389584\n> [] puppetagent_time_anchor value=0.000399\n> [] puppetagent_time_sshauthorizedkey value=0.000655\n> [] puppetagent_time_service value=0\n> [] puppetagent_time_package value=1.297537\n> [] puppetagent_time_total value=9.45297606225586\n> [] puppetagent_time_configretrieval value=5.89822006225586\n> [] puppetagent_time_lastrun value=1444940131\n> [] puppetagent_time_cron value=0.000646\n> [] puppetagent_version_config value=1444940121\n> [] puppetagent_version_puppet value=3.7.5\n```\n\n## Measurements:\n#### PuppetAgent int64 measurements:\n\nMeta:\n- units: int64\n- tags: ``\n\nMeasurement names:\n - puppetagent_events_failure\n - puppetagent_events_total\n - puppetagent_events_success\n - puppetagent_resources_failed\n - puppetagent_resources_scheduled\n - puppetagent_resources_changed\n - puppetagent_resources_skipped\n - puppetagent_resources_total\n - puppetagent_resources_failedtorestart\n - puppetagent_resources_restarted\n - puppetagent_resources_outofsync\n - puppetagent_changes_total\n - puppetagent_time_service\n - puppetagent_time_lastrun\n - puppetagent_version_config\n\n#### PuppetAgent float64 measurements:\n\nMeta:\n- units: float64\n- tags: ``\n\nMeasurement names:\n - puppetagent_time_user\n - puppetagent_time_schedule\n - puppetagent_time_filebucket\n - puppetagent_time_file\n - puppetagent_time_exec\n - puppetagent_time_anchor\n - puppetagent_time_sshauthorizedkey\n - puppetagent_time_package\n - puppetagent_time_total\n - puppetagent_time_configretrieval\n - puppetagent_time_lastrun\n - puppetagent_time_cron\n - puppetagent_version_config\n\n#### PuppetAgent string measurements:\n\nMeta:\n- units: string\n- tags: ``\n\nMeasurement names:\n - puppetagent_version_puppet\n",image:Ca.a},{id:"rabbitmq",name:"RabbitMQ",markdown:'# RabbitMQ Input Plugin\n\nReads metrics from RabbitMQ servers via the [Management Plugin][management].\n\nFor additional details reference the [RabbitMQ Management HTTP Stats][management-reference].\n\n[management]: https://www.rabbitmq.com/management.html\n[management-reference]: https://raw.githack.com/rabbitmq/rabbitmq-management/rabbitmq_v3_6_9/priv/www/api/index.html\n\n### Configuration\n\n```toml\n[[inputs.rabbitmq]]\n  ## Management Plugin url. (default: http://localhost:15672)\n  # url = "http://localhost:15672"\n  ## Tag added to rabbitmq_overview series; deprecated: use tags\n  # name = "rmq-server-1"\n  ## Credentials\n  # username = "guest"\n  # password = "guest"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n\n  ## Optional request timeouts\n  ##\n  ## ResponseHeaderTimeout, if non-zero, specifies the amount of time to wait\n  ## for a server\'s response headers after fully writing the request.\n  # header_timeout = "3s"\n  ##\n  ## client_timeout specifies a time limit for requests made by this client.\n  ## Includes connection time, any redirects, and reading the response body.\n  # client_timeout = "4s"\n\n  ## A list of nodes to gather as the rabbitmq_node measurement. If not\n  ## specified, metrics for all nodes are gathered.\n  # nodes = ["rabbit@node1", "rabbit@node2"]\n\n  ## A list of queues to gather as the rabbitmq_queue measurement. If not\n  ## specified, metrics for all queues are gathered.\n  # queues = ["telegraf"]\n\n  ## A list of exchanges to gather as the rabbitmq_exchange measurement. If not\n  ## specified, metrics for all exchanges are gathered.\n  # exchanges = ["telegraf"]\n\n  ## Queues to include and exclude. Globs accepted.\n  ## Note that an empty array for both will include all queues\n  # queue_name_include = []\n  # queue_name_exclude = []\n\n  ## Federation upstreams to include and exclude specified as an array of glob\n  ## pattern strings.  Federation links can also be limited by the queue and\n  ## exchange filters.\n  # federation_upstream_include = []\n  # federation_upstream_exclude = []\n```\n\n### Metrics\n\n- rabbitmq_overview\n  - tags:\n    - url\n    - name\n  - fields:\n    - channels (int, channels)\n    - connections (int, connections)\n    - consumers (int, consumers)\n    - exchanges (int, exchanges)\n    - messages (int, messages)\n    - messages_acked (int, messages)\n    - messages_delivered (int, messages)\n    - messages_delivered_get (int, messages)\n    - messages_published (int, messages)\n    - messages_ready (int, messages)\n    - messages_unacked (int, messages)\n    - queues (int, queues)\n    - clustering_listeners (int, cluster nodes)\n    - amqp_listeners (int, amqp nodes up)\n    - return_unroutable (int, number of unroutable messages)\n    - return_unroutable_rate (float, number of unroutable messages per second)\n\n+ rabbitmq_node\n  - tags:\n    - url\n    - node\n    - url\n  - fields:\n    - disk_free (int, bytes)\n    - disk_free_limit (int, bytes)\n    - disk_free_alarm (int, disk alarm)\n    - fd_total (int, file descriptors)\n    - fd_used (int, file descriptors)\n    - mem_limit (int, bytes)\n    - mem_used (int, bytes)\n    - mem_alarm (int, memory a)\n    - proc_total (int, erlang processes)\n    - proc_used (int, erlang processes)\n    - run_queue (int, erlang processes)\n    - sockets_total (int, sockets)\n    - sockets_used (int, sockets)\n    - running (int, node up)\n    - uptime (int, milliseconds)\n    - mnesia_disk_tx_count (int, number of disk transaction)\n    - mnesia_ram_tx_count (int, number of ram transaction)\n    - mnesia_disk_tx_count_rate (float, number of disk transaction per second)\n    - mnesia_ram_tx_count_rate (float, number of ram transaction per second)\n    - gc_num (int, number of garbage collection)\n    - gc_bytes_reclaimed (int, bytes)\n    - gc_num_rate (float, number of garbage collection per second)\n    - gc_bytes_reclaimed_rate (float, bytes per second)\n    - io_read_avg_time (float, number of read operations)\n    - io_read_avg_time_rate (int, number of read operations per second)\n    - io_read_bytes (int, bytes)\n    - io_read_bytes_rate (float, bytes per second)\n    - io_write_avg_time (int, milliseconds)\n    - io_write_avg_time_rate (float, milliseconds per second)\n    - io_write_bytes (int, bytes)\n    - io_write_bytes_rate (float, bytes per second)\n    - mem_connection_readers (int, bytes)\n    - mem_connection_writers (int, bytes)\n    - mem_connection_channels (int, bytes)\n    - mem_connection_other (int, bytes)\n    - mem_queue_procs (int, bytes)\n    - mem_queue_slave_procs (int, bytes)\n    - mem_plugins (int, bytes)\n    - mem_other_proc (int, bytes)\n    - mem_metrics (int, bytes)\n    - mem_mgmt_db (int, bytes)\n    - mem_mnesia (int, bytes)\n    - mem_other_ets (int, bytes)\n    - mem_binary (int, bytes)\n    - mem_msg_index (int, bytes)\n    - mem_code (int, bytes)\n    - mem_atom (int, bytes)\n    - mem_other_system (int, bytes)\n    - mem_allocated_unused (int, bytes)\n    - mem_reserved_unallocated (int, bytes)\n    - mem_total (int, bytes)\n\n- rabbitmq_queue\n  - tags:\n    - url\n    - queue\n    - vhost\n    - node\n    - durable\n    - auto_delete\n  - fields:\n    - consumer_utilisation (float, percent)\n    - consumers (int, int)\n    - idle_since (string, time - e.g., "2006-01-02 15:04:05")\n    - memory (int, bytes)\n    - message_bytes (int, bytes)\n    - message_bytes_persist (int, bytes)\n    - message_bytes_ram (int, bytes)\n    - message_bytes_ready (int, bytes)\n    - message_bytes_unacked (int, bytes)\n    - messages (int, count)\n    - messages_ack (int, count)\n    - messages_ack_rate (float, messages per second)\n    - messages_deliver (int, count)\n    - messages_deliver_rate (float, messages per second)\n    - messages_deliver_get (int, count)\n    - messages_deliver_get_rate (float, messages per second)\n    - messages_publish (int, count)\n    - messages_publish_rate (float, messages per second)\n    - messages_ready (int, count)\n    - messages_redeliver (int, count)\n    - messages_redeliver_rate (float, messages per second)\n    - messages_unack (int, count)\n    - slave_nodes (int, count)\n    - synchronised_slave_nodes (int, count)\n\n+ rabbitmq_exchange\n  - tags:\n    - url\n    - exchange\n    - type\n    - vhost\n    - internal\n    - durable\n    - auto_delete\n  - fields:\n    - messages_publish_in (int, count)\n    - messages_publish_in_rate (int, messages per second)\n    - messages_publish_out (int, count)\n    - messages_publish_out_rate (int, messages per second)\n\n- rabbitmq_federation\n  - tags:\n    - url\n    - vhost\n    - type\n    - upstream\n    - exchange\n    - upstream_exchange\n    - queue\n    - upstream_queue\n  - fields:\n    - acks_uncommitted (int, count)\n    - consumers (int, count)\n    - messages_unacknowledged (int, count)\n    - messages_uncommitted (int, count)\n    - messages_unconfirmed (int, count)\n    - messages_confirm (int, count)\n    - messages_publish (int, count)\n    - messages_return_unroutable (int, count)\n\n### Sample Queries\n\nMessage rates for the entire node can be calculated from total message counts. For instance, to get the rate of messages published per minute, use this query:\n\n```\nSELECT NON_NEGATIVE_DERIVATIVE(LAST("messages_published"), 1m) AS messages_published_rate FROM rabbitmq_overview WHERE time > now() - 10m GROUP BY time(1m)\n```\n\n### Example Output\n\n```\nrabbitmq_queue,url=http://amqp.example.org:15672,queue=telegraf,vhost=influxdb,node=rabbit@amqp.example.org,durable=true,auto_delete=false,host=amqp.example.org messages_deliver_get=0i,messages_publish=329i,messages_publish_rate=0.2,messages_redeliver_rate=0,message_bytes_ready=0i,message_bytes_unacked=0i,messages_deliver=329i,messages_unack=0i,consumers=1i,idle_since="",messages=0i,messages_deliver_rate=0.2,messages_deliver_get_rate=0.2,messages_redeliver=0i,memory=43032i,message_bytes_ram=0i,messages_ack=329i,messages_ready=0i,messages_ack_rate=0.2,consumer_utilisation=1,message_bytes=0i,message_bytes_persist=0i 1493684035000000000\nrabbitmq_overview,url=http://amqp.example.org:15672,host=amqp.example.org channels=2i,consumers=1i,exchanges=17i,messages_acked=329i,messages=0i,messages_ready=0i,messages_unacked=0i,connections=2i,queues=1i,messages_delivered=329i,messages_published=329i,clustering_listeners=2i,amqp_listeners=1i 1493684035000000000\nrabbitmq_node,url=http://amqp.example.org:15672,node=rabbit@amqp.example.org,host=amqp.example.org fd_total=1024i,fd_used=32i,mem_limit=8363329126i,sockets_total=829i,disk_free=8175935488i,disk_free_limit=50000000i,mem_used=58771080i,proc_total=1048576i,proc_used=267i,run_queue=0i,sockets_used=2i,running=1i 149368403500000000\nrabbitmq_exchange,url=http://amqp.example.org:15672,exchange=telegraf,type=fanout,vhost=influxdb,internal=false,durable=true,auto_delete=false,host=amqp.example.org messages_publish_in=2i,messages_publish_out=1i 149368403500000000\n```\n',image:Pa.a},{id:"raindrops",name:"Raindrops",markdown:'# Raindrops Input Plugin\n\nThe [raindrops](http://raindrops.bogomips.org/) plugin reads from\nspecified raindops [middleware](http://raindrops.bogomips.org/Raindrops/Middleware.html) URI and adds stats to InfluxDB.\n\n### Configuration:\n\n```toml\n# Read raindrops stats\n[[inputs.raindrops]]\n  urls = ["http://localhost:8080/_raindrops"]\n```\n\n### Measurements & Fields:\n\n- raindrops\n    - calling (integer, count)\n    - writing (integer, count)\n- raindrops_listen\n    - active (integer, bytes)\n    - queued (integer, bytes)\n\n### Tags:\n\n- Raindops calling/writing of all the workers:\n    - server\n    - port\n\n- raindrops_listen (ip:port):\n    - ip\n    - port\n\n- raindrops_listen (Unix Socket):\n    - socket\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter raindrops --test\n* Plugin: raindrops, Collection 1\n> raindrops,port=8080,server=localhost calling=0i,writing=0i 1455479896806238204\n> raindrops_listen,ip=0.0.0.0,port=8080 active=0i,queued=0i 1455479896806561938\n> raindrops_listen,ip=0.0.0.0,port=8081 active=1i,queued=0i 1455479896806605749\n> raindrops_listen,ip=127.0.0.1,port=8082 active=0i,queued=0i 1455479896806646315\n> raindrops_listen,ip=0.0.0.0,port=8083 active=0i,queued=0i 1455479896806683252\n> raindrops_listen,ip=0.0.0.0,port=8084 active=0i,queued=0i 1455479896806712025\n> raindrops_listen,ip=0.0.0.0,port=3000 active=0i,queued=0i 1455479896806779197\n> raindrops_listen,socket=/tmp/listen.me active=0i,queued=0i 1455479896806813907\n```\n',image:Ma.a},{id:"ras",name:"RAS Daemon",markdown:'# RAS Daemon Input Plugin\n\nThis plugin is only available on Linux (only for `386`, `amd64`, `arm` and `arm64` architectures).\n\nThe `RAS` plugin gathers and counts errors provided by [RASDaemon](https://github.com/mchehab/rasdaemon).\n\n### Configuration\n\n```toml\n[[inputs.ras]]\n  ## Optional path to RASDaemon sqlite3 database.\n  ## Default: /var/lib/rasdaemon/ras-mc_event.db\n  # db_path = ""\n```\n\nIn addition `RASDaemon` runs, by default, with `--enable-sqlite3` flag. In case of problems with SQLite3 database please verify this is still a default option.\n\n### Metrics\n\n- ras\n  - tags:\n    - socket_id\n  - fields:\n    - memory_read_corrected_errors\n    - memory_read_uncorrectable_errors\n    - memory_write_corrected_errors\n    - memory_write_uncorrectable_errors\n    - cache_l0_l1_errors\n    - tlb_instruction_errors\n    - cache_l2_errors\n    - upi_errors\n    - processor_base_errors\n    - processor_bus_errors\n    - internal_timer_errors\n    - smm_handler_code_access_violation_errors\n    - internal_parity_errors\n    - frc_errors\n    - external_mce_errors\n    - microcode_rom_parity_errors\n    - unclassified_mce_errors\n\nPlease note that `processor_base_errors` is aggregate counter measuring the following MCE events:\n- internal_timer_errors\n- smm_handler_code_access_violation_errors\n- internal_parity_errors\n- frc_errors\n- external_mce_errors\n- microcode_rom_parity_errors\n- unclassified_mce_errors\n\n### Permissions\n\nThis plugin requires access to SQLite3 database from `RASDaemon`. Please make sure that user has required permissions to this database.\n\n### Example Output\n\n```\nras,host=ubuntu,socket_id=0 external_mce_base_errors=1i,frc_errors=1i,instruction_tlb_errors=5i,internal_parity_errors=1i,internal_timer_errors=1i,l0_and_l1_cache_errors=7i,memory_read_corrected_errors=25i,memory_read_uncorrectable_errors=0i,memory_write_corrected_errors=5i,memory_write_uncorrectable_errors=0i,microcode_rom_parity_errors=1i,processor_base_errors=7i,processor_bus_errors=1i,smm_handler_code_access_violation_errors=1i,unclassified_mce_base_errors=1i 1598867393000000000\nras,host=ubuntu level_2_cache_errors=0i,upi_errors=0i 1598867393000000000\n```\n',image:Ea.a},{id:"ravendb",name:"RavenDB",markdown:'# RavenDB Input Plugin\n\nReads metrics from RavenDB servers via monitoring endpoints APIs.\n\nRequires RavenDB Server 5.2+.\n\n### Configuration\n\nThe following is an example config for RavenDB. **Note:** The client certificate used should have `Operator` permissions on the cluster.\n\n```toml\n[[inputs.ravendb]]\n  ## Node URL and port that RavenDB is listening on\n  url = "https://localhost:8080"\n\n  ## RavenDB X509 client certificate setup\n  tls_cert = "/etc/telegraf/raven.crt"\n  tls_key = "/etc/telegraf/raven.key"\n\n  ## Optional request timeout\n  ##\n  ## Timeout, specifies the amount of time to wait\n  ## for a server\'s response headers after fully writing the request and \n  ## time limit for requests made by this client\n  # timeout = "5s"\n\n  ## List of statistics which are collected\n  # At least one is required\n  # Allowed values: server, databases, indexes, collections\n  #  \n  # stats_include = ["server", "databases", "indexes", "collections"]\n\n  ## List of db where database stats are collected\n  ## If empty, all db are concerned\n  # db_stats_dbs = []\n\n  ## List of db where index status are collected\n  ## If empty, all indexes from all db are concerned\n  # index_stats_dbs = []\n  \n  ## List of db where collection status are collected\n  ## If empty, all collections from all db are concerned\n  # collection_stats_dbs = []\n```\n\n### Metrics\n\n- ravendb_server\n  - tags:\n    - url\n    - node_tag\n    - cluster_id\n    - public_server_url (optional)  \n  - fields:\n    - backup_current_number_of_running_backups\n    - backup_max_number_of_concurrent_backups\n    - certificate_server_certificate_expiration_left_in_sec (optional)\n    - certificate_well_known_admin_certificates (optional, separated by \';\')\n    - cluster_current_term\n    - cluster_index      \n    - cluster_node_state\n      - 0 -> Passive\n      - 1 -> Candidate\n      - 2 -> Follower\n      - 3 -> LeaderElect\n      - 4 -> Leader\n    - config_public_tcp_server_urls (optional, separated by \';\')\n    - config_server_urls\n    - config_tcp_server_urls (optional, separated by \';\')\n    - cpu_assigned_processor_count\n    - cpu_machine_usage\n    - cpu_machine_io_wait (optional)\n    - cpu_process_usage\n    - cpu_processor_count\n    - cpu_thread_pool_available_worker_threads\n    - cpu_thread_pool_available_completion_port_threads\n    - databases_loaded_count\n    - databases_total_count\n    - disk_remaining_storage_space_percentage\n    - disk_system_store_used_data_file_size_in_mb\n    - disk_system_store_total_data_file_size_in_mb\n    - disk_total_free_space_in_mb\n    - license_expiration_left_in_sec (optional)\n    - license_max_cores\n    - license_type\n    - license_utilized_cpu_cores\n    - memory_allocated_in_mb  \n    - memory_installed_in_mb\n    - memory_low_memory_severity\n      - 0 -> None\n      - 1 -> Low\n      - 2 -> Extremely Low\n    - memory_physical_in_mb\n    - memory_total_dirty_in_mb\n    - memory_total_swap_size_in_mb\n    - memory_total_swap_usage_in_mb\n    - memory_working_set_swap_usage_in_mb\n    - network_concurrent_requests_count\n    - network_last_authorized_non_cluster_admin_request_time_in_sec (optional)\n    - network_last_request_time_in_sec (optional)\n    - network_requests_per_sec\n    - network_tcp_active_connections\n    - network_total_requests\n    - server_full_version\n    - server_process_id\n    - server_version\n    - uptime_in_sec\n  \n- ravendb_databases\n  - tags:\n    - url\n    - database_name\n    - database_id\n    - node_tag\n    - public_server_url (optional)\n  - fields:\n    - counts_alerts\n    - counts_attachments\n    - counts_documents\n    - counts_performance_hints\n    - counts_rehabs\n    - counts_replication_factor\n    - counts_revisions\n    - counts_unique_attachments\n    - statistics_doc_puts_per_sec\n    - statistics_map_index_indexes_per_sec\n    - statistics_map_reduce_index_mapped_per_sec\n    - statistics_map_reduce_index_reduced_per_sec\n    - statistics_request_average_duration_in_ms\n    - statistics_requests_count\n    - statistics_requests_per_sec\n    - indexes_auto_count\n    - indexes_count\n    - indexes_disabled_count\n    - indexes_errors_count\n    - indexes_errored_count\n    - indexes_idle_count\n    - indexes_stale_count\n    - indexes_static_count\n    - storage_documents_allocated_data_file_in_mb\n    - storage_documents_used_data_file_in_mb\n    - storage_indexes_allocated_data_file_in_mb\n    - storage_indexes_used_data_file_in_mb\n    - storage_total_allocated_storage_file_in_mb\n    - storage_total_free_space_in_mb\n    - time_since_last_backup_in_sec (optional)\n    - uptime_in_sec\n\n- ravendb_indexes\n  - tags: \n    - database_name\n    - index_name\n    - node_tag\n    - public_server_url (optional)\n    - url\n  - fields\n    - errors\n    - is_invalid\n    - lock_mode\n      - Unlock\n      - LockedIgnore\n      - LockedError\n    - mapped_per_sec\n    - priority\n      - Low\n      - Normal\n      - High\n    - reduced_per_sec\n    - state\n      - Normal\n      - Disabled\n      - Idle\n      - Error\n    - status\n      - Running\n      - Paused\n      - Disabled\n    - time_since_last_indexing_in_sec (optional)\n    - time_since_last_query_in_sec (optional)\n    - type\n      - None\n      - AutoMap\n      - AutoMapReduce\n      - Map\n      - MapReduce\n      - Faulty\n      - JavaScriptMap\n      - JavaScriptMapReduce\n\n- ravendb_collections\n  - tags:\n    - collection_name\n    - database_name\n    - node_tag\n    - public_server_url (optional)\n    - url\n  - fields\n    - documents_count\n    - documents_size_in_bytes\n    - revisions_size_in_bytes\n    - tombstones_size_in_bytes\n    - total_size_in_bytes\n\n### Example output\n\n```\n> ravendb_server,cluster_id=07aecc42-9194-4181-999c-1c42450692c9,host=DESKTOP-2OISR6D,node_tag=A,url=http://localhost:8080 backup_current_number_of_running_backups=0i,backup_max_number_of_concurrent_backups=4i,certificate_server_certificate_expiration_left_in_sec=-1,cluster_current_term=2i,cluster_index=10i,cluster_node_state=4i,config_server_urls="http://127.0.0.1:8080",cpu_assigned_processor_count=8i,cpu_machine_usage=19.09944089456869,cpu_process_usage=0.16977205323024872,cpu_processor_count=8i,cpu_thread_pool_available_completion_port_threads=1000i,cpu_thread_pool_available_worker_threads=32763i,databases_loaded_count=1i,databases_total_count=1i,disk_remaining_storage_space_percentage=18i,disk_system_store_total_data_file_size_in_mb=35184372088832i,disk_system_store_used_data_file_size_in_mb=31379031064576i,disk_total_free_space_in_mb=42931i,license_expiration_left_in_sec=24079222.8772186,license_max_cores=256i,license_type="Enterprise",license_utilized_cpu_cores=8i,memory_allocated_in_mb=205i,memory_installed_in_mb=16384i,memory_low_memory_severity=0i,memory_physical_in_mb=16250i,memory_total_dirty_in_mb=0i,memory_total_swap_size_in_mb=0i,memory_total_swap_usage_in_mb=0i,memory_working_set_swap_usage_in_mb=0i,network_concurrent_requests_count=1i,network_last_request_time_in_sec=0.0058717,network_requests_per_sec=0.09916543455308825,network_tcp_active_connections=128i,network_total_requests=10i,server_full_version="5.2.0-custom-52",server_process_id=31044i,server_version="5.2",uptime_in_sec=56i 1613027977000000000\n> ravendb_databases,database_id=ced0edba-8f80-48b8-8e81-c3d2c6748ec3,database_name=db1,host=DESKTOP-2OISR6D,node_tag=A,url=http://localhost:8080 counts_alerts=0i,counts_attachments=17i,counts_documents=1059i,counts_performance_hints=0i,counts_rehabs=0i,counts_replication_factor=1i,counts_revisions=5475i,counts_unique_attachments=17i,indexes_auto_count=0i,indexes_count=7i,indexes_disabled_count=0i,indexes_errored_count=0i,indexes_errors_count=0i,indexes_idle_count=0i,indexes_stale_count=0i,indexes_static_count=7i,statistics_doc_puts_per_sec=0,statistics_map_index_indexes_per_sec=0,statistics_map_reduce_index_mapped_per_sec=0,statistics_map_reduce_index_reduced_per_sec=0,statistics_request_average_duration_in_ms=0,statistics_requests_count=0i,statistics_requests_per_sec=0,storage_documents_allocated_data_file_in_mb=140737488355328i,storage_documents_used_data_file_in_mb=74741020884992i,storage_indexes_allocated_data_file_in_mb=175921860444160i,storage_indexes_used_data_file_in_mb=120722940755968i,storage_total_allocated_storage_file_in_mb=325455441821696i,storage_total_free_space_in_mb=42931i,uptime_in_sec=54 1613027977000000000\n> ravendb_indexes,database_name=db1,host=DESKTOP-2OISR6D,index_name=Orders/Totals,node_tag=A,url=http://localhost:8080 errors=0i,is_invalid=false,lock_mode="Unlock",mapped_per_sec=0,priority="Normal",reduced_per_sec=0,state="Normal",status="Running",time_since_last_indexing_in_sec=45.4256655,time_since_last_query_in_sec=45.4304202,type="Map" 1613027977000000000\n> ravendb_collections,collection_name=@hilo,database_name=db1,host=DESKTOP-2OISR6D,node_tag=A,url=http://localhost:8080 documents_count=8i,documents_size_in_bytes=122880i,revisions_size_in_bytes=0i,tombstones_size_in_bytes=122880i,total_size_in_bytes=245760i 1613027977000000000\n```\n\n### Contributors\n\n- Marcin Lewandowski (https://github.com/ml054/)\n- Casey Barton (https://github.com/bartoncasey)',image:Na.a},{id:"redfish",name:"Redfish",markdown:'# Redfish Input Plugin\n\nThe `redfish` plugin gathers metrics and status information about CPU temperature, fanspeed, Powersupply, voltage, hostname and Location details (datacenter, placement, rack and room) of hardware servers for which [DMTF\'s Redfish](https://redfish.dmtf.org/) is enabled.\n\nTelegraf minimum version: Telegraf 1.15.0\n\n### Configuration\n\n```toml\n[[inputs.redfish]]\n  ## Redfish API Base URL.\n  address = "https://127.0.0.1:5000"\n\n  ## Credentials for the Redfish API.\n  username = "root"\n  password = "password123456"\n\n  ## System Id to collect data for in Redfish APIs.\n  computer_system_id="System.Embedded.1"\n\n  ## Amount of time allowed to complete the HTTP request\n  # timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics\n\n- redfish_thermal_temperatures\n  - tags:\n    - source\n    - member_id\n    - address\n    - name\n    - datacenter (available only if location data is found)\n    - rack (available only if location data is found)\n    - room (available only if location data is found)\n    - row (available only if location data is found)\n    - state\n    - health\n  - fields:\n    - reading_celsius\n    - upper_threshold_critical\n    - upper_threshold_fatal\n    - lower_threshold_critical\n    - lower_threshold_fatal\n\n\n+ redfish_thermal_fans\n  - tags:\n    - source\n    - member_id\n    - address\n    - name\n    - datacenter (available only if location data is found)\n    - rack (available only if location data is found)\n    - room (available only if location data is found)\n    - row (available only if location data is found)\n    - state\n    - health\n  - fields:\n    - reading_rpm (or) reading_percent\n    - upper_threshold_critical\n    - upper_threshold_fatal\n    - lower_threshold_critical\n    - lower_threshold_fatal\n\n\n- redfish_power_powersupplies\n  - tags:\n    - source\n    - address\n    - member_id\n    - name\n    - datacenter (available only if location data is found)\n    - rack (available only if location data is found)\n    - room (available only if location data is found)\n    - row (available only if location data is found)\n    - state\n    - health\n  - fields:\n    - last_power_output_watts\n    - line_input_voltage\n    - power_capacity_watts\n    - power_input_watts\n    - power_output_watts\n\n\n- redfish_power_voltages (available only if voltage data is found)\n  - tags:\n    - source\n    - address\n    - member_id\n    - name\n    - datacenter (available only if location data is found)\n    - rack (available only if location data is found)\n    - room (available only if location data is found)\n    - row (available only if location data is found)\n    - state\n    - health\n  - fields:\n    - reading_volts\n    - upper_threshold_critical\n    - upper_threshold_fatal\n    - lower_threshold_critical\n    - lower_threshold_fatal\n\n\n### Example Output\n\n```\nredfish_thermal_temperatures,source=test-hostname,name=CPU1,address=http://190.0.0.1,member_id="0"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_celsius=41,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_temperatures,source=test-hostname,name=CPU2,address=http://190.0.0.1,member_id="1"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_celsius=51,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_temperatures,source=test-hostname,name=SystemBoardInlet,address=http://190.0.0.1,member_id="2"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_celsius=23,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_temperatures,source=test-hostname,name=SystemBoardExhaust,address=http://190.0.0.1,member_id="3"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_celsius=33,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_fans,source=test-hostname,name=SystemBoardFan1A,address=http://190.0.0.1,member_id="0"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_rpm=17720,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_fans,source=test-hostname,name=SystemBoardFan1B,address=http://190.0.0.1,member_id="1"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_rpm=17760,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_thermal_fans,source=test-hostname,name=SystemBoardFan2A,address=http://190.0.0.1,member_id="2"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_rpm=17880,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_power_powersupplies,source=test-hostname,name=PS1Status,address=http://190.0.0.1,member_id="0"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" power_capacity_watts=750,power_input_watts=900,power_output_watts=208,last_power_output_watts=98,line_input_reading_volts=204 1582114112000000000\nredfish_power_powersupplies,source=test-hostname,name=PS2Status,address=http://190.0.0.1,member_id="1",datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" power_capacity_watts=750,power_input_watts=900,power_output_watts=194,last_power_output_watts=98,line_input_reading_volts=204 1582114112000000000\nredfish_power_voltages,source=test-hostname,name=CPU1MEM345,address=http://190.0.0.1,member_id="0"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_volts=1,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_power_voltages,source=test-hostname,name=CPU1MEM345,address=http://190.0.0.1,member_id="1"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_volts=1,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_power_voltages,source=test-hostname,name=CPU1MEM347,address=http://190.0.0.1,member_id="2"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_volts=1,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\nredfish_power_voltages,source=test-hostname,name=PS1voltage1,address=http://190.0.0.1,member_id="12"datacenter="Tampa",health="OK",rack="12",room="tbc",row="3",state="Enabled" reading_volts=208,upper_threshold_critical=59,upper_threshold_fatal=64 1582114112000000000\n\n```\n',image:La.a},{id:"redis",name:"Redis",markdown:'# Redis Input Plugin\n\n### Configuration:\n\n```toml\n# Read Redis\'s basic status information\n[[inputs.redis]]\n  ## specify servers via a url matching:\n  ##  [protocol://][:password]@address[:port]\n  ##  e.g.\n  ##    tcp://localhost:6379\n  ##    tcp://:password@192.168.99.100\n  ##\n  ## If no servers are specified, then localhost is used as the host.\n  ## If no port is specified, 6379 is used\n  servers = ["tcp://localhost:6379"]\n  ## Optional. Specify redis commands to retrieve values\n  # [[inputs.redis.commands]]\n  # command = ["get", "sample-key"]\n  # field = "sample-key-value"\n  # type = "string"\n\n  ## specify server password\n  # password = "s#cr@t%"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = true\n```\n\n### Measurements & Fields:\n\nThe plugin gathers the results of the [INFO](https://redis.io/commands/info) redis command.\nThere are two separate measurements: _redis_ and _redis\\_keyspace_, the latter is used for gathering database related statistics.\n\nAdditionally the plugin also calculates the hit/miss ratio (keyspace\\_hitrate) and the elapsed time since the last rdb save (rdb\\_last\\_save\\_time\\_elapsed).\n\n- redis\n    - keyspace_hitrate(float, number)\n    - rdb_last_save_time_elapsed(int, seconds)\n\n    **Server**\n    - uptime(int, seconds)\n    - lru_clock(int, number)\n    - redis_version(string)\n\n    **Clients**\n    - clients(int, number)\n    - client_longest_output_list(int, number)\n    - client_biggest_input_buf(int, number)\n    - blocked_clients(int, number)\n\n    **Memory**\n    - used_memory(int, bytes)\n    - used_memory_rss(int, bytes)\n    - used_memory_peak(int, bytes)\n    - total_system_memory(int, bytes)\n    - used_memory_lua(int, bytes)\n    - maxmemory(int, bytes)\n    - maxmemory_policy(string)\n    - mem_fragmentation_ratio(float, number)\n\n    **Persistence**\n    - loading(int,flag)\n    - rdb_changes_since_last_save(int, number)\n    - rdb_bgsave_in_progress(int, flag)\n    - rdb_last_save_time(int, seconds)\n    - rdb_last_bgsave_status(string)\n    - rdb_last_bgsave_time_sec(int, seconds)\n    - rdb_current_bgsave_time_sec(int, seconds)\n    - aof_enabled(int, flag)\n    - aof_rewrite_in_progress(int, flag)\n    - aof_rewrite_scheduled(int, flag)\n    - aof_last_rewrite_time_sec(int, seconds)\n    - aof_current_rewrite_time_sec(int, seconds)\n    - aof_last_bgrewrite_status(string)\n    - aof_last_write_status(string)\n\n    **Stats**\n    - total_connections_received(int, number)\n    - total_commands_processed(int, number)\n    - instantaneous_ops_per_sec(int, number)\n    - total_net_input_bytes(int, bytes)\n    - total_net_output_bytes(int, bytes)\n    - instantaneous_input_kbps(float, KB/sec)\n    - instantaneous_output_kbps(float, KB/sec)\n    - rejected_connections(int, number)\n    - sync_full(int, number)\n    - sync_partial_ok(int, number)\n    - sync_partial_err(int, number)\n    - expired_keys(int, number)\n    - evicted_keys(int, number)\n    - keyspace_hits(int, number)\n    - keyspace_misses(int, number)\n    - pubsub_channels(int, number)\n    - pubsub_patterns(int, number)\n    - latest_fork_usec(int, microseconds)\n    - migrate_cached_sockets(int, number)\n\n    **Replication**\n    - connected_slaves(int, number)\n    - master_link_down_since_seconds(int, number)\n    - master_link_status(string)\n    - master_repl_offset(int, number)\n    - second_repl_offset(int, number)\n    - repl_backlog_active(int, number)\n    - repl_backlog_size(int, bytes)\n    - repl_backlog_first_byte_offset(int, number)\n    - repl_backlog_histlen(int, bytes)\n\n    **CPU**\n    - used_cpu_sys(float, number)\n    - used_cpu_user(float, number)\n    - used_cpu_sys_children(float, number)\n    - used_cpu_user_children(float, number)\n\n    **Cluster**\n    - cluster_enabled(int, flag)\n\n- redis_keyspace\n    - keys(int, number)\n    - expires(int, number)\n    - avg_ttl(int, number)\n\n- redis_cmdstat\n    Every Redis used command will have 3 new fields:\n    - calls(int, number)\n    - usec(int, mircoseconds)\n    - usec_per_call(float, microseconds)\n\n- redis_replication\n  - tags:\n    - replication_role\n    - replica_ip\n    - replica_port\n    - state (either "online", "wait_bgsave", or "send_bulk")\n\n  - fields:\n    - lag(int, number)\n    - offset(int, number)\n\n### Tags:\n\n- All measurements have the following tags:\n    - port\n    - server\n    - replication_role\n\n- The redis_keyspace measurement has an additional database tag:\n    - database\n\n- The redis_cmdstat measurement has an additional tag:\n    - command\n\n### Example Output:\n\nUsing this configuration:\n```toml\n[[inputs.redis]]\n  ## specify servers via a url matching:\n  ##  [protocol://][:password]@address[:port]\n  ##  e.g.\n  ##    tcp://localhost:6379\n  ##    tcp://:password@192.168.99.100\n  ##\n  ## If no servers are specified, then localhost is used as the host.\n  ## If no port is specified, 6379 is used\n  servers = ["tcp://localhost:6379"]\n```\n\nWhen run with:\n```\n./telegraf --config telegraf.conf --input-filter redis --test\n```\n\nIt produces:\n```\n* Plugin: redis, Collection 1\n> redis,server=localhost,port=6379,replication_role=master,host=host keyspace_hitrate=1,clients=2i,blocked_clients=0i,instantaneous_input_kbps=0,sync_full=0i,pubsub_channels=0i,pubsub_patterns=0i,total_net_output_bytes=6659253i,used_memory=842448i,total_system_memory=8351916032i,aof_current_rewrite_time_sec=-1i,rdb_changes_since_last_save=0i,sync_partial_err=0i,latest_fork_usec=508i,instantaneous_output_kbps=0,expired_keys=0i,used_memory_peak=843416i,aof_rewrite_in_progress=0i,aof_last_bgrewrite_status="ok",migrate_cached_sockets=0i,connected_slaves=0i,maxmemory_policy="noeviction",aof_rewrite_scheduled=0i,total_net_input_bytes=3125i,used_memory_rss=9564160i,repl_backlog_histlen=0i,rdb_last_bgsave_status="ok",aof_last_rewrite_time_sec=-1i,keyspace_misses=0i,client_biggest_input_buf=5i,used_cpu_user=1.33,maxmemory=0i,rdb_current_bgsave_time_sec=-1i,total_commands_processed=271i,repl_backlog_size=1048576i,used_cpu_sys=3,uptime=2822i,lru_clock=16706281i,used_memory_lua=37888i,rejected_connections=0i,sync_partial_ok=0i,evicted_keys=0i,rdb_last_save_time_elapsed=1922i,rdb_last_save_time=1493099368i,instantaneous_ops_per_sec=0i,used_cpu_user_children=0,client_longest_output_list=0i,master_repl_offset=0i,repl_backlog_active=0i,keyspace_hits=2i,used_cpu_sys_children=0,cluster_enabled=0i,rdb_last_bgsave_time_sec=0i,aof_last_write_status="ok",total_connections_received=263i,aof_enabled=0i,repl_backlog_first_byte_offset=0i,mem_fragmentation_ratio=11.35,loading=0i,rdb_bgsave_in_progress=0i 1493101290000000000\n```\n\nredis_keyspace:\n```\n> redis_keyspace,database=db1,host=host,server=localhost,port=6379,replication_role=master keys=1i,expires=0i,avg_ttl=0i 1493101350000000000\n```\n\nredis_command:\n```\n> redis_cmdstat,command=publish,host=host,port=6379,replication_role=master,server=localhost calls=68113i,usec=325146i,usec_per_call=4.77 1559227136000000000\n```\n',image:Ua.a},{id:"rethinkdb",name:"RethinkDB",markdown:'# RethinkDB Input Plugin\n\nCollect metrics from [RethinkDB](https://www.rethinkdb.com/).\n\n### Configuration\n\nThis section contains the default TOML to configure the plugin.  You can\ngenerate it using `telegraf --usage rethinkdb`.\n\n```toml\n[[inputs.rethinkdb]]\n  ## An array of URI to gather stats about. Specify an ip or hostname\n  ## with optional port add password. ie,\n  ##   rethinkdb://user:auth_key@10.10.3.30:28105,\n  ##   rethinkdb://10.10.3.33:18832,\n  ##   10.0.0.1:10000, etc.\n  servers = ["127.0.0.1:28015"]\n\n  ## If you use actual rethinkdb of > 2.3.0 with username/password authorization,\n  ## protocol have to be named "rethinkdb2" - it will use 1_0 H.\n  # servers = ["rethinkdb2://username:password@127.0.0.1:28015"]\n\n  ## If you use older versions of rethinkdb (<2.2) with auth_key, protocol\n  ## have to be named "rethinkdb".\n  # servers = ["rethinkdb://username:auth_key@127.0.0.1:28015"]\n```\n\n### Metrics\n\n- rethinkdb\n  - tags:\n    - type\n    - ns\n    - rethinkdb_host\n    - rethinkdb_hostname\n  - fields:\n    - cache_bytes_in_use (integer, bytes)\n    - disk_read_bytes_per_sec (integer, reads)\n    - disk_read_bytes_total (integer, bytes)\n    - disk_written_bytes_per_sec (integer, bytes)\n    - disk_written_bytes_total (integer, bytes)\n    - disk_usage_data_bytes (integer, bytes)\n    - disk_usage_garbage_bytes (integer, bytes)\n    - disk_usage_metadata_bytes (integer, bytes)\n    - disk_usage_preallocated_bytes (integer, bytes)\n\n+ rethinkdb_engine\n  - tags:\n    - type\n    - ns\n    - rethinkdb_host\n    - rethinkdb_hostname\n  - fields:\n    - active_clients (integer, clients)\n    - clients (integer, clients)\n    - queries_per_sec (integer, queries)\n    - total_queries (integer, queries)\n    - read_docs_per_sec (integer, reads)\n    - total_reads (integer, reads)\n    - written_docs_per_sec (integer, writes)\n    - total_writes (integer, writes)\n',image:Ba.a},{id:"riak",name:"Riak",markdown:'# Riak Input Plugin\n\nThe Riak plugin gathers metrics from one or more riak instances.\n\n### Configuration:\n\n```toml\n# Description\n[[inputs.riak]]\n  # Specify a list of one or more riak http servers\n  servers = ["http://localhost:8098"]\n```\n\n### Measurements & Fields:\n\nRiak provides one measurement named "riak", with the following fields:\n\n- cpu_avg1\n- cpu_avg15\n- cpu_avg5\n- memory_code\n- memory_ets\n- memory_processes\n- memory_system\n- memory_total\n- node_get_fsm_objsize_100\n- node_get_fsm_objsize_95\n- node_get_fsm_objsize_99\n- node_get_fsm_objsize_mean\n- node_get_fsm_objsize_median\n- node_get_fsm_siblings_100\n- node_get_fsm_siblings_95\n- node_get_fsm_siblings_99\n- node_get_fsm_siblings_mean\n- node_get_fsm_siblings_median\n- node_get_fsm_time_100\n- node_get_fsm_time_95\n- node_get_fsm_time_99\n- node_get_fsm_time_mean\n- node_get_fsm_time_median\n- node_gets\n- node_gets_total\n- node_put_fsm_time_100\n- node_put_fsm_time_95\n- node_put_fsm_time_99\n- node_put_fsm_time_mean\n- node_put_fsm_time_median\n- node_puts\n- node_puts_total\n- pbc_active\n- pbc_connects\n- pbc_connects_total\n- vnode_gets\n- vnode_gets_total\n- vnode_index_reads\n- vnode_index_reads_total\n- vnode_index_writes\n- vnode_index_writes_total\n- vnode_puts\n- vnode_puts_total\n- read_repairs\n- read_repairs_total\n\nMeasurements of time (such as node_get_fsm_time_mean) are measured in nanoseconds.\n\n### Tags:\n\nAll measurements have the following tags:\n\n- server (the host:port of the given server address, ex. `127.0.0.1:8087`)\n- nodename (the internal node name received, ex. `riak@127.0.0.1`)\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter riak --test\n> riak,nodename=riak@127.0.0.1,server=localhost:8098 cpu_avg1=31i,cpu_avg15=69i,cpu_avg5=51i,memory_code=11563738i,memory_ets=5925872i,memory_processes=30236069i,memory_system=93074971i,memory_total=123311040i,node_get_fsm_objsize_100=0i,node_get_fsm_objsize_95=0i,node_get_fsm_objsize_99=0i,node_get_fsm_objsize_mean=0i,node_get_fsm_objsize_median=0i,node_get_fsm_siblings_100=0i,node_get_fsm_siblings_95=0i,node_get_fsm_siblings_99=0i,node_get_fsm_siblings_mean=0i,node_get_fsm_siblings_median=0i,node_get_fsm_time_100=0i,node_get_fsm_time_95=0i,node_get_fsm_time_99=0i,node_get_fsm_time_mean=0i,node_get_fsm_time_median=0i,node_gets=0i,node_gets_total=19i,node_put_fsm_time_100=0i,node_put_fsm_time_95=0i,node_put_fsm_time_99=0i,node_put_fsm_time_mean=0i,node_put_fsm_time_median=0i,node_puts=0i,node_puts_total=0i,pbc_active=0i,pbc_connects=0i,pbc_connects_total=20i,vnode_gets=0i,vnode_gets_total=57i,vnode_index_reads=0i,vnode_index_reads_total=0i,vnode_index_writes=0i,vnode_index_writes_total=0i,vnode_puts=0i,vnode_puts_total=0i,read_repair=0i,read_repairs_total=0i 1455913392622482332\n```\n',image:Ha.a},{id:"riemann_listener",name:"Riemann Listener",markdown:'# Riemann Listener Input Plugin\n\nThe Riemann Listener is a simple input plugin that listens for messages from\nclient that use riemann clients using riemann-protobuff format.\n\n\n### Configuration:\n\nThis is a sample configuration for the plugin.\n\n```toml\n[[inputs.rimann_listener]]\n  ## URL to listen on\n  ## Default is "tcp://:5555"\n  #  service_address = "tcp://:8094"\n  #  service_address = "tcp://127.0.0.1:http"\n  #  service_address = "tcp4://:8094"\n  #  service_address = "tcp6://:8094"\n  #  service_address = "tcp6://[2001:db8::1]:8094"\n\n  ## Maximum number of concurrent connections.\n  ## 0 (default) is unlimited.\n  #  max_connections = 1024\n  ## Read timeout.\n  ## 0 (default) is unlimited.\n  #  read_timeout = "30s"\n  ## Optional TLS configuration.\n  #  tls_cert = "/etc/telegraf/cert.pem"\n  #  tls_key  = "/etc/telegraf/key.pem"\n  ## Enables client authentication if set.\n  #  tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n  ## Maximum socket buffer size (in bytes when no unit specified).\n  #  read_buffer_size = "64KiB"\n  ## Period between keep alive probes.\n  ## 0 disables keep alive probes.\n  ## Defaults to the OS configuration.\n  #  keep_alive_period = "5m"\n```\nJust like Riemann the default port is 5555. This can be configured, refer configuration above.\n\nRiemann `Service` is mapped as `measurement`. `metric` and `TTL` are converted into field values.\nAs Riemann tags as simply an array, they are converted into the `influx_line` format key-value, where both key and value are the tags.\n',image:Ga.a},{id:"salesforce",name:"Salesforce",markdown:'# Salesforce Input Plugin\n\nThe Salesforce plugin gathers metrics about the limits in your Salesforce organization and the remaining usage.\nIt fetches its data from the [limits endpoint](https://developer.salesforce.com/docs/atlas.en-us.api_rest.meta/api_rest/resources_limits.htm) of Salesforce\'s REST API.\n\n### Configuration:\n\n```toml\n# Gather Metrics about Salesforce limits and remaining usage\n[[inputs.salesforce]]\n  username = "your_username"\n  password = "your_password"\n  ## (Optional) security token\n  security_token = "your_security_token"\n  ## (Optional) environment type (sandbox or production)\n  ## default is: production\n  # environment = "production"\n  ## (Optional) API version (default: "39.0")\n  # version = "39.0"\n```\n\n### Measurements & Fields:\n\nSalesforce provide one measurement named "salesforce".\nEach entry is converted to snake\\_case and 2 fields are created.\n\n- \\<key\\>_max represents the limit threshold\n- \\<key\\>_remaining represents the usage remaining before hitting the limit threshold\n\n- salesforce\n    - \\<key\\>_max (int)\n    - \\<key\\>_remaining (int)\n    - (...)\n\n### Tags:\n\n- All measurements have the following tags:\n    - host\n    - organization_id (t18 char organisation ID)\n\n\n### Example Output:\n\n```\n$./telegraf --config telegraf.conf --input-filter salesforce --test\n\nsalesforce,organization_id=XXXXXXXXXXXXXXXXXX,host=xxxxx.salesforce.com daily_workflow_emails_max=546000i,hourly_time_based_workflow_max=50i,daily_async_apex_executions_remaining=250000i,daily_durable_streaming_api_events_remaining=1000000i,streaming_api_concurrent_clients_remaining=2000i,daily_bulk_api_requests_remaining=10000i,hourly_sync_report_runs_remaining=500i,daily_api_requests_max=5000000i,data_storage_mb_remaining=1073i,file_storage_mb_remaining=1069i,daily_generic_streaming_api_events_remaining=10000i,hourly_async_report_runs_remaining=1200i,hourly_time_based_workflow_remaining=50i,daily_streaming_api_events_remaining=1000000i,single_email_max=5000i,hourly_dashboard_refreshes_remaining=200i,streaming_api_concurrent_clients_max=2000i,daily_durable_generic_streaming_api_events_remaining=1000000i,daily_api_requests_remaining=4999998i,hourly_dashboard_results_max=5000i,hourly_async_report_runs_max=1200i,daily_durable_generic_streaming_api_events_max=1000000i,hourly_dashboard_results_remaining=5000i,concurrent_sync_report_runs_max=20i,durable_streaming_api_concurrent_clients_remaining=2000i,daily_workflow_emails_remaining=546000i,hourly_dashboard_refreshes_max=200i,daily_streaming_api_events_max=1000000i,hourly_sync_report_runs_max=500i,hourly_o_data_callout_max=10000i,mass_email_max=5000i,mass_email_remaining=5000i,single_email_remaining=5000i,hourly_dashboard_statuses_max=999999999i,concurrent_async_get_report_instances_max=200i,daily_durable_streaming_api_events_max=1000000i,daily_generic_streaming_api_events_max=10000i,hourly_o_data_callout_remaining=10000i,concurrent_sync_report_runs_remaining=20i,daily_bulk_api_requests_max=10000i,data_storage_mb_max=1073i,hourly_dashboard_statuses_remaining=999999999i,concurrent_async_get_report_instances_remaining=200i,daily_async_apex_executions_max=250000i,durable_streaming_api_concurrent_clients_max=2000i,file_storage_mb_max=1073i 1501565661000000000\n```\n',image:Ka.a},{id:"sensors",name:"LM Sensors",markdown:"# LM Sensors Input Plugin\n\nCollect [lm-sensors](https://en.wikipedia.org/wiki/Lm_sensors) metrics - requires the lm-sensors\npackage installed.\n\nThis plugin collects sensor metrics with the `sensors` executable from the lm-sensor package.\n\n### Configuration:\n```toml\n# Monitor sensors, requires lm-sensors package\n[[inputs.sensors]]\n  ## Remove numbers from field names.\n  ## If true, a field name like 'temp1_input' will be changed to 'temp_input'.\n  # remove_numbers = true\n\n  ## Timeout is the maximum amount of time that the sensors command can run.\n  # timeout = \"5s\"\n```\n\n### Measurements & Fields:\nFields are created dynamically depending on the sensors. All fields are float.\n\n### Tags:\n\n- All measurements have the following tags:\n    - chip\n    - feature\n\n### Example Output:\n\n#### Default\n```\n$ telegraf --config telegraf.conf --input-filter sensors --test\n* Plugin: sensors, Collection 1\n> sensors,chip=power_meter-acpi-0,feature=power1 power_average=0,power_average_interval=300 1466751326000000000\n> sensors,chip=k10temp-pci-00c3,feature=temp1 temp_crit=70,temp_crit_hyst=65,temp_input=29,temp_max=70 1466751326000000000\n> sensors,chip=k10temp-pci-00cb,feature=temp1 temp_input=29,temp_max=70 1466751326000000000\n> sensors,chip=k10temp-pci-00d3,feature=temp1 temp_input=27.5,temp_max=70 1466751326000000000\n> sensors,chip=k10temp-pci-00db,feature=temp1 temp_crit=70,temp_crit_hyst=65,temp_input=29.5,temp_max=70 1466751326000000000\n```\n\n#### With remove_numbers=false\n```\n* Plugin: sensors, Collection 1\n> sensors,chip=power_meter-acpi-0,feature=power1 power1_average=0,power1_average_interval=300 1466753424000000000\n> sensors,chip=k10temp-pci-00c3,feature=temp1 temp1_crit=70,temp1_crit_hyst=65,temp1_input=29.125,temp1_max=70 1466753424000000000\n> sensors,chip=k10temp-pci-00cb,feature=temp1 temp1_input=29,temp1_max=70 1466753424000000000\n> sensors,chip=k10temp-pci-00d3,feature=temp1 temp1_input=29.5,temp1_max=70 1466753424000000000\n> sensors,chip=k10temp-pci-00db,feature=temp1 temp1_crit=70,temp1_crit_hyst=65,temp1_input=30,temp1_max=70 1466753424000000000\n```\n",image:Xa.a},{id:"sflow",name:"SFlow",markdown:'# SFlow Input Plugin\n\nThe SFlow Input Plugin provides support for acting as an SFlow V5 collector in\naccordance with the specification from [sflow.org](https://sflow.org/).\n\nCurrently only Flow Samples of Ethernet / IPv4 & IPv4 TCP & UDP headers are\nturned into metrics.  Counters and other header samples are ignored.\n\n#### Series Cardinality Warning\n\nThis plugin may produce a high number of series which, when not controlled\nfor, will cause high load on your database. Use the following techniques to\navoid cardinality issues:\n\n- Use [metric filtering][] options to exclude unneeded measurements and tags.\n- Write to a database with an appropriate [retention policy][].\n- Consider using the [Time Series Index][tsi].\n- Monitor your databases [series cardinality][].\n- Consult the [InfluxDB documentation][influx-docs] for the most up-to-date techniques.\n\n### Configuration\n\n```toml\n[[inputs.sflow]]\n  ## Address to listen for sFlow packets.\n  ##   example: service_address = "udp://:6343"\n  ##            service_address = "udp4://:6343"\n  ##            service_address = "udp6://:6343"\n  service_address = "udp://:6343"\n\n  ## Set the size of the operating system\'s receive buffer.\n  ##   example: read_buffer_size = "64KiB"\n  # read_buffer_size = ""\n```\n\n### Metrics\n\n- sflow\n  - tags:\n    - agent_address (IP address of the agent that obtained the sflow sample and sent it to this collector)\n    - source_id_type(source_id_type field of flow_sample or flow_sample_expanded structures)\n    - source_id_index(source_id_index field of flow_sample or flow_sample_expanded structures)\n    - input_ifindex (value (input) field of flow_sample or flow_sample_expanded structures)\n    - output_ifindex (value (output) field of flow_sample or flow_sample_expanded structures)\n    - sample_direction (source_id_index, netif_index_in and netif_index_out)\n    - header_protocol (header_protocol field of sampled_header structures)\n    - ether_type (eth_type field of an ETHERNET-ISO88023 header)\n    - src_ip (source_ipaddr field of IPv4 or IPv6 structures)\n    - src_port (src_port field of TCP or UDP structures)\n    - src_port_name (src_port)\n    - src_mac (source_mac_addr field of an ETHERNET-ISO88023 header)\n    - src_vlan (src_vlan field of extended_switch structure)\n    - src_priority (src_priority field of extended_switch structure)\n    - src_mask_len (src_mask_len field of extended_router structure)\n    - dst_ip (destination_ipaddr field of IPv4 or IPv6 structures)\n    - dst_port (dst_port field of TCP or UDP structures)\n    - dst_port_name (dst_port)\n    - dst_mac (destination_mac_addr field of an ETHERNET-ISO88023 header)\n    - dst_vlan (dst_vlan field of extended_switch structure)\n    - dst_priority (dst_priority field of extended_switch structure)\n    - dst_mask_len (dst_mask_len field of extended_router structure)\n    - next_hop (next_hop field of extended_router structure)\n    - ip_version (ip_ver field of IPv4 or IPv6 structures)\n    - ip_protocol (ip_protocol field of IPv4 or IPv6 structures)\n    - ip_dscp (ip_dscp field of IPv4 or IPv6 structures)\n    - ip_ecn (ecn field of IPv4 or IPv6 structures)\n    - tcp_urgent_pointer (urgent_pointer field of TCP structure)\n  - fields:\n    - bytes (integer, the product of frame_length and packets)\n    - drops (integer, drops field of flow_sample or flow_sample_expanded structures)\n    - packets (integer, sampling_rate field of flow_sample or flow_sample_expanded structures)\n    - frame_length (integer, frame_length field of sampled_header structures)\n    - header_size (integer, header_size field of sampled_header structures)\n    - ip_fragment_offset (integer, ip_ver field of IPv4 structures)\n    - ip_header_length (integer, ip_ver field of IPv4 structures)\n    - ip_total_length (integer, ip_total_len field of IPv4 structures)\n    - ip_ttl (integer, ip_ttl field of IPv4 structures or ip_hop_limit field IPv6 structures)\n    - tcp_header_length (integer, size field of TCP structure. This value is specified in 32-bit words. It must be multiplied by 4 to produce a value in bytes.)\n    - tcp_window_size (integer, window_size field of TCP structure)\n    - udp_length (integer, length field of UDP structures)\n    - ip_flags (integer, ip_ver field of IPv4 structures)\n    - tcp_flags (integer, TCP flags of TCP IP header (IPv4 or IPv6))\n\n### Troubleshooting\n\nThe [sflowtool][] utility can be used to print sFlow packets, and compared\nagainst the metrics produced by Telegraf.\n```\nsflowtool -p 6343\n```\n\nIf opening an issue, in addition to the output of sflowtool it will also be\nhelpful to collect a packet capture.  Adjust the interface, host and port as\nneeded:\n```\n$ sudo tcpdump -s 0 -i eth0 -w telegraf-sflow.pcap host 127.0.0.1 and port 6343\n```\n\n[sflowtool]: https://github.com/sflow/sflowtool\n\n### Example Output\n```\nsflow,agent_address=0.0.0.0,dst_ip=10.0.0.2,dst_mac=ff:ff:ff:ff:ff:ff,dst_port=40042,ether_type=IPv4,header_protocol=ETHERNET-ISO88023,input_ifindex=6,ip_dscp=27,ip_ecn=0,output_ifindex=1073741823,source_id_index=3,source_id_type=0,src_ip=10.0.0.1,src_mac=ff:ff:ff:ff:ff:ff,src_port=443 bytes=1570i,drops=0i,frame_length=157i,header_length=128i,ip_flags=2i,ip_fragment_offset=0i,ip_total_length=139i,ip_ttl=42i,sampling_rate=10i,tcp_header_length=0i,tcp_urgent_pointer=0i,tcp_window_size=14i 1584473704793580447\n```\n\n### Reference Documentation\n\nThis sflow implementation was built from the reference document \n[sflow.org/sflow_version_5.txt](sflow_version_5)\n\n\n[metric filtering]: https://github.com/influxdata/telegraf/blob/master/docs/CONFIGURATION.md#metric-filtering\n[retention policy]: https://docs.influxdata.com/influxdb/latest/guides/downsampling_and_retention/\n[tsi]: https://docs.influxdata.com/influxdb/latest/concepts/time-series-index/\n[series cardinality]: https://docs.influxdata.com/influxdb/latest/query_language/spec/#show-cardinality\n[influx-docs]: https://docs.influxdata.com/influxdb/latest/\n[sflow_version_5]: https://sflow.org/sflow_version_5.txt\n',image:$a.a},{id:"smart",name:"S.M.A.R.T.",markdown:'# S.M.A.R.T. Input Plugin\n\nGet metrics using the command line utility `smartctl` for S.M.A.R.T. (Self-Monitoring, Analysis and Reporting Technology) storage devices. SMART is a monitoring system included in computer hard disk drives (HDDs) and solid-state drives (SSDs) that detects and reports on various indicators of drive reliability, with the intent of enabling the anticipation of hardware failures.\nSee smartmontools (https://www.smartmontools.org/).\n\nSMART information is separated between different measurements: `smart_device` is used for general information, while `smart_attribute` stores the detailed attribute information if `attributes = true` is enabled in the plugin configuration.\n\nIf no devices are specified, the plugin will scan for SMART devices via the following command:\n\n```\nsmartctl --scan\n```\n\nMetrics will be reported from the following `smartctl` command:\n\n```\nsmartctl --info --attributes --health -n <nocheck> --format=brief <device>\n```\n\nThis plugin supports _smartmontools_ version 5.41 and above, but v. 5.41 and v. 5.42\nmight require setting `nocheck`, see the comment in the sample configuration.\nAlso, NVMe capabilities were introduced in version 6.5.\n\nTo enable SMART on a storage device run:\n\n```\nsmartctl -s on <device>\n```\n## NVMe vendor specific attributes\n\nFor NVMe disk type, plugin can use command line utility `nvme-cli`. It has a feature \nto easy access a vendor specific attributes.\nThis plugin supports nmve-cli version 1.5 and above (https://github.com/linux-nvme/nvme-cli). \nIn case of `nvme-cli` absence NVMe vendor specific metrics will not be obtained.\n\nVendor specific SMART metrics for NVMe disks may be reported from the following `nvme` command:\n\n```\nnvme <vendor> smart-log-add <device>\n```\n\nNote that vendor plugins for `nvme-cli` could require different naming convention and report format.\n\nTo see installed plugin extensions, depended on the nvme-cli version, look at the bottom of:\n```\nnvme help\n```\n\nTo gather disk vendor id (vid) `id-ctrl` could be used:\n```\nnvme id-ctrl <device>\n```\nAssociation between a vid and company can be found there: https://pcisig.com/membership/member-companies.\n\nDevices affiliation to being NVMe or non NVMe will be determined thanks to:\n```\nsmartctl --scan\n```\nand:\n```\nsmartctl --scan -d nvme\n```\n\n## Configuration\n\n```toml\n# Read metrics from storage devices supporting S.M.A.R.T.\n[[inputs.smart]]\n    ## Optionally specify the path to the smartctl executable\n    # path_smartctl = "/usr/bin/smartctl"\n  \n    ## Optionally specify the path to the nvme-cli executable\n    # path_nvme = "/usr/bin/nvme"\n  \n    ## Optionally specify if vendor specific attributes should be propagated for NVMe disk case\n    ## ["auto-on"] - automatically find and enable additional vendor specific disk info\n    ## ["vendor1", "vendor2", ...] - e.g. "Intel" enable additional Intel specific disk info\n    # enable_extensions = ["auto-on"]\n  \n    ## On most platforms used cli utilities requires root access.\n    ## Setting \'use_sudo\' to true will make use of sudo to run smartctl or nvme-cli.\n    ## Sudo must be configured to allow the telegraf user to run smartctl or nvme-cli\n    ## without a password.\n    # use_sudo = false\n  \n    ## Skip checking disks in this power mode. Defaults to\n    ## "standby" to not wake up disks that have stopped rotating.\n    ## See --nocheck in the man pages for smartctl.\n    ## smartctl version 5.41 and 5.42 have faulty detection of\n    ## power mode and might require changing this value to\n    ## "never" depending on your disks.\n    # nocheck = "standby"\n  \n    ## Gather all returned S.M.A.R.T. attribute metrics and the detailed\n    ## information from each drive into the \'smart_attribute\' measurement.\n    # attributes = false\n  \n    ## Optionally specify devices to exclude from reporting if disks auto-discovery is performed.\n    # excludes = [ "/dev/pass6" ]\n  \n    ## Optionally specify devices and device type, if unset\n    ## a scan (smartctl --scan and smartctl --scan -d nvme) for S.M.A.R.T. devices will be done\n    ## and all found will be included except for the excluded in excludes.\n    # devices = [ "/dev/ada0 -d atacam", "/dev/nvme0"]\n  \n    ## Timeout for the cli command to complete.\n    # timeout = "30s"\n```\n\n## Permissions\n\nIt\'s important to note that this plugin references smartctl and nvme-cli, which may require additional permissions to execute successfully.\nDepending on the user/group permissions of the telegraf user executing this plugin, you may need to use sudo.\n\nYou will need the following in your telegraf config:\n```toml\n[[inputs.smart]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# For smartctl add the following lines:\nCmnd_Alias SMARTCTL = /usr/bin/smartctl\ntelegraf  ALL=(ALL) NOPASSWD: SMARTCTL\nDefaults!SMARTCTL !logfile, !syslog, !pam_session\n\n# For nvme-cli add the following lines:\nCmnd_Alias NVME = /path/to/nvme\ntelegraf  ALL=(ALL) NOPASSWD: NVME\nDefaults!NVME !logfile, !syslog, !pam_session\n```\nTo run smartctl or nvme with `sudo` wrapper script can be created. `path_smartctl` or\n`path_nvme` in the configuration should be set to execute this script.\n\n## Metrics\n\n- smart_device:\n  - tags:\n    - capacity\n    - device\n    - enabled\n    - model\n    - serial_no\n    - wwn\n  - fields:\n    - exit_status\n    - health_ok\n    - read_error_rate\n    - seek_error\n    - temp_c\n    - udma_crc_errors\n\n- smart_attribute:\n  - tags:\n    - capacity\n    - device\n    - enabled\n    - fail\n    - flags\n    - id\n    - model\n    - name\n    - serial_no\n    - wwn\n  - fields:\n    - exit_status\n    - raw_value\n    - threshold\n    - value\n    - worst\n\n#### Flags\n\nThe interpretation of the tag `flags` is:\n - `K` auto-keep\n - `C` event count\n - `R` error rate\n - `S` speed/performance\n - `O` updated online\n - `P` prefailure warning\n\n#### Exit Status\n\nThe `exit_status` field captures the exit status of the used cli utilities command which\nis defined by a bitmask. For the interpretation of the bitmask see the man page for\nsmartctl or nvme-cli.\n\n## Device Names\nDevice names, e.g., `/dev/sda`, are *not persistent*, and may be\nsubject to change across reboots or system changes. Instead, you can use the\n*World Wide Name* (WWN) or serial number to identify devices. On Linux block\ndevices can be referenced by the WWN in the following location:\n`/dev/disk/by-id/`.\n## Troubleshooting\nIf you expect to see more SMART metrics than this plugin shows, be sure to use a proper version\nof smartctl or nvme-cli utility which has the functionality to gather desired data. Also, check\nyour device capability because not every SMART metrics are mandatory. \nFor example the number of temperature sensors depends on the device specification.\n\nIf this plugin is not working as expected for your SMART enabled device,\nplease run these commands and include the output in a bug report:\n\nFor non NVMe devices (from smartctl version >= 7.0 this will also return NVMe devices by default):\n```\nsmartctl --scan\n```\nFor NVMe devices:\n```\nsmartctl --scan -d nvme\n```\nRun the following command replacing your configuration setting for NOCHECK and\nthe DEVICE (name of the device could be taken from the previous command):\n```\nsmartctl --info --health --attributes --tolerance=verypermissive --nocheck NOCHECK --format=brief -d DEVICE\n```\nIf you try to gather vendor specific metrics, please provide this commad\nand replace vendor and device to match your case:\n```\nnvme VENDOR smart-log-add DEVICE\n```\n## Example SMART Plugin Outputs\n```\nsmart_device,enabled=Enabled,host=mbpro.local,device=rdisk0,model=APPLE\\ SSD\\ SM0512F,serial_no=S1K5NYCD964433,wwn=5002538655584d30,capacity=500277790720 udma_crc_errors=0i,exit_status=0i,health_ok=true,read_error_rate=0i,temp_c=40i 1502536854000000000\nsmart_attribute,capacity=500277790720,device=rdisk0,enabled=Enabled,fail=-,flags=-O-RC-,host=mbpro.local,id=199,model=APPLE\\ SSD\\ SM0512F,name=UDMA_CRC_Error_Count,serial_no=S1K5NYCD964433,wwn=5002538655584d30 exit_status=0i,raw_value=0i,threshold=0i,value=200i,worst=200i 1502536854000000000\nsmart_attribute,capacity=500277790720,device=rdisk0,enabled=Enabled,fail=-,flags=-O---K,host=mbpro.local,id=199,model=APPLE\\ SSD\\ SM0512F,name=Unknown_SSD_Attribute,serial_no=S1K5NYCD964433,wwn=5002538655584d30 exit_status=0i,raw_value=0i,threshold=0i,value=100i,worst=100i 1502536854000000000\n```\n',image:Za.a},{id:"snmp",name:"SNMP",markdown:'# SNMP Input Plugin\n\nThe `snmp` input plugin uses polling to gather metrics from SNMP agents.\nSupport for gathering individual OIDs as well as complete SNMP tables is\nincluded.\n\n### Prerequisites\n\nThis plugin uses the `snmptable` and `snmptranslate` programs from the\n[net-snmp][] project.  These tools will need to be installed into the `PATH` in\norder to be located.  Other utilities from the net-snmp project may be useful\nfor troubleshooting, but are not directly used by the plugin.\n\nThese programs will load available MIBs on the system.  Typically the default\ndirectory for MIBs is `/usr/share/snmp/mibs`, but if your MIBs are in a\ndifferent location you may need to make the paths known to net-snmp.  The\nlocation of these files can be configured in the `snmp.conf` or via the\n`MIBDIRS` environment variable. See [`man 1 snmpcmd`][man snmpcmd] for more\ninformation.\n\n### Configuration\n```toml\n[[inputs.snmp]]\n  ## Agent addresses to retrieve values from.\n  ##   format:  agents = ["<scheme://><hostname>:<port>"]\n  ##   scheme:  optional, either udp, udp4, udp6, tcp, tcp4, tcp6.  \n  ##            default is udp\n  ##   port:    optional\n  ##   example: agents = ["udp://127.0.0.1:161"]\n  ##            agents = ["tcp://127.0.0.1:161"]\n  ##            agents = ["udp4://v4only-snmp-agent"]\n  agents = ["udp://127.0.0.1:161"]\n\n  ## Timeout for each request.\n  # timeout = "5s"\n\n  ## SNMP version; can be 1, 2, or 3.\n  # version = 2\n\n  ## SNMP community string.\n  # community = "public"\n\n  ## Agent host tag\n  # agent_host_tag = "agent_host"\n\n  ## Number of retries to attempt.\n  # retries = 3\n\n  ## The GETBULK max-repetitions parameter.\n  # max_repetitions = 10\n\n  ## SNMPv3 authentication and encryption options.\n  ##\n  ## Security Name.\n  # sec_name = "myuser"\n  ## Authentication protocol; one of "MD5", "SHA", "SHA224", "SHA256", "SHA384", "SHA512" or "".\n  # auth_protocol = "MD5"\n  ## Authentication password.\n  # auth_password = "pass"\n  ## Security Level; one of "noAuthNoPriv", "authNoPriv", or "authPriv".\n  # sec_level = "authNoPriv"\n  ## Context Name.\n  # context_name = ""\n  ## Privacy protocol used for encrypted messages; one of "DES", "AES", "AES192", "AES192C", "AES256", "AES256C", or "".\n  ### Protocols "AES192", "AES192", "AES256", and "AES256C" require the underlying net-snmp tools \n  ### to be compiled with --enable-blumenthal-aes (http://www.net-snmp.org/docs/INSTALL.html)\n  # priv_protocol = ""\n  ## Privacy password used for encrypted messages.\n  # priv_password = ""\n\n  ## Add fields and tables defining the variables you wish to collect.  This\n  ## example collects the system uptime and interface variables.  Reference the\n  ## full plugin documentation for configuration details.\n  [[inputs.snmp.field]]\n    oid = "RFC1213-MIB::sysUpTime.0"\n    name = "uptime"\n\n  [[inputs.snmp.field]]\n    oid = "RFC1213-MIB::sysName.0"\n    name = "source"\n    is_tag = true\n\n  [[inputs.snmp.table]]\n    oid = "IF-MIB::ifTable"\n    name = "interface"\n    inherit_tags = ["source"]\n\n    [[inputs.snmp.table.field]]\n      oid = "IF-MIB::ifDescr"\n      name = "ifDescr"\n      is_tag = true\n```\n\n#### Configure SNMP Requests\n\nThis plugin provides two methods for configuring the SNMP requests: `fields`\nand `tables`.  Use the `field` option to gather single ad-hoc variables.\nTo collect SNMP tables, use the `table` option.\n\n##### Field\n\nUse a `field` to collect a variable by OID.  Requests specified with this\noption operate similar to the `snmpget` utility.\n\n```toml\n[[inputs.snmp]]\n  # ... snip ...\n\n  [[inputs.snmp.field]]\n    ## Object identifier of the variable as a numeric or textual OID.\n    oid = "RFC1213-MIB::sysName.0"\n\n    ## Name of the field or tag to create.  If not specified, it defaults to\n    ## the value of \'oid\'. If \'oid\' is numeric, an attempt to translate the\n    ## numeric OID into a textual OID will be made.\n    # name = ""\n\n    ## If true the variable will be added as a tag, otherwise a field will be\n    ## created.\n    # is_tag = false\n\n    ## Apply one of the following conversions to the variable value:\n    ##   float(X):    Convert the input value into a float and divides by the\n    ##                Xth power of 10. Effectively just moves the decimal left\n    ##                X places. For example a value of `123` with `float(2)`\n    ##                will result in `1.23`.\n    ##   float:       Convert the value into a float with no adjustment. Same\n    ##                as `float(0)`.\n    ##   int:         Convert the value into an integer.\n    ##   hwaddr:      Convert the value to a MAC address.\n    ##   ipaddr:      Convert the value to an IP address.\n    ##   hextoint:X:Y Convert a hex string value to integer. Where X is the Endian\n    ##                and Y the bit size. For example: hextoint:LittleEndian:uint64\n    ##                or hextoint:BigEndian:uint32. Valid options for the Endian are:\n    ##                BigEndian and LittleEndian. For the bit size: uint16, uint32\n    ##                and uint64.\n    ##                      \n    # conversion = ""\n```\n\n##### Table\n\nUse a `table` to configure the collection of a SNMP table.  SNMP requests\nformed with this option operate similarly way to the `snmptable` command.\n\nControl the handling of specific table columns using a nested `field`.  These\nnested fields are specified similarly to a top-level `field`.\n\nBy default all columns of the SNMP table will be collected - it is not required\nto add a nested field for each column, only those which you wish to modify. To\n*only* collect certain columns, omit the `oid` from the `table` section and only\ninclude `oid` settings in `field` sections. For more complex include/exclude\ncases for columns use [metric filtering][].\n\nOne [metric][] is created for each row of the SNMP table.\n\n```toml\n[[inputs.snmp]]\n  # ... snip ...\n\n  [[inputs.snmp.table]]\n    ## Object identifier of the SNMP table as a numeric or textual OID.\n    oid = "IF-MIB::ifTable"\n\n    ## Name of the field or tag to create.  If not specified, it defaults to\n    ## the value of \'oid\'.  If \'oid\' is numeric an attempt to translate the\n    ## numeric OID into a textual OID will be made.\n    # name = ""\n\n    ## Which tags to inherit from the top-level config and to use in the output\n    ## of this table\'s measurement.\n    ## example: inherit_tags = ["source"]\n    # inherit_tags = []\n\n    ## Add an \'index\' tag with the table row number.  Use this if the table has\n    ## no indexes or if you are excluding them.  This option is normally not\n    ## required as any index columns are automatically added as tags.\n    # index_as_tag = false\n\n    [[inputs.snmp.table.field]]\n      ## OID to get. May be a numeric or textual module-qualified OID.\n      oid = "IF-MIB::ifDescr"\n\n      ## Name of the field or tag to create.  If not specified, it defaults to\n      ## the value of \'oid\'. If \'oid\' is numeric an attempt to translate the\n      ## numeric OID into a textual OID will be made.\n      # name = ""\n\n      ## Output this field as a tag.\n      # is_tag = false\n\n      ## The OID sub-identifier to strip off so that the index can be matched\n      ## against other fields in the table.\n      # oid_index_suffix = ""\n\n      ## Specifies the length of the index after the supplied table OID (in OID\n      ## path segments). Truncates the index after this point to remove non-fixed\n      ## value or length index suffixes.\n      # oid_index_length = 0\n\n      ## Specifies if the value of given field should be snmptranslated\n      ## by default no field values are translated\n      # translate = true\n```\n\n### Troubleshooting\n\nCheck that a numeric field can be translated to a textual field:\n```\n$ snmptranslate .1.3.6.1.2.1.1.3.0\nDISMAN-EVENT-MIB::sysUpTimeInstance\n```\n\nRequest a top-level field:\n```\n$ snmpget -v2c -c public 127.0.0.1 sysUpTime.0\n```\n\nRequest a table:\n```\n$ snmptable -v2c -c public 127.0.0.1 ifTable\n```\n\nTo collect a packet capture, run this command in the background while running\nTelegraf or one of the above commands.  Adjust the interface, host and port as\nneeded:\n```\n$ sudo tcpdump -s 0 -i eth0 -w telegraf-snmp.pcap host 127.0.0.1 and port 161\n```\n\n### Example Output\n\n```\nsnmp,agent_host=127.0.0.1,source=loaner uptime=11331974i 1575509815000000000\ninterface,agent_host=127.0.0.1,ifDescr=wlan0,ifIndex=3,source=example.org ifAdminStatus=1i,ifInDiscards=0i,ifInErrors=0i,ifInNUcastPkts=0i,ifInOctets=3436617431i,ifInUcastPkts=2717778i,ifInUnknownProtos=0i,ifLastChange=0i,ifMtu=1500i,ifOperStatus=1i,ifOutDiscards=0i,ifOutErrors=0i,ifOutNUcastPkts=0i,ifOutOctets=581368041i,ifOutQLen=0i,ifOutUcastPkts=1354338i,ifPhysAddress="c8:5b:76:c9:e6:8c",ifSpecific=".0.0",ifSpeed=0i,ifType=6i 1575509815000000000\ninterface,agent_host=127.0.0.1,ifDescr=eth0,ifIndex=2,source=example.org ifAdminStatus=1i,ifInDiscards=0i,ifInErrors=0i,ifInNUcastPkts=21i,ifInOctets=3852386380i,ifInUcastPkts=3634004i,ifInUnknownProtos=0i,ifLastChange=9088763i,ifMtu=1500i,ifOperStatus=1i,ifOutDiscards=0i,ifOutErrors=0i,ifOutNUcastPkts=0i,ifOutOctets=434865441i,ifOutQLen=0i,ifOutUcastPkts=2110394i,ifPhysAddress="c8:5b:76:c9:e6:8c",ifSpecific=".0.0",ifSpeed=1000000000i,ifType=6i 1575509815000000000\ninterface,agent_host=127.0.0.1,ifDescr=lo,ifIndex=1,source=example.org ifAdminStatus=1i,ifInDiscards=0i,ifInErrors=0i,ifInNUcastPkts=0i,ifInOctets=51555569i,ifInUcastPkts=339097i,ifInUnknownProtos=0i,ifLastChange=0i,ifMtu=65536i,ifOperStatus=1i,ifOutDiscards=0i,ifOutErrors=0i,ifOutNUcastPkts=0i,ifOutOctets=51555569i,ifOutQLen=0i,ifOutUcastPkts=339097i,ifSpecific=".0.0",ifSpeed=10000000i,ifType=24i 1575509815000000000\n```\n\n[net-snmp]: http://www.net-snmp.org/\n[man snmpcmd]: http://net-snmp.sourceforge.net/docs/man/snmpcmd.html#lbAK\n[metric filtering]: /docs/CONFIGURATION.md#metric-filtering\n[metric]: /docs/METRICS.md\n',image:ii.a},{id:"snmp_legacy",name:"SNMP Legacy",markdown:'# SNMP Legacy Input Plugin\n\nThe SNMP input plugin gathers metrics from SNMP agents\n\n### Configuration:\n\n\n#### Very simple example\n\nIn this example, the plugin will gather value of OIDS:\n\n - `.1.3.6.1.2.1.2.2.1.4.1`\n\n```toml\n# Very Simple Example\n[[inputs.snmp]]\n\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Simple list of OIDs to get, in addition to "collect"\n    get_oids = [".1.3.6.1.2.1.2.2.1.4.1"]\n```\n\n\n#### Simple example\n\nIn this example, Telegraf gathers value of OIDS:\n\n - named **ifnumber**\n - named **interface_speed**\n\nWith **inputs.snmp.get** section the plugin gets the oid number:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed*\n\nAs you can see *ifSpeed* is not a valid OID. In order to get\nthe valid OID, the plugin uses `snmptranslate_file` to match the OID:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed* => `.1.3.6.1.2.1.2.2.1.5`\n\nAlso as the plugin will append `instance` to the corresponding OID:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed* => `.1.3.6.1.2.1.2.2.1.5.1`\n\nIn this example, the plugin will gather value of OIDS:\n\n- `.1.3.6.1.2.1.2.1.0`\n- `.1.3.6.1.2.1.2.2.1.5.1`\n\n\n```toml\n# Simple example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which get/bulk do you want to collect for this host\n    collect = ["ifnumber", "interface_speed"]\n\n  [[inputs.snmp.get]]\n    name = "ifnumber"\n    oid = ".1.3.6.1.2.1.2.1.0"\n\n  [[inputs.snmp.get]]\n    name = "interface_speed"\n    oid = "ifSpeed"\n    instance = "1"\n\n```\n\n\n#### Simple bulk example\n\nIn this example, Telegraf gathers value of OIDS:\n\n - named **ifnumber**\n - named **interface_speed**\n - named **if_out_octets**\n\nWith **inputs.snmp.get** section the plugin gets oid number:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed*\n\nWith **inputs.snmp.bulk** section the plugin gets the oid number:\n\n - **if_out_octets** => *ifOutOctets*\n\nAs you can see *ifSpeed* and *ifOutOctets* are not a valid OID.\nIn order to get the valid OID, the plugin uses `snmptranslate_file`\nto match the OID:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed* => `.1.3.6.1.2.1.2.2.1.5`\n - **if_out_octets** => *ifOutOctets*  => `.1.3.6.1.2.1.2.2.1.16`\n\nAlso, the plugin will append `instance` to the corresponding OID:\n\n - **ifnumber** => `.1.3.6.1.2.1.2.1.0`\n - **interface_speed** => *ifSpeed* => `.1.3.6.1.2.1.2.2.1.5.1`\n\nAnd **if_out_octets** is a bulk request, the plugin will gathers all\nOIDS in the table.\n\n- `.1.3.6.1.2.1.2.2.1.16.1`\n- `.1.3.6.1.2.1.2.2.1.16.2`\n- `.1.3.6.1.2.1.2.2.1.16.3`\n- `.1.3.6.1.2.1.2.2.1.16.4`\n- `.1.3.6.1.2.1.2.2.1.16.5`\n- `...`\n\nIn this example, the plugin will gather value of OIDS:\n\n- `.1.3.6.1.2.1.2.1.0`\n- `.1.3.6.1.2.1.2.2.1.5.1`\n- `.1.3.6.1.2.1.2.2.1.16.1`\n- `.1.3.6.1.2.1.2.2.1.16.2`\n- `.1.3.6.1.2.1.2.2.1.16.3`\n- `.1.3.6.1.2.1.2.2.1.16.4`\n- `.1.3.6.1.2.1.2.2.1.16.5`\n- `...`\n\n\n```toml\n# Simple bulk example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which get/bulk do you want to collect for this host\n    collect = ["interface_speed", "if_number", "if_out_octets"]\n\n  [[inputs.snmp.get]]\n    name = "interface_speed"\n    oid = "ifSpeed"\n    instance = "1"\n\n  [[inputs.snmp.get]]\n    name = "if_number"\n    oid = "ifNumber"\n\n  [[inputs.snmp.bulk]]\n    name = "if_out_octets"\n    oid = "ifOutOctets"\n```\n\n\n#### Table example\n\nIn this example, we remove collect attribute to the host section,\nbut you can still use it in combination of the following part.\n\nNote: This example is like a bulk request a but using an\nother configuration\n\nTelegraf gathers value of OIDS of the table:\n\n - named **iftable1**\n\nWith **inputs.snmp.table** section the plugin gets oid number:\n\n - **iftable1** => `.1.3.6.1.2.1.31.1.1.1`\n\nAlso **iftable1** is a table, the plugin will gathers all\nOIDS in the table and in the subtables\n\n- `.1.3.6.1.2.1.31.1.1.1.1`\n- `.1.3.6.1.2.1.31.1.1.1.1.1`\n- `.1.3.6.1.2.1.31.1.1.1.1.2`\n- `.1.3.6.1.2.1.31.1.1.1.1.3`\n- `.1.3.6.1.2.1.31.1.1.1.1.4`\n- `.1.3.6.1.2.1.31.1.1.1.1....`\n- `.1.3.6.1.2.1.31.1.1.1.2`\n- `.1.3.6.1.2.1.31.1.1.1.2....`\n- `.1.3.6.1.2.1.31.1.1.1.3`\n- `.1.3.6.1.2.1.31.1.1.1.3....`\n- `.1.3.6.1.2.1.31.1.1.1.4`\n- `.1.3.6.1.2.1.31.1.1.1.4....`\n- `.1.3.6.1.2.1.31.1.1.1.5`\n- `.1.3.6.1.2.1.31.1.1.1.5....`\n- `.1.3.6.1.2.1.31.1.1.1.6....`\n- `...`\n\n```toml\n# Table example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which get/bulk do you want to collect for this host\n    # Which table do you want to collect\n    [[inputs.snmp.host.table]]\n      name = "iftable1"\n\n  # table without mapping neither subtables\n  # This is like bulk request\n  [[inputs.snmp.table]]\n    name = "iftable1"\n    oid = ".1.3.6.1.2.1.31.1.1.1"\n```\n\n\n#### Table with subtable example\n\nIn this example, we remove collect attribute to the host section,\nbut you can still use it in combination of the following part.\n\nNote: This example is like a bulk request a but using an\nother configuration\n\nTelegraf gathers value of OIDS of the table:\n\n - named **iftable2**\n\nWith **inputs.snmp.table** section *AND* **sub_tables** attribute,\nthe plugin will get OIDS from subtables:\n\n - **iftable2** => `.1.3.6.1.2.1.2.2.1.13`\n\nAlso **iftable2** is a table, the plugin will gathers all\nOIDS in subtables:\n\n- `.1.3.6.1.2.1.2.2.1.13.1`\n- `.1.3.6.1.2.1.2.2.1.13.2`\n- `.1.3.6.1.2.1.2.2.1.13.3`\n- `.1.3.6.1.2.1.2.2.1.13.4`\n- `.1.3.6.1.2.1.2.2.1.13....`\n\n\n```toml\n# Table with subtable example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which table do you want to collect\n    [[inputs.snmp.host.table]]\n      name = "iftable2"\n\n  # table without mapping but with subtables\n  [[inputs.snmp.table]]\n    name = "iftable2"\n    sub_tables = [".1.3.6.1.2.1.2.2.1.13"]\n    # note\n    # oid attribute is useless\n```\n\n\n#### Table with mapping example\n\nIn this example, we remove collect attribute to the host section,\nbut you can still use it in combination of the following part.\n\nTelegraf gathers value of OIDS of the table:\n\n - named **iftable3**\n\nWith **inputs.snmp.table** section the plugin gets oid number:\n\n - **iftable3** => `.1.3.6.1.2.1.31.1.1.1`\n\nAlso **iftable2** is a table, the plugin will gathers all\nOIDS in the table and in the subtables\n\n- `.1.3.6.1.2.1.31.1.1.1.1`\n- `.1.3.6.1.2.1.31.1.1.1.1.1`\n- `.1.3.6.1.2.1.31.1.1.1.1.2`\n- `.1.3.6.1.2.1.31.1.1.1.1.3`\n- `.1.3.6.1.2.1.31.1.1.1.1.4`\n- `.1.3.6.1.2.1.31.1.1.1.1....`\n- `.1.3.6.1.2.1.31.1.1.1.2`\n- `.1.3.6.1.2.1.31.1.1.1.2....`\n- `.1.3.6.1.2.1.31.1.1.1.3`\n- `.1.3.6.1.2.1.31.1.1.1.3....`\n- `.1.3.6.1.2.1.31.1.1.1.4`\n- `.1.3.6.1.2.1.31.1.1.1.4....`\n- `.1.3.6.1.2.1.31.1.1.1.5`\n- `.1.3.6.1.2.1.31.1.1.1.5....`\n- `.1.3.6.1.2.1.31.1.1.1.6....`\n- `...`\n\nBut the **include_instances** attribute will filter which OIDS\nwill be gathered; As you see, there is an other attribute, `mapping_table`.\n`include_instances` and `mapping_table` permit to build a hash table\nto filter only OIDS you want.\nLet\'s say, we have the following data on SNMP server:\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.1` has as value: `enp5s0`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.2` has as value: `enp5s1`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.3` has as value: `enp5s2`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.4` has as value: `eth0`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.5` has as value: `eth1`\n\nThe plugin will build the following hash table:\n\n| instance name | instance id |\n|---------------|-------------|\n| `enp5s0`      | `1`         |\n| `enp5s1`      | `2`         |\n| `enp5s2`      | `3`         |\n| `eth0`        | `4`         |\n| `eth1`        | `5`         |\n\nWith the **include_instances** attribute, the plugin will gather\nthe following OIDS:\n\n- `.1.3.6.1.2.1.31.1.1.1.1.1`\n- `.1.3.6.1.2.1.31.1.1.1.1.5`\n- `.1.3.6.1.2.1.31.1.1.1.2.1`\n- `.1.3.6.1.2.1.31.1.1.1.2.5`\n- `.1.3.6.1.2.1.31.1.1.1.3.1`\n- `.1.3.6.1.2.1.31.1.1.1.3.5`\n- `.1.3.6.1.2.1.31.1.1.1.4.1`\n- `.1.3.6.1.2.1.31.1.1.1.4.5`\n- `.1.3.6.1.2.1.31.1.1.1.5.1`\n- `.1.3.6.1.2.1.31.1.1.1.5.5`\n- `.1.3.6.1.2.1.31.1.1.1.6.1`\n- `.1.3.6.1.2.1.31.1.1.1.6.5`\n- `...`\n\nNote: the plugin will add instance name as tag *instance*\n\n```toml\n# Simple table with mapping example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which table do you want to collect\n    [[inputs.snmp.host.table]]\n      name = "iftable3"\n      include_instances = ["enp5s0", "eth1"]\n\n  # table with mapping but without subtables\n  [[inputs.snmp.table]]\n    name = "iftable3"\n    oid = ".1.3.6.1.2.1.31.1.1.1"\n    # if empty. get all instances\n    mapping_table = ".1.3.6.1.2.1.31.1.1.1.1"\n    # if empty, get all subtables\n```\n\n\n#### Table with both mapping and subtable example\n\nIn this example, we remove collect attribute to the host section,\nbut you can still use it in combination of the following part.\n\nTelegraf gathers value of OIDS of the table:\n\n - named **iftable4**\n\nWith **inputs.snmp.table** section *AND* **sub_tables** attribute,\nthe plugin will get OIDS from subtables:\n\n - **iftable4** => `.1.3.6.1.2.1.31.1.1.1`\n\nAlso **iftable2** is a table, the plugin will gathers all\nOIDS in the table and in the subtables\n\n- `.1.3.6.1.2.1.31.1.1.1.6.1\n- `.1.3.6.1.2.1.31.1.1.1.6.2`\n- `.1.3.6.1.2.1.31.1.1.1.6.3`\n- `.1.3.6.1.2.1.31.1.1.1.6.4`\n- `.1.3.6.1.2.1.31.1.1.1.6....`\n- `.1.3.6.1.2.1.31.1.1.1.10.1`\n- `.1.3.6.1.2.1.31.1.1.1.10.2`\n- `.1.3.6.1.2.1.31.1.1.1.10.3`\n- `.1.3.6.1.2.1.31.1.1.1.10.4`\n- `.1.3.6.1.2.1.31.1.1.1.10....`\n\nBut the **include_instances** attribute will filter which OIDS\nwill be gathered; As you see, there is an other attribute, `mapping_table`.\n`include_instances` and `mapping_table` permit to build a hash table\nto filter only OIDS you want.\nLet\'s say, we have the following data on SNMP server:\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.1` has as value: `enp5s0`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.2` has as value: `enp5s1`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.3` has as value: `enp5s2`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.4` has as value: `eth0`\n - OID: `.1.3.6.1.2.1.31.1.1.1.1.5` has as value: `eth1`\n\nThe plugin will build the following hash table:\n\n| instance name | instance id |\n|---------------|-------------|\n| `enp5s0`      | `1`         |\n| `enp5s1`      | `2`         |\n| `enp5s2`      | `3`         |\n| `eth0`        | `4`         |\n| `eth1`        | `5`         |\n\nWith the **include_instances** attribute, the plugin will gather\nthe following OIDS:\n\n- `.1.3.6.1.2.1.31.1.1.1.6.1`\n- `.1.3.6.1.2.1.31.1.1.1.6.5`\n- `.1.3.6.1.2.1.31.1.1.1.10.1`\n- `.1.3.6.1.2.1.31.1.1.1.10.5`\n\nNote: the plugin will add instance name as tag *instance*\n\n\n\n```toml\n# Table with both mapping and subtable example\n[[inputs.snmp]]\n  ## Use \'oids.txt\' file to translate oids to names\n  ## To generate \'oids.txt\' you need to run:\n  ##   snmptranslate -m all -Tz -On | sed -e \'s/"//g\' > /tmp/oids.txt\n  ## Or if you have an other MIB folder with custom MIBs\n  ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e \'s/"//g\' > oids.txt\n  snmptranslate_file = "/tmp/oids.txt"\n  [[inputs.snmp.host]]\n    address = "127.0.0.1:161"\n    # SNMP community\n    community = "public" # default public\n    # SNMP version (1, 2 or 3)\n    # Version 3 not supported yet\n    version = 2 # default 2\n    # Which table do you want to collect\n    [[inputs.snmp.host.table]]\n      name = "iftable4"\n      include_instances = ["enp5s0", "eth1"]\n\n  # table with both mapping and subtables\n  [[inputs.snmp.table]]\n    name = "iftable4"\n    # if empty get all instances\n    mapping_table = ".1.3.6.1.2.1.31.1.1.1.1"\n    # if empty get all subtables\n    # sub_tables could be not "real subtables"  \n    sub_tables=[".1.3.6.1.2.1.2.2.1.13", "bytes_recv", "bytes_send"]\n    # note\n    # oid attribute is useless\n\n  # SNMP SUBTABLES\n  [[inputs.snmp.subtable]]\n    name = "bytes_recv"\n    oid = ".1.3.6.1.2.1.31.1.1.1.6"\n    unit = "octets"\n\n  [[inputs.snmp.subtable]]\n    name = "bytes_send"\n    oid = ".1.3.6.1.2.1.31.1.1.1.10"\n    unit = "octets"\n```\n\n#### Configuration notes\n\n- In **inputs.snmp.table** section, the `oid` attribute is useless if\n  the `sub_tables` attributes is defined\n\n- In **inputs.snmp.subtable** section, you can put a name from `snmptranslate_file`\n  as `oid` attribute instead of a valid OID\n\n### Measurements & Fields:\n\nWith the last example (Table with both mapping and subtable example):\n\n- ifHCOutOctets\n    - ifHCOutOctets\n- ifInDiscards\n    - ifInDiscards\n- ifHCInOctets\n    - ifHCInOctets\n\n### Tags:\n\nWith the last example (Table with both mapping and subtable example):\n\n- ifHCOutOctets\n    - host\n    - instance\n    - unit\n- ifInDiscards\n    - host\n    - instance\n- ifHCInOctets\n    - host\n    - instance\n    - unit\n\n### Example Output:\n\nWith the last example (Table with both mapping and subtable example):\n\n```\nifHCOutOctets,host=127.0.0.1,instance=enp5s0,unit=octets ifHCOutOctets=10565628i 1456878706044462901\nifInDiscards,host=127.0.0.1,instance=enp5s0 ifInDiscards=0i 1456878706044510264\nifHCInOctets,host=127.0.0.1,instance=enp5s0,unit=octets ifHCInOctets=76351777i 1456878706044531312\n```\n',image:ti.a},{id:"snmp_trap",name:"SNMP Trap",markdown:'# SNMP Trap Input Plugin\n\nThe SNMP Trap plugin is a service input plugin that receives SNMP\nnotifications (traps and inform requests).\n\nNotifications are received on plain UDP. The port to listen is\nconfigurable.\n\n### Prerequisites\n\nThis plugin uses the `snmptranslate` programs from the\n[net-snmp][] project.  These tools will need to be installed into the `PATH` in\norder to be located.  Other utilities from the net-snmp project may be useful\nfor troubleshooting, but are not directly used by the plugin.\n\nThese programs will load available MIBs on the system.  Typically the default\ndirectory for MIBs is `/usr/share/snmp/mibs`, but if your MIBs are in a\ndifferent location you may need to make the paths known to net-snmp.  The\nlocation of these files can be configured in the `snmp.conf` or via the\n`MIBDIRS` environment variable. See [`man 1 snmpcmd`][man snmpcmd] for more\ninformation.\n\n### Configuration\n```toml\n[[inputs.snmp_trap]]\n  ## Transport, local address, and port to listen on.  Transport must\n  ## be "udp://".  Omit local address to listen on all interfaces.\n  ##   example: "udp://127.0.0.1:1234"\n  ##\n  ## Special permissions may be required to listen on a port less than\n  ## 1024.  See README.md for details\n  ##\n  # service_address = "udp://:162"\n  ##\n  ## Path to mib files\n  # path = ["/usr/share/snmp/mibs"]\n  ##\n  ## Timeout running snmptranslate command\n  # timeout = "5s"\n  ## Snmp version\n  # version = "2c"\n  ## SNMPv3 authentication and encryption options.\n  ##\n  ## Security Name.\n  # sec_name = "myuser"\n  ## Authentication protocol; one of "MD5", "SHA" or "".\n  # auth_protocol = "MD5"\n  ## Authentication password.\n  # auth_password = "pass"\n  ## Security Level; one of "noAuthNoPriv", "authNoPriv", or "authPriv".\n  # sec_level = "authNoPriv"\n  ## Privacy protocol used for encrypted messages; one of "DES", "AES", "AES192", "AES192C", "AES256", "AES256C" or "".\n  # priv_protocol = ""\n  ## Privacy password used for encrypted messages.\n  # priv_password = ""\n```\n\n#### Using a Privileged Port\n\nOn many operating systems, listening on a privileged port (a port\nnumber less than 1024) requires extra permission.  Since the default\nSNMP trap port 162 is in this category, using telegraf to receive SNMP\ntraps may need extra permission.\n\nInstructions for listening on a privileged port vary by operating\nsystem. It is not recommended to run telegraf as superuser in order to\nuse a privileged port. Instead follow the principle of least privilege\nand use a more specific operating system mechanism to allow telegraf to\nuse the port.  You may also be able to have telegraf use an\nunprivileged port and then configure a firewall port forward rule from\nthe privileged port.\n\nTo use a privileged port on Linux, you can use setcap to enable the\nCAP_NET_BIND_SERVICE capability on the telegraf binary:\n\n```\nsetcap cap_net_bind_service=+ep /usr/bin/telegraf\n```\n\nOn Mac OS, listening on privileged ports is unrestricted on versions\n10.14 and later.\n\n### Metrics\n\n- snmp_trap\n  - tags:\n\t- source (string, IP address of trap source)\n\t- name (string, value from SNMPv2-MIB::snmpTrapOID.0 PDU)\n\t- mib (string, MIB from SNMPv2-MIB::snmpTrapOID.0 PDU)\n\t- oid (string, OID string from SNMPv2-MIB::snmpTrapOID.0 PDU)\n\t- version (string, "1" or "2c" or "3")\n\t- context_name (string, value from v3 trap)\n\t- engine_id (string, value from v3 trap)\n\t- community (string, value from 1 or 2c trap)\n  - fields:\n\t- Fields are mapped from variables in the trap. Field names are\n      the trap variable names after MIB lookup. Field values are trap\n      variable values.\n\n### Example Output\n```\nsnmp_trap,mib=SNMPv2-MIB,name=coldStart,oid=.1.3.6.1.6.3.1.1.5.1,source=192.168.122.102,version=2c,community=public snmpTrapEnterprise.0="linux",sysUpTimeInstance=1i 1574109187723429814\nsnmp_trap,mib=NET-SNMP-AGENT-MIB,name=nsNotifyShutdown,oid=.1.3.6.1.4.1.8072.4.0.2,source=192.168.122.102,version=2c,community=public sysUpTimeInstance=5803i,snmpTrapEnterprise.0="netSnmpNotificationPrefix" 1574109186555115459\n```\n\n[net-snmp]: http://www.net-snmp.org/\n[man snmpcmd]: http://net-snmp.sourceforge.net/docs/man/snmpcmd.html#lbAK\n',image:si.a},{id:"socket_listener",name:"Socket Listener",markdown:'# Socket Listener Input Plugin\n\nThe Socket Listener is a service input plugin that listens for messages from\nstreaming (tcp, unix) or datagram (udp, unixgram) protocols.\n\nThe plugin expects messages in the\n[Telegraf Input Data Formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).\n\n### Configuration:\n\nThis is a sample configuration for the plugin.\n\n```toml\n# Generic socket listener capable of handling multiple socket types.\n[[inputs.socket_listener]]\n  ## URL to listen on\n  # service_address = "tcp://:8094"\n  # service_address = "tcp://127.0.0.1:http"\n  # service_address = "tcp4://:8094"\n  # service_address = "tcp6://:8094"\n  # service_address = "tcp6://[2001:db8::1]:8094"\n  # service_address = "udp://:8094"\n  # service_address = "udp4://:8094"\n  # service_address = "udp6://:8094"\n  # service_address = "unix:///tmp/telegraf.sock"\n  # service_address = "unixgram:///tmp/telegraf.sock"\n\n  ## Change the file mode bits on unix sockets.  These permissions may not be\n  ## respected by some platforms, to safely restrict write permissions it is best\n  ## to place the socket into a directory that has previously been created\n  ## with the desired permissions.\n  ##   ex: socket_mode = "777"\n  # socket_mode = ""\n\n  ## Maximum number of concurrent connections.\n  ## Only applies to stream sockets (e.g. TCP).\n  ## 0 (default) is unlimited.\n  # max_connections = 1024\n\n  ## Read timeout.\n  ## Only applies to stream sockets (e.g. TCP).\n  ## 0 (default) is unlimited.\n  # read_timeout = "30s"\n\n  ## Optional TLS configuration.\n  ## Only applies to stream sockets (e.g. TCP).\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key  = "/etc/telegraf/key.pem"\n  ## Enables client authentication if set.\n  # tls_allowed_cacerts = ["/etc/telegraf/clientca.pem"]\n\n  ## Maximum socket buffer size (in bytes when no unit specified).\n  ## For stream sockets, once the buffer fills up, the sender will start backing up.\n  ## For datagram sockets, once the buffer fills up, metrics will start dropping.\n  ## Defaults to the OS default.\n  # read_buffer_size = "64KiB"\n\n  ## Period between keep alive probes.\n  ## Only applies to TCP sockets.\n  ## 0 disables keep alive probes.\n  ## Defaults to the OS configuration.\n  # keep_alive_period = "5m"\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  # data_format = "influx"\n\n  ## Content encoding for message payloads, can be set to "gzip" to or\n  ## "identity" to apply no encoding.\n  # content_encoding = "identity"\n```\n\n## A Note on UDP OS Buffer Sizes\n\nThe `read_buffer_size` config option can be used to adjust the size of the socket\nbuffer, but this number is limited by OS settings. On Linux, `read_buffer_size`\nwill default to `rmem_default` and will be capped by `rmem_max`. On BSD systems,\n`read_buffer_size` is capped by `maxsockbuf`, and there is no OS default\nsetting.\n\nInstructions on how to adjust these OS settings are available below.\n\nSome OSes (most notably, Linux) place very restrictive limits on the performance\nof UDP protocols. It is _highly_ recommended that you increase these OS limits to\nat least 8MB before trying to run large amounts of UDP traffic to your instance.\n8MB is just a recommendation, and can be adjusted higher.\n\n### Linux\n\nCheck the current UDP/IP receive buffer limit & default by typing the following\ncommands:\n\n```\nsysctl net.core.rmem_max\nsysctl net.core.rmem_default\n```\n\nIf the values are less than 8388608 bytes you should add the following lines to\nthe /etc/sysctl.conf file:\n\n```\nnet.core.rmem_max=8388608\nnet.core.rmem_default=8388608\n```\n\nChanges to /etc/sysctl.conf do not take effect until reboot.\nTo update the values immediately, type the following commands as root:\n\n```\nsysctl -w net.core.rmem_max=8388608\nsysctl -w net.core.rmem_default=8388608\n```\n\n### BSD/Darwin\n\nOn BSD/Darwin systems you need to add about a 15% padding to the kernel limit\nsocket buffer. Meaning if you want an 8MB buffer (8388608 bytes) you need to set\nthe kernel limit to `8388608*1.15 = 9646900`. This is not documented anywhere but\nhappens\n[in the kernel here.](https://github.com/freebsd/freebsd/blob/master/sys/kern/uipc_sockbuf.c#L63-L64)\n\nCheck the current UDP/IP buffer limit by typing the following command:\n\n```\nsysctl kern.ipc.maxsockbuf\n```\n\nIf the value is less than 9646900 bytes you should add the following lines\nto the /etc/sysctl.conf file (create it if necessary):\n\n```\nkern.ipc.maxsockbuf=9646900\n```\n\nChanges to /etc/sysctl.conf do not take effect until reboot.\nTo update the values immediately, type the following command as root:\n\n```\nsysctl -w kern.ipc.maxsockbuf=9646900\n```\n',image:ri.a},{id:"solr",name:"Solr",markdown:'# Solr Input Plugin\n\nThe [solr](http://lucene.apache.org/solr/) plugin collects stats via the\n[MBean Request Handler](https://cwiki.apache.org/confluence/display/solr/MBean+Request+Handler)\n\nMore about [performance statistics](https://cwiki.apache.org/confluence/display/solr/Performance+Statistics+Reference)\n\nTested from 3.5 to 7.*\n\n### Configuration:\n\n```toml\n[[inputs.solr]]\n  ## specify a list of one or more Solr servers\n  servers = ["http://localhost:8983"]\n  ##\n  ## specify a list of one or more Solr cores (default - all)\n  # cores = ["main"]\n  ##\n  ## Optional HTTP Basic Auth Credentials\n  # username = "username"\n  # password = "pa$$word"\n```\n\n### Example output of gathered metrics:\n\n```\n➜  ~ telegraf -config telegraf.conf -input-filter solr -test\n* Plugin: solr, Collection 1\n> solr_core,core=main,handler=searcher,host=testhost deleted_docs=17616645i,max_docs=261848363i,num_docs=244231718i 1478214949000000000\n> solr_core,core=main,handler=core,host=testhost deleted_docs=0i,max_docs=0i,num_docs=0i 1478214949000000000\n> solr_queryhandler,core=main,handler=/replication,host=testhost 15min_rate_reqs_per_second=0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000444659081257,5min_rate_reqs_per_second=0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000014821969375,75th_pc_request_time=16.484211,95th_pc_request_time=16.484211,999th_pc_request_time=16.484211,99th_pc_request_time=16.484211,avg_requests_per_second=0.0000008443809966322143,avg_time_per_request=12.984811,errors=0i,handler_start=1474662050865i,median_request_time=11.352427,requests=3i,timeouts=0i,total_time=38.954433 1478214949000000000\n> solr_queryhandler,core=main,handler=/update/extract,host=testhost 15min_rate_reqs_per_second=0,5min_rate_reqs_per_second=0,75th_pc_request_time=0,95th_pc_request_time=0,999th_pc_request_time=0,99th_pc_request_time=0,avg_requests_per_second=0,avg_time_per_request=0,errors=0i,handler_start=0i,median_request_time=0,requests=0i,timeouts=0i,total_time=0 1478214949000000000\n> solr_queryhandler,core=main,handler=org.apache.solr.handler.component.SearchHandler,host=testhost 15min_rate_reqs_per_second=0,5min_rate_reqs_per_second=0,75th_pc_request_time=0,95th_pc_request_time=0,999th_pc_request_time=0,99th_pc_request_time=0,avg_requests_per_second=0,avg_time_per_request=0,errors=0i,handler_start=1474662050861i,median_request_time=0,requests=0i,timeouts=0i,total_time=0 1478214949000000000\n> solr_queryhandler,core=main,handler=/tvrh,host=testhost 15min_rate_reqs_per_second=0,5min_rate_reqs_per_second=0,75th_pc_request_time=0,95th_pc_request_time=0,999th_pc_request_time=0,99th_pc_request_time=0,avg_requests_per_second=0,avg_time_per_request=0,errors=0i,handler_start=0i,median_request_time=0,requests=0i,timeouts=0i,total_time=0 1478214949000000000\n[…]\n```\n',image:_i.a},{id:"sql",name:"SQL",markdown:'# SQL Input Plugin\n\nThis plugin reads metrics from performing SQL queries against a SQL server. Different server\ntypes are supported and their settings might differ (especially the connection parameters).\nPlease check the list of [supported SQL drivers](https://github.com/influxdata/telegraf/blob/master/docs/SQL_DRIVERS_INPUT.md) for the\n`driver` name and options for the data-source-name (`dsn`) options.\n\n### Configuration\n\nThis section contains the default TOML to configure the plugin.  You can\ngenerate it using `telegraf --usage <plugin-name>`.\n\n```toml\n[[inputs.sql]]\n  ## Database Driver\n  ## See https://github.com/influxdata/telegraf/blob/master/docs/SQL_DRIVERS_INPUT.md for\n  ## a list of supported drivers.\n  driver = "mysql"\n\n  ## Data source name for connecting\n  ## The syntax and supported options depends on selected driver.\n  dsn = "username:password@mysqlserver:3307/dbname?param=value"\n\n  ## Timeout for any operation\n  # timeout = "5s"\n\n  ## Connection time limits\n  ## By default the maximum idle time and maximum lifetime of a connection is unlimited, i.e. the connections\n  ## will not be closed automatically. If you specify a positive time, the connections will be closed after\n  ## idleing or existing for at least that amount of time, respectively.\n  # connection_max_idle_time = "0s"\n  # connection_max_life_time = "0s"\n\n  ## Connection count limits\n  ## By default the number of open connections is not limited and the number of maximum idle connections\n  ## will be inferred from the number of queries specified. If you specify a positive number for any of the\n  ## two options, connections will be closed when reaching the specified limit. The number of idle connections\n  ## will be clipped to the maximum number of connections limit if any.\n  # connection_max_open = 0\n  # connection_max_idle = auto\n\n  [[inputs.sql.query]]\n    ## Query to perform on the server\n    query="SELECT user,state,latency,score FROM Scoreboard WHERE application > 0"\n    ## Alternatively to specifying the query directly you can select a file here containing the SQL query.\n    ## Only one of \'query\' and \'query_script\' can be specified!\n    # query_script = "/path/to/sql/script.sql"\n\n    ## Name of the measurement\n    ## In case both measurement and \'measurement_col\' are given, the latter takes precedence.\n    # measurement = "sql"\n\n    ## Column name containing the name of the measurement\n    ## If given, this will take precedence over the \'measurement\' setting. In case a query result\n    ## does not contain the specified column, we fall-back to the \'measurement\' setting.\n    # measurement_column = ""\n\n    ## Column name containing the time of the measurement\n    ## If ommited, the time of the query will be used.\n    # time_column = ""\n\n    ## Format of the time contained in \'time_col\'\n    ## The time must be \'unix\', \'unix_ms\', \'unix_us\', \'unix_ns\', or a golang time format.\n    ## See https://golang.org/pkg/time/#Time.Format for details.\n    # time_format = "unix"\n\n    ## Column names containing tags\n    ## An empty include list will reject all columns and an empty exclude list will not exclude any column.\n    ## I.e. by default no columns will be returned as tag and the tags are empty.\n    # tag_columns_include = []\n    # tag_columns_exclude = []\n\n    ## Column names containing fields (explicit types)\n    ## Convert the given columns to the corresponding type. Explicit type conversions take precedence over\n\t\t## the automatic (driver-based) conversion below.\n\t\t## NOTE: Columns should not be specified for multiple types or the resulting type is undefined.\n    # field_columns_float = []\n    # field_columns_int = []\n\t\t# field_columns_uint = []\n\t\t# field_columns_bool = []\n\t\t# field_columns_string = []\n\n    ## Column names containing fields (automatic types)\n    ## An empty include list is equivalent to \'[*]\' and all returned columns will be accepted. An empty\n    ## exclude list will not exclude any column. I.e. by default all columns will be returned as fields.\n    ## NOTE: We rely on the database driver to perform automatic datatype conversion.\n    # field_columns_include = []\n    # field_columns_exclude = []\n```\n\n### Options\n#### Driver\nThe `driver` and `dsn` options specify how to connect to the database. As especially the `dsn` format and\nvalues vary with the `driver` refer to the list of [supported SQL drivers](https://github.com/influxdata/telegraf/blob/master/docs/SQL_DRIVERS_INPUT.md) for possible values and more details.\n\n#### Connection limits\nWith these options you can limit the number of connections kept open by this plugin. Details about the exact\nworkings can be found in the [golang sql documentation](https://golang.org/pkg/database/sql/#DB.SetConnMaxIdleTime).\n\n#### Query sections\nMultiple `query` sections can be specified for this plugin. Each specified query will first be prepared on the server\nand then executed in every interval using the column mappings specified. Please note that `tag` and `field` columns\nare not exclusive, i.e. a column can be added to both. When using both `include` and `exclude` lists, the `exclude`\nlist takes precedence over the `include` list. I.e. given you specify `foo` in both lists, `foo` will _never_ pass\nthe filter. In case any the columns specified in `measurement_col` or `time_col` are _not_ returned by the query,\nthe plugin falls-back to the documented defaults. Fields or tags specified in the includes of the options but missing\nin the returned query are silently ignored.\n\n### Types\nThis plugin relies on the driver to do the type conversion. For the different properties of the metric the following\ntypes are accepted.\n\n#### Measurement\nOnly columns of type `string`  are accepted.\n\n#### Time\nFor the metric time columns of type `time` are accepted directly. For numeric columns, `time_format` should be set\nto any of `unix`, `unix_ms`, `unix_ns` or `unix_us` accordingly. By default the a timestamp in `unix` format is\nexpected. For string columns, please specify the `time_format` accordingly.\nSee the [golang time documentation](https://golang.org/pkg/time/#Time.Format) for details.\n\n#### Tags\nFor tags columns with textual values (`string` and `bytes`), signed and unsigned integers (8, 16, 32 and 64 bit),\nfloating-point (32 and 64 bit), `boolean` and `time` values are accepted. Those values will be converted to string.\n\n#### Fields\nFor fields columns with textual values (`string` and `bytes`), signed and unsigned integers (8, 16, 32 and 64 bit),\nfloating-point (32 and 64 bit), `boolean` and `time` values are accepted. Here `bytes` will be converted to `string`,\nsigned and unsigned integer values will be converted to `int64` or `uint64` respectively. Floating-point values are converted to `float64` and `time` is converted to a nanosecond timestamp of type `int64`.\n\n### Example Output\nUsing the [MariaDB sample database](https://www.mariadbtutorial.com/getting-started/mariadb-sample-database) and the\nconfiguration\n```toml\n[[inputs.sql]]\n  driver = "mysql"\n  dsn = "root:password@/nation"\n\n  [[inputs.sql.query]]\n    query="SELECT * FROM guests"\n    measurement = "nation"\n    tag_cols_include = ["name"]\n    field_cols_exclude = ["name"]\n```\n\nTelegraf will output the following metrics\n```\nnation,host=Hugin,name=John guest_id=1i 1611332164000000000\nnation,host=Hugin,name=Jane guest_id=2i 1611332164000000000\nnation,host=Hugin,name=Jean guest_id=3i 1611332164000000000\nnation,host=Hugin,name=Storm guest_id=4i 1611332164000000000\nnation,host=Hugin,name=Beast guest_id=5i 1611332164000000000\n```\n',image:ui.a},{id:"sqlserver",name:"SQL Server",markdown:'# SQL Server Input Plugin\nThe `sqlserver` plugin provides metrics for your SQL Server instance. Recorded metrics are\nlightweight and use Dynamic Management Views supplied by SQL Server.\n\n### The SQL Server plugin supports the following editions/versions of SQL Server\n- SQL Server\n  - 2012 or newer (Plugin support aligned with the [official Microsoft SQL Server support](https://docs.microsoft.com/en-us/sql/sql-server/end-of-support/sql-server-end-of-life-overview?view=sql-server-ver15#lifecycle-dates))\n  - End-of-life SQL Server versions are not guaranteed to be supported by Telegraf. Any issues with the SQL Server plugin for these EOL versions will \n  need to be addressed by the community. \n- Azure SQL Database (Single)\n- Azure SQL Managed Instance\n\n### Additional Setup:\n\nYou have to create a login on every SQL Server instance  or Azure SQL Managed instance you want to monitor, with following script:\n```sql\nUSE master;\nGO\nCREATE LOGIN [telegraf] WITH PASSWORD = N\'mystrongpassword\';\nGO\nGRANT VIEW SERVER STATE TO [telegraf];\nGO\nGRANT VIEW ANY DEFINITION TO [telegraf];\nGO\n```\n\nFor Azure SQL Database, you require the View Database State permission and can create a user with a password directly in the database.\n```sql\nCREATE USER [telegraf] WITH PASSWORD = N\'mystrongpassword\';\nGO\nGRANT VIEW DATABASE STATE TO [telegraf];\nGO\n```\n\n### Configuration:\n\n```toml\n[agent]\n  ## Default data collection interval for all inputs, can be changed as per collection interval needs\n  interval = "10s"\n\n# Read metrics from Microsoft SQL Server\n[[inputs.sqlserver]]\n  ## Specify instances to monitor with a list of connection strings.\n  ## All connection parameters are optional.\n  ## By default, the host is localhost, listening on default port, TCP 1433.\n  ##   for Windows, the user is the currently running AD user (SSO).\n  ##   See https://github.com/denisenkom/go-mssqldb for detailed connection\n  ##   parameters, in particular, tls connections can be created like so:\n  ##   "encrypt=true;certificate=<cert>;hostNameInCertificate=<SqlServer host fqdn>"\n  servers = [\n    "Server=192.168.1.10;Port=1433;User Id=<user>;Password=<pw>;app name=telegraf;log=1;",\n  ]\n\n  ## "database_type" enables a specific set of queries depending on the database type. If specified, it replaces azuredb = true/false and query_version = 2\n  ## In the config file, the sql server plugin section should be repeated each with a set of servers for a specific database_type.\n  ## Possible values for database_type are - "AzureSQLDB" or "AzureSQLManagedInstance" or "SQLServer"\n\n  ## Queries enabled by default for database_type = "AzureSQLDB" are - \n  ## AzureSQLDBResourceStats, AzureSQLDBResourceGovernance, AzureSQLDBWaitStats, AzureSQLDBDatabaseIO, AzureSQLDBServerProperties, \n  ## AzureSQLDBOsWaitstats, AzureSQLDBMemoryClerks, AzureSQLDBPerformanceCounters, AzureSQLDBRequests, AzureSQLDBSchedulers\n\n  # database_type = "AzureSQLDB"\n\n  ## A list of queries to include. If not specified, all the above listed queries are used.\n  # include_query = []\n\n  ## A list of queries to explicitly ignore.\n  # exclude_query = []\n\n  ## Queries enabled by default for database_type = "AzureSQLManagedInstance" are - \n  ## AzureSQLMIResourceStats, AzureSQLMIResourceGovernance, AzureSQLMIDatabaseIO, AzureSQLMIServerProperties, AzureSQLMIOsWaitstats, \n  ## AzureSQLMIMemoryClerks, AzureSQLMIPerformanceCounters, AzureSQLMIRequests, AzureSQLMISchedulers\n\n  # database_type = "AzureSQLManagedInstance"\n\n  # include_query = []\n\n  # exclude_query = []\n\n  ## Queries enabled by default for database_type = "SQLServer" are - \n  ## SQLServerPerformanceCounters, SQLServerWaitStatsCategorized, SQLServerDatabaseIO, SQLServerProperties, SQLServerMemoryClerks, \n  ## SQLServerSchedulers, SQLServerRequests, SQLServerVolumeSpace, SQLServerCpu\n\n  database_type = "SQLServer"\n\n  include_query = []\n\n  ## SQLServerAvailabilityReplicaStates and SQLServerDatabaseReplicaStates are optional queries and hence excluded here as default\n  exclude_query = ["SQLServerAvailabilityReplicaStates", "SQLServerDatabaseReplicaStates"]\n\n  ## Following are old config settings, you may use them only if you are using the earlier flavor of queries, however it is recommended to use \n  ## the new mechanism of identifying the database_type there by use it\'s corresponding queries\n\n  ## Optional parameter, setting this to 2 will use a new version\n  ## of the collection queries that break compatibility with the original\n  ## dashboards.\n  ## Version 2 - is compatible from SQL Server 2012 and later versions and also for SQL Azure DB\n  # query_version = 2\n\n  ## If you are using AzureDB, setting this to true will gather resource utilization metrics\n  # azuredb = false\n\n  ## Toggling this to true will emit an additional metric called "sqlserver_telegraf_health". \n  ## This metric tracks the count of attempted queries and successful queries for each SQL instance specified in "servers". \n  ## The purpose of this metric is to assist with identifying and diagnosing any connectivity or query issues. \n  ## This setting/metric is optional and is disabled by default.\n  # health_metric = false\n\n  ## Possible queries accross different versions of the collectors\n  ## Queries enabled by default for specific Database Type\n  \n  ## database_type =  AzureSQLDB  by default collects the following queries\n  ## - AzureSQLDBWaitStats\n  ## - AzureSQLDBResourceStats \n  ## - AzureSQLDBResourceGovernance\n  ## - AzureSQLDBDatabaseIO\n  ## - AzureSQLDBServerProperties\n  ## - AzureSQLDBOsWaitstats\n  ## - AzureSQLDBMemoryClerks\n  ## - AzureSQLDBPerformanceCounters\n  ## - AzureSQLDBRequests\n  ## - AzureSQLDBSchedulers\n\n   ## database_type =  AzureSQLManagedInstance by default collects the following queries\n   ## - AzureSQLMIResourceStats \n   ## - AzureSQLMIResourceGovernance \n   ## - AzureSQLMIDatabaseIO \n   ## - AzureSQLMIServerProperties \n   ## - AzureSQLMIOsWaitstats \n   ## - AzureSQLMIMemoryClerks\n   ## - AzureSQLMIPerformanceCounters\n   ## - AzureSQLMIRequests\n   ## - AzureSQLMISchedulers\n\n   ## database_type =  SQLServer by default collects the following queries\n   ## - SQLServerPerformanceCounters \n   ## - SQLServerWaitStatsCategorized \n   ## - SQLServerDatabaseIO \n   ## - SQLServerProperties \n   ## - SQLServerMemoryClerks \n   ## - SQLServerSchedulers\n   ## - SQLServerRequests\n   ## - SQLServerVolumeSpace\n   ## - SQLServerCpu\n   ## and following as optional (if mentioned in the include_query list)\n   ## - SQLServerAvailabilityReplicaStates\n   ## - SQLServerDatabaseReplicaStates\n\n  ## Version 2 by default collects the following queries\n  ## Version 2 is being deprecated, please consider using database_type.\n  ## - PerformanceCounters\n  ## - WaitStatsCategorized\n  ## - DatabaseIO\n  ## - ServerProperties\n  ## - MemoryClerk\n  ## - Schedulers\n  ## - SqlRequests\n  ## - VolumeSpace\n  ## - Cpu\n\n  ## Version 1 by default collects the following queries\n  ## Version 1 is deprecated, please consider using database_type.\n  ## - PerformanceCounters\n  ## - WaitStatsCategorized\n  ## - CPUHistory\n  ## - DatabaseIO\n  ## - DatabaseSize\n  ## - DatabaseStats\n  ## - DatabaseProperties\n  ## - MemoryClerk\n  ## - VolumeSpace\n  ## - PerformanceMetrics\n\n```\n\n### Support for Azure Active Directory (AAD) authentication using [Managed Identity](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview)\n\nAzure SQL Database supports 2 main methods of authentication: [SQL authentication and AAD authentication](https://docs.microsoft.com/en-us/azure/azure-sql/database/security-overview#authentication). The recommended practice is to [use AAD authentication when possible](https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-overview).\n\nAAD is a more modern authentication protocol, allows for easier credential/role management, and can eliminate the need to include passwords in a connection string.\n\nTo enable support for AAD authentication, we leverage the existing AAD authentication support in the [SQL Server driver for Go](https://github.com/denisenkom/go-mssqldb#azure-active-directory-authentication---preview)\n\n#### How to use AAD Auth with MSI\n\n- Configure "system-assigned managed identity" for Azure resources on the Monitoring VM (the VM that\'d connect to the SQL server/database) [using the Azure portal](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/qs-configure-portal-windows-vm).\n- On the database being monitored, create/update a USER with the name of the Monitoring VM as the principal using the below script. This might require allow-listing the client machine\'s IP address (from where the below SQL script is being run) on the SQL Server resource.\n```sql\nEXECUTE (\'IF EXISTS(SELECT * FROM sys.database_principals WHERE name = \'\'<Monitoring_VM_Name>\'\')\n    BEGIN\n        DROP USER [<Monitoring_VM_Name>]\n    END\')\nEXECUTE (\'CREATE USER [<Monitoring_VM_Name>] FROM EXTERNAL PROVIDER\')\nEXECUTE (\'GRANT VIEW DATABASE STATE TO [<Monitoring_VM_Name>]\')\n```\n- On the SQL Server resource of the database(s) being monitored, go to "Firewalls and Virtual Networks" tab and allowlist the monitoring VM IP address.\n- On the Monitoring VM, update the telegraf config file with the database connection string in the following format. Please note AAD based auth is currently only supported for Azure SQL Database and Azure SQL Managed Instance (but not for SQL Server), as described [here](https://docs.microsoft.com/en-us/azure/azure-sql/database/security-overview#authentication).\n- On the Monitoring VM, update the telegraf config file with the database connection string in the following format.\n- On the Monitoring VM, update the telegraf config file with the database connection string in the following format. The connection string only provides the server and database name, but no password (since the VM\'s system-assigned managed identity would be used for authentication).\n```toml\n  servers = [\n    "Server=<Azure_SQL_Server_Name>.database.windows.net;Port=1433;Database=<Azure_SQL_Database_Name>;app name=telegraf;log=1;",\n  ]\n```\n- Please note AAD based auth is currently only supported for Azure SQL Database and Azure SQL Managed Instance (but not for SQL Server), as described [here](https://docs.microsoft.com/en-us/azure/azure-sql/database/security-overview#authentication).\n\n### Metrics:\nTo provide backwards compatibility, this plugin support two versions of metrics queries.\n\n**Note**: Version 2 queries are not backwards compatible with the old queries. Any dashboards or queries based on the old query format will not work with the new format. The version 2 queries only report raw metrics, no math has been done to calculate deltas. To graph this data you must calculate deltas in your dashboarding software.\n\n#### Version 1 (query_version=1): This is Deprecated in 1.6, all future development will be under configuration option database_type.\nThe original metrics queries provide:\n- *Performance counters*: 1000+ metrics from `sys.dm_os_performance_counters`\n- *Performance metrics*: special performance and ratio metrics\n- *Wait stats*: wait tasks categorized from `sys.dm_os_wait_stats`\n- *Memory clerk*: memory breakdown from `sys.dm_os_memory_clerks`\n- *Database size*: databases size trend from `sys.dm_io_virtual_file_stats`\n- *Database IO*: databases I/O from `sys.dm_io_virtual_file_stats`\n- *Database latency*: databases latency from `sys.dm_io_virtual_file_stats`\n- *Database properties*: databases properties, state and recovery model, from `sys.databases`\n- *OS Volume*: available, used and total space from `sys.dm_os_volume_stats`\n- *CPU*: cpu usage from `sys.dm_os_ring_buffers`\n\nIf you are using the original queries all stats have the following tags:\n- `servername`:  hostname:instance\n- `type`: type of stats to easily filter measurements\n\n#### Version 2 (query_version=2): Being deprecated, All future development will be under configuration option database_type.\nThe new (version 2) metrics provide:\n- *Database IO*: IO stats from `sys.dm_io_virtual_file_stats`\n- *Memory Clerk*: Memory clerk breakdown from `sys.dm_os_memory_clerks`, most clerks have been given a friendly name.\n- *Performance Counters*: A select list of performance counters from `sys.dm_os_performance_counters`. Some of the important metrics included:\n  - *Activity*: Transactions/sec/database, Batch requests/sec, blocked processes, + more\n  - *Availability Groups*: Bytes sent to replica, Bytes received from replica, Log bytes received, Log send queue, transaction delay, + more\n  - *Log activity*: Log bytes flushed/sec, Log flushes/sec, Log Flush Wait Time\n  - *Memory*: PLE, Page reads/sec, Page writes/sec, + more\n  - *TempDB*: Free space, Version store usage, Active temp tables, temp table creation rate, + more\n  - *Resource Governor*: CPU Usage, Requests/sec, Queued Requests, and Blocked tasks per workload group + more\n- *Server properties*: Number of databases in all possible states (online, offline, suspect, etc.), cpu count, physical memory, SQL Server service uptime, and SQL Server version. In the case of Azure SQL relevant properties such as Tier, #Vcores, Memory etc.\n- *Wait stats*: Wait time in ms, number of waiting tasks, resource wait time, signal wait time, max wait time in ms, wait type, and wait category. The waits are categorized using the same categories used in Query Store.\n- *Schedulers* - This captures `sys.dm_os_schedulers`.\n- *SqlRequests* - This captures a snapshot of `sys.dm_exec_requests` and `sys.dm_exec_sessions` that gives you running requests as well as wait types and\n  blocking sessions.\n- *VolumeSpace* - uses `sys.dm_os_volume_stats` to get total, used and occupied space on every disk that contains a data or log file. (Note that even if enabled it won\'t get any data from Azure SQL Database or SQL Managed Instance). It is pointless to run this with high frequency (ie: every 10s), but it won\'t cause any problem.\n- *Cpu* - uses the buffer ring (`sys.dm_os_ring_buffers`) to get CPU data, the table is updated once per minute. (Note that even if enabled it won\'t get any data from Azure SQL Database or SQL Managed Instance).\n\n  In order to allow tracking on a per statement basis this query produces a\n  unique tag for each query.  Depending on the database workload, this may\n  result in a high cardinality series.  Reference the FAQ for tips on\n  [managing series cardinality][cardinality].\n\n- *Azure Managed Instances*\n  - Stats from `sys.server_resource_stats`\n  - Resource governance stats from `sys.dm_instance_resource_governance`\n- *Azure SQL Database* in addition to other stats\n  - Stats from `sys.dm_db_wait_stats`\n  - Resource governance stats from `sys.dm_user_db_resource_governance`\n  - Stats from `sys.dm_db_resource_stats`\n  \n\n\n#### database_type = "AzureSQLDB \nThese are metrics for Azure SQL Database (single database) and are very similar to version 2 but split out for maintenance reasons, better ability to test,differences in DMVs:\n- AzureSQLDBDatabaseIO: IO stats from `sys.dm_io_virtual_file_stats` including resource governance time, RBPEX, IO for Hyperscale.\n- AzureSQLDBMemoryClerks: Memory clerk breakdown from `sys.dm_os_memory_clerks`.\n= AzureSQLDBResourceGovernance: Relevant properties indicatign resource limits from `sys.dm_user_db_resource_governance`\n- AzureSQLDBPerformanceCounters: A select list of performance counters from `sys.dm_os_performance_counters` including cloud specific counters for SQL Hyperscale.\n- AzureSQLDBServerProperties: Relevant Azure SQL relevant properties from  such as Tier, #Vcores, Memory etc, storage, etc.\n- AzureSQLDBWaitstats: Wait time in ms from `sys.dm_db_wait_stats`, number of waiting tasks, resource wait time, signal wait time, max wait time in ms, wait type, and wait category. The waits are categorized using the same categories used in Query Store. These waits are collected only as of the end of the a statement. and for a specific database only.\n- *AzureSQLOsWaitstats*: Wait time in ms from `sys.dm_os_wait_stats`, number of waiting tasks, resource wait time, signal wait time, max wait time in ms, wait type, and wait category. The waits are categorized using the same categories used in Query Store. These waits are collected as they occur and instance wide\n- *AzureSQLDBRequests: Requests which are blocked or have a wait type from `sys.dm_exec_sessions` and `sys.dm_exec_requests`\n- *AzureSQLDBSchedulers* - This captures `sys.dm_os_schedulers` snapshots.\n\n\n#### database_type = "AzureSQLManagedInstance \nThese are metrics for Azure SQL Managed instance, are very similar to version 2 but split out for maintenance reasons, better ability to test, differences in DMVs:\n- AzureSQLMIDatabaseIO: IO stats from `sys.dm_io_virtual_file_stats` including resource governance time, RBPEX, IO for Hyperscale.\n- AzureSQLMIMemoryClerks: Memory clerk breakdown from `sys.dm_os_memory_clerks`.\n- AzureSQLMIResourceGovernance: Relevant properties indicatign resource limits from `sys.dm_instance_resource_governance`\n- AzureSQLMIPerformanceCounters: A select list of performance counters from `sys.dm_os_performance_counters` including cloud specific counters for SQL Hyperscale.\n- AzureSQLMIServerProperties: Relevant Azure SQL relevant properties such as Tier, #Vcores, Memory etc, storage, etc.\n- AzureSQLMIOsWaitstats: Wait time in ms from `sys.dm_os_wait_stats`, number of waiting tasks, resource wait time, signal wait time, max wait time in ms, wait type, and wait category. The waits are categorized using the same categories used in Query Store. These waits are collected as they occur and instance wide\n- AzureSQLMIRequests: Requests which are blocked or have a wait type from `sys.dm_exec_sessions` and `sys.dm_exec_requests`\n- AzureSQLMISchedulers - This captures `sys.dm_os_schedulers` snapshots.\n\n#### database_type = "SQLServer \n- SQLServerDatabaseIO: IO stats from `sys.dm_io_virtual_file_stats`\n- SQLServerMemoryClerks: Memory clerk breakdown from `sys.dm_os_memory_clerks`, most clerks have been given a friendly name.\n- SQLServerPerformanceCounters: A select list of performance counters from `sys.dm_os_performance_counters`. Some of the important metrics included:\n  - *Activity*: Transactions/sec/database, Batch requests/sec, blocked processes, + more\n  - *Availability Groups*: Bytes sent to replica, Bytes received from replica, Log bytes received, Log send queue, transaction delay, + more\n  - *Log activity*: Log bytes flushed/sec, Log flushes/sec, Log Flush Wait Time\n  - *Memory*: PLE, Page reads/sec, Page writes/sec, + more\n  - *TempDB*: Free space, Version store usage, Active temp tables, temp table creation rate, + more\n  - *Resource Governor*: CPU Usage, Requests/sec, Queued Requests, and Blocked tasks per workload group + more\n- SQLServerProperties: Number of databases in all possible states (online, offline, suspect, etc.), cpu count, physical memory, SQL Server service uptime, and SQL Server version. In the case of Azure SQL relevant properties such as Tier, #Vcores, Memory etc.\n- SQLServerWaitStatsCategorized: Wait time in ms, number of waiting tasks, resource wait time, signal wait time, max wait time in ms, wait type, and wait category. The waits are categorized using the same categories used in Query Store.\n- SQLServerSchedulers - This captures `sys.dm_os_schedulers`.\n- SQLServerRequests - This captures a snapshot of `sys.dm_exec_requests` and `sys.dm_exec_sessions` that gives you running requests as well as wait types and\n  blocking sessions.\n- SQLServerVolumeSpace - uses `sys.dm_os_volume_stats` to get total, used and occupied space on every disk that contains a data or log file. (Note that even if enabled it won\'t get any data from Azure SQL Database or SQL Managed Instance). It is pointless to run this with high frequency (ie: every 10s), but it won\'t cause any problem.\n- SQLServerCpu - uses the buffer ring (`sys.dm_os_ring_buffers`) to get CPU data, the table is updated once per minute. (Note that even if enabled it won\'t get any data from Azure SQL Database or SQL Managed Instance).\n- SQLServerAvailabilityReplicaStates: Collects availability replica state information from `sys.dm_hadr_availability_replica_states` for a High Availability / Disaster Recovery (HADR) setup\n- SQLServerDatabaseReplicaStates: Collects database replica state information from `sys.dm_hadr_database_replica_states` for a High Availability / Disaster Recovery (HADR) setup\n\n\n#### Output Measures\nThe guiding principal is that all data collected from the same primary DMV ends up in the same measure irrespective of database_type.\n`sqlserver_database_io` - Used by  AzureSQLDBDatabaseIO, AzureSQLMIDatabaseIO, SQLServerDatabaseIO, DatabaseIO given the data is from `sys.dm_io_virtual_file_stats`\n`sqlserver_waitstats` - Used by  WaitStatsCategorized,AzureSQLDBOsWaitstats,AzureSQLMIOsWaitstats\n`sqlserver_server_properties` - Used by  SQLServerProperties, AzureSQLDBServerProperties , AzureSQLMIServerProperties,ServerProperties\n`sqlserver_memory_clerks` - Used by SQLServerMemoryClerks, AzureSQLDBMemoryClerks, AzureSQLMIMemoryClerks,MemoryClerk\n`sqlserver_performance` - Used by  SQLServerPerformanceCounters, AzureSQLDBPerformanceCounters, AzureSQLMIPerformanceCounters,PerformanceCounters\n`sys.dm_os_schedulers`  - Used by SQLServerSchedulers,AzureSQLDBServerSchedulers, AzureSQLMIServerSchedulers\n\n\n\nThe following Performance counter metrics can be used directly, with no delta calculations:\n - SQLServer:Buffer Manager\\Buffer cache hit ratio\n - SQLServer:Buffer Manager\\Page life expectancy\n - SQLServer:Buffer Node\\Page life expectancy\n - SQLServer:Database Replica\\Log Apply Pending Queue\n - SQLServer:Database Replica\\Log Apply Ready Queue\n - SQLServer:Database Replica\\Log Send Queue\n - SQLServer:Database Replica\\Recovery Queue\n - SQLServer:Databases\\Data File(s) Size (KB)\n - SQLServer:Databases\\Log File(s) Size (KB)\n - SQLServer:Databases\\Log File(s) Used Size (KB)\n - SQLServer:Databases\\XTP Memory Used (KB)\n - SQLServer:General Statistics\\Active Temp Tables\n - SQLServer:General Statistics\\Processes blocked\n - SQLServer:General Statistics\\Temp Tables For Destruction\n - SQLServer:General Statistics\\User Connections\n - SQLServer:Memory Broker Clerks\\Memory broker clerk size\n - SQLServer:Memory Manager\\Memory Grants Pending\n - SQLServer:Memory Manager\\Target Server Memory (KB)\n - SQLServer:Memory Manager\\Total Server Memory (KB)\n - SQLServer:Resource Pool Stats\\Active memory grant amount (KB)\n - SQLServer:Resource Pool Stats\\Disk Read Bytes/sec\n - SQLServer:Resource Pool Stats\\Disk Read IO Throttled/sec\n - SQLServer:Resource Pool Stats\\Disk Read IO/sec\n - SQLServer:Resource Pool Stats\\Disk Write Bytes/sec\n - SQLServer:Resource Pool Stats\\Disk Write IO Throttled/sec\n - SQLServer:Resource Pool Stats\\Disk Write IO/sec\n - SQLServer:Resource Pool Stats\\Used memory (KB)\n - SQLServer:Transactions\\Free Space in tempdb (KB)\n - SQLServer:Transactions\\Version Store Size (KB)\n - SQLServer:User Settable\\Query\n - SQLServer:Workload Group Stats\\Blocked tasks\n - SQLServer:Workload Group Stats\\CPU usage %\n - SQLServer:Workload Group Stats\\Queued requests\n - SQLServer:Workload Group Stats\\Requests completed/sec\n\nVersion 2 queries have the following tags:\n- `sql_instance`: Physical host and instance name (hostname:instance)\n- `database_name`:  For Azure SQLDB, database_name denotes the name of the Azure SQL Database as server name is a logical construct.\n\n#### Health Metric\nAll collection versions (version 1, version 2, and database_type) support an optional plugin health metric called `sqlserver_telegraf_health`. This metric tracks if connections to SQL Server are succeeding or failing. Users can leverage this metric to detect if their SQL Server monitoring is not working as intended.\n\nIn the configuration file, toggling `health_metric` to `true` will enable collection of this metric. By default, this value is set to `false` and the metric is not collected. The health metric emits one record for each connection specified by `servers` in the configuration file.\n\nThe health metric emits the following tags:\n- `sql_instance` - Name of the server specified in the connection string. This value is emitted as-is in the connection string. If the server could not be parsed from the connection string, a constant placeholder value is emitted\n- `database_name` -  Name of the database or (initial catalog) specified in the connection string. This value is emitted as-is in the connection string. If the database could not be parsed from the connection string, a constant placeholder value is emitted\n\nThe health metric emits the following fields:\n- `attempted_queries` - Number of queries that were attempted for this connection\n- `successful_queries` - Number of queries that completed successfully for this connection\n- `database_type` - Type of database as specified by `database_type`. If `database_type` is empty, the `QueryVersion` and `AzureDB` fields are concatenated instead\n\nIf `attempted_queries` and `successful_queries` are not equal for a given connection, some metrics were not successfully gathered for that connection. If `successful_queries` is 0, no metrics were successfully gathered.\n\n[cardinality]: /docs/FAQ.md#user-content-q-how-can-i-manage-series-cardinality\n',image:mi.a},{id:"stackdriver",name:"Stackdriver Google Cloud Monitoring",markdown:'# Stackdriver Google Cloud Monitoring Input Plugin\n\nQuery data from Google Cloud Monitoring (formerly Stackdriver) using the\n[Cloud Monitoring API v3][stackdriver].\n\nThis plugin accesses APIs which are [chargeable][pricing]; you might incur\ncosts.\n\n### Configuration\n\n```toml\n[[inputs.stackdriver]]\n  ## GCP Project\n  project = "erudite-bloom-151019"\n\n  ## Include timeseries that start with the given metric type.\n  metric_type_prefix_include = [\n    "compute.googleapis.com/",\n  ]\n\n  ## Exclude timeseries that start with the given metric type.\n  # metric_type_prefix_exclude = []\n\n  ## Most metrics are updated no more than once per minute; it is recommended\n  ## to override the agent level interval with a value of 1m or greater.\n  interval = "1m"\n\n  ## Maximum number of API calls to make per second.  The quota for accounts\n  ## varies, it can be viewed on the API dashboard:\n  ##   https://cloud.google.com/monitoring/quotas#quotas_and_limits\n  # rate_limit = 14\n\n  ## The delay and window options control the number of points selected on\n  ## each gather.  When set, metrics are gathered between:\n  ##   start: now() - delay - window\n  ##   end:   now() - delay\n  #\n  ## Collection delay; if set too low metrics may not yet be available.\n  # delay = "5m"\n  #\n  ## If unset, the window will start at 1m and be updated dynamically to span\n  ## the time between calls (approximately the length of the plugin interval).\n  # window = "1m"\n\n  ## TTL for cached list of metric types.  This is the maximum amount of time\n  ## it may take to discover new metrics.\n  # cache_ttl = "1h"\n\n  ## If true, raw bucket counts are collected for distribution value types.\n  ## For a more lightweight collection, you may wish to disable and use\n  ## distribution_aggregation_aligners instead.\n  # gather_raw_distribution_buckets = true\n\n  ## Aggregate functions to be used for metrics whose value type is\n  ## distribution.  These aggregate values are recorded in in addition to raw\n  ## bucket counts; if they are enabled.\n  ##\n  ## For a list of aligner strings see:\n  ##   https://cloud.google.com/monitoring/api/ref_v3/rpc/google.monitoring.v3#aligner\n  # distribution_aggregation_aligners = [\n  # \t"ALIGN_PERCENTILE_99",\n  # \t"ALIGN_PERCENTILE_95",\n  # \t"ALIGN_PERCENTILE_50",\n  # ]\n\n  ## Filters can be added to reduce the number of time series matched.  All\n  ## functions are supported: starts_with, ends_with, has_substring, and\n  ## one_of.  Only the \'=\' operator is supported.\n  ##\n  ## The logical operators when combining filters are defined statically using\n  ## the following values:\n  ##   filter ::= <resource_labels> {AND <metric_labels>}\n  ##   resource_labels ::= <resource_labels> {OR <resource_label>}\n  ##   metric_labels ::= <metric_labels> {OR <metric_label>}\n  ##\n  ## For more details, see https://cloud.google.com/monitoring/api/v3/filters\n  #\n  ## Resource labels refine the time series selection with the following expression:\n  ##   resource.labels.<key> = <value>\n  # [[inputs.stackdriver.filter.resource_labels]]\n  #   key = "instance_name"\n  #   value = \'starts_with("localhost")\'\n  #\n  ## Metric labels refine the time series selection with the following expression:\n  ##   metric.labels.<key> = <value>\n  #  [[inputs.stackdriver.filter.metric_labels]]\n  #  \t key = "device_name"\n  #  \t value = \'one_of("sda", "sdb")\'\n```\n\n#### Authentication\n\nIt is recommended to use a service account to authenticate with the\nStackdriver Monitoring API.  [Getting Started with Authentication][auth].\n\n### Metrics\n\nMetrics are created using one of there patterns depending on if the value type\nis a scalar value, raw distribution buckets, or aligned bucket values.\n\nIn all cases, the Stackdriver metric type is split on the last component into\nthe measurement and field:\n```\ncompute.googleapis.com/instance/disk/read_bytes_count\n└──────────  measurement  ─────────┘ └──  field  ───┘\n```\n\n**Scalar Values:**\n\n- measurement\n  - tags:\n    - resource_labels\n    - metric_labels\n  - fields:\n    - field\n\n\n**Distributions:**\n\nDistributions are represented by a set of fields along with the bucket values\ntagged with the bucket boundary.  Buckets are cumulative: each bucket\nrepresents the total number of items less than the `lt` tag.\n\n- measurement\n  - tags:\n    - resource_labels\n    - metric_labels\n  - fields:\n    - field_count\n    - field_mean\n    - field_sum_of_squared_deviation\n    - field_range_min\n    - field_range_max\n\n+ measurement\n  - tags:\n    - resource_labels\n    - metric_labels\n    - lt (less than)\n  - fields:\n    - field_bucket\n\n**Aligned Aggregations:**\n\n- measurement\n  - tags:\n    - resource_labels\n    - metric_labels\n  - fields:\n    - field_alignment_function\n\n### Troubleshooting\n\nWhen Telegraf is ran with `--debug`, detailed information about the performed\nqueries will be logged.\n\n### Example Output\n```\n```\n[stackdriver]: https://cloud.google.com/monitoring/api/v3/\n[auth]: https://cloud.google.com/docs/authentication/getting-started\n[pricing]: https://cloud.google.com/stackdriver/pricing#stackdriver_monitoring_services\n',image:hi.a},{id:"statsd",name:"StatsD",markdown:'# StatsD Input Plugin\n\n### Configuration\n\n```toml\n# Statsd Server\n[[inputs.statsd]]\n  ## Protocol, must be "tcp", "udp4", "udp6" or "udp" (default=udp)\n  protocol = "udp"\n\n  ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)\n  max_tcp_connections = 250\n\n  ## Enable TCP keep alive probes (default=false)\n  tcp_keep_alive = false\n\n  ## Specifies the keep-alive period for an active network connection.\n  ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.\n  ## Defaults to the OS configuration.\n  # tcp_keep_alive_period = "2h"\n\n  ## Address and port to host UDP listener on\n  service_address = ":8125"\n\n  ## The following configuration options control when telegraf clears it\'s cache\n  ## of previous values. If set to false, then telegraf will only clear it\'s\n  ## cache when the daemon is restarted.\n  ## Reset gauges every interval (default=true)\n  delete_gauges = true\n  ## Reset counters every interval (default=true)\n  delete_counters = true\n  ## Reset sets every interval (default=true)\n  delete_sets = true\n  ## Reset timings & histograms every interval (default=true)\n  delete_timings = true\n\n  ## Percentiles to calculate for timing & histogram stats.\n  percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0]\n\n  ## separator to use between elements of a statsd metric\n  metric_separator = "_"\n\n  ## Parses tags in the datadog statsd format\n  ## http://docs.datadoghq.com/guides/dogstatsd/\n  ## deprecated in 1.10; use datadog_extensions option instead\n  parse_data_dog_tags = false\n\n  ## Parses extensions to statsd in the datadog statsd format\n  ## currently supports metrics and datadog tags.\n  ## http://docs.datadoghq.com/guides/dogstatsd/\n  datadog_extensions = false\n\n  ## Parses distributions metric as specified in the datadog statsd format\n  ## https://docs.datadoghq.com/developers/metrics/types/?tab=distribution#definition\n  datadog_distributions = false\n\n  ## Statsd data translation templates, more info can be read here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/TEMPLATE_PATTERN.md\n  # templates = [\n  #     "cpu.* measurement*"\n  # ]\n\n  ## Number of UDP messages allowed to queue up, once filled,\n  ## the statsd server will start dropping packets\n  allowed_pending_messages = 10000\n\n  ## Number of timing/histogram values to track per-measurement in the\n  ## calculation of percentiles. Raising this limit increases the accuracy\n  ## of percentiles but also increases the memory usage and cpu time.\n  percentile_limit = 1000\n\n  ## Maximum socket buffer size in bytes, once the buffer fills up, metrics\n  ## will start dropping.  Defaults to the OS default.\n  # read_buffer_size = 65535\n\n  ## Max duration (TTL) for each metric to stay cached/reported without being updated.\n  # max_ttl = "10h"\n```\n\n### Description\n\nThe statsd plugin is a special type of plugin which runs a backgrounded statsd\nlistener service while telegraf is running.\n\nThe format of the statsd messages was based on the format described in the\noriginal [etsy statsd](https://github.com/etsy/statsd/blob/master/docs/metric_types.md)\nimplementation. In short, the telegraf statsd listener will accept:\n\n- Gauges\n    - `users.current.den001.myapp:32|g` <- standard\n    - `users.current.den001.myapp:+10|g` <- additive\n    - `users.current.den001.myapp:-10|g`\n- Counters\n    - `deploys.test.myservice:1|c` <- increments by 1\n    - `deploys.test.myservice:101|c` <- increments by 101\n    - `deploys.test.myservice:1|c|@0.1` <- with sample rate, increments by 10\n- Sets\n    - `users.unique:101|s`\n    - `users.unique:101|s`\n    - `users.unique:102|s` <- would result in a count of 2 for `users.unique`\n- Timings & Histograms\n    - `load.time:320|ms`\n    - `load.time.nanoseconds:1|h`\n    - `load.time:200|ms|@0.1` <- sampled 1/10 of the time\n- Distributions\n    - `load.time:320|d`\n    - `load.time.nanoseconds:1|d`\n    - `load.time:200|d|@0.1` <- sampled 1/10 of the time\n\nIt is possible to omit repetitive names and merge individual stats into a\nsingle line by separating them with additional colons:\n\n  - `users.current.den001.myapp:32|g:+10|g:-10|g`\n  - `deploys.test.myservice:1|c:101|c:1|c|@0.1`\n  - `users.unique:101|s:101|s:102|s`\n  - `load.time:320|ms:200|ms|@0.1`\n\nThis also allows for mixed types in a single line:\n\n  - `foo:1|c:200|ms`\n\nThe string `foo:1|c:200|ms` is internally split into two individual metrics\n`foo:1|c` and `foo:200|ms` which are added to the aggregator separately.\n\n\n### Influx Statsd\n\nIn order to take advantage of InfluxDB\'s tagging system, we have made a couple\nadditions to the standard statsd protocol. First, you can specify\ntags in a manner similar to the line-protocol, like this:\n\n```\nusers.current,service=payroll,region=us-west:32|g\n```\n\n\x3c!-- TODO Second, you can specify multiple fields within a measurement:\n\n```\ncurrent.users,service=payroll,server=host01:west=10,east=10,central=2,south=10|g\n``` --\x3e\n\n### Measurements:\n\nMeta:\n- tags: `metric_type=<gauge|set|counter|timing|histogram>`\n\nOutputted measurements will depend entirely on the measurements that the user\nsends, but here is a brief rundown of what you can expect to find from each\nmetric type:\n\n- Gauges\n    - Gauges are a constant data type. They are not subject to averaging, and they\n    don’t change unless you change them. That is, once you set a gauge value, it\n    will be a flat line on the graph until you change it again.\n- Counters\n    - Counters are the most basic type. They are treated as a count of a type of\n    event. They will continually increase unless you set `delete_counters=true`.\n- Sets\n    - Sets count the number of unique values passed to a key. For example, you\n    could count the number of users accessing your system using `users:<user_id>|s`.\n    No matter how many times the same user_id is sent, the count will only increase\n    by 1.\n- Timings & Histograms\n    - Timers are meant to track how long something took. They are an invaluable\n    tool for tracking application performance.\n    - The following aggregate measurements are made for timers:\n        - `statsd_<name>_lower`: The lower bound is the lowest value statsd saw\n        for that stat during that interval.\n        - `statsd_<name>_upper`: The upper bound is the highest value statsd saw\n        for that stat during that interval.\n        - `statsd_<name>_mean`: The mean is the average of all values statsd saw\n        for that stat during that interval.\n        - `statsd_<name>_stddev`: The stddev is the sample standard deviation\n        of all values statsd saw for that stat during that interval.\n        - `statsd_<name>_sum`: The sum is the sample sum of all values statsd saw\n        for that stat during that interval.\n        - `statsd_<name>_count`: The count is the number of timings statsd saw\n        for that stat during that interval. It is not averaged.\n        - `statsd_<name>_percentile_<P>` The `Pth` percentile is a value x such\n        that `P%` of all the values statsd saw for that stat during that time\n        period are below x. The most common value that people use for `P` is the\n        `90`, this is a great number to try to optimize.\n- Distributions\n    - The Distribution metric represents the global statistical distribution of a set of values calculated across your entire distributed infrastructure in one time interval. A Distribution can be used to instrument logical objects, like services, independently from the underlying hosts.\n    - Unlike the Histogram metric type, which aggregates on the Agent during a given time interval, a Distribution metric sends all the raw data during a time interval.\n\n### Plugin arguments\n\n- **protocol** string: Protocol used in listener - tcp or udp options\n- **max_tcp_connections** []int: Maximum number of concurrent TCP connections\nto allow. Used when protocol is set to tcp.\n- **tcp_keep_alive** boolean: Enable TCP keep alive probes\n- **tcp_keep_alive_period** duration: Specifies the keep-alive period for an active network connection\n- **service_address** string: Address to listen for statsd UDP packets on\n- **delete_gauges** boolean: Delete gauges on every collection interval\n- **delete_counters** boolean: Delete counters on every collection interval\n- **delete_sets** boolean: Delete set counters on every collection interval\n- **delete_timings** boolean: Delete timings on every collection interval\n- **percentiles** []int: Percentiles to calculate for timing & histogram stats\n- **allowed_pending_messages** integer: Number of messages allowed to queue up\nwaiting to be processed. When this fills, messages will be dropped and logged.\n- **percentile_limit** integer: Number of timing/histogram values to track\nper-measurement in the calculation of percentiles. Raising this limit increases\nthe accuracy of percentiles but also increases the memory usage and cpu time.\n- **templates** []string: Templates for transforming statsd buckets into influx\nmeasurements and tags.\n- **parse_data_dog_tags** boolean: Enable parsing of tags in DataDog\'s dogstatsd format (http://docs.datadoghq.com/guides/dogstatsd/)\n- **datadog_extensions** boolean: Enable parsing of DataDog\'s extensions to dogstatsd format (http://docs.datadoghq.com/guides/dogstatsd/)\n- **datadog_distributions** boolean: Enable parsing of the Distribution metric in DataDog\'s dogstatsd format (https://docs.datadoghq.com/developers/metrics/types/?tab=distribution#definition)\n- **max_ttl** config.Duration: Max duration (TTL) for each metric to stay cached/reported without being updated.\n\n### Statsd bucket -> InfluxDB line-protocol Templates\n\nThe plugin supports specifying templates for transforming statsd buckets into\nInfluxDB measurement names and tags. The templates have a _measurement_ keyword,\nwhich can be used to specify parts of the bucket that are to be used in the\nmeasurement name. Other words in the template are used as tag names. For example,\nthe following template:\n\n```\ntemplates = [\n    "measurement.measurement.region"\n]\n```\n\nwould result in the following transformation:\n\n```\ncpu.load.us-west:100|g\n=> cpu_load,region=us-west 100\n```\n\nUsers can also filter the template to use based on the name of the bucket,\nusing glob matching, like so:\n\n```\ntemplates = [\n    "cpu.* measurement.measurement.region",\n    "mem.* measurement.measurement.host"\n]\n```\n\nwhich would result in the following transformation:\n\n```\ncpu.load.us-west:100|g\n=> cpu_load,region=us-west 100\n\nmem.cached.localhost:256|g\n=> mem_cached,host=localhost 256\n```\n\nConsult the [Template Patterns](/docs/TEMPLATE_PATTERN.md) documentation for\nadditional details.\n',image:fi.a},{id:"suricata",name:"Suricata",markdown:'# Suricata Input Plugin\n\nThis plugin reports internal performance counters of the Suricata IDS/IPS\nengine, such as captured traffic volume, memory usage, uptime, flow counters,\nand much more. It provides a socket for the Suricata log output to write JSON\nstats output to, and processes the incoming data to fit Telegraf\'s format.\n\n### Configuration\n\n```toml\n[[inputs.suricata]]\n  ## Data sink for Suricata stats log.\n  # This is expected to be a filename of a\n  # unix socket to be created for listening.\n  source = "/var/run/suricata-stats.sock"\n\n  # Delimiter for flattening field keys, e.g. subitem "alert" of "detect"\n  # becomes "detect_alert" when delimiter is "_".\n  delimiter = "_"\n```\n\n### Metrics\n\nFields in the \'suricata\' measurement follow the JSON format used by Suricata\'s\nstats output.\nSee http://suricata.readthedocs.io/en/latest/performance/statistics.html for\nmore information.\n\nAll fields are numeric.\n- suricata\n  - tags:\n    - thread: `Global` for global statistics (if enabled), thread IDs (e.g. `W#03-enp0s31f6`) for thread-specific statistics\n  - fields:\n    - app_layer_flow_dcerpc_udp\n    - app_layer_flow_dns_tcp\n    - app_layer_flow_dns_udp\n    - app_layer_flow_enip_udp\n    - app_layer_flow_failed_tcp\n    - app_layer_flow_failed_udp\n    - app_layer_flow_http\n    - app_layer_flow_ssh\n    - app_layer_flow_tls\n    - app_layer_tx_dns_tcp\n    - app_layer_tx_dns_udp\n    - app_layer_tx_enip_udp\n    - app_layer_tx_http\n    - app_layer_tx_smtp\n    - capture_kernel_drops\n    - capture_kernel_packets\n    - decoder_avg_pkt_size\n    - decoder_bytes\n    - decoder_ethernet\n    - decoder_gre\n    - decoder_icmpv4\n    - decoder_icmpv4_ipv4_unknown_ver\n    - decoder_icmpv6\n    - decoder_invalid\n    - decoder_ipv4\n    - decoder_ipv6\n    - decoder_max_pkt_size\n    - decoder_pkts\n    - decoder_tcp\n    - decoder_tcp_hlen_too_small\n    - decoder_tcp_invalid_optlen\n    - decoder_teredo\n    - decoder_udp\n    - decoder_vlan\n    - detect_alert\n    - dns_memcap_global\n    - dns_memuse\n    - flow_memuse\n    - flow_mgr_closed_pruned\n    - flow_mgr_est_pruned\n    - flow_mgr_flows_checked\n    - flow_mgr_flows_notimeout\n    - flow_mgr_flows_removed\n    - flow_mgr_flows_timeout\n    - flow_mgr_flows_timeout_inuse\n    - flow_mgr_new_pruned\n    - flow_mgr_rows_checked\n    - flow_mgr_rows_empty\n    - flow_mgr_rows_maxlen\n    - flow_mgr_rows_skipped\n    - flow_spare\n    - flow_tcp_reuse\n    - http_memuse\n    - tcp_memuse\n    - tcp_pseudo\n    - tcp_reassembly_gap\n    - tcp_reassembly_memuse\n    - tcp_rst\n    - tcp_sessions\n    - tcp_syn\n    - tcp_synack\n    - ...\n\n\n#### Suricata configuration\n\nSuricata needs to deliver the \'stats\' event type to a given unix socket for\nthis plugin to pick up. This can be done, for example, by creating an additional\noutput in the Suricata configuration file:\n\n```yaml\n- eve-log:\n    enabled: yes\n    filetype: unix_stream\n    filename: /tmp/suricata-stats.sock\n    types:\n      - stats:\n         threads: yes\n```\n\n#### FreeBSD tuning\n\n\nUnder FreeBSD it is necessary to increase the localhost buffer space to at least 16384, default is 8192 \notherwise messages from Suricata are truncated as they exceed the default available buffer space, \nconsequently no statistics are processed by the plugin.\n\n```text\nsysctl -w net.local.stream.recvspace=16384\nsysctl -w net.local.stream.sendspace=16384\n```\n\n\n### Example Output\n\n```text\nsuricata,host=myhost,thread=FM#01 flow_mgr_rows_empty=0,flow_mgr_rows_checked=65536,flow_mgr_closed_pruned=0,flow_emerg_mode_over=0,flow_mgr_flows_timeout_inuse=0,flow_mgr_rows_skipped=65535,flow_mgr_bypassed_pruned=0,flow_mgr_flows_removed=0,flow_mgr_est_pruned=0,flow_mgr_flows_notimeout=1,flow_mgr_flows_checked=1,flow_mgr_rows_busy=0,flow_spare=10000,flow_mgr_rows_maxlen=1,flow_mgr_new_pruned=0,flow_emerg_mode_entered=0,flow_tcp_reuse=0,flow_mgr_flows_timeout=0 1568368562545197545\nsuricata,host=myhost,thread=W#04-wlp4s0 decoder_ltnull_pkt_too_small=0,decoder_ipraw_invalid_ip_version=0,defrag_ipv4_reassembled=0,tcp_no_flow=0,app_layer_flow_tls=1,decoder_udp=25,defrag_ipv6_fragments=0,defrag_ipv4_fragments=0,decoder_tcp=59,decoder_vlan=0,decoder_pkts=84,decoder_vlan_qinq=0,decoder_avg_pkt_size=574,flow_memcap=0,defrag_max_frag_hits=0,tcp_ssn_memcap_drop=0,capture_kernel_packets=84,app_layer_flow_dcerpc_udp=0,app_layer_tx_dns_tcp=0,tcp_rst=0,decoder_icmpv4=0,app_layer_tx_tls=0,decoder_ipv4=84,decoder_erspan=0,decoder_ltnull_unsupported_type=0,decoder_invalid=0,app_layer_flow_ssh=0,capture_kernel_drops=0,app_layer_flow_ftp=0,app_layer_tx_http=0,tcp_pseudo_failed=0,defrag_ipv6_reassembled=0,defrag_ipv6_timeouts=0,tcp_pseudo=0,tcp_sessions=1,decoder_ethernet=84,decoder_raw=0,decoder_sctp=0,app_layer_flow_dns_udp=1,decoder_gre=0,app_layer_flow_http=0,app_layer_flow_imap=0,tcp_segment_memcap_drop=0,detect_alert=0,app_layer_flow_failed_tcp=0,decoder_teredo=0,decoder_mpls=0,decoder_ppp=0,decoder_max_pkt_size=1422,decoder_ipv6=0,tcp_reassembly_gap=0,app_layer_flow_dcerpc_tcp=0,decoder_ipv4_in_ipv6=0,tcp_stream_depth_reached=0,app_layer_flow_dns_tcp=0,app_layer_flow_smtp=0,tcp_syn=1,decoder_sll=0,tcp_invalid_checksum=0,app_layer_tx_dns_udp=1,decoder_bytes=48258,defrag_ipv4_timeouts=0,app_layer_flow_msn=0,decoder_pppoe=0,decoder_null=0,app_layer_flow_failed_udp=3,app_layer_tx_smtp=0,decoder_icmpv6=0,decoder_ipv6_in_ipv6=0,tcp_synack=1,app_layer_flow_smb=0,decoder_dce_pkt_too_small=0 1568368562545174807\nsuricata,host=myhost,thread=W#01-wlp4s0 tcp_synack=0,app_layer_flow_imap=0,decoder_ipv4_in_ipv6=0,decoder_max_pkt_size=684,decoder_gre=0,defrag_ipv4_timeouts=0,tcp_invalid_checksum=0,decoder_ipv4=53,flow_memcap=0,app_layer_tx_http=0,app_layer_tx_smtp=0,decoder_null=0,tcp_no_flow=0,app_layer_tx_tls=0,app_layer_flow_ssh=0,app_layer_flow_smtp=0,decoder_pppoe=0,decoder_teredo=0,decoder_ipraw_invalid_ip_version=0,decoder_ltnull_pkt_too_small=0,tcp_rst=0,decoder_ppp=0,decoder_ipv6=29,app_layer_flow_dns_udp=3,decoder_vlan=0,app_layer_flow_dcerpc_tcp=0,tcp_syn=0,defrag_ipv4_fragments=0,defrag_ipv6_timeouts=0,decoder_raw=0,defrag_ipv6_reassembled=0,tcp_reassembly_gap=0,tcp_sessions=0,decoder_udp=44,tcp_segment_memcap_drop=0,app_layer_tx_dns_udp=3,app_layer_flow_tls=0,decoder_tcp=37,defrag_ipv4_reassembled=0,app_layer_flow_failed_udp=6,app_layer_flow_ftp=0,decoder_icmpv6=1,tcp_stream_depth_reached=0,capture_kernel_drops=0,decoder_sll=0,decoder_bytes=15883,decoder_ethernet=91,tcp_pseudo=0,app_layer_flow_http=0,decoder_sctp=0,decoder_pkts=91,decoder_avg_pkt_size=174,decoder_erspan=0,app_layer_flow_msn=0,app_layer_flow_smb=0,capture_kernel_packets=91,decoder_icmpv4=0,decoder_ipv6_in_ipv6=0,tcp_ssn_memcap_drop=0,decoder_vlan_qinq=0,decoder_ltnull_unsupported_type=0,decoder_invalid=0,defrag_max_frag_hits=0,tcp_pseudo_failed=0,detect_alert=0,app_layer_tx_dns_tcp=0,app_layer_flow_failed_tcp=0,app_layer_flow_dcerpc_udp=0,app_layer_flow_dns_tcp=0,defrag_ipv6_fragments=0,decoder_mpls=0,decoder_dce_pkt_too_small=0 1568368562545148438\nsuricata,host=myhost flow_memuse=7094464,tcp_memuse=3276800,tcp_reassembly_memuse=12332832,dns_memuse=0,dns_memcap_state=0,dns_memcap_global=0,http_memuse=0,http_memcap=0 1568368562545144569\nsuricata,host=myhost,thread=W#07-wlp4s0 app_layer_tx_http=0,app_layer_tx_dns_tcp=0,decoder_vlan=0,decoder_pppoe=0,decoder_sll=0,decoder_tcp=0,flow_memcap=0,app_layer_flow_msn=0,tcp_no_flow=0,tcp_rst=0,tcp_segment_memcap_drop=0,tcp_sessions=0,detect_alert=0,defrag_ipv6_reassembled=0,decoder_ipraw_invalid_ip_version=0,decoder_erspan=0,decoder_icmpv4=0,app_layer_tx_dns_udp=2,decoder_ltnull_pkt_too_small=0,decoder_bytes=1998,decoder_ipv6=1,defrag_ipv4_fragments=0,defrag_ipv6_fragments=0,app_layer_tx_smtp=0,decoder_ltnull_unsupported_type=0,decoder_max_pkt_size=342,app_layer_flow_ftp=0,decoder_ipv6_in_ipv6=0,defrag_ipv4_reassembled=0,defrag_ipv6_timeouts=0,app_layer_flow_dns_tcp=0,decoder_avg_pkt_size=181,defrag_ipv4_timeouts=0,tcp_stream_depth_reached=0,decoder_mpls=0,app_layer_flow_dns_udp=2,tcp_ssn_memcap_drop=0,app_layer_flow_dcerpc_tcp=0,app_layer_flow_failed_udp=2,app_layer_flow_smb=0,app_layer_flow_failed_tcp=0,decoder_invalid=0,decoder_null=0,decoder_gre=0,decoder_ethernet=11,app_layer_flow_ssh=0,defrag_max_frag_hits=0,capture_kernel_drops=0,tcp_pseudo_failed=0,app_layer_flow_smtp=0,decoder_udp=10,decoder_sctp=0,decoder_teredo=0,decoder_icmpv6=1,tcp_pseudo=0,tcp_synack=0,app_layer_tx_tls=0,app_layer_flow_imap=0,capture_kernel_packets=11,decoder_pkts=11,decoder_raw=0,decoder_ppp=0,tcp_syn=0,tcp_invalid_checksum=0,app_layer_flow_tls=0,decoder_ipv4_in_ipv6=0,app_layer_flow_http=0,decoder_dce_pkt_too_small=0,decoder_ipv4=10,decoder_vlan_qinq=0,tcp_reassembly_gap=0,app_layer_flow_dcerpc_udp=0 1568368562545110847\nsuricata,host=myhost,thread=W#06-wlp4s0 app_layer_tx_smtp=0,decoder_ipv6_in_ipv6=0,decoder_dce_pkt_too_small=0,tcp_segment_memcap_drop=0,tcp_sessions=1,decoder_ppp=0,tcp_pseudo_failed=0,app_layer_tx_dns_tcp=0,decoder_invalid=0,defrag_ipv4_timeouts=0,app_layer_flow_smb=0,app_layer_flow_ssh=0,decoder_bytes=19407,decoder_null=0,app_layer_flow_tls=1,decoder_avg_pkt_size=473,decoder_pkts=41,decoder_pppoe=0,decoder_tcp=32,defrag_ipv4_reassembled=0,tcp_reassembly_gap=0,decoder_raw=0,flow_memcap=0,defrag_ipv6_timeouts=0,app_layer_flow_smtp=0,app_layer_tx_http=0,decoder_sll=0,decoder_udp=8,decoder_ltnull_pkt_too_small=0,decoder_ltnull_unsupported_type=0,decoder_ipv4_in_ipv6=0,decoder_vlan=0,decoder_max_pkt_size=1422,tcp_no_flow=0,app_layer_flow_failed_tcp=0,app_layer_flow_dns_tcp=0,app_layer_flow_ftp=0,decoder_icmpv4=0,defrag_max_frag_hits=0,tcp_rst=0,app_layer_flow_msn=0,app_layer_flow_failed_udp=2,app_layer_flow_dns_udp=0,app_layer_flow_dcerpc_udp=0,decoder_ipv4=39,decoder_ethernet=41,defrag_ipv6_reassembled=0,tcp_ssn_memcap_drop=0,app_layer_tx_tls=0,decoder_gre=0,decoder_vlan_qinq=0,tcp_pseudo=0,app_layer_flow_imap=0,app_layer_flow_dcerpc_tcp=0,defrag_ipv4_fragments=0,defrag_ipv6_fragments=0,tcp_synack=1,app_layer_flow_http=0,app_layer_tx_dns_udp=0,capture_kernel_packets=41,decoder_ipv6=2,tcp_invalid_checksum=0,tcp_stream_depth_reached=0,decoder_ipraw_invalid_ip_version=0,decoder_icmpv6=1,tcp_syn=1,detect_alert=0,capture_kernel_drops=0,decoder_teredo=0,decoder_erspan=0,decoder_sctp=0,decoder_mpls=0 1568368562545084670\nsuricata,host=myhost,thread=W#02-wlp4s0 decoder_tcp=53,tcp_rst=3,tcp_reassembly_gap=0,defrag_ipv6_timeouts=0,tcp_ssn_memcap_drop=0,app_layer_flow_dcerpc_tcp=0,decoder_max_pkt_size=1422,decoder_ipv6_in_ipv6=0,tcp_no_flow=0,app_layer_flow_ftp=0,app_layer_flow_ssh=0,decoder_pkts=82,decoder_sctp=0,tcp_invalid_checksum=0,app_layer_flow_dns_tcp=0,decoder_ipraw_invalid_ip_version=0,decoder_bytes=26441,decoder_erspan=0,tcp_pseudo_failed=0,tcp_syn=1,app_layer_tx_http=0,app_layer_tx_smtp=0,decoder_teredo=0,decoder_ipv4=80,defrag_ipv4_fragments=0,tcp_stream_depth_reached=0,app_layer_flow_smb=0,capture_kernel_packets=82,decoder_null=0,decoder_ltnull_pkt_too_small=0,decoder_ppp=0,decoder_icmpv6=1,app_layer_flow_dns_udp=2,app_layer_flow_http=0,app_layer_tx_dns_udp=3,decoder_mpls=0,decoder_sll=0,defrag_ipv4_reassembled=0,tcp_segment_memcap_drop=0,app_layer_flow_imap=0,decoder_ltnull_unsupported_type=0,decoder_icmpv4=0,decoder_raw=0,defrag_ipv4_timeouts=0,app_layer_flow_failed_udp=8,decoder_gre=0,capture_kernel_drops=0,defrag_ipv6_reassembled=0,tcp_pseudo=0,app_layer_flow_tls=1,decoder_avg_pkt_size=322,decoder_dce_pkt_too_small=0,decoder_ethernet=82,defrag_ipv6_fragments=0,tcp_sessions=1,tcp_synack=1,app_layer_tx_dns_tcp=0,decoder_vlan=0,flow_memcap=0,decoder_vlan_qinq=0,decoder_udp=28,decoder_invalid=0,detect_alert=0,app_layer_flow_failed_tcp=0,app_layer_tx_tls=0,decoder_pppoe=0,decoder_ipv6=2,decoder_ipv4_in_ipv6=0,defrag_max_frag_hits=0,app_layer_flow_dcerpc_udp=0,app_layer_flow_smtp=0,app_layer_flow_msn=0 1568368562545061864\nsuricata,host=myhost,thread=W#08-wlp4s0 decoder_dce_pkt_too_small=0,app_layer_tx_dns_tcp=0,decoder_pkts=58,decoder_ppp=0,decoder_raw=0,decoder_ipv4_in_ipv6=0,decoder_max_pkt_size=1392,tcp_invalid_checksum=0,tcp_syn=0,decoder_ipv4=51,decoder_ipv6_in_ipv6=0,decoder_tcp=0,decoder_ltnull_pkt_too_small=0,flow_memcap=0,decoder_udp=58,tcp_ssn_memcap_drop=0,tcp_pseudo=0,app_layer_flow_dcerpc_udp=0,app_layer_flow_dns_udp=5,app_layer_tx_http=0,capture_kernel_drops=0,decoder_vlan=0,tcp_segment_memcap_drop=0,app_layer_flow_ftp=0,app_layer_flow_imap=0,app_layer_flow_http=0,app_layer_flow_tls=0,decoder_icmpv4=0,decoder_sctp=0,defrag_ipv4_timeouts=0,tcp_reassembly_gap=0,detect_alert=0,decoder_ethernet=58,tcp_pseudo_failed=0,decoder_teredo=0,defrag_ipv4_reassembled=0,tcp_sessions=0,app_layer_flow_msn=0,decoder_ipraw_invalid_ip_version=0,tcp_no_flow=0,app_layer_flow_dns_tcp=0,decoder_null=0,defrag_ipv4_fragments=0,app_layer_flow_dcerpc_tcp=0,app_layer_flow_failed_udp=8,app_layer_tx_tls=0,decoder_bytes=15800,decoder_ipv6=7,tcp_stream_depth_reached=0,decoder_invalid=0,decoder_ltnull_unsupported_type=0,app_layer_tx_dns_udp=6,decoder_pppoe=0,decoder_avg_pkt_size=272,decoder_erspan=0,defrag_ipv6_timeouts=0,app_layer_flow_failed_tcp=0,decoder_gre=0,decoder_sll=0,defrag_max_frag_hits=0,app_layer_flow_ssh=0,capture_kernel_packets=58,decoder_mpls=0,decoder_vlan_qinq=0,tcp_rst=0,app_layer_flow_smb=0,app_layer_tx_smtp=0,decoder_icmpv6=0,defrag_ipv6_fragments=0,defrag_ipv6_reassembled=0,tcp_synack=0,app_layer_flow_smtp=0 1568368562545035575\nsuricata,host=myhost,thread=W#05-wlp4s0 tcp_reassembly_gap=0,capture_kernel_drops=0,decoder_ltnull_unsupported_type=0,tcp_sessions=0,tcp_stream_depth_reached=0,tcp_pseudo_failed=0,app_layer_flow_failed_tcp=0,app_layer_tx_dns_tcp=0,decoder_null=0,decoder_dce_pkt_too_small=0,decoder_udp=7,tcp_rst=3,app_layer_flow_dns_tcp=0,decoder_invalid=0,defrag_ipv4_reassembled=0,tcp_synack=0,app_layer_flow_ftp=0,decoder_bytes=3117,decoder_pppoe=0,app_layer_flow_dcerpc_tcp=0,app_layer_flow_smb=0,decoder_ipv6_in_ipv6=0,decoder_ipraw_invalid_ip_version=0,app_layer_flow_imap=0,app_layer_tx_dns_udp=2,decoder_ppp=0,decoder_ipv4=21,decoder_tcp=14,flow_memcap=0,tcp_syn=0,tcp_invalid_checksum=0,decoder_teredo=0,decoder_ltnull_pkt_too_small=0,defrag_max_frag_hits=0,app_layer_tx_tls=0,decoder_pkts=24,decoder_sll=0,defrag_ipv6_fragments=0,app_layer_flow_dcerpc_udp=0,app_layer_flow_smtp=0,decoder_icmpv6=3,defrag_ipv6_timeouts=0,decoder_ipv6=3,decoder_raw=0,defrag_ipv6_reassembled=0,tcp_no_flow=0,detect_alert=0,app_layer_flow_tls=0,decoder_ethernet=24,decoder_vlan=0,decoder_icmpv4=0,decoder_ipv4_in_ipv6=0,app_layer_flow_failed_udp=1,decoder_mpls=0,decoder_max_pkt_size=653,decoder_sctp=0,defrag_ipv4_timeouts=0,tcp_ssn_memcap_drop=0,app_layer_flow_dns_udp=1,app_layer_tx_smtp=0,capture_kernel_packets=24,decoder_vlan_qinq=0,decoder_gre=0,app_layer_flow_ssh=0,app_layer_flow_msn=0,defrag_ipv4_fragments=0,app_layer_flow_http=0,tcp_segment_memcap_drop=0,tcp_pseudo=0,app_layer_tx_http=0,decoder_erspan=0,decoder_avg_pkt_size=129 1568368562545009684\nsuricata,host=myhost,thread=W#03-wlp4s0 app_layer_flow_failed_tcp=0,decoder_teredo=0,decoder_ipv6_in_ipv6=0,tcp_pseudo_failed=0,tcp_stream_depth_reached=0,tcp_syn=0,decoder_gre=0,tcp_segment_memcap_drop=0,tcp_ssn_memcap_drop=0,app_layer_tx_smtp=0,decoder_raw=0,decoder_ltnull_pkt_too_small=0,tcp_sessions=0,tcp_reassembly_gap=0,app_layer_flow_ssh=0,app_layer_flow_imap=0,decoder_ipv4=463,decoder_ethernet=463,capture_kernel_packets=463,decoder_pppoe=0,defrag_ipv4_reassembled=0,app_layer_flow_tls=0,app_layer_flow_dcerpc_udp=0,app_layer_flow_dns_udp=0,decoder_vlan=0,decoder_ipraw_invalid_ip_version=0,decoder_mpls=0,tcp_no_flow=0,decoder_avg_pkt_size=445,decoder_udp=432,flow_memcap=0,app_layer_tx_dns_udp=0,app_layer_flow_msn=0,app_layer_flow_http=0,app_layer_flow_dcerpc_tcp=0,decoder_ipv6=0,decoder_ipv4_in_ipv6=0,defrag_ipv4_timeouts=0,defrag_ipv4_fragments=0,defrag_ipv6_timeouts=0,decoder_sctp=0,defrag_ipv6_fragments=0,app_layer_flow_dns_tcp=0,app_layer_tx_tls=0,defrag_max_frag_hits=0,decoder_bytes=206345,decoder_vlan_qinq=0,decoder_invalid=0,decoder_ppp=0,tcp_rst=0,detect_alert=0,capture_kernel_drops=0,app_layer_flow_failed_udp=4,decoder_null=0,decoder_icmpv4=0,decoder_icmpv6=0,decoder_ltnull_unsupported_type=0,defrag_ipv6_reassembled=0,tcp_invalid_checksum=0,tcp_synack=0,decoder_tcp=31,tcp_pseudo=0,app_layer_flow_smb=0,app_layer_flow_smtp=0,decoder_max_pkt_size=1463,decoder_dce_pkt_too_small=0,app_layer_tx_http=0,decoder_pkts=463,decoder_sll=0,app_layer_flow_ftp=0,app_layer_tx_dns_tcp=0,decoder_erspan=0 1568368562544966078\n```\n',image:yi.a},{id:"swap",name:"Swap",markdown:"# Swap Input Plugin\n\nThe swap plugin collects system swap metrics.\n\nFor more information on what swap memory is, read [All about Linux swap space](https://www.linux.com/news/all-about-linux-swap-space).\n\n### Configuration:\n\n```toml\n# Read metrics about swap memory usage\n[[inputs.swap]]\n  # no configuration\n```\n\n### Metrics:\n\n- swap\n  - fields:\n    - free (int, bytes): free swap memory\n    - total (int, bytes): total swap memory\n    - used (int, bytes): used swap memory\n    - used_percent (float, percent): percentage of swap memory used\n    - in (int, bytes): data swapped in since last boot calculated from page number\n    - out (int, bytes): data swapped out since last boot calculated from page number\n\n### Example Output:\n\n```\nswap total=20855394304i,used_percent=45.43883523785713,used=9476448256i,free=1715331072i 1511894782000000000\n```\n",image:wi.a},{id:"synproxy",name:"Synproxy",markdown:'# Synproxy Input Plugin\n\nThe synproxy plugin gathers the synproxy counters. Synproxy is a Linux netfilter module used for SYN attack mitigation. \nThe use of synproxy is documented in `man iptables-extensions` under the SYNPROXY section.\n\n\n### Configuration\n\nThe synproxy plugin does not need any configuration\n\n```toml\n[[inputs.synproxy]]\n  # no configuration\n```\n\n### Metrics\n\nThe following synproxy counters are gathered\n\n- synproxy\n  - fields:\n    - cookie_invalid (uint32, packets, counter) - Invalid cookies\n    - cookie_retrans (uint32, packets, counter) - Cookies retransmitted\n    - cookie_valid (uint32, packets, counter) - Valid cookies\n    - entries (uint32, packets, counter) - Entries\n    - syn_received (uint32, packets, counter) - SYN received\n    - conn_reopened (uint32, packets, counter) - Connections reopened\n\n### Sample Queries\n\nGet the number of packets per 5 minutes for the measurement in the last hour from InfluxDB:\n```sql\nSELECT difference(last("cookie_invalid")) AS "cookie_invalid", difference(last("cookie_retrans")) AS "cookie_retrans", difference(last("cookie_valid")) AS "cookie_valid", difference(last("entries")) AS "entries", difference(last("syn_received")) AS "syn_received", difference(last("conn_reopened")) AS "conn_reopened" FROM synproxy WHERE time > NOW() - 1h GROUP BY time(5m) FILL(null);\n```\n\n### Troubleshooting\n\nExecute the following CLI command in Linux to test the synproxy counters:\n```sh\ncat /proc/net/stat/synproxy\n```\n\n### Example Output\n\nThis section shows example output in Line Protocol format.\n\n```\nsynproxy,host=Filter-GW01,rack=filter-node1 conn_reopened=0i,cookie_invalid=235i,cookie_retrans=0i,cookie_valid=8814i,entries=0i,syn_received=8742i 1549550634000000000\n```\n',image:xi.a},{id:"syslog",name:"Syslog",markdown:'# Syslog Input Plugin\n\nThe syslog plugin listens for syslog messages transmitted over\na Unix Domain socket,\n[UDP](https://tools.ietf.org/html/rfc5426),\n[TCP](https://tools.ietf.org/html/rfc6587), or\n[TLS](https://tools.ietf.org/html/rfc5425); with or without the octet counting framing.\n\nSyslog messages should be formatted according to\n[RFC 5424](https://tools.ietf.org/html/rfc5424).\n\n### Configuration\n\n```toml\n[[inputs.syslog]]\n  ## Protocol, address and port to host the syslog receiver.\n  ## If no host is specified, then localhost is used.\n  ## If no port is specified, 6514 is used (RFC5425#section-4.1).\n  ##   ex: server = "tcp://localhost:6514"\n  ##       server = "udp://:6514"\n  ##       server = "unix:///var/run/telegraf-syslog.sock"\n  server = "tcp://:6514"\n\n  ## TLS Config\n  # tls_allowed_cacerts = ["/etc/telegraf/ca.pem"]\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n\n  ## Period between keep alive probes.\n  ## 0 disables keep alive probes.\n  ## Defaults to the OS configuration.\n  ## Only applies to stream sockets (e.g. TCP).\n  # keep_alive_period = "5m"\n\n  ## Maximum number of concurrent connections (default = 0).\n  ## 0 means unlimited.\n  ## Only applies to stream sockets (e.g. TCP).\n  # max_connections = 1024\n\n  ## Read timeout is the maximum time allowed for reading a single message (default = 5s).\n  ## 0 means unlimited.\n  # read_timeout = "5s"\n\n  ## The framing technique with which it is expected that messages are transported (default = "octet-counting").\n  ## Whether the messages come using the octect-counting (RFC5425#section-4.3.1, RFC6587#section-3.4.1),\n  ## or the non-transparent framing technique (RFC6587#section-3.4.2).\n  ## Must be one of "octect-counting", "non-transparent".\n  # framing = "octet-counting"\n\n  ## The trailer to be expected in case of non-transparent framing (default = "LF").\n  ## Must be one of "LF", or "NUL".\n  # trailer = "LF"\n\n  ## Whether to parse in best effort mode or not (default = false).\n  ## By default best effort parsing is off.\n  # best_effort = false\n\n  ## Character to prepend to SD-PARAMs (default = "_").\n  ## A syslog message can contain multiple parameters and multiple identifiers within structured data section.\n  ## Eg., [id1 name1="val1" name2="val2"][id2 name1="val1" nameA="valA"]\n  ## For each combination a field is created.\n  ## Its name is created concatenating identifier, sdparam_separator, and parameter name.\n  # sdparam_separator = "_"\n```\n\n#### Message transport\n\nThe `framing` option only applies to streams. It governs the way we expect to receive messages within the stream.\nNamely, with the [`"octet counting"`](https://tools.ietf.org/html/rfc5425#section-4.3) technique (default) or with the [`"non-transparent"`](https://tools.ietf.org/html/rfc6587#section-3.4.2) framing.\n\nThe `trailer` option only applies when `framing` option is `"non-transparent"`. It must have one of the following values: `"LF"` (default), or `"NUL"`.\n\n#### Best effort\n\nThe [`best_effort`](https://github.com/influxdata/go-syslog#best-effort-mode)\noption instructs the parser to extract partial but valid info from syslog\nmessages. If unset only full messages will be collected.\n\n#### Rsyslog Integration\n\nRsyslog can be configured to forward logging messages to Telegraf by configuring\n[remote logging](https://www.rsyslog.com/doc/v8-stable/configuration/actions.html#remote-machine).\n\nMost system are setup with a configuration split between `/etc/rsyslog.conf`\nand the files in the `/etc/rsyslog.d/` directory, it is recommended to add the\nnew configuration into the config directory to simplify updates to the main\nconfig file.\n\nAdd the following lines to `/etc/rsyslog.d/50-telegraf.conf` making\nadjustments to the target address as needed:\n```\n$ActionQueueType LinkedList # use asynchronous processing\n$ActionQueueFileName srvrfwd # set file name, also enables disk mode\n$ActionResumeRetryCount -1 # infinite retries on insert failure\n$ActionQueueSaveOnShutdown on # save in-memory data if rsyslog shuts down\n\n# forward over tcp with octet framing according to RFC 5425\n*.* @@(o)127.0.0.1:6514;RSYSLOG_SyslogProtocol23Format\n\n# uncomment to use udp according to RFC 5424\n#*.* @127.0.0.1:6514;RSYSLOG_SyslogProtocol23Format\n```\n\nYou can alternately use `advanced` format (aka RainerScript):\n```\n# forward over tcp with octet framing according to RFC 5425\naction(type="omfwd" Protocol="tcp" TCP_Framing="octet-counted" Target="127.0.0.1" Port="6514" Template="RSYSLOG_SyslogProtocol23Format")\n\n# uncomment to use udp according to RFC 5424\n#action(type="omfwd" Protocol="udp" Target="127.0.0.1" Port="6514" Template="RSYSLOG_SyslogProtocol23Format")\n```\n\nTo complete TLS setup please refer to [rsyslog docs](https://www.rsyslog.com/doc/v8-stable/tutorials/tls.html).\n\n### Metrics\n\n- syslog\n  - tags\n    - severity (string)\n    - facility (string)\n    - hostname (string)\n    - appname (string)\n  - fields\n    - version (integer)\n    - severity_code (integer)\n    - facility_code (integer)\n    - timestamp (integer): the time recorded in the syslog message\n    - procid (string)\n    - msgid (string)\n    - sdid (bool)\n    - *Structured Data* (string)\n  - timestamp: the time the messages was received\n\n#### Structured Data\n\nStructured data produces field keys by combining the `SD_ID` with the `PARAM_NAME` combined using the `sdparam_separator` as in the following example:\n```\n170 <165>1 2018-10-01:14:15.000Z mymachine.example.com evntslog - ID47 [exampleSDID@32473 iut="3" eventSource="Application" eventID="1011"] An application event log entry...\n```\n```\nsyslog,appname=evntslog,facility=local4,hostname=mymachine.example.com,severity=notice exampleSDID@32473_eventID="1011",exampleSDID@32473_eventSource="Application",exampleSDID@32473_iut="3",facility_code=20i,message="An application event log entry...",msgid="ID47",severity_code=5i,timestamp=1065910455003000000i,version=1i 1538421339749472344\n```\n\n### Troubleshooting\n\nYou can send debugging messages directly to the input plugin using netcat:\n\n```sh\n# TCP with octet framing\necho "57 <13>1 2018-10-01T12:00:00.0Z example.org root - - - test" | nc 127.0.0.1 6514\n\n# UDP\necho "<13>1 2018-10-01T12:00:00.0Z example.org root - - - test" | nc -u 127.0.0.1 6514\n```\n\n#### RFC3164\n\nRFC3164 encoded messages are not currently supported.  You may see the following error if a message encoded in this format:\n```\nE! Error in plugin [inputs.syslog]: expecting a version value in the range 1-999 [col 5]\n```\n\nYou can use rsyslog to translate RFC3164 syslog messages into RFC5424 format.\n',image:Si.a},{id:"sysstat",name:"sysstat",markdown:'# sysstat Input Plugin\n\nCollect [sysstat](https://github.com/sysstat/sysstat) metrics - requires the sysstat\npackage installed.\n\nThis plugin collects system metrics with the sysstat collector utility `sadc` and parses\nthe created binary data file with the `sadf` utility.\n\n### Configuration:\n\n```toml\n# Sysstat metrics collector\n[[inputs.sysstat]]\n  ## Path to the sadc command.\n  #\n  ## On Debian and Arch Linux the default path is /usr/lib/sa/sadc whereas\n  ## on RHEL and CentOS the default path is /usr/lib64/sa/sadc\n  sadc_path = "/usr/lib/sa/sadc" # required\n\n  ## Path to the sadf command, if it is not in PATH\n  # sadf_path = "/usr/bin/sadf"\n\n  ## Activities is a list of activities, that are passed as argument to the\n  ## sadc collector utility (e.g: DISK, SNMP etc...)\n  ## The more activities that are added, the more data is collected.\n  # activities = ["DISK"]\n\n  ## Group metrics to measurements.\n  ##\n  ## If group is false each metric will be prefixed with a description\n  ## and represents itself a measurement.\n  ##\n  ## If Group is true, corresponding metrics are grouped to a single measurement.\n  # group = true\n\n  ## Options for the sadf command. The values on the left represent the sadf options and\n  ## the values on the right their description (wich are used for grouping and prefixing metrics).\n  ##\n  ## Run \'sar -h\' or \'man sar\' to find out the supported options for your sysstat version.\n  [inputs.sysstat.options]\n\t-C = "cpu"\n\t-B = "paging"\n\t-b = "io"\n\t-d = "disk"             # requires DISK activity\n\t"-n ALL" = "network"\n\t"-P ALL" = "per_cpu"\n\t-q = "queue"\n\t-R = "mem"\n\t-r = "mem_util"\n\t-S = "swap_util"\n\t-u = "cpu_util"\n\t-v = "inode"\n\t-W = "swap"\n\t-w = "task"\n  #\t-H = "hugepages"        # only available for newer linux distributions\n  #\t"-I ALL" = "interrupts" # requires INT activity\n\n  ## Device tags can be used to add additional tags for devices. For example the configuration below\n  ## adds a tag vg with value rootvg for all metrics with sda devices.\n  # [[inputs.sysstat.device_tags.sda]]\n  #  vg = "rootvg"\n```\n\n### Measurements & Fields:\n#### If group=true\n- cpu\n    - pct_idle (float)\n    - pct_iowait (float)\n    - pct_nice (float)\n    - pct_steal (float)\n    - pct_system (float)\n    - pct_user (float)\n\n- disk\n    - avgqu-sz (float)\n    - avgrq-sz (float)\n    - await (float)\n    - pct_util (float)\n    - rd_sec_pers (float)\n    - svctm (float)\n    - tps (float)\n\nAnd much more, depending on the options you configure.\n\n#### If group=false\n- cpu_pct_idle\n    - value (float)\n- cpu_pct_iowait\n    - value (float)\n- cpu_pct_nice\n    - value (float)\n- cpu_pct_steal\n    - value (float)\n- cpu_pct_system\n    - value (float)\n- cpu_pct_user\n    - value (float)\n- disk_avgqu-sz\n    - value (float)\n- disk_avgrq-sz\n    - value (float)\n- disk_await\n    - value (float)\n- disk_pct_util\n    - value (float)\n- disk_rd_sec_per_s\n    - value (float)\n- disk_svctm\n    - value (float)\n- disk_tps\n    - value (float)\n\nAnd much more, depending on the options you configure.\n\n### Tags:\n\n- All measurements have the following tags:\n    - device\n\nAnd more if you define some `device_tags`.\n### Example Output:\n\nWith the configuration below:\n```toml\n[[inputs.sysstat]]\n  sadc_path = "/usr/lib/sa/sadc" # required\n  activities = ["DISK", "SNMP", "INT"]\n  group = true\n  [inputs.sysstat.options]\n\t-C = "cpu"\n\t-B = "paging"\n\t-b = "io"\n\t-d = "disk"             # requires DISK activity\n\t-H = "hugepages"\n\t"-I ALL" = "interrupts" # requires INT activity\n\t"-n ALL" = "network"\n\t"-P ALL" = "per_cpu"\n\t-q = "queue"\n\t-R = "mem"\n\t"-r ALL" = "mem_util"\n\t-S = "swap_util"\n\t-u = "cpu_util"\n\t-v = "inode"\n\t-W = "swap"\n\t-w = "task"\n  [[inputs.sysstat.device_tags.sda]]\n    vg = "rootvg"\n```\n\nyou get the following output:\n```\n$ telegraf --config telegraf.conf --input-filter sysstat --test\n* Plugin: sysstat, Collection 1\n> cpu_util,device=all pct_idle=98.85,pct_iowait=0,pct_nice=0.38,pct_steal=0,pct_system=0.64,pct_user=0.13 1459255626657883725\n> swap pswpin_per_s=0,pswpout_per_s=0 1459255626658387650\n> per_cpu,device=cpu1 pct_idle=98.98,pct_iowait=0,pct_nice=0.26,pct_steal=0,pct_system=0.51,pct_user=0.26 1459255626659630437\n> per_cpu,device=all pct_idle=98.85,pct_iowait=0,pct_nice=0.38,pct_steal=0,pct_system=0.64,pct_user=0.13 1459255626659670744\n> per_cpu,device=cpu0 pct_idle=98.73,pct_iowait=0,pct_nice=0.76,pct_steal=0,pct_system=0.51,pct_user=0 1459255626659697515\n> hugepages kbhugfree=0,kbhugused=0,pct_hugused=0 1459255626660057517\n> network,device=lo coll_per_s=0,pct_ifutil=0,rxcmp_per_s=0,rxdrop_per_s=0,rxerr_per_s=0,rxfifo_per_s=0,rxfram_per_s=0,rxkB_per_s=0.81,rxmcst_per_s=0,rxpck_per_s=16,txcarr_per_s=0,txcmp_per_s=0,txdrop_per_s=0,txerr_per_s=0,txfifo_per_s=0,txkB_per_s=0.81,txpck_per_s=16 1459255626661197666\n> network access_per_s=0,active_per_s=0,asmf_per_s=0,asmok_per_s=0,asmrq_per_s=0,atmptf_per_s=0,badcall_per_s=0,call_per_s=0,estres_per_s=0,fragcrt_per_s=0,fragf_per_s=0,fragok_per_s=0,fwddgm_per_s=0,getatt_per_s=0,hit_per_s=0,iadrerr_per_s=0,iadrmk_per_s=0,iadrmkr_per_s=0,idel_per_s=16,idgm_per_s=0,idgmerr_per_s=0,idisc_per_s=0,idstunr_per_s=0,iech_per_s=0,iechr_per_s=0,ierr_per_s=0,ihdrerr_per_s=0,imsg_per_s=0,ip-frag=0,iparmpb_per_s=0,irec_per_s=16,iredir_per_s=0,iseg_per_s=16,isegerr_per_s=0,isrcq_per_s=0,itm_per_s=0,itmex_per_s=0,itmr_per_s=0,iukwnpr_per_s=0,miss_per_s=0,noport_per_s=0,oadrmk_per_s=0,oadrmkr_per_s=0,odgm_per_s=0,odisc_per_s=0,odstunr_per_s=0,oech_per_s=0,oechr_per_s=0,oerr_per_s=0,omsg_per_s=0,onort_per_s=0,oparmpb_per_s=0,oredir_per_s=0,orq_per_s=16,orsts_per_s=0,oseg_per_s=16,osrcq_per_s=0,otm_per_s=0,otmex_per_s=0,otmr_per_s=0,packet_per_s=0,passive_per_s=0,rawsck=0,read_per_s=0,retrans_per_s=0,saccess_per_s=0,scall_per_s=0,sgetatt_per_s=0,sread_per_s=0,swrite_per_s=0,tcp-tw=7,tcp_per_s=0,tcpsck=1543,totsck=4052,udp_per_s=0,udpsck=2,write_per_s=0 1459255626661381788\n> network,device=ens33 coll_per_s=0,pct_ifutil=0,rxcmp_per_s=0,rxdrop_per_s=0,rxerr_per_s=0,rxfifo_per_s=0,rxfram_per_s=0,rxkB_per_s=0,rxmcst_per_s=0,rxpck_per_s=0,txcarr_per_s=0,txcmp_per_s=0,txdrop_per_s=0,txerr_per_s=0,txfifo_per_s=0,txkB_per_s=0,txpck_per_s=0 1459255626661533072\n> disk,device=sda,vg=rootvg avgqu-sz=0.01,avgrq-sz=8.5,await=3.31,pct_util=0.1,rd_sec_per_s=0,svctm=0.25,tps=4,wr_sec_per_s=34 1459255626663974389\n> queue blocked=0,ldavg-1=1.61,ldavg-15=1.34,ldavg-5=1.67,plist-sz=1415,runq-sz=0 1459255626664159054\n> paging fault_per_s=0.25,majflt_per_s=0,pct_vmeff=0,pgfree_per_s=19,pgpgin_per_s=0,pgpgout_per_s=17,pgscand_per_s=0,pgscank_per_s=0,pgsteal_per_s=0 1459255626664304249\n> mem_util kbactive=2206568,kbanonpg=1472208,kbbuffers=118020,kbcached=1035252,kbcommit=8717200,kbdirty=156,kbinact=418912,kbkstack=24672,kbmemfree=1744868,kbmemused=3610272,kbpgtbl=87116,kbslab=233804,kbvmused=0,pct_commit=136.13,pct_memused=67.42 1459255626664554981\n> io bread_per_s=0,bwrtn_per_s=34,rtps=0,tps=4,wtps=4 1459255626664596198\n> inode dentunusd=235039,file-nr=17120,inode-nr=94505,pty-nr=14 1459255626664663693\n> interrupts,device=i000 intr_per_s=0 1459255626664800109\n> interrupts,device=i003 intr_per_s=0 1459255626665255145\n> interrupts,device=i004 intr_per_s=0 1459255626665281776\n> interrupts,device=i006 intr_per_s=0 1459255626665297416\n> interrupts,device=i007 intr_per_s=0 1459255626665321008\n> interrupts,device=i010 intr_per_s=0 1459255626665339413\n> interrupts,device=i012 intr_per_s=0 1459255626665361510\n> interrupts,device=i013 intr_per_s=0 1459255626665381327\n> interrupts,device=i015 intr_per_s=1 1459255626665397313\n> interrupts,device=i001 intr_per_s=0.25 1459255626665412985\n> interrupts,device=i002 intr_per_s=0 1459255626665430475\n> interrupts,device=i005 intr_per_s=0 1459255626665453944\n> interrupts,device=i008 intr_per_s=0 1459255626665470650\n> interrupts,device=i011 intr_per_s=0 1459255626665486069\n> interrupts,device=i009 intr_per_s=0 1459255626665502913\n> interrupts,device=i014 intr_per_s=0 1459255626665518152\n> task cswch_per_s=722.25,proc_per_s=0 1459255626665849646\n> cpu,device=all pct_idle=98.85,pct_iowait=0,pct_nice=0.38,pct_steal=0,pct_system=0.64,pct_user=0.13 1459255626666639715\n> mem bufpg_per_s=0,campg_per_s=1.75,frmpg_per_s=-8.25 1459255626666770205\n> swap_util kbswpcad=0,kbswpfree=1048572,kbswpused=0,pct_swpcad=0,pct_swpused=0 1459255626667313276\n```\n\nIf you change the group value to false like below:\n```toml\n[[inputs.sysstat]]\n  sadc_path = "/usr/lib/sa/sadc" # required\n  activities = ["DISK", "SNMP", "INT"]\n  group = false\n  [inputs.sysstat.options]\n\t-C = "cpu"\n\t-B = "paging"\n\t-b = "io"\n\t-d = "disk"             # requires DISK activity\n\t-H = "hugepages"\n\t"-I ALL" = "interrupts" # requires INT activity\n\t"-n ALL" = "network"\n\t"-P ALL" = "per_cpu"\n\t-q = "queue"\n\t-R = "mem"\n\t"-r ALL" = "mem_util"\n\t-S = "swap_util"\n\t-u = "cpu_util"\n\t-v = "inode"\n\t-W = "swap"\n\t-w = "task"\n  [[inputs.sysstat.device_tags.sda]]\n    vg = "rootvg"\n```\n\nyou get the following output:\n```\n$ telegraf -config telegraf.conf -input-filter sysstat -test\n* Plugin: sysstat, Collection 1\n> io_tps value=0.5 1459255780126025822\n> io_rtps value=0 1459255780126025822\n> io_wtps value=0.5 1459255780126025822\n> io_bread_per_s value=0 1459255780126025822\n> io_bwrtn_per_s value=38 1459255780126025822\n> cpu_util_pct_user,device=all value=39.07 1459255780126025822\n> cpu_util_pct_nice,device=all value=0 1459255780126025822\n> cpu_util_pct_system,device=all value=47.94 1459255780126025822\n> cpu_util_pct_iowait,device=all value=0 1459255780126025822\n> cpu_util_pct_steal,device=all value=0 1459255780126025822\n> cpu_util_pct_idle,device=all value=12.98 1459255780126025822\n> swap_pswpin_per_s value=0 1459255780126025822\n> cpu_pct_user,device=all value=39.07 1459255780126025822\n> cpu_pct_nice,device=all value=0 1459255780126025822\n> cpu_pct_system,device=all value=47.94 1459255780126025822\n> cpu_pct_iowait,device=all value=0 1459255780126025822\n> cpu_pct_steal,device=all value=0 1459255780126025822\n> cpu_pct_idle,device=all value=12.98 1459255780126025822\n> per_cpu_pct_user,device=all value=39.07 1459255780126025822\n> per_cpu_pct_nice,device=all value=0 1459255780126025822\n> per_cpu_pct_system,device=all value=47.94 1459255780126025822\n> per_cpu_pct_iowait,device=all value=0 1459255780126025822\n> per_cpu_pct_steal,device=all value=0 1459255780126025822\n> per_cpu_pct_idle,device=all value=12.98 1459255780126025822\n> per_cpu_pct_user,device=cpu0 value=33.5 1459255780126025822\n> per_cpu_pct_nice,device=cpu0 value=0 1459255780126025822\n> per_cpu_pct_system,device=cpu0 value=65.25 1459255780126025822\n> per_cpu_pct_iowait,device=cpu0 value=0 1459255780126025822\n> per_cpu_pct_steal,device=cpu0 value=0 1459255780126025822\n> per_cpu_pct_idle,device=cpu0 value=1.25 1459255780126025822\n> per_cpu_pct_user,device=cpu1 value=44.85 1459255780126025822\n> per_cpu_pct_nice,device=cpu1 value=0 1459255780126025822\n> per_cpu_pct_system,device=cpu1 value=29.55 1459255780126025822\n> per_cpu_pct_iowait,device=cpu1 value=0 1459255780126025822\n> per_cpu_pct_steal,device=cpu1 value=0 1459255780126025822\n> per_cpu_pct_idle,device=cpu1 value=25.59 1459255780126025822\n> hugepages_kbhugfree value=0 1459255780126025822\n> hugepages_kbhugused value=0 1459255780126025822\n> hugepages_pct_hugused value=0 1459255780126025822\n> interrupts_intr_per_s,device=i000 value=0 1459255780126025822\n> inode_dentunusd value=252876 1459255780126025822\n> mem_util_kbmemfree value=1613612 1459255780126025822\n> disk_tps,device=sda,vg=rootvg value=0.5 1459255780126025822\n> swap_pswpout_per_s value=0 1459255780126025822\n> network_rxpck_per_s,device=ens33 value=0 1459255780126025822\n> queue_runq-sz value=4 1459255780126025822\n> task_proc_per_s value=0 1459255780126025822\n> task_cswch_per_s value=2019 1459255780126025822\n> mem_frmpg_per_s value=0 1459255780126025822\n> mem_bufpg_per_s value=0.5 1459255780126025822\n> mem_campg_per_s value=1.25 1459255780126025822\n> interrupts_intr_per_s,device=i001 value=0 1459255780126025822\n> inode_file-nr value=19104 1459255780126025822\n> mem_util_kbmemused value=3741528 1459255780126025822\n> disk_rd_sec_per_s,device=sda,vg=rootvg value=0 1459255780126025822\n> network_txpck_per_s,device=ens33 value=0 1459255780126025822\n> queue_plist-sz value=1512 1459255780126025822\n> paging_pgpgin_per_s value=0 1459255780126025822\n> paging_pgpgout_per_s value=19 1459255780126025822\n> paging_fault_per_s value=0.25 1459255780126025822\n> paging_majflt_per_s value=0 1459255780126025822\n> paging_pgfree_per_s value=34.25 1459255780126025822\n> paging_pgscank_per_s value=0 1459255780126025822\n> paging_pgscand_per_s value=0 1459255780126025822\n> paging_pgsteal_per_s value=0 1459255780126025822\n> paging_pct_vmeff value=0 1459255780126025822\n> interrupts_intr_per_s,device=i002 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i003 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i004 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i005 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i006 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i007 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i008 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i009 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i010 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i011 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i012 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i013 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i014 value=0 1459255780126025822\n> interrupts_intr_per_s,device=i015 value=1 1459255780126025822\n> inode_inode-nr value=94709 1459255780126025822\n> inode_pty-nr value=14 1459255780126025822\n> mem_util_pct_memused value=69.87 1459255780126025822\n> mem_util_kbbuffers value=118252 1459255780126025822\n> mem_util_kbcached value=1045240 1459255780126025822\n> mem_util_kbcommit value=9628152 1459255780126025822\n> mem_util_pct_commit value=150.35 1459255780126025822\n> mem_util_kbactive value=2303752 1459255780126025822\n> mem_util_kbinact value=428340 1459255780126025822\n> mem_util_kbdirty value=104 1459255780126025822\n> mem_util_kbanonpg value=1568676 1459255780126025822\n> mem_util_kbslab value=240032 1459255780126025822\n> mem_util_kbkstack value=26224 1459255780126025822\n> mem_util_kbpgtbl value=98056 1459255780126025822\n> mem_util_kbvmused value=0 1459255780126025822\n> disk_wr_sec_per_s,device=sda,vg=rootvg value=38 1459255780126025822\n> disk_avgrq-sz,device=sda,vg=rootvg value=76 1459255780126025822\n> disk_avgqu-sz,device=sda,vg=rootvg value=0 1459255780126025822\n> disk_await,device=sda,vg=rootvg value=2 1459255780126025822\n> disk_svctm,device=sda,vg=rootvg value=2 1459255780126025822\n> disk_pct_util,device=sda,vg=rootvg value=0.1 1459255780126025822\n> network_rxkB_per_s,device=ens33 value=0 1459255780126025822\n> network_txkB_per_s,device=ens33 value=0 1459255780126025822\n> network_rxcmp_per_s,device=ens33 value=0 1459255780126025822\n> network_txcmp_per_s,device=ens33 value=0 1459255780126025822\n> network_rxmcst_per_s,device=ens33 value=0 1459255780126025822\n> network_pct_ifutil,device=ens33 value=0 1459255780126025822\n> network_rxpck_per_s,device=lo value=10.75 1459255780126025822\n> network_txpck_per_s,device=lo value=10.75 1459255780126025822\n> network_rxkB_per_s,device=lo value=0.77 1459255780126025822\n> network_txkB_per_s,device=lo value=0.77 1459255780126025822\n> network_rxcmp_per_s,device=lo value=0 1459255780126025822\n> network_txcmp_per_s,device=lo value=0 1459255780126025822\n> network_rxmcst_per_s,device=lo value=0 1459255780126025822\n> network_pct_ifutil,device=lo value=0 1459255780126025822\n> network_rxerr_per_s,device=ens33 value=0 1459255780126025822\n> network_txerr_per_s,device=ens33 value=0 1459255780126025822\n> network_coll_per_s,device=ens33 value=0 1459255780126025822\n> network_rxdrop_per_s,device=ens33 value=0 1459255780126025822\n> network_txdrop_per_s,device=ens33 value=0 1459255780126025822\n> network_txcarr_per_s,device=ens33 value=0 1459255780126025822\n> network_rxfram_per_s,device=ens33 value=0 1459255780126025822\n> network_rxfifo_per_s,device=ens33 value=0 1459255780126025822\n> network_txfifo_per_s,device=ens33 value=0 1459255780126025822\n> network_rxerr_per_s,device=lo value=0 1459255780126025822\n> network_txerr_per_s,device=lo value=0 1459255780126025822\n> network_coll_per_s,device=lo value=0 1459255780126025822\n> network_rxdrop_per_s,device=lo value=0 1459255780126025822\n> network_txdrop_per_s,device=lo value=0 1459255780126025822\n> network_txcarr_per_s,device=lo value=0 1459255780126025822\n> network_rxfram_per_s,device=lo value=0 1459255780126025822\n> network_rxfifo_per_s,device=lo value=0 1459255780126025822\n> network_txfifo_per_s,device=lo value=0 1459255780126025822\n> network_call_per_s value=0 1459255780126025822\n> network_retrans_per_s value=0 1459255780126025822\n> network_read_per_s value=0 1459255780126025822\n> network_write_per_s value=0 1459255780126025822\n> network_access_per_s value=0 1459255780126025822\n> network_getatt_per_s value=0 1459255780126025822\n> network_scall_per_s value=0 1459255780126025822\n> network_badcall_per_s value=0 1459255780126025822\n> network_packet_per_s value=0 1459255780126025822\n> network_udp_per_s value=0 1459255780126025822\n> network_tcp_per_s value=0 1459255780126025822\n> network_hit_per_s value=0 1459255780126025822\n> network_miss_per_s value=0 1459255780126025822\n> network_sread_per_s value=0 1459255780126025822\n> network_swrite_per_s value=0 1459255780126025822\n> network_saccess_per_s value=0 1459255780126025822\n> network_sgetatt_per_s value=0 1459255780126025822\n> network_totsck value=4234 1459255780126025822\n> network_tcpsck value=1637 1459255780126025822\n> network_udpsck value=2 1459255780126025822\n> network_rawsck value=0 1459255780126025822\n> network_ip-frag value=0 1459255780126025822\n> network_tcp-tw value=4 1459255780126025822\n> network_irec_per_s value=10.75 1459255780126025822\n> network_fwddgm_per_s value=0 1459255780126025822\n> network_idel_per_s value=10.75 1459255780126025822\n> network_orq_per_s value=10.75 1459255780126025822\n> network_asmrq_per_s value=0 1459255780126025822\n> network_asmok_per_s value=0 1459255780126025822\n> network_fragok_per_s value=0 1459255780126025822\n> network_fragcrt_per_s value=0 1459255780126025822\n> network_ihdrerr_per_s value=0 1459255780126025822\n> network_iadrerr_per_s value=0 1459255780126025822\n> network_iukwnpr_per_s value=0 1459255780126025822\n> network_idisc_per_s value=0 1459255780126025822\n> network_odisc_per_s value=0 1459255780126025822\n> network_onort_per_s value=0 1459255780126025822\n> network_asmf_per_s value=0 1459255780126025822\n> network_fragf_per_s value=0 1459255780126025822\n> network_imsg_per_s value=0 1459255780126025822\n> network_omsg_per_s value=0 1459255780126025822\n> network_iech_per_s value=0 1459255780126025822\n> network_iechr_per_s value=0 1459255780126025822\n> network_oech_per_s value=0 1459255780126025822\n> network_oechr_per_s value=0 1459255780126025822\n> network_itm_per_s value=0 1459255780126025822\n> network_itmr_per_s value=0 1459255780126025822\n> network_otm_per_s value=0 1459255780126025822\n> network_otmr_per_s value=0 1459255780126025822\n> network_iadrmk_per_s value=0 1459255780126025822\n> network_iadrmkr_per_s value=0 1459255780126025822\n> network_oadrmk_per_s value=0 1459255780126025822\n> network_oadrmkr_per_s value=0 1459255780126025822\n> network_ierr_per_s value=0 1459255780126025822\n> network_oerr_per_s value=0 1459255780126025822\n> network_idstunr_per_s value=0 1459255780126025822\n> network_odstunr_per_s value=0 1459255780126025822\n> network_itmex_per_s value=0 1459255780126025822\n> network_otmex_per_s value=0 1459255780126025822\n> network_iparmpb_per_s value=0 1459255780126025822\n> network_oparmpb_per_s value=0 1459255780126025822\n> network_isrcq_per_s value=0 1459255780126025822\n> network_osrcq_per_s value=0 1459255780126025822\n> network_iredir_per_s value=0 1459255780126025822\n> network_oredir_per_s value=0 1459255780126025822\n> network_active_per_s value=0 1459255780126025822\n> network_passive_per_s value=0 1459255780126025822\n> network_iseg_per_s value=10.75 1459255780126025822\n> network_oseg_per_s value=9.5 1459255780126025822\n> network_atmptf_per_s value=0 1459255780126025822\n> network_estres_per_s value=0 1459255780126025822\n> network_retrans_per_s value=1.5 1459255780126025822\n> network_isegerr_per_s value=0.25 1459255780126025822\n> network_orsts_per_s value=0 1459255780126025822\n> network_idgm_per_s value=0 1459255780126025822\n> network_odgm_per_s value=0 1459255780126025822\n> network_noport_per_s value=0 1459255780126025822\n> network_idgmerr_per_s value=0 1459255780126025822\n> queue_ldavg-1 value=2.1 1459255780126025822\n> queue_ldavg-5 value=1.82 1459255780126025822\n> queue_ldavg-15 value=1.44 1459255780126025822\n> queue_blocked value=0 1459255780126025822\n> swap_util_kbswpfree value=1048572 1459255780126025822\n> swap_util_kbswpused value=0 1459255780126025822\n> swap_util_pct_swpused value=0 1459255780126025822\n> swap_util_kbswpcad value=0 1459255780126025822\n> swap_util_pct_swpcad value=0 1459255780126025822\n```\n',image:Ci.a},{id:"system",name:"System",markdown:'# System Input Plugin\n\nThe system plugin gathers general stats on system load, uptime,\nand number of users logged in. It is similar to the unix `uptime` command.\n\nNumber of CPUs is obtained from the /proc/cpuinfo file.\n\n### Configuration:\n\n```toml\n# Read metrics about system load & uptime\n[[inputs.system]]\n  # no configuration\n```\n#### Permissions:\n\nThe `n_users` field requires read access to `/var/run/utmp`, and may require\nthe `telegraf` user to be added to the `utmp` group on some systems. If this file does not exist `n_users` will be skipped.\n\n### Metrics:\n\n- system\n  - fields:\n\t- load1 (float)\n\t- load15 (float)\n\t- load5 (float)\n\t- n_users (integer)\n\t- n_cpus (integer)\n\t- uptime (integer, seconds)\n\t- uptime_format (string, deprecated in 1.10, use `uptime` field)\n\n### Example Output:\n\n```\nsystem,host=tyrion load1=3.72,load5=2.4,load15=2.1,n_users=3i,n_cpus=4i 1483964144000000000\nsystem,host=tyrion uptime=1249632i 1483964144000000000\nsystem,host=tyrion uptime_format="14 days, 11:07" 1483964144000000000\n```\n',image:Mi.a},{id:"systemd_units",name:"systemd Units",markdown:'# systemd Units Input Plugin\n\nThe systemd_units plugin gathers systemd unit status on Linux. It relies on\n`systemctl list-units --all --plain --type=service` to collect data on service status.\n\nThe results are tagged with the unit name and provide enumerated fields for\nloaded, active and running fields, indicating the unit health.\n\nThis plugin is related to the [win_services module](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/win_services/), which\nfulfills the same purpose on windows.\n\nIn addition to services, this plugin can gather other unit types as well,\nsee `systemctl list-units --all --type help` for possible options.\n\n### Configuration\n```toml\n[[inputs.systemd_units]]\n  ## Set timeout for systemctl execution\n  # timeout = "1s"\n  #\n  ## Filter for a specific unit type, default is "service", other possible\n  ## values are "socket", "target", "device", "mount", "automount", "swap",\n  ## "timer", "path", "slice" and "scope ":\n  # unittype = "service"\n```\n\n### Metrics\n- systemd_units:\n  - tags:\n    - name (string, unit name)\n    - load (string, load state)\n    - active (string, active state)\n    - sub (string, sub state)\n  - fields:\n    - load_code (int, see below)\n    - active_code (int, see below)\n    - sub_code (int, see below)\n\n#### Load\n\nenumeration of [unit_load_state_table](https://github.com/systemd/systemd/blob/c87700a1335f489be31cd3549927da68b5638819/src/basic/unit-def.c#L87)\n\n| Value | Meaning     | Description                     |\n| ----- | -------     | -----------                     |\n| 0     | loaded      | unit is ~                       |\n| 1     | stub        | unit is ~                       |\n| 2     | not-found   | unit is ~                       |\n| 3     | bad-setting | unit is ~                       |\n| 4     | error       | unit is ~                       |\n| 5     | merged      | unit is ~                       |\n| 6     | masked      | unit is ~                       |\n\n#### Active\n\nenumeration of [unit_active_state_table](https://github.com/systemd/systemd/blob/c87700a1335f489be31cd3549927da68b5638819/src/basic/unit-def.c#L99)\n\n| Value | Meaning   | Description                        |\n| ----- | -------   | -----------                        |\n| 0     | active       | unit is ~                       |\n| 1     | reloading    | unit is ~                       |\n| 2     | inactive     | unit is ~                       |\n| 3     | failed       | unit is ~                       |\n| 4     | activating   | unit is ~                       |\n| 5     | deactivating | unit is ~                       |\n\n#### Sub\n\nenumeration of sub states, see various [unittype_state_tables](https://github.com/systemd/systemd/blob/c87700a1335f489be31cd3549927da68b5638819/src/basic/unit-def.c#L163);\nduplicates were removed, tables are hex aligned to keep some space for future\nvalues\n\n| Value  | Meaning               | Description                         |\n| -----  | -------               | -----------                         |\n|        |                       | service_state_table start at 0x0000 |\n| 0x0000 | running               | unit is ~                           |\n| 0x0001 | dead                  | unit is ~                           |\n| 0x0002 | start-pre             | unit is ~                           |\n| 0x0003 | start                 | unit is ~                           |\n| 0x0004 | exited                | unit is ~                           |\n| 0x0005 | reload                | unit is ~                           |\n| 0x0006 | stop                  | unit is ~                           |\n| 0x0007 | stop-watchdog         | unit is ~                           |\n| 0x0008 | stop-sigterm          | unit is ~                           |\n| 0x0009 | stop-sigkill          | unit is ~                           |\n| 0x000a | stop-post             | unit is ~                           |\n| 0x000b | final-sigterm         | unit is ~                           |\n| 0x000c | failed                | unit is ~                           |\n| 0x000d | auto-restart          | unit is ~                           |\n|        |                       | service_state_table start at 0x0010 |\n| 0x0010 | waiting               | unit is ~                           |\n|        |                       | service_state_table start at 0x0020 |\n| 0x0020 | tentative             | unit is ~                           |\n| 0x0021 | plugged               | unit is ~                           |\n|        |                       | service_state_table start at 0x0030 |\n| 0x0030 | mounting              | unit is ~                           |\n| 0x0031 | mounting-done         | unit is ~                           |\n| 0x0032 | mounted               | unit is ~                           |\n| 0x0033 | remounting            | unit is ~                           |\n| 0x0034 | unmounting            | unit is ~                           |\n| 0x0035 | remounting-sigterm    | unit is ~                           |\n| 0x0036 | remounting-sigkill    | unit is ~                           |\n| 0x0037 | unmounting-sigterm    | unit is ~                           |\n| 0x0038 | unmounting-sigkill    | unit is ~                           |\n|        |                       | service_state_table start at 0x0040 |\n|        |                       | service_state_table start at 0x0050 |\n| 0x0050 | abandoned             | unit is ~                           |\n|        |                       | service_state_table start at 0x0060 |\n| 0x0060 | active                | unit is ~                           |\n|        |                       | service_state_table start at 0x0070 |\n| 0x0070 | start-chown           | unit is ~                           |\n| 0x0071 | start-post            | unit is ~                           |\n| 0x0072 | listening             | unit is ~                           |\n| 0x0073 | stop-pre              | unit is ~                           |\n| 0x0074 | stop-pre-sigterm      | unit is ~                           |\n| 0x0075 | stop-pre-sigkill      | unit is ~                           |\n| 0x0076 | final-sigkill         | unit is ~                           |\n|        |                       | service_state_table start at 0x0080 |\n| 0x0080 | activating            | unit is ~                           |\n| 0x0081 | activating-done       | unit is ~                           |\n| 0x0082 | deactivating          | unit is ~                           |\n| 0x0083 | deactivating-sigterm  | unit is ~                           |\n| 0x0084 | deactivating-sigkill  | unit is ~                           |\n|        |                       | service_state_table start at 0x0090 |\n|        |                       | service_state_table start at 0x00a0 |\n| 0x00a0 | elapsed               | unit is ~                           |\n|        |                       |                                     |\n\n### Example Output\n\n```\nsystemd_units,host=host1.example.com,name=dbus.service,load=loaded,active=active,sub=running load_code=0i,active_code=0i,sub_code=0i 1533730725000000000\nsystemd_units,host=host1.example.com,name=networking.service,load=loaded,active=failed,sub=failed load_code=0i,active_code=3i,sub_code=12i 1533730725000000000\nsystemd_units,host=host1.example.com,name=ssh.service,load=loaded,active=active,sub=running load_code=0i,active_code=0i,sub_code=0i 1533730725000000000\n...\n```\n',image:Pi.a},{id:"tail",name:"Tail",markdown:'# Tail Input Plugin\n\nThe tail plugin "tails" a logfile and parses each log message.\n\nBy default, the tail plugin acts like the following unix tail command:\n\n```\ntail -F --lines=0 myfile.log\n```\n\n- `-F` means that it will follow the _name_ of the given file, so\nthat it will be compatible with log-rotated files, and that it will retry on\ninaccessible files.\n- `--lines=0` means that it will start at the end of the file (unless\nthe `from_beginning` option is set).\n\nsee http://man7.org/linux/man-pages/man1/tail.1.html for more details.\n\nThe plugin expects messages in one of the\n[Telegraf Input Data Formats](https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md).\n\n### Configuration\n\n```toml\n[[inputs.tail]]\n  ## File names or a pattern to tail.\n  ## These accept standard unix glob matching rules, but with the addition of\n  ## ** as a "super asterisk". ie:\n  ##   "/var/log/**.log"  -> recursively find all .log files in /var/log\n  ##   "/var/log/*/*.log" -> find all .log files with a parent dir in /var/log\n  ##   "/var/log/apache.log" -> just tail the apache log file\n  ##   "/var/log/log[!1-2]*  -> tail files without 1-2\n  ##   "/var/log/log[^1-2]*  -> identical behavior as above\n  ## See https://github.com/gobwas/glob for more examples\n  ##\n  files = ["/var/mymetrics.out"]\n\n  ## Read file from beginning.\n  # from_beginning = false\n\n  ## Whether file is a named pipe\n  # pipe = false\n\n  ## Method used to watch for file updates.  Can be either "inotify" or "poll".\n  # watch_method = "inotify"\n\n  ## Maximum lines of the file to process that have not yet be written by the\n  ## output.  For best throughput set based on the number of metrics on each\n  ## line and the size of the output\'s metric_batch_size.\n  # max_undelivered_lines = 1000\n\n  ## Character encoding to use when interpreting the file contents.  Invalid\n  ## characters are replaced using the unicode replacement character.  When set\n  ## to the empty string the data is not decoded to text.\n  ##   ex: character_encoding = "utf-8"\n  ##       character_encoding = "utf-16le"\n  ##       character_encoding = "utf-16be"\n  ##       character_encoding = ""\n  # character_encoding = ""\n\n  ## Data format to consume.\n  ## Each data format has its own unique set of configuration options, read\n  ## more about them here:\n  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n  data_format = "influx"\n\n  ## Set the tag that will contain the path of the tailed file. If you don\'t want this tag, set it to an empty string.\n  # path_tag = "path"\n\n  ## multiline parser/codec\n  ## https://www.elastic.co/guide/en/logstash/2.4/plugins-filters-multiline.html\n  #[inputs.tail.multiline]\n    ## The pattern should be a regexp which matches what you believe to be an indicator that the field is part of an event consisting of multiple lines of log data.\n    #pattern = "^\\s"\n\n    ## The field\'s value must be previous or next and indicates the relation to the\n    ## multi-line event.\n    #match_which_line = "previous"\n\n    ## The invert_match can be true or false (defaults to false). \n    ## If true, a message not matching the pattern will constitute a match of the multiline filter and the what will be applied. (vice-versa is also true)\n    #invert_match = false\n\n    #After the specified timeout, this plugin sends the multiline event even if no new pattern is found to start a new event. The default is 5s.\n    #timeout = 5s\n```\n\n### Metrics\n\nMetrics are produced according to the `data_format` option.  Additionally a\ntag labeled `path` is added to the metric containing the filename being tailed.\n',image:Ei.a},{id:"tcp_listener",name:"TCP Listener",markdown:"# TCP Listener Input Plugin\n\n> DEPRECATED: As of version 1.3 the TCP listener plugin has been deprecated in favor of the\n> [socket_listener plugin](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/socket_listener)\n",image:Ni.a},{id:"teamspeak",name:"Teamspeak 3",markdown:'# Teamspeak 3 Input Plugin\n\nThis plugin uses the Teamspeak 3 ServerQuery interface of the Teamspeak server to collect statistics of one or more\nvirtual servers. If you are querying an external Teamspeak server, make sure to add the host which is running Telegraf\nto query_ip_whitelist.txt in the Teamspeak Server directory. For information about how to configure the server take a look \nthe [Teamspeak 3 ServerQuery Manual](http://media.teamspeak.com/ts3_literature/TeamSpeak%203%20Server%20Query%20Manual.pdf)\n\n### Configuration:\n\n```toml\n# Reads metrics from a Teamspeak 3 Server via ServerQuery\n[[inputs.teamspeak]]\n  ## Server address for Teamspeak 3 ServerQuery\n  # server = "127.0.0.1:10011"\n  ## Username for ServerQuery\n  username = "serverqueryuser"\n  ## Password for ServerQuery\n  password = "secret"\n  ## Array of virtual servers\n  # virtual_servers = [1]\n```\n\n### Measurements:\n\n- teamspeak\n    - uptime\n    - clients_online\n    - total_ping\n    - total_packet_loss\n    - packets_sent_total\n    - packets_received_total\n    - bytes_sent_total\n    - bytes_received_total\n    - query_clients_online\n\n### Tags:\n\n- The following tags are used:\n    - virtual_server\n    - name\n\n### Example output:\n\n```\nteamspeak,virtual_server=1,name=LeopoldsServer,host=vm01 bytes_received_total=29638202639i,uptime=13567846i,total_ping=26.89,total_packet_loss=0,packets_sent_total=415821252i,packets_received_total=237069900i,bytes_sent_total=55309568252i,clients_online=11i,query_clients_online=1i 1507406561000000000\n```',image:Li.a},{id:"temp",name:"Temperature",markdown:"# Temperature Input Plugin\n\nThe temp input plugin gather metrics on system temperature.  This plugin is\nmeant to be multi platform and uses platform specific collection methods.\n\nCurrently supports Linux and Windows.\n\n### Configuration\n\n```toml\n[[inputs.temp]]\n  # no configuration\n```\n\n### Metrics\n\n- temp\n  - tags:\n    - sensor\n  - fields:\n    - temp (float, celcius)\n\n\n### Troubleshooting\n\nOn **Windows**, the plugin uses a WMI call that is can be replicated with the\nfollowing command:\n```\nwmic /namespace:\\\\root\\wmi PATH MSAcpi_ThermalZoneTemperature\n```\n\n### Example Output\n\n```\ntemp,sensor=coretemp_physicalid0_crit temp=100 1531298763000000000\ntemp,sensor=coretemp_physicalid0_critalarm temp=0 1531298763000000000\ntemp,sensor=coretemp_physicalid0_input temp=100 1531298763000000000\ntemp,sensor=coretemp_physicalid0_max temp=100 1531298763000000000\n```\n",image:Ui.a},{id:"tengine",name:"Tengine",markdown:'# Tengine Input Plugin\n\nThe tengine plugin gathers metrics from the\n[Tengine Web Server](http://tengine.taobao.org/) via the\n[reqstat](http://tengine.taobao.org/document/http_reqstat.html) module.\n\n### Configuration:\n\n```toml\n# Read Tengine\'s basic status information (ngx_http_reqstat_module)\n[[inputs.tengine]]\n  ## An array of Tengine reqstat module URI to gather stats.\n  urls = ["http://127.0.0.1/us"]\n\n  ## HTTP response timeout (default: 5s)\n  # response_timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Metrics:\n\n- Measurement\n  - tags:\n    - port\n    - server\n    - server_name\n  - fields:\n    - bytes_in (integer, total number of bytes received from client)\n    - bytes_out (integer, total number of bytes sent to client)\n    - conn_total (integer, total number of accepted connections)\n    - req_total (integer, total number of processed requests)\n    - http_2xx (integer, total number of 2xx requests)\n    - http_3xx (integer, total number of 3xx requests)\n    - http_4xx (integer, total number of 4xx requests)\n    - http_5xx (integer, total number of 5xx requests)\n    - http_other_status (integer, total number of other requests)\n    - rt (integer, accumulation or rt)\n    - ups_req (integer, total number of requests calling for upstream)\n    - ups_rt (integer, accumulation or upstream rt)\n    - ups_tries (integer, total number of times calling for upstream)\n    - http_200 (integer, total number of 200 requests)\n    - http_206 (integer, total number of 206 requests)\n    - http_302 (integer, total number of 302 requests)\n    - http_304 (integer, total number of 304 requests)\n    - http_403 (integer, total number of 403 requests)\n    - http_404 (integer, total number of 404 requests)\n    - http_416 (integer, total number of 416 requests)\n    - http_499 (integer, total number of 499 requests)\n    - http_500 (integer, total number of 500 requests)\n    - http_502 (integer, total number of 502 requests)\n    - http_503 (integer, total number of 503 requests)\n    - http_504 (integer, total number of 504 requests)\n    - http_508 (integer, total number of 508 requests)\n    - http_other_detail_status (integer, total number of requests of other status codes*http_ups_4xx total number of requests of upstream 4xx)\n    - http_ups_5xx (integer, total number of requests of upstream 5xx)\n\n### Example Output:\n\n```\ntengine,host=gcp-thz-api-5,port=80,server=localhost,server_name=localhost bytes_in=9129i,bytes_out=56334i,conn_total=14i,http_200=90i,http_206=0i,http_2xx=90i,http_302=0i,http_304=0i,http_3xx=0i,http_403=0i,http_404=0i,http_416=0i,http_499=0i,http_4xx=0i,http_500=0i,http_502=0i,http_503=0i,http_504=0i,http_508=0i,http_5xx=0i,http_other_detail_status=0i,http_other_status=0i,http_ups_4xx=0i,http_ups_5xx=0i,req_total=90i,rt=0i,ups_req=0i,ups_rt=0i,ups_tries=0i 1526546308000000000\ntengine,host=gcp-thz-api-5,port=80,server=localhost,server_name=28.79.190.35.bc.googleusercontent.com bytes_in=1500i,bytes_out=3009i,conn_total=4i,http_200=1i,http_206=0i,http_2xx=1i,http_302=0i,http_304=0i,http_3xx=0i,http_403=0i,http_404=1i,http_416=0i,http_499=0i,http_4xx=3i,http_500=0i,http_502=0i,http_503=0i,http_504=0i,http_508=0i,http_5xx=0i,http_other_detail_status=0i,http_other_status=0i,http_ups_4xx=0i,http_ups_5xx=0i,req_total=4i,rt=0i,ups_req=0i,ups_rt=0i,ups_tries=0i 1526546308000000000\ntengine,host=gcp-thz-api-5,port=80,server=localhost,server_name=www.google.com bytes_in=372i,bytes_out=786i,conn_total=1i,http_200=1i,http_206=0i,http_2xx=1i,http_302=0i,http_304=0i,http_3xx=0i,http_403=0i,http_404=0i,http_416=0i,http_499=0i,http_4xx=0i,http_500=0i,http_502=0i,http_503=0i,http_504=0i,http_508=0i,http_5xx=0i,http_other_detail_status=0i,http_other_status=0i,http_ups_4xx=0i,http_ups_5xx=0i,req_total=1i,rt=0i,ups_req=0i,ups_rt=0i,ups_tries=0i 1526546308000000000\ntengine,host=gcp-thz-api-5,port=80,server=localhost,server_name=35.190.79.28 bytes_in=4433i,bytes_out=10259i,conn_total=5i,http_200=3i,http_206=0i,http_2xx=3i,http_302=0i,http_304=0i,http_3xx=0i,http_403=0i,http_404=11i,http_416=0i,http_499=0i,http_4xx=11i,http_500=0i,http_502=0i,http_503=0i,http_504=0i,http_508=0i,http_5xx=0i,http_other_detail_status=0i,http_other_status=0i,http_ups_4xx=0i,http_ups_5xx=0i,req_total=14i,rt=0i,ups_req=0i,ups_rt=0i,ups_tries=0i 1526546308000000000\ntengine,host=gcp-thz-api-5,port=80,server=localhost,server_name=tenka-prod-api.txwy.tw bytes_in=3014397400i,bytes_out=14279992835i,conn_total=36844i,http_200=3177339i,http_206=0i,http_2xx=3177339i,http_302=0i,http_304=0i,http_3xx=0i,http_403=0i,http_404=123i,http_416=0i,http_499=0i,http_4xx=123i,http_500=17214i,http_502=4453i,http_503=80i,http_504=0i,http_508=0i,http_5xx=21747i,http_other_detail_status=0i,http_other_status=0i,http_ups_4xx=123i,http_ups_5xx=21747i,req_total=3199209i,rt=245874536i,ups_req=2685076i,ups_rt=245858217i,ups_tries=2685076i 1526546308000000000\n```\n',image:Bi.a},{id:"tomcat",name:"Tomcat",markdown:'# Tomcat Input Plugin\n\nThe Tomcat plugin collects statistics available from the tomcat manager status page from the `http://<host>/manager/status/all?XML=true URL.` (`XML=true` will return only xml data).\n\nSee the [Tomcat documentation](https://tomcat.apache.org/tomcat-9.0-doc/manager-howto.html#Server_Status) for details of these statistics.\n\n### Configuration:\n\n```toml\n# Gather metrics from the Tomcat server status page.\n[[inputs.tomcat]]\n  ## URL of the Tomcat server status\n  # url = "http://127.0.0.1:8080/manager/status/all?XML=true"\n\n  ## HTTP Basic Auth Credentials\n  # username = "tomcat"\n  # password = "s3cret"\n\n  ## Request timeout\n  # timeout = "5s"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## Use TLS but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Measurements & Fields:\n\n- tomcat_jvm_memory\n  - free\n  - total\n  - max\n- tomcat_jvm_memorypool\n  - max_threads\n  - current_thread_count\n  - current_threads_busy\n  - max_time\n  - processing_time\n  - request_count\n  - error_count\n  - bytes_received\n  - bytes_sent\n- tomcat_connector\n  - max_threads\n  - current_thread_count\n  - current_thread_busy\n  - max_time\n  - processing_time\n  - request_count\n  - error_count\n  - bytes_received\n  - bytes_sent\n\n### Tags:\n\n- tomcat_jvm_memorypool has the following tags:\n  - name\n  - type\n- tomcat_connector\n  - name\n\n### Example Output:\n\n```\ntomcat_jvm_memory,host=N8-MBP free=20014352i,max=127729664i,total=41459712i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Eden\\ Space,type=Heap\\ memory committed=11534336i,init=2228224i,max=35258368i,used=1941200i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Survivor\\ Space,type=Heap\\ memory committed=1376256i,init=262144i,max=4390912i,used=1376248i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Tenured\\ Gen,type=Heap\\ memory committed=28549120i,init=5636096i,max=88080384i,used=18127912i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Code\\ Cache,type=Non-heap\\ memory committed=6946816i,init=2555904i,max=251658240i,used=6406528i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Compressed\\ Class\\ Space,type=Non-heap\\ memory committed=1966080i,init=0i,max=1073741824i,used=1816120i 1474663361000000000\ntomcat_jvm_memorypool,host=N8-MBP,name=Metaspace,type=Non-heap\\ memory committed=18219008i,init=0i,max=-1i,used=17559376i 1474663361000000000\ntomcat_connector,host=N8-MBP,name=ajp-bio-8009 bytes_received=0i,bytes_sent=0i,current_thread_count=0i,current_threads_busy=0i,error_count=0i,max_threads=200i,max_time=0i,processing_time=0i,request_count=0i 1474663361000000000\ntomcat_connector,host=N8-MBP,name=http-bio-8080 bytes_received=0i,bytes_sent=86435i,current_thread_count=10i,current_threads_busy=1i,error_count=2i,max_threads=200i,max_time=167i,processing_time=245i,request_count=15i 1474663361000000000\n```\n',image:Hi.a},{id:"trig",name:"Trig",markdown:"# Trig Input Plugin\n\nThe `trig` plugin is for demonstration purposes and inserts sine and cosine\n\n### Configuration\n\n```toml\n# Inserts sine and cosine waves for demonstration purposes\n[[inputs.trig]]\n  ## Set the amplitude\n  amplitude = 10.0\n```\n\n### Metrics\n\n- trig\n  - fields:\n    - cosine (float)\n    - sine (float)\n\n\n### Example Output\n\n```\ntrig,host=MBP15-SWANG.local cosine=10,sine=0 1632338680000000000\ntrig,host=MBP15-SWANG.local sine=5.877852522924732,cosine=8.090169943749473 1632338690000000000\ntrig,host=MBP15-SWANG.local sine=9.510565162951535,cosine=3.0901699437494745 1632338700000000000\n```\n",image:Hn.a},{id:"twemproxy",name:"Twemproxy",markdown:'# Twemproxy Input Plugin\n\nThe `twemproxy` plugin gathers statistics from [Twemproxy](https://github.com/twitter/twemproxy) servers.\n\n\n### Configuration\n\n```toml\n# Read Twemproxy stats data\n[[inputs.twemproxy]]\n  ## Twemproxy stats address and port (no scheme)\n  addr = "localhost:22222"\n  ## Monitor pool name\n  pools = ["redis_pool", "mc_pool"]\n```\n',image:Gi.a},{id:"udp_listener",name:"UDP Listener",markdown:"# UDP Listener Input Plugin\n\n> DEPRECATED: As of version 1.3 the UDP listener plugin has been deprecated in favor of the\n> [socket_listener plugin](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/socket_listener)\n",image:Ki.a},{id:"unbound",name:"Unbound",markdown:'# Unbound Input Plugin\n\nThis plugin gathers stats from [Unbound](https://www.unbound.net/) -\na validating, recursive, and caching DNS resolver.\n\n### Configuration:\n\n```toml\n# A plugin to collect stats from the Unbound DNS resolver\n[[inputs.unbound]]\n  ## Address of server to connect to, read from unbound conf default, optionally \':port\'\n  ## Will lookup IP if given a hostname\n  server = "127.0.0.1:8953"\n\n  ## If running as a restricted user you can prepend sudo for additional access:\n  # use_sudo = false\n\n  ## The default location of the unbound-control binary can be overridden with:\n  # binary = "/usr/sbin/unbound-control"\n\n  ## The default location of the unbound config file can be overridden with:\n  # config_file = "/etc/unbound/unbound.conf"\n\n  ## The default timeout of 1s can be overridden with:\n  # timeout = "1s"\n\n  ## When set to true, thread metrics are tagged with the thread id.\n  ##\n  ## The default is false for backwards compatibility, and will be changed to\n  ## true in a future version.  It is recommended to set to true on new\n  ## deployments.\n  thread_as_tag = false\n```\n\n#### Permissions:\n\nIt\'s important to note that this plugin references unbound-control, which may require additional permissions to execute successfully.\nDepending on the user/group permissions of the telegraf user executing this plugin, you may need to alter the group membership, set facls, or use sudo.\n\n**Group membership (Recommended)**:\n```bash\n$ groups telegraf\ntelegraf : telegraf\n\n$ usermod -a -G unbound telegraf\n\n$ groups telegraf\ntelegraf : telegraf unbound\n```\n\n**Sudo privileges**:\nIf you use this method, you will need the following in your telegraf config:\n```toml\n[[inputs.unbound]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias UNBOUNDCTL = /usr/sbin/unbound-control\ntelegraf  ALL=(ALL) NOPASSWD: UNBOUNDCTL\nDefaults!UNBOUNDCTL !logfile, !syslog, !pam_session\n```\n\nPlease use the solution you see as most appropriate.\n\n### Metrics:\n\nThis is the full list of stats provided by unbound-control and potentially collected\ndepending of your unbound configuration.  Histogram related statistics will never be collected,\nextended statistics can also be imported ("extended-statistics: yes" in unbound configuration).\nIn the output, the dots in the unbound-control stat name are replaced by underscores(see\nhttps://www.unbound.net/documentation/unbound-control.html for details).\n\nShown metrics are with `thread_as_tag` enabled.\n\n- unbound\n  - fields:\n    total_num_queries\n    total_num_cachehits\n    total_num_cachemiss\n    total_num_prefetch\n    total_num_recursivereplies\n    total_requestlist_avg\n    total_requestlist_max\n    total_requestlist_overwritten\n    total_requestlist_exceeded\n    total_requestlist_current_all\n    total_requestlist_current_user\n    total_recursion_time_avg\n    total_recursion_time_median\n    time_now\n    time_up\n    time_elapsed\n    mem_total_sbrk\n    mem_cache_rrset\n    mem_cache_message\n    mem_mod_iterator\n    mem_mod_validator\n    num_query_type_A\n    num_query_type_PTR\n    num_query_type_TXT\n    num_query_type_AAAA\n    num_query_type_SRV\n    num_query_type_ANY\n    num_query_class_IN\n    num_query_opcode_QUERY\n    num_query_tcp\n    num_query_ipv6\n    num_query_flags_QR\n    num_query_flags_AA\n    num_query_flags_TC\n    num_query_flags_RD\n    num_query_flags_RA\n    num_query_flags_Z\n    num_query_flags_AD\n    num_query_flags_CD\n    num_query_edns_present\n    num_query_edns_DO\n    num_answer_rcode_NOERROR\n    num_answer_rcode_SERVFAIL\n    num_answer_rcode_NXDOMAIN\n    num_answer_rcode_nodata\n    num_answer_secure\n    num_answer_bogus\n    num_rrset_bogus\n    unwanted_queries\n    unwanted_replies\n\n- unbound_thread\n  - tags:\n    - thread\n  - fields:\n    - num_queries\n    - num_cachehits\n    - num_cachemiss\n    - num_prefetch\n    - num_recursivereplies\n    - requestlist_avg\n    - requestlist_max\n    - requestlist_overwritten\n    - requestlist_exceeded\n    - requestlist_current_all\n    - requestlist_current_user\n    - recursion_time_avg\n    - recursion_time_median\n\n### Example Output:\n```\nunbound,host=localhost total_requestlist_avg=0,total_requestlist_exceeded=0,total_requestlist_overwritten=0,total_requestlist_current_user=0,total_recursion_time_avg=0.029186,total_tcpusage=0,total_num_queries=51,total_num_queries_ip_ratelimited=0,total_num_recursivereplies=6,total_requestlist_max=0,time_now=1522804978.784814,time_elapsed=310.435217,total_num_cachemiss=6,total_num_zero_ttl=0,time_up=310.435217,total_num_cachehits=45,total_num_prefetch=0,total_requestlist_current_all=0,total_recursion_time_median=0.016384 1522804979000000000\nunbound_threads,host=localhost,thread=0 num_queries_ip_ratelimited=0,requestlist_current_user=0,recursion_time_avg=0.029186,num_prefetch=0,requestlist_overwritten=0,requestlist_exceeded=0,requestlist_current_all=0,tcpusage=0,num_cachehits=37,num_cachemiss=6,num_recursivereplies=6,requestlist_avg=0,num_queries=43,num_zero_ttl=0,requestlist_max=0,recursion_time_median=0.032768 1522804979000000000\nunbound_threads,host=localhost,thread=1 num_zero_ttl=0,recursion_time_avg=0,num_queries_ip_ratelimited=0,num_cachehits=8,num_prefetch=0,requestlist_exceeded=0,recursion_time_median=0,tcpusage=0,num_cachemiss=0,num_recursivereplies=0,requestlist_max=0,requestlist_overwritten=0,requestlist_current_user=0,num_queries=8,requestlist_avg=0,requestlist_current_all=0 1522804979000000000\n```\n',image:Xi.a},{id:"uwsgi",name:"uWSGI",markdown:'# uWSGI Input Plugin\n\nThe uWSGI input plugin gathers metrics about uWSGI using its [Stats Server](https://uwsgi-docs.readthedocs.io/en/latest/StatsServer.html).\n\n### Configuration\n\n```toml\n[[inputs.uwsgi]]\n  ## List with urls of uWSGI Stats servers. Url must match pattern:\n  ## scheme://address[:port]\n  ##\n  ## For example:\n  ## servers = ["tcp://localhost:5050", "http://localhost:1717", "unix:///tmp/statsock"]\n  servers = ["tcp://127.0.0.1:1717"]\n\n  ## General connection timeout\n  # timeout = "5s"\n```\n\n\n### Metrics:\n\n - uwsgi_overview\n  - tags:\n    - source\n    - uid\n    - gid\n    - version\n  - fields:\n    - listen_queue\n    - listen_queue_errors\n    - signal_queue\n    - load\n    - pid\n\n+ uwsgi_workers\n  - tags:\n    - worker_id\n    - source\n  - fields:\n    - requests\n    - accepting\n    - delta_request\n    - exceptions\n    - harakiri_count\n    - pid\n    - signals\n    - signal_queue\n    - status\n    - rss\n    - vsz\n    - running_time\n    - last_spawn\n    - respawn_count\n    - tx\n    - avg_rt\n\n- uwsgi_apps\n  - tags:\n    - app_id\n    - worker_id\n    - source\n  - fields:\n    - modifier1\n    - requests\n    - startup_time\n    - exceptions\n\n+ uwsgi_cores\n  - tags:\n    - core_id\n    - worker_id\n    - source\n  - fields:\n    - requests\n    - static_requests\n    - routed_requests\n    - offloaded_requests\n    - write_errors\n    - read_errors\n    - in_request \n\n\n### Example Output:\n\n```\nuwsgi_overview,gid=0,uid=0,source=172.17.0.2,version=2.0.18 listen_queue=0i,listen_queue_errors=0i,load=0i,pid=1i,signal_queue=0i 1564441407000000000\nuwsgi_workers,source=172.17.0.2,worker_id=1 accepting=1i,avg_rt=0i,delta_request=0i,exceptions=0i,harakiri_count=0i,last_spawn=1564441202i,pid=6i,requests=0i,respawn_count=1i,rss=0i,running_time=0i,signal_queue=0i,signals=0i,status="idle",tx=0i,vsz=0i 1564441407000000000\nuwsgi_apps,app_id=0,worker_id=1,source=172.17.0.2 exceptions=0i,modifier1=0i,requests=0i,startup_time=0i 1564441407000000000\nuwsgi_cores,core_id=0,worker_id=1,source=172.17.0.2 in_request=0i,offloaded_requests=0i,read_errors=0i,requests=0i,routed_requests=0i,static_requests=0i,write_errors=0i 1564441407000000000\n```\n\n',image:$i.a},{id:"varnish",name:"Varnish",markdown:'# Varnish Input Plugin\n\nThis plugin gathers stats from [Varnish HTTP Cache](https://varnish-cache.org/)\n\n### Configuration:\n\n```toml\n[[inputs.varnish]]\n  ## If running as a restricted user you can prepend sudo for additional access:\n  #use_sudo = false\n\n  ## The default location of the varnishstat binary can be overridden with:\n  binary = "/usr/bin/varnishstat"\n\n  ## By default, telegraf gather stats for 3 metric points.\n  ## Setting stats will override the defaults shown below.\n  ## Glob matching can be used, ie, stats = ["MAIN.*"]\n  ## stats may also be set to ["*"], which will collect all stats\n  stats = ["MAIN.cache_hit", "MAIN.cache_miss", "MAIN.uptime"]\n\n  ## Optional name for the varnish instance (or working directory) to query\n  ## Usually append after -n in varnish cli\n  # instance_name = instanceName\n\n  ## Timeout for varnishstat command\n  # timeout = "1s"\n```\n\n### Measurements & Fields:\n\nThis is the full list of stats provided by varnish. Stats will be grouped by their capitalized prefix (eg MAIN, \nMEMPOOL, etc). In the output, the prefix will be used as a tag, and removed from field names.\n\n- varnish\n    - MAIN.uptime                                    (uint64, count,  Child process uptime)\n    - MAIN.sess_conn                                 (uint64, count,  Sessions accepted)\n    - MAIN.sess_drop                                 (uint64, count,  Sessions dropped)\n    - MAIN.sess_fail                                 (uint64, count,  Session accept failures)\n    - MAIN.sess_pipe_overflow                        (uint64, count,  Session pipe overflow)\n    - MAIN.client_req_400                            (uint64, count,  Client requests received,)\n    - MAIN.client_req_411                            (uint64, count,  Client requests received,)\n    - MAIN.client_req_413                            (uint64, count,  Client requests received,)\n    - MAIN.client_req_417                            (uint64, count,  Client requests received,)\n    - MAIN.client_req                                (uint64, count,  Good client requests)\n    - MAIN.cache_hit                                 (uint64, count,  Cache hits)\n    - MAIN.cache_hitpass                             (uint64, count,  Cache hits for)\n    - MAIN.cache_miss                                (uint64, count,  Cache misses)\n    - MAIN.backend_conn                              (uint64, count,  Backend conn. success)\n    - MAIN.backend_unhealthy                         (uint64, count,  Backend conn. not)\n    - MAIN.backend_busy                              (uint64, count,  Backend conn. too)\n    - MAIN.backend_fail                              (uint64, count,  Backend conn. failures)\n    - MAIN.backend_reuse                             (uint64, count,  Backend conn. reuses)\n    - MAIN.backend_toolate                           (uint64, count,  Backend conn. was)\n    - MAIN.backend_recycle                           (uint64, count,  Backend conn. recycles)\n    - MAIN.backend_retry                             (uint64, count,  Backend conn. retry)\n    - MAIN.fetch_head                                (uint64, count,  Fetch no body)\n    - MAIN.fetch_length                              (uint64, count,  Fetch with Length)\n    - MAIN.fetch_chunked                             (uint64, count,  Fetch chunked)\n    - MAIN.fetch_eof                                 (uint64, count,  Fetch EOF)\n    - MAIN.fetch_bad                                 (uint64, count,  Fetch bad T- E)\n    - MAIN.fetch_close                               (uint64, count,  Fetch wanted close)\n    - MAIN.fetch_oldhttp                             (uint64, count,  Fetch pre HTTP/1.1)\n    - MAIN.fetch_zero                                (uint64, count,  Fetch zero len)\n    - MAIN.fetch_1xx                                 (uint64, count,  Fetch no body)\n    - MAIN.fetch_204                                 (uint64, count,  Fetch no body)\n    - MAIN.fetch_304                                 (uint64, count,  Fetch no body)\n    - MAIN.fetch_failed                              (uint64, count,  Fetch failed (all)\n    - MAIN.fetch_no_thread                           (uint64, count,  Fetch failed (no)\n    - MAIN.pools                                     (uint64, count,  Number of thread)\n    - MAIN.threads                                   (uint64, count,  Total number of)\n    - MAIN.threads_limited                           (uint64, count,  Threads hit max)\n    - MAIN.threads_created                           (uint64, count,  Threads created)\n    - MAIN.threads_destroyed                         (uint64, count,  Threads destroyed)\n    - MAIN.threads_failed                            (uint64, count,  Thread creation failed)\n    - MAIN.thread_queue_len                          (uint64, count,  Length of session)\n    - MAIN.busy_sleep                                (uint64, count,  Number of requests)\n    - MAIN.busy_wakeup                               (uint64, count,  Number of requests)\n    - MAIN.sess_queued                               (uint64, count,  Sessions queued for)\n    - MAIN.sess_dropped                              (uint64, count,  Sessions dropped for)\n    - MAIN.n_object                                  (uint64, count,  object structs made)\n    - MAIN.n_vampireobject                           (uint64, count,  unresurrected objects)\n    - MAIN.n_objectcore                              (uint64, count,  objectcore structs made)\n    - MAIN.n_objecthead                              (uint64, count,  objecthead structs made)\n    - MAIN.n_waitinglist                             (uint64, count,  waitinglist structs made)\n    - MAIN.n_backend                                 (uint64, count,  Number of backends)\n    - MAIN.n_expired                                 (uint64, count,  Number of expired)\n    - MAIN.n_lru_nuked                               (uint64, count,  Number of LRU)\n    - MAIN.n_lru_moved                               (uint64, count,  Number of LRU)\n    - MAIN.losthdr                                   (uint64, count,  HTTP header overflows)\n    - MAIN.s_sess                                    (uint64, count,  Total sessions seen)\n    - MAIN.s_req                                     (uint64, count,  Total requests seen)\n    - MAIN.s_pipe                                    (uint64, count,  Total pipe sessions)\n    - MAIN.s_pass                                    (uint64, count,  Total pass- ed requests)\n    - MAIN.s_fetch                                   (uint64, count,  Total backend fetches)\n    - MAIN.s_synth                                   (uint64, count,  Total synthetic responses)\n    - MAIN.s_req_hdrbytes                            (uint64, count,  Request header bytes)\n    - MAIN.s_req_bodybytes                           (uint64, count,  Request body bytes)\n    - MAIN.s_resp_hdrbytes                           (uint64, count,  Response header bytes)\n    - MAIN.s_resp_bodybytes                          (uint64, count,  Response body bytes)\n    - MAIN.s_pipe_hdrbytes                           (uint64, count,  Pipe request header)\n    - MAIN.s_pipe_in                                 (uint64, count,  Piped bytes from)\n    - MAIN.s_pipe_out                                (uint64, count,  Piped bytes to)\n    - MAIN.sess_closed                               (uint64, count,  Session Closed)\n    - MAIN.sess_pipeline                             (uint64, count,  Session Pipeline)\n    - MAIN.sess_readahead                            (uint64, count,  Session Read Ahead)\n    - MAIN.sess_herd                                 (uint64, count,  Session herd)\n    - MAIN.shm_records                               (uint64, count,  SHM records)\n    - MAIN.shm_writes                                (uint64, count,  SHM writes)\n    - MAIN.shm_flushes                               (uint64, count,  SHM flushes due)\n    - MAIN.shm_cont                                  (uint64, count,  SHM MTX contention)\n    - MAIN.shm_cycles                                (uint64, count,  SHM cycles through)\n    - MAIN.sms_nreq                                  (uint64, count,  SMS allocator requests)\n    - MAIN.sms_nobj                                  (uint64, count,  SMS outstanding allocations)\n    - MAIN.sms_nbytes                                (uint64, count,  SMS outstanding bytes)\n    - MAIN.sms_balloc                                (uint64, count,  SMS bytes allocated)\n    - MAIN.sms_bfree                                 (uint64, count,  SMS bytes freed)\n    - MAIN.backend_req                               (uint64, count,  Backend requests made)\n    - MAIN.n_vcl                                     (uint64, count,  Number of loaded)\n    - MAIN.n_vcl_avail                               (uint64, count,  Number of VCLs)\n    - MAIN.n_vcl_discard                             (uint64, count,  Number of discarded)\n    - MAIN.bans                                      (uint64, count,  Count of bans)\n    - MAIN.bans_completed                            (uint64, count,  Number of bans)\n    - MAIN.bans_obj                                  (uint64, count,  Number of bans)\n    - MAIN.bans_req                                  (uint64, count,  Number of bans)\n    - MAIN.bans_added                                (uint64, count,  Bans added)\n    - MAIN.bans_deleted                              (uint64, count,  Bans deleted)\n    - MAIN.bans_tested                               (uint64, count,  Bans tested against)\n    - MAIN.bans_obj_killed                           (uint64, count,  Objects killed by)\n    - MAIN.bans_lurker_tested                        (uint64, count,  Bans tested against)\n    - MAIN.bans_tests_tested                         (uint64, count,  Ban tests tested)\n    - MAIN.bans_lurker_tests_tested                  (uint64, count,  Ban tests tested)\n    - MAIN.bans_lurker_obj_killed                    (uint64, count,  Objects killed by)\n    - MAIN.bans_dups                                 (uint64, count,  Bans superseded by)\n    - MAIN.bans_lurker_contention                    (uint64, count,  Lurker gave way)\n    - MAIN.bans_persisted_bytes                      (uint64, count,  Bytes used by)\n    - MAIN.bans_persisted_fragmentation              (uint64, count,  Extra bytes in)\n    - MAIN.n_purges                                  (uint64, count,  Number of purge)\n    - MAIN.n_obj_purged                              (uint64, count,  Number of purged)\n    - MAIN.exp_mailed                                (uint64, count,  Number of objects)\n    - MAIN.exp_received                              (uint64, count,  Number of objects)\n    - MAIN.hcb_nolock                                (uint64, count,  HCB Lookups without)\n    - MAIN.hcb_lock                                  (uint64, count,  HCB Lookups with)\n    - MAIN.hcb_insert                                (uint64, count,  HCB Inserts)\n    - MAIN.esi_errors                                (uint64, count,  ESI parse errors)\n    - MAIN.esi_warnings                              (uint64, count,  ESI parse warnings)\n    - MAIN.vmods                                     (uint64, count,  Loaded VMODs)\n    - MAIN.n_gzip                                    (uint64, count,  Gzip operations)\n    - MAIN.n_gunzip                                  (uint64, count,  Gunzip operations)\n    - MAIN.vsm_free                                  (uint64, count,  Free VSM space)\n    - MAIN.vsm_used                                  (uint64, count,  Used VSM space)\n    - MAIN.vsm_cooling                               (uint64, count,  Cooling VSM space)\n    - MAIN.vsm_overflow                              (uint64, count,  Overflow VSM space)\n    - MAIN.vsm_overflowed                            (uint64, count,  Overflowed VSM space)\n    - MGT.uptime                                     (uint64, count,  Management process uptime)\n    - MGT.child_start                                (uint64, count,  Child process started)\n    - MGT.child_exit                                 (uint64, count,  Child process normal)\n    - MGT.child_stop                                 (uint64, count,  Child process unexpected)\n    - MGT.child_died                                 (uint64, count,  Child process died)\n    - MGT.child_dump                                 (uint64, count,  Child process core)\n    - MGT.child_panic                                (uint64, count,  Child process panic)\n    - MEMPOOL.vbc.live                               (uint64, count,  In use)\n    - MEMPOOL.vbc.pool                               (uint64, count,  In Pool)\n    - MEMPOOL.vbc.sz_wanted                          (uint64, count,  Size requested)\n    - MEMPOOL.vbc.sz_needed                          (uint64, count,  Size allocated)\n    - MEMPOOL.vbc.allocs                             (uint64, count,  Allocations )\n    - MEMPOOL.vbc.frees                              (uint64, count,  Frees )\n    - MEMPOOL.vbc.recycle                            (uint64, count,  Recycled from pool)\n    - MEMPOOL.vbc.timeout                            (uint64, count,  Timed out from)\n    - MEMPOOL.vbc.toosmall                           (uint64, count,  Too small to)\n    - MEMPOOL.vbc.surplus                            (uint64, count,  Too many for)\n    - MEMPOOL.vbc.randry                             (uint64, count,  Pool ran dry)\n    - MEMPOOL.busyobj.live                           (uint64, count,  In use)\n    - MEMPOOL.busyobj.pool                           (uint64, count,  In Pool)\n    - MEMPOOL.busyobj.sz_wanted                      (uint64, count,  Size requested)\n    - MEMPOOL.busyobj.sz_needed                      (uint64, count,  Size allocated)\n    - MEMPOOL.busyobj.allocs                         (uint64, count,  Allocations )\n    - MEMPOOL.busyobj.frees                          (uint64, count,  Frees )\n    - MEMPOOL.busyobj.recycle                        (uint64, count,  Recycled from pool)\n    - MEMPOOL.busyobj.timeout                        (uint64, count,  Timed out from)\n    - MEMPOOL.busyobj.toosmall                       (uint64, count,  Too small to)\n    - MEMPOOL.busyobj.surplus                        (uint64, count,  Too many for)\n    - MEMPOOL.busyobj.randry                         (uint64, count,  Pool ran dry)\n    - MEMPOOL.req0.live                              (uint64, count,  In use)\n    - MEMPOOL.req0.pool                              (uint64, count,  In Pool)\n    - MEMPOOL.req0.sz_wanted                         (uint64, count,  Size requested)\n    - MEMPOOL.req0.sz_needed                         (uint64, count,  Size allocated)\n    - MEMPOOL.req0.allocs                            (uint64, count,  Allocations )\n    - MEMPOOL.req0.frees                             (uint64, count,  Frees )\n    - MEMPOOL.req0.recycle                           (uint64, count,  Recycled from pool)\n    - MEMPOOL.req0.timeout                           (uint64, count,  Timed out from)\n    - MEMPOOL.req0.toosmall                          (uint64, count,  Too small to)\n    - MEMPOOL.req0.surplus                           (uint64, count,  Too many for)\n    - MEMPOOL.req0.randry                            (uint64, count,  Pool ran dry)\n    - MEMPOOL.sess0.live                             (uint64, count,  In use)\n    - MEMPOOL.sess0.pool                             (uint64, count,  In Pool)\n    - MEMPOOL.sess0.sz_wanted                        (uint64, count,  Size requested)\n    - MEMPOOL.sess0.sz_needed                        (uint64, count,  Size allocated)\n    - MEMPOOL.sess0.allocs                           (uint64, count,  Allocations )\n    - MEMPOOL.sess0.frees                            (uint64, count,  Frees )\n    - MEMPOOL.sess0.recycle                          (uint64, count,  Recycled from pool)\n    - MEMPOOL.sess0.timeout                          (uint64, count,  Timed out from)\n    - MEMPOOL.sess0.toosmall                         (uint64, count,  Too small to)\n    - MEMPOOL.sess0.surplus                          (uint64, count,  Too many for)\n    - MEMPOOL.sess0.randry                           (uint64, count,  Pool ran dry)\n    - MEMPOOL.req1.live                              (uint64, count,  In use)\n    - MEMPOOL.req1.pool                              (uint64, count,  In Pool)\n    - MEMPOOL.req1.sz_wanted                         (uint64, count,  Size requested)\n    - MEMPOOL.req1.sz_needed                         (uint64, count,  Size allocated)\n    - MEMPOOL.req1.allocs                            (uint64, count,  Allocations )\n    - MEMPOOL.req1.frees                             (uint64, count,  Frees )\n    - MEMPOOL.req1.recycle                           (uint64, count,  Recycled from pool)\n    - MEMPOOL.req1.timeout                           (uint64, count,  Timed out from)\n    - MEMPOOL.req1.toosmall                          (uint64, count,  Too small to)\n    - MEMPOOL.req1.surplus                           (uint64, count,  Too many for)\n    - MEMPOOL.req1.randry                            (uint64, count,  Pool ran dry)\n    - MEMPOOL.sess1.live                             (uint64, count,  In use)\n    - MEMPOOL.sess1.pool                             (uint64, count,  In Pool)\n    - MEMPOOL.sess1.sz_wanted                        (uint64, count,  Size requested)\n    - MEMPOOL.sess1.sz_needed                        (uint64, count,  Size allocated)\n    - MEMPOOL.sess1.allocs                           (uint64, count,  Allocations )\n    - MEMPOOL.sess1.frees                            (uint64, count,  Frees )\n    - MEMPOOL.sess1.recycle                          (uint64, count,  Recycled from pool)\n    - MEMPOOL.sess1.timeout                          (uint64, count,  Timed out from)\n    - MEMPOOL.sess1.toosmall                         (uint64, count,  Too small to)\n    - MEMPOOL.sess1.surplus                          (uint64, count,  Too many for)\n    - MEMPOOL.sess1.randry                           (uint64, count,  Pool ran dry)\n    - SMA.s0.c_req                                   (uint64, count,  Allocator requests)\n    - SMA.s0.c_fail                                  (uint64, count,  Allocator failures)\n    - SMA.s0.c_bytes                                 (uint64, count,  Bytes allocated)\n    - SMA.s0.c_freed                                 (uint64, count,  Bytes freed)\n    - SMA.s0.g_alloc                                 (uint64, count,  Allocations outstanding)\n    - SMA.s0.g_bytes                                 (uint64, count,  Bytes outstanding)\n    - SMA.s0.g_space                                 (uint64, count,  Bytes available)\n    - SMA.Transient.c_req                            (uint64, count,  Allocator requests)\n    - SMA.Transient.c_fail                           (uint64, count,  Allocator failures)\n    - SMA.Transient.c_bytes                          (uint64, count,  Bytes allocated)\n    - SMA.Transient.c_freed                          (uint64, count,  Bytes freed)\n    - SMA.Transient.g_alloc                          (uint64, count,  Allocations outstanding)\n    - SMA.Transient.g_bytes                          (uint64, count,  Bytes outstanding)\n    - SMA.Transient.g_space                          (uint64, count,  Bytes available)\n    - VBE.default(127.0.0.1,,8080).vcls              (uint64, count,  VCL references)\n    - VBE.default(127.0.0.1,,8080).happy             (uint64, count,  Happy health probes)\n    - VBE.default(127.0.0.1,,8080).bereq_hdrbytes    (uint64, count,  Request header bytes)\n    - VBE.default(127.0.0.1,,8080).bereq_bodybytes   (uint64, count,  Request body bytes)\n    - VBE.default(127.0.0.1,,8080).beresp_hdrbytes   (uint64, count,  Response header bytes)\n    - VBE.default(127.0.0.1,,8080).beresp_bodybytes  (uint64, count,  Response body bytes)\n    - VBE.default(127.0.0.1,,8080).pipe_hdrbytes     (uint64, count,  Pipe request header)\n    - VBE.default(127.0.0.1,,8080).pipe_out          (uint64, count,  Piped bytes to)\n    - VBE.default(127.0.0.1,,8080).pipe_in           (uint64, count,  Piped bytes from)\n    - LCK.sms.creat                                  (uint64, count,  Created locks)\n    - LCK.sms.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.sms.locks                                  (uint64, count,  Lock Operations)\n    - LCK.smp.creat                                  (uint64, count,  Created locks)\n    - LCK.smp.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.smp.locks                                  (uint64, count,  Lock Operations)\n    - LCK.sma.creat                                  (uint64, count,  Created locks)\n    - LCK.sma.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.sma.locks                                  (uint64, count,  Lock Operations)\n    - LCK.smf.creat                                  (uint64, count,  Created locks)\n    - LCK.smf.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.smf.locks                                  (uint64, count,  Lock Operations)\n    - LCK.hsl.creat                                  (uint64, count,  Created locks)\n    - LCK.hsl.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.hsl.locks                                  (uint64, count,  Lock Operations)\n    - LCK.hcb.creat                                  (uint64, count,  Created locks)\n    - LCK.hcb.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.hcb.locks                                  (uint64, count,  Lock Operations)\n    - LCK.hcl.creat                                  (uint64, count,  Created locks)\n    - LCK.hcl.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.hcl.locks                                  (uint64, count,  Lock Operations)\n    - LCK.vcl.creat                                  (uint64, count,  Created locks)\n    - LCK.vcl.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.vcl.locks                                  (uint64, count,  Lock Operations)\n    - LCK.sessmem.creat                              (uint64, count,  Created locks)\n    - LCK.sessmem.destroy                            (uint64, count,  Destroyed locks)\n    - LCK.sessmem.locks                              (uint64, count,  Lock Operations)\n    - LCK.sess.creat                                 (uint64, count,  Created locks)\n    - LCK.sess.destroy                               (uint64, count,  Destroyed locks)\n    - LCK.sess.locks                                 (uint64, count,  Lock Operations)\n    - LCK.wstat.creat                                (uint64, count,  Created locks)\n    - LCK.wstat.destroy                              (uint64, count,  Destroyed locks)\n    - LCK.wstat.locks                                (uint64, count,  Lock Operations)\n    - LCK.herder.creat                               (uint64, count,  Created locks)\n    - LCK.herder.destroy                             (uint64, count,  Destroyed locks)\n    - LCK.herder.locks                               (uint64, count,  Lock Operations)\n    - LCK.wq.creat                                   (uint64, count,  Created locks)\n    - LCK.wq.destroy                                 (uint64, count,  Destroyed locks)\n    - LCK.wq.locks                                   (uint64, count,  Lock Operations)\n    - LCK.objhdr.creat                               (uint64, count,  Created locks)\n    - LCK.objhdr.destroy                             (uint64, count,  Destroyed locks)\n    - LCK.objhdr.locks                               (uint64, count,  Lock Operations)\n    - LCK.exp.creat                                  (uint64, count,  Created locks)\n    - LCK.exp.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.exp.locks                                  (uint64, count,  Lock Operations)\n    - LCK.lru.creat                                  (uint64, count,  Created locks)\n    - LCK.lru.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.lru.locks                                  (uint64, count,  Lock Operations)\n    - LCK.cli.creat                                  (uint64, count,  Created locks)\n    - LCK.cli.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.cli.locks                                  (uint64, count,  Lock Operations)\n    - LCK.ban.creat                                  (uint64, count,  Created locks)\n    - LCK.ban.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.ban.locks                                  (uint64, count,  Lock Operations)\n    - LCK.vbp.creat                                  (uint64, count,  Created locks)\n    - LCK.vbp.destroy                                (uint64, count,  Destroyed locks)\n    - LCK.vbp.locks                                  (uint64, count,  Lock Operations)\n    - LCK.backend.creat                              (uint64, count,  Created locks)\n    - LCK.backend.destroy                            (uint64, count,  Destroyed locks)\n    - LCK.backend.locks                              (uint64, count,  Lock Operations)\n    - LCK.vcapace.creat                              (uint64, count,  Created locks)\n    - LCK.vcapace.destroy                            (uint64, count,  Destroyed locks)\n    - LCK.vcapace.locks                              (uint64, count,  Lock Operations)\n    - LCK.nbusyobj.creat                             (uint64, count,  Created locks)\n    - LCK.nbusyobj.destroy                           (uint64, count,  Destroyed locks)\n    - LCK.nbusyobj.locks                             (uint64, count,  Lock Operations)\n    - LCK.busyobj.creat                              (uint64, count,  Created locks)\n    - LCK.busyobj.destroy                            (uint64, count,  Destroyed locks)\n    - LCK.busyobj.locks                              (uint64, count,  Lock Operations)\n    - LCK.mempool.creat                              (uint64, count,  Created locks)\n    - LCK.mempool.destroy                            (uint64, count,  Destroyed locks)\n    - LCK.mempool.locks                              (uint64, count,  Lock Operations)\n    - LCK.vxid.creat                                 (uint64, count,  Created locks)\n    - LCK.vxid.destroy                               (uint64, count,  Destroyed locks)\n    - LCK.vxid.locks                                 (uint64, count,  Lock Operations)\n    - LCK.pipestat.creat                             (uint64, count,  Created locks)\n    - LCK.pipestat.destroy                           (uint64, count,  Destroyed locks)\n    - LCK.pipestat.locks                             (uint64, count,  Lock Operations)\n\n\n### Tags:\n\nAs indicated above, the  prefix of a varnish stat will be used as it\'s \'section\' tag. So section tag may have one of \nthe following values:\n- section:\n  - MAIN\n  - MGT\n  - MEMPOOL\n  - SMA\n  - VBE\n  - LCK\n  \n  \n\n### Permissions:\n\nIt\'s important to note that this plugin references varnishstat, which may require additional permissions to execute successfully.\nDepending on the user/group permissions of the telegraf user executing this plugin, you may need to alter the group membership, set facls, or use sudo.\n\n**Group membership (Recommended)**:\n```bash\n$ groups telegraf\ntelegraf : telegraf\n\n$ usermod -a -G varnish telegraf\n\n$ groups telegraf\ntelegraf : telegraf varnish\n```\n\n**Extended filesystem ACL\'s**:\n```bash\n$ getfacl /var/lib/varnish/<hostname>/_.vsm\n# file: var/lib/varnish/<hostname>/_.vsm\n# owner: root\n# group: root\nuser::rw-\ngroup::r--\nother::---\n\n$ setfacl -m u:telegraf:r /var/lib/varnish/<hostname>/_.vsm\n\n$ getfacl /var/lib/varnish/<hostname>/_.vsm\n# file: var/lib/varnish/<hostname>/_.vsm\n# owner: root\n# group: root\nuser::rw-\nuser:telegraf:r--\ngroup::r--\nmask::r--\nother::---\n```\n\n**Sudo privileges**:\nIf you use this method, you will need the following in your telegraf config:\n```toml\n[[inputs.varnish]]\n  use_sudo = true\n```\n\nYou will also need to update your sudoers file:\n```bash\n$ visudo\n# Add the following line:\nCmnd_Alias VARNISHSTAT = /usr/bin/varnishstat\ntelegraf  ALL=(ALL) NOPASSWD: VARNISHSTAT\nDefaults!VARNISHSTAT !logfile, !syslog, !pam_session\n```\n\nPlease use the solution you see as most appropriate.\n\n### Example Output:\n\n```\n telegraf --config etc/telegraf.conf --input-filter varnish --test\n* Plugin: varnish, Collection 1\n> varnish,host=rpercy-VirtualBox,section=MAIN cache_hit=0i,cache_miss=0i,uptime=8416i 1462765437090957980\n```\n',image:Zi.a},{id:"vsphere",name:"VMware vSphere",markdown:'# VMware vSphere Input Plugin\n\nThe VMware vSphere plugin uses the vSphere API to gather metrics from multiple vCenter servers.\n\n* Clusters\n* Hosts\n* VMs\n* Datastores\n\n## Supported versions of vSphere\nThis plugin supports vSphere version 5.5 through 6.7.\n\n## Configuration\n\nNOTE: To disable collection of a specific resource type, simply exclude all metrics using the XX_metric_exclude.\nFor example, to disable collection of VMs, add this:\n\n```\nvm_metric_exclude = [ "*" ]\n```\n\n```toml\n# Read metrics from one or many vCenters\n[[inputs.vsphere]]\n    ## List of vCenter URLs to be monitored. These three lines must be uncommented\n  ## and edited for the plugin to work.\n  vcenters = [ "https://vcenter.local/sdk" ]\n  username = "user@corp.local"\n  password = "secret"\n\n  ## VMs\n  ## Typical VM metrics (if omitted or empty, all metrics are collected)\n  # vm_include = [ "/*/vm/**"] # Inventory path to VMs to collect (by default all are collected)\n  # vm_exclude = [] # Inventory paths to exclude\n  vm_metric_include = [\n    "cpu.demand.average",\n    "cpu.idle.summation",\n    "cpu.latency.average",\n    "cpu.readiness.average",\n    "cpu.ready.summation",\n    "cpu.run.summation",\n    "cpu.usagemhz.average",\n    "cpu.used.summation",\n    "cpu.wait.summation",\n    "mem.active.average",\n    "mem.granted.average",\n    "mem.latency.average",\n    "mem.swapin.average",\n    "mem.swapinRate.average",\n    "mem.swapout.average",\n    "mem.swapoutRate.average",\n    "mem.usage.average",\n    "mem.vmmemctl.average",\n    "net.bytesRx.average",\n    "net.bytesTx.average",\n    "net.droppedRx.summation",\n    "net.droppedTx.summation",\n    "net.usage.average",\n    "power.power.average",\n    "virtualDisk.numberReadAveraged.average",\n    "virtualDisk.numberWriteAveraged.average",\n    "virtualDisk.read.average",\n    "virtualDisk.readOIO.latest",\n    "virtualDisk.throughput.usage.average",\n    "virtualDisk.totalReadLatency.average",\n    "virtualDisk.totalWriteLatency.average",\n    "virtualDisk.write.average",\n    "virtualDisk.writeOIO.latest",\n    "sys.uptime.latest",\n  ]\n  # vm_metric_exclude = [] ## Nothing is excluded by default\n  # vm_instances = true ## true by default\n\n  ## Hosts\n  ## Typical host metrics (if omitted or empty, all metrics are collected)\n  # host_include = [ "/*/host/**"] # Inventory path to hosts to collect (by default all are collected)\n  # host_exclude [] # Inventory paths to exclude\n  host_metric_include = [\n    "cpu.coreUtilization.average",\n    "cpu.costop.summation",\n    "cpu.demand.average",\n    "cpu.idle.summation",\n    "cpu.latency.average",\n    "cpu.readiness.average",\n    "cpu.ready.summation",\n    "cpu.swapwait.summation",\n    "cpu.usage.average",\n    "cpu.usagemhz.average",\n    "cpu.used.summation",\n    "cpu.utilization.average",\n    "cpu.wait.summation",\n    "disk.deviceReadLatency.average",\n    "disk.deviceWriteLatency.average",\n    "disk.kernelReadLatency.average",\n    "disk.kernelWriteLatency.average",\n    "disk.numberReadAveraged.average",\n    "disk.numberWriteAveraged.average",\n    "disk.read.average",\n    "disk.totalReadLatency.average",\n    "disk.totalWriteLatency.average",\n    "disk.write.average",\n    "mem.active.average",\n    "mem.latency.average",\n    "mem.state.latest",\n    "mem.swapin.average",\n    "mem.swapinRate.average",\n    "mem.swapout.average",\n    "mem.swapoutRate.average",\n    "mem.totalCapacity.average",\n    "mem.usage.average",\n    "mem.vmmemctl.average",\n    "net.bytesRx.average",\n    "net.bytesTx.average",\n    "net.droppedRx.summation",\n    "net.droppedTx.summation",\n    "net.errorsRx.summation",\n    "net.errorsTx.summation",\n    "net.usage.average",\n    "power.power.average",\n    "storageAdapter.numberReadAveraged.average",\n    "storageAdapter.numberWriteAveraged.average",\n    "storageAdapter.read.average",\n    "storageAdapter.write.average",\n    "sys.uptime.latest",\n  ]\n    ## Collect IP addresses? Valid values are "ipv4" and "ipv6"\n  # ip_addresses = ["ipv6", "ipv4" ]\n\n  # host_metric_exclude = [] ## Nothing excluded by default\n  # host_instances = true ## true by default\n\n\n  ## Clusters\n  # cluster_include = [ "/*/host/**"] # Inventory path to clusters to collect (by default all are collected)\n  # cluster_exclude = [] # Inventory paths to exclude\n  # cluster_metric_include = [] ## if omitted or empty, all metrics are collected\n  # cluster_metric_exclude = [] ## Nothing excluded by default\n  # cluster_instances = false ## false by default\n\n  ## Datastores\n  # datastore_include = [ "/*/datastore/**"] # Inventory path to datastores to collect (by default all are collected)\n  # datastore_exclude = [] # Inventory paths to exclude\n  # datastore_metric_include = [] ## if omitted or empty, all metrics are collected\n  # datastore_metric_exclude = [] ## Nothing excluded by default\n  # datastore_instances = false ## false by default\n\n  ## Datacenters\n  # datacenter_include = [ "/*/host/**"] # Inventory path to clusters to collect (by default all are collected)\n  # datacenter_exclude = [] # Inventory paths to exclude\n  datacenter_metric_include = [] ## if omitted or empty, all metrics are collected\n  datacenter_metric_exclude = [ "*" ] ## Datacenters are not collected by default.\n  # datacenter_instances = false ## false by default\n\n  ## Plugin Settings\n  ## separator character to use for measurement and field names (default: "_")\n  # separator = "_"\n\n  ## number of objects to retrieve per query for realtime resources (vms and hosts)\n  ## set to 64 for vCenter 5.5 and 6.0 (default: 256)\n  # max_query_objects = 256\n\n  ## number of metrics to retrieve per query for non-realtime resources (clusters and datastores)\n  ## set to 64 for vCenter 5.5 and 6.0 (default: 256)\n  # max_query_metrics = 256\n\n  ## number of go routines to use for collection and discovery of objects and metrics\n  # collect_concurrency = 1\n  # discover_concurrency = 1\n\n  ## the interval before (re)discovering objects subject to metrics collection (default: 300s)\n  # object_discovery_interval = "300s"\n\n  ## timeout applies to any of the api request made to vcenter\n  # timeout = "60s"\n\n  ## When set to true, all samples are sent as integers. This makes the output\n  ## data types backwards compatible with Telegraf 1.9 or lower. Normally all\n  ## samples from vCenter, with the exception of percentages, are integer\n  ## values, but under some conditions, some averaging takes place internally in\n  ## the plugin. Setting this flag to "false" will send values as floats to\n  ## preserve the full precision when averaging takes place.\n  # use_int_samples = true\n\n  ## The number of vSphere 5 minute metric collection cycles to look back for non-realtime metrics. In \n  ## some versions (6.7, 7.0 and possible more), certain metrics, such as cluster metrics, may be reported\n  ## with a significant delay (>30min). If this happens, try increasing this number. Please note that increasing\n  ## it too much may cause performance issues.\n  # metric_lookback = 3\n\n  ## Custom attributes from vCenter can be very useful for queries in order to slice the\n  ## metrics along different dimension and for forming ad-hoc relationships. They are disabled\n  ## by default, since they can add a considerable amount of tags to the resulting metrics. To\n  ## enable, simply set custom_attribute_exclude to [] (empty set) and use custom_attribute_include\n  ## to select the attributes you want to include.\n  ## By default, since they can add a considerable amount of tags to the resulting metrics. To\n  ## enable, simply set custom_attribute_exclude to [] (empty set) and use custom_attribute_include\n  ## to select the attributes you want to include.\n  # custom_attribute_include = []\n  # custom_attribute_exclude = ["*"]\n\n  ## Optional SSL Config\n  # ssl_ca = "/path/to/cafile"\n  # ssl_cert = "/path/to/certfile"\n  # ssl_key = "/path/to/keyfile"\n  ## Use SSL but skip chain & host verification\n  # insecure_skip_verify = false\n```\n\n### Objects and Metrics Per Query\n\nBy default, in vCenter\'s configuration a limit is set to the number of entities that are included in a performance chart query. Default settings for vCenter 6.5 and above is 256. Prior versions of vCenter have this set to 64.\nA vCenter administrator can change this setting, see this [VMware KB article](https://kb.vmware.com/s/article/2107096) for more information.\n\nAny modification should be reflected in this plugin by modifying the parameter `max_query_objects`\n\n```\n  ## number of objects to retrieve per query for realtime resources (vms and hosts)\n  ## set to 64 for vCenter 5.5 and 6.0 (default: 256)\n  # max_query_objects = 256\n```\n\n### Collection and Discovery concurrency\n\nOn large vCenter setups it may be prudent to have multiple concurrent go routines collect performance metrics\nin order to avoid potential errors for time elapsed during a collection cycle. This should never be greater than 8,\nthough the default of 1 (no concurrency) should be sufficient for most configurations.\n\nFor setting up concurrency, modify `collect_concurrency` and `discover_concurrency` parameters.\n\n```\n  ## number of go routines to use for collection and discovery of objects and metrics\n  # collect_concurrency = 1\n  # discover_concurrency = 1\n```\n\n### Inventory Paths\nResources to be monitored can be selected using Inventory Paths. This treats the vSphere inventory as a tree structure similar\nto a file system. A vSphere inventory has a structure similar to this:\n\n```\n<root>\n+-DC0 # Virtual datacenter\n   +-datastore # Datastore folder (created by system)\n   | +-Datastore1\n   +-host # Host folder (created by system)\n   | +-Cluster1\n   | | +-Host1\n   | | | +-VM1\n   | | | +-VM2\n   | | | +-hadoop1\n   | +-Host2 # Dummy cluster created for non-clustered host\n   | | +-Host2\n   | | | +-VM3\n   | | | +-VM4\n   +-vm # VM folder (created by system)\n   | +-VM1\n   | +-VM2\n   | +-Folder1\n   | | +-hadoop1\n   | | +-NestedFolder1\n   | | | +-VM3\n   | | | +-VM4\n```\n\n#### Using Inventory Paths\nUsing familiar UNIX-style paths, one could select e.g. VM2 with the path ```/DC0/vm/VM2```.\n\nOften, we want to select a group of resource, such as all the VMs in a folder. We could use the path ```/DC0/vm/Folder1/*``` for that.\n\nAnother possibility is to select objects using a partial name, such as ```/DC0/vm/Folder1/hadoop*``` yielding all vms in Folder1 with a name starting with "hadoop".\n\nFinally, due to the arbitrary nesting of the folder structure, we need a "recursive wildcard" for traversing multiple folders. We use the "**" symbol for that. If we want to look for a VM with a name starting with "hadoop" in any folder, we could use the following path: ```/DC0/vm/**/hadoop*```\n\n#### Multiple paths to VMs\nAs we can see from the example tree above, VMs appear both in its on folder under the datacenter, as well as under the hosts. This is useful when you like to select VMs on a specific host. For example, ```/DC0/host/Cluster1/Host1/hadoop*``` selects all VMs with a name starting with "hadoop" that are running on Host1.\n\nWe can extend this to looking at a cluster level: ```/DC0/host/Cluster1/*/hadoop*```. This selects any VM matching "hadoop*" on any host in Cluster1.\n## Performance Considerations\n\n### Realtime vs. historical metrics\n\nvCenter keeps two different kinds of metrics, known as realtime and historical metrics.\n\n* Realtime metrics: Available at a 20 second granularity. These metrics are stored in memory and are very fast and cheap to query. Our tests have shown that a complete set of realtime metrics for 7000 virtual machines can be obtained in less than 20 seconds. Realtime metrics are only available on **ESXi hosts** and **virtual machine** resources. Realtime metrics are only stored for 1 hour in vCenter.\n* Historical metrics: Available at a (default) 5 minute, 30 minutes, 2 hours and 24 hours rollup levels. The vSphere Telegraf plugin only uses the most granular rollup which defaults to 5 minutes but can be changed in vCenter to other interval durations. These metrics are stored in the vCenter database and can be expensive and slow to query. Historical metrics are the only type of metrics available for **clusters**, **datastores** and **datacenters**.\n\nFor more information, refer to the vSphere documentation here: https://pubs.vmware.com/vsphere-50/index.jsp?topic=%2Fcom.vmware.wssdk.pg.doc_50%2FPG_Ch16_Performance.18.2.html\n\nThis distinction has an impact on how Telegraf collects metrics. A single instance of an input plugin can have one and only one collection interval, which means that you typically set the collection interval based on the most frequently collected metric. Let\'s assume you set the collection interval to 1 minute. All realtime metrics will be collected every minute. Since the historical metrics are only available on a 5 minute interval, the vSphere Telegraf plugin automatically skips four out of five collection cycles for these metrics. This works fine in many cases. Problems arise when the collection of historical metrics takes longer than the collection interval. This will cause error messages similar to this to appear in the Telegraf logs:\n\n```2019-01-16T13:41:10Z W! [agent] input "inputs.vsphere" did not complete within its interval```\n\nThis will disrupt the metric collection and can result in missed samples. The best practice workaround is to specify two instances of the vSphere plugin, one for the realtime metrics with a short collection interval and one for the historical metrics with a longer interval. You can use the ```*_metric_exclude``` to turn off the resources you don\'t want to collect metrics for in each instance. For example:\n\n```toml\n## Realtime instance\n[[inputs.vsphere]]\n  interval = "60s"\n  vcenters = [ "https://someaddress/sdk" ]\n  username = "someuser@vsphere.local"\n  password = "secret"\n\n  insecure_skip_verify = true\n  force_discover_on_init = true\n\n  # Exclude all historical metrics\n  datastore_metric_exclude = ["*"]\n  cluster_metric_exclude = ["*"]\n  datacenter_metric_exclude = ["*"]\n\n  collect_concurrency = 5\n  discover_concurrency = 5\n\n# Historical instance\n[[inputs.vsphere]]\n\n  interval = "300s"\n  \n  vcenters = [ "https://someaddress/sdk" ]\n  username = "someuser@vsphere.local"\n  password = "secret"\n\n  insecure_skip_verify = true\n  force_discover_on_init = true\n  host_metric_exclude = ["*"] # Exclude realtime metrics\n  vm_metric_exclude = ["*"] # Exclude realtime metrics\n\n  max_query_metrics = 256\n  collect_concurrency = 3\n```\n\n### Configuring max_query_metrics setting\n\nThe ```max_query_metrics``` determines the maximum number of metrics to attempt to retrieve in one call to vCenter. Generally speaking, a higher number means faster and more efficient queries. However, the number of allowed metrics in a query is typically limited in vCenter by the ```config.vpxd.stats.maxQueryMetrics``` setting in vCenter. The value defaults to 64 on vSphere 5.5 and older and 256 on newver versions of vCenter. The vSphere plugin always checks this setting and will automatically reduce the number if the limit configured in vCenter is lower than max_query_metrics in the plugin. This will result in a log message similar to this:\n\n```2019-01-21T03:24:18Z W! [input.vsphere] Configured max_query_metrics is 256, but server limits it to 64. Reducing.```\n\nYou may ask a vCenter administrator to increase this limit to help boost performance.\n\n### Cluster metrics and the max_query_metrics setting\n\nCluster metrics are handled a bit differently by vCenter. They are aggregated from ESXi and virtual machine metrics and may not be available when you query their most recent values. When this happens, vCenter will attempt to perform that aggregation on the fly. Unfortunately, all the subqueries needed internally in vCenter to perform this aggregation will count towards ```config.vpxd.stats.maxQueryMetrics```. This means that even a very small query may result in an error message similar to this:\n\n```2018-11-02T13:37:11Z E! Error in plugin [inputs.vsphere]: ServerFaultCode: This operation is restricted by the administrator - \'vpxd.stats.maxQueryMetrics\'. Contact your system administrator```\n\nThere are two ways of addressing this:\n* Ask your vCenter administrator to set ```config.vpxd.stats.maxQueryMetrics``` to a number that\'s higher than the total number of virtual machines managed by a vCenter instance.\n* Exclude the cluster metrics and use either the basicstats aggregator to calculate sums and averages per cluster or use queries in the visualization tool to obtain the same result.\n\n### Concurrency settings\n\nThe vSphere plugin allows you to specify two concurrency settings:\n* ```collect_concurrency```: The maximum number of simultaneous queries for performance metrics allowed per resource type.\n* ```discover_concurrency```: The  maximum number of simultaneous queries for resource discovery allowed.\n\nWhile a higher level of concurrency typically has a positive impact on performance, increasing these numbers too much can cause performance issues at the vCenter server. A rule of thumb is to set these parameters to the number of virtual machines divided by 1500 and rounded up to the nearest integer.\n\n### Configuring historical_interval setting\n\nWhen the vSphere plugin queries vCenter for historical statistics it queries for statistics that exist at a specific interval.  The default historical interval duration is 5 minutes but if this interval has been changed then you must override the default query interval in the vSphere plugin.\n* ```historical_interval```: The interval of the most granular statistics configured in vSphere represented in seconds.\n\n## Measurements &amp; Fields\n\n- Cluster Stats\n\t- Cluster services: CPU, memory, failover\n\t- CPU: total, usage\n\t- Memory: consumed, total, vmmemctl\n\t- VM operations: # changes, clone, create, deploy, destroy, power, reboot, reconfigure, register, reset, shutdown, standby, vmotion\n- Host Stats:\n\t- CPU: total, usage, cost, mhz\n\t- Datastore: iops, latency, read/write bytes, # reads/writes\n\t- Disk: commands, latency, kernel reads/writes, # reads/writes, queues\n\t- Memory: total, usage, active, latency, swap, shared, vmmemctl\n\t- Network: broadcast, bytes, dropped, errors, multicast, packets, usage\n\t- Power: energy, usage, capacity\n\t- Res CPU: active, max, running\n\t- Storage Adapter: commands, latency, # reads/writes\n\t- Storage Path: commands, latency, # reads/writes\n\t- System Resources: cpu active, cpu max, cpu running, cpu usage, mem allocated, mem consumed, mem shared, swap\n\t- System: uptime\n\t- Flash Module: active VMDKs\n- VM Stats:\n\t- CPU: demand, usage, readiness, cost, mhz\n\t- Datastore: latency, # reads/writes\n\t- Disk: commands, latency, # reads/writes, provisioned, usage\n\t- Memory: granted, usage, active, swap, vmmemctl\n\t- Network: broadcast, bytes, dropped, multicast, packets, usage\n\t- Power: energy, usage\n\t- Res CPU: active, max, running\n\t- System: operating system uptime, uptime\n\t- Virtual Disk: seeks, # reads/writes, latency, load\n- Datastore stats:\n\t- Disk: Capacity, provisioned, used\n\nFor a detailed list of commonly available metrics, please refer to [METRICS.md](METRICS.md)\n\n## Tags\n\n- all metrics\n\t- vcenter (vcenter url)\n- all host metrics\n\t- cluster (vcenter cluster)\n- all vm metrics\n\t- cluster (vcenter cluster)\n\t- esxhost (name of ESXi host)\n\t- guest (guest operating system id)\n- cpu stats for Host and VM\n\t- cpu (cpu core - not all CPU fields will have this tag)\n- datastore stats for Host and VM\n\t- datastore (id of datastore)\n- disk stats for Host and VM\n\t- disk (name of disk)\n- disk.used.capacity for Datastore\n\t- disk (type of disk)\n- net stats for Host and VM\n\t- interface (name of network interface)\n- storageAdapter stats for Host\n\t- adapter (name of storage adapter)\n- storagePath stats for Host\n\t- path (id of storage path)\n- sys.resource* stats for Host\n\t- resource (resource type)\n- vflashModule stats for Host\n\t- module (name of flash module)\n- virtualDisk stats for VM\n\t- disk (name of virtual disk)\n\n## Sample output\n\n```\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 run_summation=2608i,ready_summation=129i,usage_average=5.01,used_summation=2134i,demand_average=326i 1535660299000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 bytesRx_average=321i,bytesTx_average=335i 1535660299000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 write_average=144i,read_average=4i 1535660299000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 bytesRx_average=242i,bytesTx_average=308i 1535660299000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 write_average=232i,read_average=4i 1535660299000000000\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 usage_average=5.49,used_summation=1804i,demand_average=308i,run_summation=2001i,ready_summation=120i 1535660299000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 usage_average=4.19,used_summation=2108i,demand_average=285i,run_summation=1793i,ready_summation=93i 1535660299000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 bytesRx_average=272i,bytesTx_average=419i 1535660299000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 write_average=229i,read_average=4i 1535660299000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 run_summation=2277i,ready_summation=118i,usage_average=4.67,used_summation=2546i,demand_average=289i 1535660299000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 bytesRx_average=243i,bytesTx_average=296i 1535660299000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 write_average=158i,read_average=4i 1535660299000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,interface=vmnic0,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=1042i,bytesTx_average=753i,bytesRx_average=660i 1535660299000000000\nvsphere_host_cpu,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 utilization_average=10.46,usage_average=22.4,readiness_average=0.4,costop_summation=2i,coreUtilization_average=19.61,wait_summation=5148518i,idle_summation=58581i,latency_average=0.6,ready_summation=13370i,used_summation=19219i 1535660299000000000\nvsphere_host_cpu,cpu=0,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 coreUtilization_average=25.6,utilization_average=11.58,used_summation=24306i,usage_average=24.26,idle_summation=86688i 1535660299000000000\nvsphere_host_cpu,cpu=1,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 coreUtilization_average=12.29,utilization_average=8.32,used_summation=31312i,usage_average=22.47,idle_summation=94934i 1535660299000000000\nvsphere_host_disk,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 read_average=331i,write_average=2800i 1535660299000000000\nvsphere_host_disk,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 write_average=2701i,read_average=258i 1535660299000000000\nvsphere_host_mem,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=93.27 1535660299000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 bytesTx_average=650i,usage_average=1414i,bytesRx_average=569i 1535660299000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=1,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 utilization_average=12.6,used_summation=25775i,usage_average=24.44,idle_summation=68886i,coreUtilization_average=17.59 1535660299000000000\nvsphere_host_disk,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 read_average=340i,write_average=2340i 1535660299000000000\nvsphere_host_disk,clustername=DC0_C0,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 write_average=2277i,read_average=282i 1535660299000000000\nvsphere_host_mem,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=104.78 1535660299000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 bytesTx_average=463i,usage_average=1131i,bytesRx_average=719i 1535660299000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,interface=vmnic0,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=1668i,bytesTx_average=838i,bytesRx_average=921i 1535660299000000000\nvsphere_host_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 used_summation=28952i,utilization_average=11.36,idle_summation=93261i,latency_average=0.46,ready_summation=12837i,usage_average=21.56,readiness_average=0.39,costop_summation=2i,coreUtilization_average=27.19,wait_summation=3820829i 1535660299000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 coreUtilization_average=24.12,utilization_average=13.83,used_summation=22462i,usage_average=24.69,idle_summation=96993i 1535660299000000000\ninternal_vsphere,host=host.example.com,os=Mac,vcenter=localhost:8989 connect_ns=4727607i,discover_ns=65389011i,discovered_objects=8i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=datastore,vcenter=localhost:8989 gather_duration_ns=296223i,gather_count=0i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=vm,vcenter=192.168.1.151 gather_duration_ns=136050i,gather_count=0i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=host,vcenter=localhost:8989 gather_count=62i,gather_duration_ns=8788033i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=host,vcenter=192.168.1.151 gather_count=0i,gather_duration_ns=162002i 1535660309000000000\ninternal_gather,host=host.example.com,input=vsphere,os=Mac gather_time_ns=17483653i,metrics_gathered=28i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,vcenter=192.168.1.151 connect_ns=0i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=vm,vcenter=localhost:8989 gather_duration_ns=7291897i,gather_count=36i 1535660309000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=datastore,vcenter=192.168.1.151 gather_duration_ns=958474i,gather_count=0i 1535660309000000000\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 usage_average=8.82,used_summation=3192i,demand_average=283i,run_summation=2419i,ready_summation=115i 1535660319000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 bytesRx_average=277i,bytesTx_average=343i 1535660319000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 read_average=1i,write_average=741i 1535660319000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 bytesRx_average=386i,bytesTx_average=369i 1535660319000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 write_average=814i,read_average=1i 1535660319000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 run_summation=1778i,ready_summation=111i,usage_average=7.54,used_summation=2339i,demand_average=297i 1535660319000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 usage_average=6.98,used_summation=2125i,demand_average=211i,run_summation=2990i,ready_summation=141i 1535660319000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 bytesRx_average=357i,bytesTx_average=268i 1535660319000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 write_average=528i,read_average=1i 1535660319000000000\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 used_summation=2374i,demand_average=195i,run_summation=3454i,ready_summation=110i,usage_average=7.34 1535660319000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 bytesRx_average=308i,bytesTx_average=246i 1535660319000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 write_average=1178i,read_average=1i 1535660319000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,interface=vmnic0,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 bytesRx_average=773i,usage_average=1521i,bytesTx_average=890i 1535660319000000000\nvsphere_host_cpu,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 wait_summation=3421258i,idle_summation=67994i,latency_average=0.36,usage_average=29.86,readiness_average=0.37,used_summation=25244i,costop_summation=2i,coreUtilization_average=21.94,utilization_average=17.19,ready_summation=15897i 1535660319000000000\nvsphere_host_cpu,cpu=0,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 utilization_average=11.32,used_summation=19333i,usage_average=14.29,idle_summation=92708i,coreUtilization_average=27.68 1535660319000000000\nvsphere_host_cpu,cpu=1,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 used_summation=28596i,usage_average=25.32,idle_summation=79553i,coreUtilization_average=28.01,utilization_average=11.33 1535660319000000000\nvsphere_host_disk,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 read_average=86i,write_average=1659i 1535660319000000000\nvsphere_host_disk,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 write_average=1997i,read_average=58i 1535660319000000000\nvsphere_host_mem,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=68.45 1535660319000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 bytesTx_average=679i,usage_average=2286i,bytesRx_average=719i 1535660319000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=1,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 utilization_average=10.52,used_summation=21693i,usage_average=23.09,idle_summation=84590i,coreUtilization_average=29.92 1535660319000000000\nvsphere_host_disk,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 read_average=113i,write_average=1236i 1535660319000000000\nvsphere_host_disk,clustername=DC0_C0,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 write_average=1708i,read_average=110i 1535660319000000000\nvsphere_host_mem,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=111.46 1535660319000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 bytesTx_average=998i,usage_average=2000i,bytesRx_average=881i 1535660319000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,interface=vmnic0,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=1683i,bytesTx_average=675i,bytesRx_average=1078i 1535660319000000000\nvsphere_host_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 used_summation=28531i,wait_summation=3139129i,utilization_average=9.99,idle_summation=98579i,latency_average=0.51,costop_summation=2i,coreUtilization_average=14.35,ready_summation=16121i,usage_average=34.19,readiness_average=0.4 1535660319000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 utilization_average=12.2,used_summation=22750i,usage_average=18.84,idle_summation=99539i,coreUtilization_average=23.05 1535660319000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=host,vcenter=localhost:8989 gather_duration_ns=7076543i,gather_count=62i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=host,vcenter=192.168.1.151 gather_duration_ns=4051303i,gather_count=0i 1535660339000000000\ninternal_gather,host=host.example.com,input=vsphere,os=Mac metrics_gathered=56i,gather_time_ns=13555029i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,vcenter=192.168.1.151 connect_ns=0i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=vm,vcenter=localhost:8989 gather_duration_ns=6335467i,gather_count=36i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=datastore,vcenter=192.168.1.151 gather_duration_ns=958474i,gather_count=0i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,vcenter=localhost:8989 discover_ns=65389011i,discovered_objects=8i,connect_ns=4727607i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=datastore,vcenter=localhost:8989 gather_duration_ns=296223i,gather_count=0i 1535660339000000000\ninternal_vsphere,host=host.example.com,os=Mac,resourcetype=vm,vcenter=192.168.1.151 gather_count=0i,gather_duration_ns=1540920i 1535660339000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 write_average=302i,read_average=11i 1535660339000000000\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 usage_average=5.58,used_summation=2941i,demand_average=298i,run_summation=3255i,ready_summation=96i 1535660339000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-35,os=Mac,source=DC0_H0_VM0,vcenter=localhost:8989,vmname=DC0_H0_VM0 bytesRx_average=155i,bytesTx_average=241i 1535660339000000000\nvsphere_vm_cpu,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 usage_average=10.3,used_summation=3053i,demand_average=346i,run_summation=3289i,ready_summation=122i 1535660339000000000\nvsphere_vm_net,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 bytesRx_average=215i,bytesTx_average=275i 1535660339000000000\nvsphere_vm_virtualDisk,esxhostname=DC0_H0,guest=other,host=host.example.com,moid=vm-38,os=Mac,source=DC0_H0_VM1,vcenter=localhost:8989,vmname=DC0_H0_VM1 write_average=252i,read_average=14i 1535660339000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 usage_average=8,used_summation=2183i,demand_average=354i,run_summation=3542i,ready_summation=128i 1535660339000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 bytesRx_average=178i,bytesTx_average=200i 1535660339000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-41,os=Mac,source=DC0_C0_RP0_VM0,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM0 write_average=283i,read_average=12i 1535660339000000000\nvsphere_vm_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 demand_average=328i,run_summation=3481i,ready_summation=122i,usage_average=7.95,used_summation=2167i 1535660339000000000\nvsphere_vm_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 bytesTx_average=282i,bytesRx_average=196i 1535660339000000000\nvsphere_vm_virtualDisk,clustername=DC0_C0,esxhostname=DC0_C0_H0,guest=other,host=host.example.com,moid=vm-44,os=Mac,source=DC0_C0_RP0_VM1,vcenter=localhost:8989,vmname=DC0_C0_RP0_VM1 write_average=321i,read_average=13i 1535660339000000000\nvsphere_host_disk,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 read_average=39i,write_average=2635i 1535660339000000000\nvsphere_host_disk,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 write_average=2635i,read_average=30i 1535660339000000000\nvsphere_host_mem,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=98.5 1535660339000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=1887i,bytesRx_average=662i,bytesTx_average=251i 1535660339000000000\nvsphere_host_net,esxhostname=DC0_H0,host=host.example.com,interface=vmnic0,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 usage_average=1481i,bytesTx_average=899i,bytesRx_average=992i 1535660339000000000\nvsphere_host_cpu,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 used_summation=50405i,costop_summation=2i,utilization_average=17.32,latency_average=0.61,ready_summation=14843i,usage_average=27.94,coreUtilization_average=32.12,wait_summation=3058787i,idle_summation=56600i,readiness_average=0.36 1535660339000000000\nvsphere_host_cpu,cpu=0,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 coreUtilization_average=37.61,utilization_average=17.05,used_summation=38013i,usage_average=32.66,idle_summation=89575i 1535660339000000000\nvsphere_host_cpu,cpu=1,esxhostname=DC0_H0,host=host.example.com,moid=host-19,os=Mac,source=DC0_H0,vcenter=localhost:8989 coreUtilization_average=25.92,utilization_average=18.72,used_summation=39790i,usage_average=40.42,idle_summation=69457i 1535660339000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,interface=vmnic0,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=1246i,bytesTx_average=673i,bytesRx_average=781i 1535660339000000000\nvsphere_host_cpu,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 coreUtilization_average=33.8,idle_summation=77121i,ready_summation=15857i,readiness_average=0.39,used_summation=29554i,costop_summation=2i,wait_summation=4338417i,utilization_average=17.87,latency_average=0.44,usage_average=28.78 1535660339000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 idle_summation=86610i,coreUtilization_average=34.36,utilization_average=19.03,used_summation=28766i,usage_average=23.72 1535660339000000000\nvsphere_host_cpu,clustername=DC0_C0,cpu=1,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 coreUtilization_average=33.15,utilization_average=16.8,used_summation=44282i,usage_average=30.08,idle_summation=93490i 1535660339000000000\nvsphere_host_disk,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 read_average=56i,write_average=1672i 1535660339000000000\nvsphere_host_disk,clustername=DC0_C0,disk=/var/folders/rf/txwdm4pj409f70wnkdlp7sz80000gq/T/govcsim-DC0-LocalDS_0-367088371@folder-5,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 write_average=2110i,read_average=48i 1535660339000000000\nvsphere_host_mem,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=116.21 1535660339000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 bytesRx_average=726i,bytesTx_average=643i,usage_average=1504i 1535660339000000000\nvsphere_host_mem,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 usage_average=116.21 1535660339000000000\nvsphere_host_net,clustername=DC0_C0,esxhostname=DC0_C0_H0,host=host.example.com,moid=host-30,os=Mac,source=DC0_C0_H0,vcenter=localhost:8989 bytesRx_average=726i,bytesTx_average=643i,usage_average=1504i 1535660339000000000\n```\n',image:to.a},{id:"webhooks",name:"Webhooks",markdown:'# Webhooks Input Plugin\n\nThis is a Telegraf service plugin that start an http server and register multiple webhook listeners.\n\n```sh\n$ telegraf config -input-filter webhooks -output-filter influxdb > config.conf.new\n```\n\nChange the config file to point to the InfluxDB server you are using and adjust the settings to match your environment. Once that is complete:\n\n```sh\n$ cp config.conf.new /etc/telegraf/telegraf.conf\n$ sudo service telegraf start\n```\n\n\n### Configuration:\n\n```toml\n[[inputs.webhooks]]\n  ## Address and port to host Webhook listener on\n  service_address = ":1619"\n\n  [inputs.webhooks.filestack]\n    path = "/filestack"\n\n  [inputs.webhooks.github]\n    path = "/github"\n    # secret = ""\n\n  [inputs.webhooks.mandrill]\n    path = "/mandrill"\n\n  [inputs.webhooks.rollbar]\n    path = "/rollbar"\n\n  [inputs.webhooks.papertrail]\n    path = "/papertrail"\n\n  [inputs.webhooks.particle]\n    path = "/particle"\n```\n\n\n### Available webhooks\n\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/filestack/README.md" target="_blank" rel="noopener noreferrer">Filestack</a>\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/github/README.md" target="_blank" rel="noopener noreferrer">Github</a>\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/mandrill/README.md" target="_blank" rel="noopener noreferrer">Mandrill</a>\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/rollbar/README.md" target="_blank" rel="noopener noreferrer">Rollbar</a>\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/papertrail/README.md" target="_blank" rel="noopener noreferrer">Papertrail</a>\n- <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/particle/README.md" target="_blank" rel="noopener noreferrer">Particle</a>\n\n\n### Adding new webhooks plugin\n\n1. Add your webhook plugin inside the `webhooks` folder\n1. Your plugin must implement the `Webhook` interface\n1. Import your plugin in the `webhooks.go` file and add it to the `Webhooks` struct\n\nBoth <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/github/README.md" target="_blank" rel="noopener noreferrer">Github</a> and <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/webhooks/rollbar/README.md" target="_blank" rel="noopener noreferrer">Rollbar</a> are good examples to follow.\n',image:so.a},{id:"win_eventlog",name:"Windows Eventlog",markdown:'# Windows Eventlog Input Plugin\n\n## Collect Windows Event Log messages\n\nSupports Windows Vista and higher.\n\nTelegraf should have Administrator permissions to subscribe for some of the Windows Events Channels, like System Log.\n\nTelegraf minimum version: Telegraf 1.16.0\n\n### Configuration\n\n```toml\n[[inputs.win_eventlog]]\n  ## Telegraf should have Administrator permissions to subscribe for some Windows Events channels\n  ## (System log, for example)\n\n  ## LCID (Locale ID) for event rendering\n  ## 1033 to force English language\n  ## 0 to use default Windows locale\n  # locale = 0\n\n  ## Name of eventlog, used only if xpath_query is empty\n  ## Example: "Application"\n  # eventlog_name = ""\n\n  ## xpath_query can be in defined short form like "Event/System[EventID=999]"\n  ## or you can form a XML Query. Refer to the Consuming Events article:\n  ## https://docs.microsoft.com/en-us/windows/win32/wes/consuming-events\n  ## XML query is the recommended form, because it is most flexible\n  ## You can create or debug XML Query by creating Custom View in Windows Event Viewer\n  ## and then copying resulting XML here\n  xpath_query = \'\'\'\n  <QueryList>\n    <Query Id="0" Path="Security">\n      <Select Path="Security">*</Select>\n      <Suppress Path="Security">*[System[( (EventID &gt;= 5152 and EventID &lt;= 5158) or EventID=5379 or EventID=4672)]]</Suppress>\n    </Query>\n    <Query Id="1" Path="Application">\n      <Select Path="Application">*[System[(Level &lt; 4)]]</Select>\n    </Query>\n    <Query Id="2" Path="Windows PowerShell">\n      <Select Path="Windows PowerShell">*[System[(Level &lt; 4)]]</Select>\n    </Query>\n    <Query Id="3" Path="System">\n      <Select Path="System">*</Select>\n    </Query>\n    <Query Id="4" Path="Setup">\n      <Select Path="Setup">*</Select>\n    </Query>\n  </QueryList>\n  \'\'\'\n\n  ## System field names:\n  ##   "Source", "EventID", "Version", "Level", "Task", "Opcode", "Keywords", "TimeCreated",\n  ##   "EventRecordID", "ActivityID", "RelatedActivityID", "ProcessID", "ThreadID", "ProcessName",\n  ##   "Channel", "Computer", "UserID", "UserName", "Message", "LevelText", "TaskText", "OpcodeText"\n\n  ## In addition to System, Data fields can be unrolled from additional XML nodes in event.\n  ## Human-readable representation of those nodes is formatted into event Message field,\n  ## but XML is more machine-parsable\n\n  # Process UserData XML to fields, if this node exists in Event XML\n  process_userdata = true\n\n  # Process EventData XML to fields, if this node exists in Event XML\n  process_eventdata = true\n\n  ## Separator character to use for unrolled XML Data field names\n  separator = "_"\n\n  ## Get only first line of Message field. For most events first line is usually more than enough\n  only_first_line_of_message = true\n\n  ## Parse timestamp from TimeCreated.SystemTime event field.\n  ## Will default to current time of telegraf processing on parsing error or if set to false\n  timestamp_from_event = true\n\n  ## Fields to include as tags. Globbing supported ("Level*" for both "Level" and "LevelText")\n  event_tags = ["Source", "EventID", "Level", "LevelText", "Task", "TaskText", "Opcode", "OpcodeText", "Keywords", "Channel", "Computer"]\n\n  ## Default list of fields to send. All fields are sent by default. Globbing supported\n  event_fields = ["*"]\n\n  ## Fields to exclude. Also applied to data fields. Globbing supported\n  exclude_fields = ["TimeCreated", "Binary", "Data_Address*"]\n\n  ## Skip those tags or fields if their value is empty or equals to zero. Globbing supported\n  exclude_empty = ["*ActivityID", "UserID"]\n```\n\n### Filtering\n\nThere are three types of filtering: **Event Log** name, **XPath Query** and **XML Query**.\n\n**Event Log** name filtering is simple:\n\n```toml\n  eventlog_name = "Application"\n  xpath_query = \'\'\'\n```\n\nFor **XPath Query** filtering set the `xpath_query` value, and `eventlog_name` will be ignored:\n\n```toml\n  eventlog_name = ""\n  xpath_query = "Event/System[EventID=999]"\n```\n\n**XML Query** is the most flexible: you can Select or Suppress any values, and give ranges for other values. XML query is the recommended form, because it is most flexible. You can create or debug XML Query by creating Custom View in Windows Event Viewer and then copying resulting XML in config file.\n\nXML Query documentation:\n\n<https://docs.microsoft.com/en-us/windows/win32/wes/consuming-events>\n\n### Metrics\n\nYou can send any field, *System*, *Computed* or *XML* as tag field. List of those fields is in the `event_tags` config array. Globbing is supported in this array, i.e. `Level*` for all fields beginning with `Level`, or `L?vel` for all fields where the name is `Level`, `L3vel`, `L@vel` and so on. Tag fields are converted to strings automatically.\n\nBy default, all other fields are sent, but you can limit that either by listing it in `event_fields` config array with globbing, or by adding some field name masks in the `exclude_fields` config array.\n\nYou can limit sending fields with empty values by adding masks of names of such fields in the `exclude_empty` config array. Value considered empty, if the System field of type `int` or `uint32` is equal to zero, or if any field of type `string` is an empty string.\n\nList of System fields:\n\n- Source (string)\n- EventID (int)\n- Version (int)\n- Level (int)\n- LevelText (string)\n- Opcode (int)\n- OpcodeText (string)\n- Task (int)\n- TaskText (string)\n- Keywords (string): comma-separated in case of multiple values\n- TimeCreated (string)\n- EventRecordID (string)\n- ActivityID (string)\n- RelatedActivityID (string)\n- ProcessID (int)\n- ThreadID (int)\n- ProcessName (string): derived from ProcessID\n- Channel (string)\n- Computer (string): useful if consumed from Forwarded Events\n- UserID (string): SID\n- UserName (string): derived from UserID, presented in form of DOMAIN\\Username\n- Message (string)\n\n### Computed fields\n\nFields `Level`, `Opcode` and `Task` are converted to text and saved as computed `*Text` fields.\n\n`Keywords` field is converted from hex uint64 value by the `_EvtFormatMessage` WINAPI function. There can be more than one value, in that case they will be comma-separated. If keywords can\'t be converted (bad device driver or forwarded from another computer with unknown Event Channel), hex uint64 is saved as is.\n\n`ProcessName` field is found by looking up ProcessID. Can be empty if telegraf doesn\'t have enough permissions.\n\n`Username` field is found by looking up SID from UserID.\n\n`Message` field is rendered from the event data, and can be several kilobytes of text with line breaks. For most events the first line of this text is more then enough, and additional info is more useful to be parsed as XML fields. So, for brevity, plugin takes only the first line. You can set `only_first_line_of_message` parameter to `false` to take full message text.\n\n`TimeCreated` field is a string in RFC3339Nano format. By default Telegraf parses it as an event timestamp. If there is a field parse error or `timestamp_from_event` configration parameter is set to `false`, then event timestamp will be set to the exact time when Telegraf has parsed this event, so it will be rounded to the nearest minute.\n\n### Additional Fields\n\nThe content of **Event Data** and **User Data** XML Nodes can be added as additional fields, and is added by default. You can disable that by setting `process_userdata` or `process_eventdata` parameters to `false`.\n\nFor the fields from additional XML Nodes the `Name` attribute is taken as the name, and inner text is the value. Type of those fields is always string.\n\nName of the field is formed from XML Path by adding _ inbetween levels. For example, if UserData XML looks like this:\n\n```xml\n<UserData>\n <CbsPackageChangeState xmlns="http://manifests.microsoft.com/win/2004/08/windows/setup_provider">\n  <PackageIdentifier>KB4566782</PackageIdentifier>\n  <IntendedPackageState>5112</IntendedPackageState>\n  <IntendedPackageStateTextized>Installed</IntendedPackageStateTextized>\n  <ErrorCode>0x0</ErrorCode>\n  <Client>UpdateAgentLCU</Client>\n </CbsPackageChangeState>\n</UserData>\n```\n\nIt will be converted to following fields:\n\n```text\nCbsPackageChangeState_PackageIdentifier = "KB4566782"\nCbsPackageChangeState_IntendedPackageState = "5112"\nCbsPackageChangeState_IntendedPackageStateTextized = "Installed"\nCbsPackageChangeState_ErrorCode = "0x0"\nCbsPackageChangeState_Client = "UpdateAgentLCU"\n```\n\nIf there are more than one field with the same name, all those fields are given suffix with number: `_1`, `_2` and so on.\n\n### Localization\n\nHuman readable Event Description is in the Message field. But it is better to be skipped in favour of the Event XML values, because they are more machine-readable.\n\nKeywords, LevelText, TaskText, OpcodeText and Message are saved with the current Windows locale by default. You can override this, for example, to English locale by setting `locale` config parameter to `1033`. Unfortunately, **Event Data** and **User Data** XML Nodes are in default Windows locale only.\n\nLocale should be present on the computer. English locale is usually available on all localized versions of modern Windows. List of locales:\n\n<https://docs.microsoft.com/en-us/openspecs/office_standards/ms-oe376/6c085406-a698-4e12-9d4d-c3b0ee3dbc4a>\n\n### Example Output\n\nSome values are changed for anonymity.\n\n```text\nwin_eventlog,Channel=System,Computer=PC,EventID=105,Keywords=0x8000000000000000,Level=4,LevelText=Information,Opcode=10,OpcodeText=General,Source=WudfUsbccidDriver,Task=1,TaskText=Driver,host=PC ProcessName="WUDFHost.exe",UserName="NT AUTHORITY\\\\LOCAL SERVICE",Data_dwMaxCCIDMessageLength="271",Data_bPINSupport="0x0",Data_bMaxCCIDBusySlots="1",EventRecordID=1914688i,UserID="S-1-5-19",Version=0i,Data_bClassGetEnvelope="0x0",Data_wLcdLayout="0x0",Data_bClassGetResponse="0x0",TimeCreated="2020-08-21T08:43:26.7481077Z",Message="The Smartcard reader reported the following class descriptor (part 2)." 1597999410000000000\n\nwin_eventlog,Channel=Security,Computer=PC,EventID=4798,Keywords=Audit\\ Success,Level=0,LevelText=Information,Opcode=0,OpcodeText=Info,Source=Microsoft-Windows-Security-Auditing,Task=13824,TaskText=User\\ Account\\ Management,host=PC Data_TargetDomainName="PC",Data_SubjectUserName="User",Data_CallerProcessId="0x3d5c",Data_SubjectLogonId="0x46d14f8d",Version=0i,EventRecordID=223157i,Message="A user\'s local group membership was enumerated.",Data_TargetUserName="User",Data_TargetSid="S-1-5-21-.-.-.-1001",Data_SubjectUserSid="S-1-5-21-.-.-.-1001",Data_CallerProcessName="C:\\\\Windows\\\\explorer.exe",ActivityID="{0d4cc11d-7099-0002-4dc1-4c0d9970d601}",UserID="",Data_SubjectDomainName="PC",TimeCreated="2020-08-21T08:43:27.3036771Z",ProcessName="lsass.exe" 1597999410000000000\n\nwin_eventlog,Channel=Microsoft-Windows-Dhcp-Client/Admin,Computer=PC,EventID=1002,Keywords=0x4000000000000001,Level=2,LevelText=Error,Opcode=76,OpcodeText=IpLeaseDenied,Source=Microsoft-Windows-Dhcp-Client,Task=3,TaskText=Address\\ Configuration\\ State\\ Event,host=PC Version=0i,Message="The IP address lease 10.20.30.40 for the Network Card with network address 0xaabbccddeeff has been denied by the DHCP server 10.20.30.1 (The DHCP Server sent a DHCPNACK message).",UserID="S-1-5-19",Data_HWLength="6",Data_HWAddress="545595B7EA01",TimeCreated="2020-08-21T08:43:42.8265853Z",EventRecordID=34i,ProcessName="svchost.exe",UserName="NT AUTHORITY\\\\LOCAL SERVICE" 1597999430000000000\n\nwin_eventlog,Channel=System,Computer=PC,EventID=10016,Keywords=Classic,Level=3,LevelText=Warning,Opcode=0,OpcodeText=Info,Source=Microsoft-Windows-DistributedCOM,Task=0,host=PC Data_param3="Активация",Data_param6="PC",Data_param8="S-1-5-21-2007059868-50816014-3139024325-1001",Version=0i,UserName="PC\\\\User",Data_param1="по умолчанию для компьютера",Data_param2="Локально",Data_param7="User",Data_param9="LocalHost (с использованием LRPC)",Data_param10="Microsoft.Windows.ShellExperienceHost_10.0.19041.423_neutral_neutral_cw5n1h2txyewy",ActivityID="{839cac9e-73a1-4559-a847-62f3a5e73e44}",ProcessName="svchost.exe",Message="The по умолчанию для компьютера permission settings do not grant Локально Активация permission for the COM Server application with CLSID ",Data_param5="{316CDED5-E4AE-4B15-9113-7055D84DCC97}",Data_param11="S-1-15-2-.-.-.-.-.-.-2861478708",TimeCreated="2020-08-21T08:43:45.5233759Z",EventRecordID=1914689i,UserID="S-1-5-21-.-.-.-1001",Data_param4="{C2F03A33-21F5-47FA-B4BB-156362A2F239}" 1597999430000000000\n\n```\n',image:io.a},{id:"win_perf_counters",name:"Windows Performance Counters",markdown:'# Windows Performance Counters Input Plugin\n\nThis document presents the input plugin to read Performance Counters on Windows operating systems.\n\nThe configuration is parsed and then tested for validity, such as\nwhether the Object, Instance and Counter exist on Telegraf startup.\n\nCounter paths are refreshed periodically, see the [CountersRefreshInterval](#countersrefreshinterval)\nconfiguration parameter for more info.\n\nIn case of query for all instances `["*"]`, the plugin does not return the instance `_Total`\nby default. See [IncludeTotal](#includetotal) for more info.\n\n## Basics\n\nThe examples contained in this file have been found on the internet\nas counters used when performance monitoring\n Active Directory and IIS in particular.\n There are a lot of other good objects to monitor, if you know what to look for.\n This file is likely to be updated in the future with more examples for\n useful configurations for separate scenarios.\n\n### Plugin wide\n\nPlugin wide entries are underneath `[[inputs.win_perf_counters]]`.\n\n#### PrintValid\n\nBool, if set to `true` will print out all matching performance objects.\n\nExample:\n`PrintValid=true`\n\n#### UseWildcardsExpansion\n\nIf `UseWildcardsExpansion` is set to true, wildcards can be used in the\ninstance name and the counter name.  When using localized Windows, counters\nwill be also be localized.  Instance indexes will also be returned in the\ninstance name.\n\nPartial wildcards (e.g. `chrome*`) are supported only in the instance name on Windows Vista and newer.\n\nIf disabled, wildcards (not partial) in instance names can still be used, but\ninstance indexes will not be returned in the instance names.\n\nExample:\n`UseWildcardsExpansion=true`\n\n#### CountersRefreshInterval\n\nConfigured counters are matched against available counters at the interval\nspecified by the `CountersRefreshInterval` parameter. The default value is `1m` (1 minute).\n\nIf wildcards are used in instance or counter names, they are expanded at this point, if the `UseWildcardsExpansion` param is set to `true`.\n\nSetting the `CountersRefreshInterval` too low (order of seconds) can cause Telegraf to create\na high CPU load.\n\nSet it to `0s` to disable periodic refreshing.\n\nExample:\n`CountersRefreshInterval=1m`\n\n#### PreVistaSupport\n\n_Deprecated. Necessary features on Windows Vista and newer are checked dynamically_\n\nBool, if set to `true`, the plugin will use the localized PerfCounter interface that has been present since before Vista for backwards compatibility.\n\nIt is recommended NOT to use this on OSes starting with Vista and newer because it requires more configuration to use this than the newer interface present since Vista.\n\nExample for Windows Server 2003, this would be set to true:\n`PreVistaSupport=true`\n\n#### UsePerfCounterTime\n\nBool, if set to `true` will request a timestamp along with the PerfCounter data. \nIf se to `false`, current time will be used.\n\nSupported on Windows Vista/Windows Server 2008 and newer\nExample:\n`UsePerfCounterTime=true`\n\n### Object\n\nSee Entry below.\n\n### Entry\nA new configuration entry consists of the TOML header starting with,\n`[[inputs.win_perf_counters.object]]`.\nThis must follow before other plugin configurations,\nbeneath the main win_perf_counters entry, `[[inputs.win_perf_counters]]`.\n\nFollowing this are 3 required key/value pairs and three optional parameters and their usage.\n\n#### ObjectName\n**Required**\n\nObjectName is the Object to query for, like Processor, DirectoryServices, LogicalDisk or similar.\n\nExample: `ObjectName = "LogicalDisk"`\n\n#### Instances\n**Required**\n\nThe instances key (this is an array) declares the instances of a counter you would like returned,\nit can be one or more values.\n\nExample: `Instances = ["C:","D:","E:"]`\n\nThis will return only for the instances\nC:, D: and E: where relevant. To get all instances of a Counter, use `["*"]` only.\nBy default any results containing `_Total` are stripped,\nunless this is specified as the wanted instance.\nAlternatively see the option `IncludeTotal` below.\n\nIt is also possible to set partial wildcards, eg. `["chrome*"]`, if the `UseWildcardsExpansion` param is set to `true`\n\nSome Objects do not have instances to select from at all.\nHere only one option is valid if you want data back,\nand that is to specify `Instances = ["------"]`.\n\n#### Counters\n**Required**\n\nThe Counters key (this is an array) declares the counters of the ObjectName\nyou would like returned, it can also be one or more values.\n\nExample: `Counters = ["% Idle Time", "% Disk Read Time", "% Disk Write Time"]`\n\nThis must be specified for every counter you want the results of, or use\n`["*"]` for all the counters of the object, if the `UseWildcardsExpansion` param\nis set to `true`.\n\n#### Measurement\n*Optional*\n\nThis key is optional. If it is not set it will be `win_perf_counters`.\nIn InfluxDB this is the key underneath which the returned data is stored.\nSo for ordering your data in a good manner,\nthis is a good key to set with a value when you want your IIS and Disk results stored\nseparately from Processor results.\n\nExample: `Measurement = "win_disk"``\n\n#### IncludeTotal\n*Optional*\n\nThis key is optional. It is a simple bool.\nIf it is not set to true or included it is treated as false.\nThis key only has effect if the Instances key is set to `["*"]`\nand you would also like all instances containing `_Total` to be returned,\nlike `_Total`, `0,_Total` and so on where applicable\n(Processor Information is one example).\n\n#### WarnOnMissing\n*Optional*\n\nThis key is optional. It is a simple bool.\nIf it is not set to true or included it is treated as false.\nThis only has effect on the first execution of the plugin.\nIt will print out any ObjectName/Instance/Counter combinations\nasked for that do not match. Useful when debugging new configurations.\n\n#### FailOnMissing\n*Internal*\n\nThis key should not be used. It is for testing purposes only.\nIt is a simple bool. If it is not set to true or included this is treated as false.\nIf this is set to true, the plugin will abort and end prematurely\nif any of the combinations of ObjectName/Instances/Counters are invalid.\n\n## Examples\n\n### Generic Queries\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # Processor usage, alternative to native, reports on a per core.\n    ObjectName = "Processor"\n    Instances = ["*"]\n    Counters = ["% Idle Time", "% Interrupt Time", "% Privileged Time", "% User Time", "% Processor Time"]\n    Measurement = "win_cpu"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # Disk times and queues\n    ObjectName = "LogicalDisk"\n    Instances = ["*"]\n    Counters = ["% Idle Time", "% Disk Time","% Disk Read Time", "% Disk Write Time", "% User Time", "Current Disk Queue Length"]\n    Measurement = "win_disk"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    ObjectName = "System"\n    Counters = ["Context Switches/sec","System Calls/sec", "Processor Queue Length"]\n    Instances = ["------"]\n    Measurement = "win_system"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # Example query where the Instance portion must be removed to get data back, such as from the Memory object.\n    ObjectName = "Memory"\n    Counters = ["Available Bytes","Cache Faults/sec","Demand Zero Faults/sec","Page Faults/sec","Pages/sec","Transition Faults/sec","Pool Nonpaged Bytes","Pool Paged Bytes"]\n    Instances = ["------"] # Use 6 x - to remove the Instance bit from the query.\n    Measurement = "win_mem"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # more counters for the Network Interface Object can be found at\n    # https://msdn.microsoft.com/en-us/library/ms803962.aspx\n    ObjectName = "Network Interface"\n    Counters = ["Bytes Received/sec","Bytes Sent/sec","Packets Received/sec","Packets Sent/sec"]\n    Instances = ["*"] # Use 6 x - to remove the Instance bit from the query.\n    Measurement = "win_net"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n### Active Directory Domain Controller\n```toml\n[[inputs.win_perf_counters]]\n  [inputs.win_perf_counters.tags]\n    monitorgroup = "ActiveDirectory"\n  [[inputs.win_perf_counters.object]]\n    ObjectName = "DirectoryServices"\n    Instances = ["*"]\n    Counters = ["Base Searches/sec","Database adds/sec","Database deletes/sec","Database modifys/sec","Database recycles/sec","LDAP Client Sessions","LDAP Searches/sec","LDAP Writes/sec"]\n    Measurement = "win_ad" # Set an alternative measurement to win_perf_counters if wanted.\n    #Instances = [""] # Gathers all instances by default, specify to only gather these\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    ObjectName = "Security System-Wide Statistics"\n    Instances = ["*"]\n    Counters = ["NTLM Authentications","Kerberos Authentications","Digest Authentications"]\n    Measurement = "win_ad"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    ObjectName = "Database"\n    Instances = ["*"]\n    Counters = ["Database Cache % Hit","Database Cache Page Fault Stalls/sec","Database Cache Page Faults/sec","Database Cache Size"]\n    Measurement = "win_db"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n### DFS Namespace + Domain Controllers\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # AD, DFS N, Useful if the server hosts a DFS Namespace or is a Domain Controller\n    ObjectName = "DFS Namespace Service Referrals"\n    Instances = ["*"]\n    Counters = ["Requests Processed","Requests Failed","Avg. Response Time"]\n    Measurement = "win_dfsn"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n    #WarnOnMissing = false # Print out when the performance counter is missing, either of object, counter or instance.\n```\n\n### DFS Replication + Domain Controllers\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # AD, DFS R, Useful if the server hosts a DFS Replication folder or is a Domain Controller\n    ObjectName = "DFS Replication Service Volumes"\n    Instances = ["*"]\n    Counters = ["Data Lookups","Database Commits"]\n    Measurement = "win_dfsr"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n    #WarnOnMissing = false # Print out when the performance counter is missing, either of object, counter or instance.\n```\n\n### DNS Server + Domain Controllers\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    ObjectName = "DNS"\n    Counters = ["Dynamic Update Received","Dynamic Update Rejected","Recursive Queries","Recursive Queries Failure","Secure Update Failure","Secure Update Received","TCP Query Received","TCP Response Sent","UDP Query Received","UDP Response Sent","Total Query Received","Total Response Sent"]\n    Instances = ["------"]\n    Measurement = "win_dns"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n### IIS / ASP.NET\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # HTTP Service request queues in the Kernel before being handed over to User Mode.\n    ObjectName = "HTTP Service Request Queues"\n    Instances = ["*"]\n    Counters = ["CurrentQueueSize","RejectedRequests"]\n    Measurement = "win_http_queues"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # IIS, ASP.NET Applications\n    ObjectName = "ASP.NET Applications"\n    Counters = ["Cache Total Entries","Cache Total Hit Ratio","Cache Total Turnover Rate","Output Cache Entries","Output Cache Hits","Output Cache Hit Ratio","Output Cache Turnover Rate","Compilations Total","Errors Total/Sec","Pipeline Instance Count","Requests Executing","Requests in Application Queue","Requests/Sec"]\n    Instances = ["*"]\n    Measurement = "win_aspnet_app"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # IIS, ASP.NET\n    ObjectName = "ASP.NET"\n    Counters = ["Application Restarts","Request Wait Time","Requests Current","Requests Queued","Requests Rejected"]\n    Instances = ["*"]\n    Measurement = "win_aspnet"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # IIS, Web Service\n    ObjectName = "Web Service"\n    Counters = ["Get Requests/sec","Post Requests/sec","Connection Attempts/sec","Current Connections","ISAPI Extension Requests/sec"]\n    Instances = ["*"]\n    Measurement = "win_websvc"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # Web Service Cache / IIS\n    ObjectName = "Web Service Cache"\n    Counters = ["URI Cache Hits %","Kernel: URI Cache Hits %","File Cache Hits %"]\n    Instances = ["*"]\n    Measurement = "win_websvc_cache"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n### Process\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # Process metrics, in this case for IIS only\n    ObjectName = "Process"\n    Counters = ["% Processor Time","Handle Count","Private Bytes","Thread Count","Virtual Bytes","Working Set"]\n    Instances = ["w3wp"]\n    Measurement = "win_proc"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n### .NET Monitoring\n```toml\n[[inputs.win_perf_counters]]\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR Exceptions, in this case for IIS only\n    ObjectName = ".NET CLR Exceptions"\n    Counters = ["# of Exceps Thrown / sec"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_exceptions"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR Jit, in this case for IIS only\n    ObjectName = ".NET CLR Jit"\n    Counters = ["% Time in Jit","IL Bytes Jitted / sec"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_jit"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR Loading, in this case for IIS only\n    ObjectName = ".NET CLR Loading"\n    Counters = ["% Time Loading"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_loading"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR LocksAndThreads, in this case for IIS only\n    ObjectName = ".NET CLR LocksAndThreads"\n    Counters = ["# of current logical Threads","# of current physical Threads","# of current recognized threads","# of total recognized threads","Queue Length / sec","Total # of Contentions","Current Queue Length"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_locks"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR Memory, in this case for IIS only\n    ObjectName = ".NET CLR Memory"\n    Counters = ["% Time in GC","# Bytes in all Heaps","# Gen 0 Collections","# Gen 1 Collections","# Gen 2 Collections","# Induced GC","Allocated Bytes/sec","Finalization Survivors","Gen 0 heap size","Gen 1 heap size","Gen 2 heap size","Large Object Heap size","# of Pinned Objects"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_mem"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n\n  [[inputs.win_perf_counters.object]]\n    # .NET CLR Security, in this case for IIS only\n    ObjectName = ".NET CLR Security"\n    Counters = ["% Time in RT checks","Stack Walk Depth","Total Runtime Checks"]\n    Instances = ["w3wp"]\n    Measurement = "win_dotnet_security"\n    #IncludeTotal=false #Set to true to include _Total instance when querying for all (*).\n```\n\n## Troubleshooting\n\nIf you are getting an error about an invalid counter, use the `typeperf` command to check the counter path\non the command line.\nE.g. `typeperf "Process(chrome*)\\% Processor Time"`\n\nIf no metrics are emitted even with the default config, you may need to repair\nyour performance counters.\n\n1. Launch the Command Prompt as Administrator (right click Runs As Administrator).\n1. Drop into the C:\\WINDOWS\\System32 directory by typing `C:` then `cd \\Windows\\System32`\n1. Rebuild your counter values, which may take a few moments so please be\n   patient, by running:\n   ```\n   lodctr /r\n   ```\n',image:ro.a},{id:"win_services",name:"Windows Services",markdown:"# Windows Services Input Plugin\n\nReports information about Windows service status.\n\nMonitoring some services may require running Telegraf with administrator privileges.\n\n### Configuration:\n\n```toml\n[[inputs.win_services]]\n  ## Names of the services to monitor. Leave empty to monitor all the available services on the host. Globs accepted.\n  service_names = [\n    \"LanmanServer\",\n    \"TermService\",\n    \"Win*\",\n  ]\n```\n\n### Measurements & Fields:\n\n- win_services\n    - state : integer\n    - startup_mode : integer\n\nThe `state` field can have the following values:\n- 1 - stopped\n- 2 - start pending\n- 3 - stop pending\n- 4 - running\n- 5 - continue pending\n- 6 - pause pending\n- 7 - paused\n\nThe `startup_mode` field can have the following values:\n- 0 - boot start\n- 1 - system start\n- 2 - auto start\n- 3 - demand start\n- 4 - disabled\n\n### Tags:\n\n- All measurements have the following tags:\n    - service_name\n    - display_name\n\n### Example Output:\n```\nwin_services,host=WIN2008R2H401,display_name=Server,service_name=LanmanServer state=4i,startup_mode=2i 1500040669000000000\nwin_services,display_name=Remote\\ Desktop\\ Services,service_name=TermService,host=WIN2008R2H401 state=1i,startup_mode=3i 1500040669000000000\n```\n### TICK Scripts\n\nA sample TICK script for a notification about a not running service.\nIt sends a notification whenever any service changes its state to be not _running_ and when it changes that state back to _running_.\nThe notification is sent via an HTTP POST call.\n\n```\nstream\n    |from()\n        .database('telegraf')\n        .retentionPolicy('autogen')\n        .measurement('win_services')\n        .groupBy('host','service_name')\n    |alert()\n        .crit(lambda: \"state\" != 4)\n        .stateChangesOnly()\n        .message('Service {{ index .Tags \"service_name\" }} on Host {{ index .Tags \"host\" }} is in state {{ index .Fields \"state\" }} ')\n        .post('http://localhost:666/alert/service')\n```\n",image:_o.a},{id:"wireguard",name:"Wireguard",markdown:'# Wireguard Input Plugin\n\nThe Wireguard input plugin collects statistics on the local Wireguard server\nusing the [`wgctrl`](https://github.com/WireGuard/wgctrl-go) library. It\nreports gauge metrics for Wireguard interface device(s) and its peers.\n\n### Configuration\n\n```toml\n# Collect Wireguard server interface and peer statistics\n[[inputs.wireguard]]\n  ## Optional list of Wireguard device/interface names to query.\n  ## If omitted, all Wireguard interfaces are queried.\n  # devices = ["wg0"]\n```\n\n### Metrics\n\n- `wireguard_device`\n  - tags:\n    - `name` (interface device name, e.g. `wg0`)\n    - `type` (Wireguard tunnel type, e.g. `linux_kernel` or `userspace`)\n  - fields:\n    - `listen_port` (int, UDP port on which the interface is listening)\n    - `firewall_mark` (int, device\'s current firewall mark)\n    - `peers` (int, number of peers associated with the device)\n\n- `wireguard_peer`\n  - tags:\n    - `device` (associated interface device name, e.g. `wg0`)\n    - `public_key` (peer public key, e.g. `NZTRIrv/ClTcQoNAnChEot+WL7OH7uEGQmx8oAN9rWE=`)\n  - fields:\n    - `persistent_keepalive_interval_ns` (int, keepalive interval in nanoseconds; 0 if unset)\n    - `protocol_version` (int, Wireguard protocol version number)\n    - `allowed_ips` (int, number of allowed IPs for this peer)\n    - `last_handshake_time_ns` (int, Unix timestamp of the last handshake for this peer in nanoseconds)\n    - `rx_bytes` (int, number of bytes received from this peer)\n    - `tx_bytes` (int, number of bytes transmitted to this peer)\n\n### Troubleshooting\n\n#### Error: `operation not permitted`\n\nWhen the kernelspace implementation of Wireguard is in use (as opposed to its\nuserspace implementations), Telegraf communicates with the module over netlink.\nThis requires Telegraf to either run as root, or for the Telegraf binary to\nhave the `CAP_NET_ADMIN` capability.\n\nTo add this capability to the Telegraf binary (to allow this communication under\nthe default user `telegraf`):\n\n```bash\n$ sudo setcap CAP_NET_ADMIN+epi $(which telegraf)\n```\n\nN.B.: This capability is a filesystem attribute on the binary itself. The\nattribute needs to be re-applied if the Telegraf binary is rotated (e.g.\non installation of new a Telegraf version from the system package manager).\n\n#### Error: `error enumerating Wireguard devices`\n\nThis usually happens when the device names specified in config are invalid.\nEnsure that `sudo wg show` succeeds, and that the device names in config match\nthose printed by this command.\n\n### Example Output\n\n```\nwireguard_device,host=WGVPN,name=wg0,type=linux_kernel firewall_mark=51820i,listen_port=58216i 1582513589000000000\nwireguard_device,host=WGVPN,name=wg0,type=linux_kernel peers=1i 1582513589000000000\nwireguard_peer,device=wg0,host=WGVPN,public_key=NZTRIrv/ClTcQoNAnChEot+WL7OH7uEGQmx8oAN9rWE= allowed_ips=2i,persistent_keepalive_interval_ns=60000000000i,protocol_version=1i 1582513589000000000\nwireguard_peer,device=wg0,host=WGVPN,public_key=NZTRIrv/ClTcQoNAnChEot+WL7OH7uEGQmx8oAN9rWE= last_handshake_time_ns=1582513584530013376i,rx_bytes=6484i,tx_bytes=13540i 1582513589000000000\n```\n',image:uo.a},{id:"wireless",name:"Wireless",markdown:"# Wireless Input Plugin\n\nThe wireless plugin gathers metrics about wireless link quality by reading the `/proc/net/wireless` file. This plugin currently supports linux only.\n\n### Configuration:\n\n```toml\n# Monitor wifi signal strength and quality\n[[inputs.wireless]]\n  ## Sets 'proc' directory path\n  ## If not specified, then default is /proc\n  # host_proc = \"/proc\"\n```\n\n### Metrics:\n\n- metric\n  - tags:\n    - interface (wireless interface)\n  - fields:\n    - status (int64, gauge) - Its current state. This is a device dependent information\n    - link (int64, percentage, gauge) - general quality of the reception\n    - level (int64, dBm, gauge) - signal strength at the receiver\n    - noise (int64, dBm, gauge) - silence level (no packet) at the receiver\n    - nwid (int64, packets, counter) - number of discarded packets due to invalid network id\n    - crypt (int64, packets, counter) - number of packet unable to decrypt\n    - frag (int64, packets, counter) - fragmented packets\n    - retry (int64, packets, counter) - cumulative retry counts\n    - misc (int64, packets, counter) - dropped for un-specified reason\n    - missed_beacon (int64, packets, counter) - missed beacon packets\n\n### Example Output:\n\nThis section shows example output in Line Protocol format.\n\n```\nwireless,host=example.localdomain,interface=wlan0 misc=0i,frag=0i,link=60i,level=-50i,noise=-256i,nwid=0i,crypt=0i,retry=1525i,missed_beacon=0i,status=0i 1519843022000000000\n```\n",image:po.a},{id:"x509_cert",name:"x509 Certificate",markdown:'# x509 Certificate Input Plugin\n\nThis plugin provides information about X509 certificate accessible via local\nfile or network connection.\n\n\n### Configuration\n\n```toml\n# Reads metrics from a SSL certificate\n[[inputs.x509_cert]]\n  ## List certificate sources, support wildcard expands for files\n  ## Prefix your entry with \'file://\' if you intend to use relative paths\n  sources = ["/etc/ssl/certs/ssl-cert-snakeoil.pem", "tcp://example.org:443",\n            "/etc/mycerts/*.mydomain.org.pem", "file:///path/to/*.pem"]\n\n  ## Timeout for SSL connection\n  # timeout = "5s"\n\n  ## Pass a different name into the TLS request (Server Name Indication).\n  ## This is synonymous with tls_server_name, and only one of the two\n  ## options may be specified at one time.\n  ##   example: server_name = "myhost.example.org"\n  # server_name = "myhost.example.org"\n\n  ## Optional TLS Config\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  # tls_server_name = "myhost.example.org"\n```\n\n\n### Metrics\n\n- x509_cert\n  - tags:\n    - source - source of the certificate\n    - organization\n    - organizational_unit\n    - country\n    - province\n    - locality\n    - verification\n    - serial_number\n    - signature_algorithm\n    - public_key_algorithm\n    - issuer_common_name\n    - issuer_serial_number\n    - san\n  - fields:\n    - verification_code (int)\n    - verification_error (string)\n    - expiry (int, seconds)\n    - age (int, seconds)\n    - startdate (int, seconds)\n    - enddate (int, seconds)\n\n\n### Example output\n\n```\nx509_cert,common_name=ubuntu,source=/etc/ssl/certs/ssl-cert-snakeoil.pem,verification=valid age=7693222i,enddate=1871249033i,expiry=307666777i,startdate=1555889033i,verification_code=0i 1563582256000000000\nx509_cert,common_name=www.example.org,country=US,locality=Los\\ Angeles,organization=Internet\\ Corporation\\ for\\ Assigned\\ Names\\ and\\ Numbers,organizational_unit=Technology,province=California,source=https://example.org:443,verification=invalid age=20219055i,enddate=1606910400i,expiry=43328144i,startdate=1543363200i,verification_code=1i,verification_error="x509: certificate signed by unknown authority" 1563582256000000000\nx509_cert,common_name=DigiCert\\ SHA2\\ Secure\\ Server\\ CA,country=US,organization=DigiCert\\ Inc,source=https://example.org:443,verification=valid age=200838255i,enddate=1678276800i,expiry=114694544i,startdate=1362744000i,verification_code=0i 1563582256000000000\nx509_cert,common_name=DigiCert\\ Global\\ Root\\ CA,country=US,organization=DigiCert\\ Inc,organizational_unit=www.digicert.com,source=https://example.org:443,verification=valid age=400465455i,enddate=1952035200i,expiry=388452944i,startdate=1163116800i,verification_code=0i 1563582256000000000\n```\n',image:go.a},{id:"zfs",name:"ZFS",markdown:'# ZFS Input Plugin\n\nThis ZFS plugin provides metrics from your ZFS filesystems. It supports ZFS on\nLinux and FreeBSD. It gets ZFS stat from `/proc/spl/kstat/zfs` on Linux and\nfrom `sysctl`, \'zfs\' and `zpool` on FreeBSD.\n\n### Configuration:\n\n```toml\n[[inputs.zfs]]\n  ## ZFS kstat path. Ignored on FreeBSD\n  ## If not specified, then default is:\n  # kstatPath = "/proc/spl/kstat/zfs"\n\n  ## By default, telegraf gather all zfs stats\n  ## Override the stats list using the kstatMetrics array:\n  ## For FreeBSD, the default is:\n  # kstatMetrics = ["arcstats", "zfetchstats", "vdev_cache_stats"]\n  ## For Linux, the default is:\n  # kstatMetrics = ["abdstats", "arcstats", "dnodestats", "dbufcachestats",\n  #     "dmu_tx", "fm", "vdev_mirror_stats", "zfetchstats", "zil"]\n\n  ## By default, don\'t gather zpool stats\n  # poolMetrics = false\n\n  ## By default, don\'t gather dataset stats\n  # datasetMetrics = false\n```\n\n### Measurements & Fields:\n\nBy default this plugin collects metrics about ZFS internals pool and dataset.\nThese metrics are either counters or measure sizes\nin bytes. These metrics will be in the `zfs` measurement with the field\nnames listed bellow.\n\nIf `poolMetrics` is enabled then additional metrics will be gathered for\neach pool.\n\nIf `datasetMetrics` is enabled then additional metrics will be gathered for\neach dataset.\n\n- zfs\n    With fields listed bellow.\n\n#### ARC Stats (FreeBSD and Linux)\n\n- arcstats_allocated (FreeBSD only)\n- arcstats_anon_evict_data (Linux only)\n- arcstats_anon_evict_metadata (Linux only)\n- arcstats_anon_evictable_data (FreeBSD only)\n- arcstats_anon_evictable_metadata (FreeBSD only)\n- arcstats_anon_size\n- arcstats_arc_loaned_bytes (Linux only)\n- arcstats_arc_meta_limit\n- arcstats_arc_meta_max\n- arcstats_arc_meta_min (FreeBSD only)\n- arcstats_arc_meta_used\n- arcstats_arc_no_grow (Linux only)\n- arcstats_arc_prune (Linux only)\n- arcstats_arc_tempreserve (Linux only)\n- arcstats_c\n- arcstats_c_max\n- arcstats_c_min\n- arcstats_data_size\n- arcstats_deleted\n- arcstats_demand_data_hits\n- arcstats_demand_data_misses\n- arcstats_demand_hit_predictive_prefetch (FreeBSD only)\n- arcstats_demand_metadata_hits\n- arcstats_demand_metadata_misses\n- arcstats_duplicate_buffers\n- arcstats_duplicate_buffers_size\n- arcstats_duplicate_reads\n- arcstats_evict_l2_cached\n- arcstats_evict_l2_eligible\n- arcstats_evict_l2_ineligible\n- arcstats_evict_l2_skip (FreeBSD only)\n- arcstats_evict_not_enough (FreeBSD only)\n- arcstats_evict_skip\n- arcstats_hash_chain_max\n- arcstats_hash_chains\n- arcstats_hash_collisions\n- arcstats_hash_elements\n- arcstats_hash_elements_max\n- arcstats_hdr_size\n- arcstats_hits\n- arcstats_l2_abort_lowmem\n- arcstats_l2_asize\n- arcstats_l2_cdata_free_on_write\n- arcstats_l2_cksum_bad\n- arcstats_l2_compress_failures\n- arcstats_l2_compress_successes\n- arcstats_l2_compress_zeros\n- arcstats_l2_evict_l1cached (FreeBSD only)\n- arcstats_l2_evict_lock_retry\n- arcstats_l2_evict_reading\n- arcstats_l2_feeds\n- arcstats_l2_free_on_write\n- arcstats_l2_hdr_size\n- arcstats_l2_hits\n- arcstats_l2_io_error\n- arcstats_l2_misses\n- arcstats_l2_read_bytes\n- arcstats_l2_rw_clash\n- arcstats_l2_size\n- arcstats_l2_write_buffer_bytes_scanned (FreeBSD only)\n- arcstats_l2_write_buffer_iter (FreeBSD only)\n- arcstats_l2_write_buffer_list_iter (FreeBSD only)\n- arcstats_l2_write_buffer_list_null_iter (FreeBSD only)\n- arcstats_l2_write_bytes\n- arcstats_l2_write_full (FreeBSD only)\n- arcstats_l2_write_in_l2 (FreeBSD only)\n- arcstats_l2_write_io_in_progress (FreeBSD only)\n- arcstats_l2_write_not_cacheable (FreeBSD only)\n- arcstats_l2_write_passed_headroom (FreeBSD only)\n- arcstats_l2_write_pios (FreeBSD only)\n- arcstats_l2_write_spa_mismatch (FreeBSD only)\n- arcstats_l2_write_trylock_fail (FreeBSD only)\n- arcstats_l2_writes_done\n- arcstats_l2_writes_error\n- arcstats_l2_writes_hdr_miss (Linux only)\n- arcstats_l2_writes_lock_retry (FreeBSD only)\n- arcstats_l2_writes_sent\n- arcstats_memory_direct_count (Linux only)\n- arcstats_memory_indirect_count (Linux only)\n- arcstats_memory_throttle_count\n- arcstats_meta_size (Linux only)\n- arcstats_mfu_evict_data (Linux only)\n- arcstats_mfu_evict_metadata (Linux only)\n- arcstats_mfu_ghost_evict_data (Linux only)\n- arcstats_mfu_ghost_evict_metadata (Linux only)\n- arcstats_metadata_size (FreeBSD only)\n- arcstats_mfu_evictable_data (FreeBSD only)\n- arcstats_mfu_evictable_metadata (FreeBSD only)\n- arcstats_mfu_ghost_evictable_data (FreeBSD only)\n- arcstats_mfu_ghost_evictable_metadata (FreeBSD only)\n- arcstats_mfu_ghost_hits\n- arcstats_mfu_ghost_size\n- arcstats_mfu_hits\n- arcstats_mfu_size\n- arcstats_misses\n- arcstats_mru_evict_data (Linux only)\n- arcstats_mru_evict_metadata (Linux only)\n- arcstats_mru_ghost_evict_data (Linux only)\n- arcstats_mru_ghost_evict_metadata (Linux only)\n- arcstats_mru_evictable_data (FreeBSD only)\n- arcstats_mru_evictable_metadata (FreeBSD only)\n- arcstats_mru_ghost_evictable_data (FreeBSD only)\n- arcstats_mru_ghost_evictable_metadata (FreeBSD only)\n- arcstats_mru_ghost_hits\n- arcstats_mru_ghost_size\n- arcstats_mru_hits\n- arcstats_mru_size\n- arcstats_mutex_miss\n- arcstats_other_size\n- arcstats_p\n- arcstats_prefetch_data_hits\n- arcstats_prefetch_data_misses\n- arcstats_prefetch_metadata_hits\n- arcstats_prefetch_metadata_misses\n- arcstats_recycle_miss (Linux only)\n- arcstats_size\n- arcstats_sync_wait_for_async (FreeBSD only)\n\n#### Zfetch Stats (FreeBSD and Linux)\n\n- zfetchstats_bogus_streams (Linux only)\n- zfetchstats_colinear_hits (Linux only)\n- zfetchstats_colinear_misses (Linux only)\n- zfetchstats_hits\n- zfetchstats_max_streams (FreeBSD only)\n- zfetchstats_misses\n- zfetchstats_reclaim_failures (Linux only)\n- zfetchstats_reclaim_successes (Linux only)\n- zfetchstats_streams_noresets (Linux only)\n- zfetchstats_streams_resets (Linux only)\n- zfetchstats_stride_hits (Linux only)\n- zfetchstats_stride_misses (Linux only)\n\n#### Vdev Cache Stats (FreeBSD)\n\n- vdev_cache_stats_delegations\n- vdev_cache_stats_hits\n- vdev_cache_stats_misses\n\n#### Pool Metrics (optional)\n\nOn Linux (reference: kstat accumulated time and queue length statistics):\n\n- zfs_pool\n    - nread (integer, bytes)\n    - nwritten (integer, bytes)\n    - reads (integer, count)\n    - writes (integer, count)\n    - wtime (integer, nanoseconds) \n    - wlentime (integer, queuelength * nanoseconds)\n    - wupdate (integer, timestamp)\n    - rtime (integer, nanoseconds)\n    - rlentime (integer, queuelength * nanoseconds)\n    - rupdate (integer, timestamp)\n    - wcnt (integer, count)\n    - rcnt (integer, count)\n\nOn FreeBSD:\n\n- zfs_pool\n    - allocated (integer, bytes)\n    - capacity (integer, bytes)\n    - dedupratio (float, ratio)\n    - free (integer, bytes)\n    - size (integer, bytes)\n    - fragmentation (integer, percent)\n\n#### Dataset Metrics (optional, only on FreeBSD)\n\n- zfs_dataset\n    - avail (integer, bytes)\n    - used (integer, bytes)\n    - usedsnap (integer, bytes\n    - usedds (integer, bytes)\n\n### Tags:\n\n- ZFS stats (`zfs`) will have the following tag:\n    - pools - A `::` concatenated list of all ZFS pools on the machine.\n    - datasets - A `::` concatenated list of all ZFS datasets on the machine.\n\n- Pool metrics (`zfs_pool`) will have the following tag:\n    - pool - with the name of the pool which the metrics are for.\n    - health - the health status of the pool. (FreeBSD only)\n\n- Dataset metrics (`zfs_dataset`) will have the following tag:\n    - dataset - with the name of the dataset which the metrics are for.\n\n### Example Output:\n\n```\n$ ./telegraf --config telegraf.conf --input-filter zfs --test\n* Plugin: zfs, Collection 1\n> zfs_pool,health=ONLINE,pool=zroot allocated=1578590208i,capacity=2i,dedupratio=1,fragmentation=1i,free=64456531968i,size=66035122176i 1464473103625653908\n> zfs_dataset,dataset=zata avail=10741741326336,used=8564135526400,usedsnap=0,usedds=90112\n> zfs,pools=zroot arcstats_allocated=4167764i,arcstats_anon_evictable_data=0i,arcstats_anon_evictable_metadata=0i,arcstats_anon_size=16896i,arcstats_arc_meta_limit=10485760i,arcstats_arc_meta_max=115269568i,arcstats_arc_meta_min=8388608i,arcstats_arc_meta_used=51977456i,arcstats_c=16777216i,arcstats_c_max=41943040i,arcstats_c_min=16777216i,arcstats_data_size=0i,arcstats_deleted=1699340i,arcstats_demand_data_hits=14836131i,arcstats_demand_data_misses=2842945i,arcstats_demand_hit_predictive_prefetch=0i,arcstats_demand_metadata_hits=1655006i,arcstats_demand_metadata_misses=830074i,arcstats_duplicate_buffers=0i,arcstats_duplicate_buffers_size=0i,arcstats_duplicate_reads=123i,arcstats_evict_l2_cached=0i,arcstats_evict_l2_eligible=332172623872i,arcstats_evict_l2_ineligible=6168576i,arcstats_evict_l2_skip=0i,arcstats_evict_not_enough=12189444i,arcstats_evict_skip=195190764i,arcstats_hash_chain_max=2i,arcstats_hash_chains=10i,arcstats_hash_collisions=43134i,arcstats_hash_elements=2268i,arcstats_hash_elements_max=6136i,arcstats_hdr_size=565632i,arcstats_hits=16515778i,arcstats_l2_abort_lowmem=0i,arcstats_l2_asize=0i,arcstats_l2_cdata_free_on_write=0i,arcstats_l2_cksum_bad=0i,arcstats_l2_compress_failures=0i,arcstats_l2_compress_successes=0i,arcstats_l2_compress_zeros=0i,arcstats_l2_evict_l1cached=0i,arcstats_l2_evict_lock_retry=0i,arcstats_l2_evict_reading=0i,arcstats_l2_feeds=0i,arcstats_l2_free_on_write=0i,arcstats_l2_hdr_size=0i,arcstats_l2_hits=0i,arcstats_l2_io_error=0i,arcstats_l2_misses=0i,arcstats_l2_read_bytes=0i,arcstats_l2_rw_clash=0i,arcstats_l2_size=0i,arcstats_l2_write_buffer_bytes_scanned=0i,arcstats_l2_write_buffer_iter=0i,arcstats_l2_write_buffer_list_iter=0i,arcstats_l2_write_buffer_list_null_iter=0i,arcstats_l2_write_bytes=0i,arcstats_l2_write_full=0i,arcstats_l2_write_in_l2=0i,arcstats_l2_write_io_in_progress=0i,arcstats_l2_write_not_cacheable=380i,arcstats_l2_write_passed_headroom=0i,arcstats_l2_write_pios=0i,arcstats_l2_write_spa_mismatch=0i,arcstats_l2_write_trylock_fail=0i,arcstats_l2_writes_done=0i,arcstats_l2_writes_error=0i,arcstats_l2_writes_lock_retry=0i,arcstats_l2_writes_sent=0i,arcstats_memory_throttle_count=0i,arcstats_metadata_size=17014784i,arcstats_mfu_evictable_data=0i,arcstats_mfu_evictable_metadata=16384i,arcstats_mfu_ghost_evictable_data=5723648i,arcstats_mfu_ghost_evictable_metadata=10709504i,arcstats_mfu_ghost_hits=1315619i,arcstats_mfu_ghost_size=16433152i,arcstats_mfu_hits=7646611i,arcstats_mfu_size=305152i,arcstats_misses=3676993i,arcstats_mru_evictable_data=0i,arcstats_mru_evictable_metadata=0i,arcstats_mru_ghost_evictable_data=0i,arcstats_mru_ghost_evictable_metadata=80896i,arcstats_mru_ghost_hits=324250i,arcstats_mru_ghost_size=80896i,arcstats_mru_hits=8844526i,arcstats_mru_size=16693248i,arcstats_mutex_miss=354023i,arcstats_other_size=34397040i,arcstats_p=4172800i,arcstats_prefetch_data_hits=0i,arcstats_prefetch_data_misses=0i,arcstats_prefetch_metadata_hits=24641i,arcstats_prefetch_metadata_misses=3974i,arcstats_size=51977456i,arcstats_sync_wait_for_async=0i,vdev_cache_stats_delegations=779i,vdev_cache_stats_hits=323123i,vdev_cache_stats_misses=59929i,zfetchstats_hits=0i,zfetchstats_max_streams=0i,zfetchstats_misses=0i 1464473103634124908\n```\n\n### Description\n\nA short description for some of the metrics.\n\n#### ARC Stats\n\n`arcstats_hits` Total amount of cache hits in the arc.\n\n`arcstats_misses` Total amount of cache misses in the arc.\n\n`arcstats_demand_data_hits` Amount of cache hits for demand data, this is what matters (is good) for your application/share.\n\n`arcstats_demand_data_misses` Amount of cache misses for demand data, this is what matters (is bad) for your application/share.\n\n`arcstats_demand_metadata_hits` Amount of cache hits for demand metadata, this matters (is good) for getting filesystem data (ls,find,…)\n\n`arcstats_demand_metadata_misses` Amount of cache misses for demand metadata, this matters (is bad) for getting filesystem data (ls,find,…)\n\n`arcstats_prefetch_data_hits` The zfs prefetcher tried to prefetch something, but it was already cached (boring)\n\n`arcstats_prefetch_data_misses` The zfs prefetcher prefetched something which was not in the cache (good job, could become a demand hit in the future)\n\n`arcstats_prefetch_metadata_hits` Same as above, but for metadata\n\n`arcstats_prefetch_metadata_misses` Same as above, but for metadata\n\n`arcstats_mru_hits` Cache hit in the “most recently used cache”, we move this to the mfu cache.\n\n`arcstats_mru_ghost_hits` Cache hit in the “most recently used ghost list” we had this item in the cache, but evicted it, maybe we should increase the mru cache size.\n\n`arcstats_mfu_hits` Cache hit in the “most frequently used cache” we move this to the beginning of the mfu cache.\n\n`arcstats_mfu_ghost_hits` Cache hit in the “most frequently used ghost list” we had this item in the cache, but evicted it, maybe we should increase the mfu cache size.\n\n`arcstats_allocated` New data is written to the cache.\n\n`arcstats_deleted` Old data is evicted (deleted) from the cache.\n\n`arcstats_evict_l2_cached` We evicted something from the arc, but its still cached in the l2 if we need it.\n\n`arcstats_evict_l2_eligible` We evicted something from the arc, and it’s not in the l2 this is sad. (maybe we hadn’t had enough time to store it there)\n\n`arcstats_evict_l2_ineligible` We evicted something which cannot be stored in the l2.\n Reasons could be:\n - We have multiple pools, we evicted something from a pool without an l2 device.\n - The zfs property secondary cache.\n\n`arcstats_c` Arc target size, this is the size the system thinks the arc should have.\n\n`arcstats_size` Total size of the arc.\n\n`arcstats_l2_hits` Hits to the L2 cache. (It was not in the arc, but in the l2 cache)\n\n`arcstats_l2_misses` Miss to the L2 cache. (It was not in the arc, and not in the l2 cache)\n\n`arcstats_l2_size` Size of the l2 cache.\n\n`arcstats_l2_hdr_size` Size of the metadata in the arc (ram) used to manage (lookup if something is in the l2) the l2 cache.\n\n#### Zfetch Stats\n\n`zfetchstats_hits` Counts the number of cache hits, to items which are in the cache because of the prefetcher.\n\n`zfetchstats_misses` Counts the number of prefetch cache misses.\n\n`zfetchstats_colinear_hits` Counts the number of cache hits, to items which are in the cache because of the prefetcher (prefetched linear reads)\n\n`zfetchstats_stride_hits` Counts the number of cache hits, to items which are in the cache because of the prefetcher (prefetched stride reads)\n\n#### Vdev Cache Stats (FreeBSD only)\nnote: the vdev cache is deprecated in some ZFS implementations\n\n`vdev_cache_stats_hits` Hits to the vdev (device level) cache.\n\n`vdev_cache_stats_misses` Misses to the vdev (device level) cache.\n\n#### ABD Stats (Linux Only)\nABD is a linear/scatter dual typed buffer for ARC\n\n`abdstats_linear_cnt` number of linear ABDs which are currently allocated\n\n`abdstats_linear_data_size` amount of data stored in all linear ABDs\n\n`abdstats_scatter_cnt` number of scatter ABDs which are currently allocated\n\n`abdstats_scatter_data_size` amount of data stored in all scatter ABDs\n\n#### DMU Stats (Linux Only)\n\n`dmu_tx_dirty_throttle` counts when writes are throttled due to the amount of dirty data growing too large\n\n`dmu_tx_memory_reclaim` counts when memory is low and throttling activity\n\n`dmu_tx_memory_reserve` counts when memory footprint of the txg exceeds the ARC size\n\n#### Fault Management Ereport errors (Linux Only)\n\n`fm_erpt-dropped` counts when an error report cannot be created (eg available memory is too low)\n\n#### ZIL (Linux Only)\nnote: ZIL measurements are system-wide, neither per-pool nor per-dataset\n\n`zil_commit_count` counts when ZFS transactions are committed to a ZIL\n',image:bo.a},{id:"zipkin",name:"Zipkin",markdown:'# Zipkin Input Plugin\n\nThis plugin implements the Zipkin http server to gather trace and timing data needed to troubleshoot latency problems in microservice architectures.\n\n*Please Note: This plugin is experimental; Its data schema may be subject to change\nbased on its main usage cases and the evolution of the OpenTracing standard.*\n\n## Configuration:\n```toml\n[[inputs.zipkin]]\n    path = "/api/v1/spans" # URL path for span data\n    port = 9411 # Port on which Telegraf listens\n```\n\nThe plugin accepts spans in `JSON` or `thrift` if the `Content-Type` is `application/json` or `application/x-thrift`, respectively.\nIf `Content-Type` is not set, then the plugin assumes it is `JSON` format.\n\n## Tracing:\n\nThis plugin uses Annotations tags and fields to track data from spans\n\n- __TRACE:__ is a set of spans that share a single root span.\nTraces are built by collecting all Spans that share a traceId.\n\n- __SPAN:__ is a set of Annotations and BinaryAnnotations that correspond to a particular RPC.\n\n- __Annotations:__ for each annotation & binary annotation of a span a metric is output. *Records an occurrence in time at the beginning and end of a request.*\n\n  Annotations may have the following values:\n\n    - __CS (client start):__ beginning of span, request is made.\n    - __SR (server receive):__ server receives request and will start processing it\n      network latency & clock jitters differ it from cs\n    - __SS (server send):__ server is done processing and sends request back to client\n      amount of time it took to process request will differ it from sr\n    - __CR (client receive):__ end of span, client receives response from server\n      RPC is considered complete with this annotation\n\n### Tags\n* __"id":__               The 64 bit ID of the span.\n* __"parent_id":__        An ID associated with a particular child span.  If there is no child span, the parent ID is set to ID.\n* __"trace_id":__        The 64 or 128-bit ID of a particular trace. Every span in a trace shares this ID. Concatenation of high and low and converted to hexadecimal.\n* __"name":__             Defines a span\n\n##### Annotations have these additional tags:\n\n* __"service_name":__     Defines a service\n* __"annotation":__       The value of an annotation\n* __"endpoint_host":__    Listening port concat with IPV4, if port is not present it will not be concatenated\n\n##### Binary Annotations have these additional tag:\n\n  * __"service_name":__     Defines a service\n  * __"annotation":__       The value of an annotation\n  * __"endpoint_host":__    Listening port concat with IPV4, if port is not present it will not be concatenated\n  * __"annotation_key":__ label describing the annotation\n\n\n### Fields:\n  * __"duration_ns":__ The time in nanoseconds between the end and beginning of a span.\n\n\n\n### Sample Queries:\n\n__Get All Span Names for Service__ `my_web_server`\n```sql\nSHOW TAG VALUES FROM "zipkin" with key="name" WHERE "service_name" = \'my_web_server\'\n```\n  - __Description:__  returns a list containing the names of the spans which have annotations with the given `service_name` of `my_web_server`.\n\n__Get All Service Names__\n```sql\nSHOW TAG VALUES FROM "zipkin" WITH KEY = "service_name"\n```\n  - __Description:__  returns a list of all `distinct` endpoint service names.\n\n__Find spans with longest duration__\n```sql\nSELECT max("duration_ns") FROM "zipkin" WHERE "service_name" = \'my_service\' AND "name" = \'my_span_name\' AND time > now() - 20m GROUP BY "trace_id",time(30s) LIMIT 5\n```\n  - __Description:__  In the last 20 minutes find the top 5 longest span durations for service `my_server` and span name `my_span_name`\n\n\n### Recommended InfluxDB setup\n\nThis test will create high cardinality data so we recommend using the [tsi influxDB engine](https://www.influxdata.com/path-1-billion-time-series-influxdb-high-cardinality-indexing-ready-testing/).\n#### How To Set Up InfluxDB For Work With Zipkin\n\n  ##### Steps\n  1. ___Update___ InfluxDB to >= 1.3, in order to use the new tsi engine.\n\n  2. ___Generate___ a config file with the following command:\n```sh\ninfluxd config > /path/for/config/file\n```\n  3. ___Add___ the following to your config file, under the `[data]` tab:\n```toml\n[data]\n  index-version = "tsi1"\n```\n\n  4. ___Start___ `influxd` with your new config file:\n```sh\ninfluxd -config=/path/to/your/config/file\n```\n\n  5. ___Update___ your retention policy:\n```sql\nALTER RETENTION POLICY "autogen" ON "telegraf" DURATION 1d SHARD DURATION 30m\n```\n\n### Example Input Trace:\n\n- [Cli microservice with two services Test](https://github.com/openzipkin/zipkin-go-opentracing/tree/master/examples/cli_with_2_services)\n- [Test data from distributed trace repo sample json](https://github.com/mattkanwisher/distributedtrace/blob/master/testclient/sample.json)\n#### [Trace Example from Zipkin model](http://zipkin.io/pages/data_model.html)\n```json\n{\n  "traceId": "bd7a977555f6b982",\n  "name": "query",\n  "id": "be2d01e33cc78d97",\n  "parentId": "ebf33e1a81dc6f71",\n  "timestamp": 1458702548786000,\n  "duration": 13000,\n  "annotations": [\n    {\n      "endpoint": {\n        "serviceName": "zipkin-query",\n        "ipv4": "192.168.1.2",\n        "port": 9411\n      },\n      "timestamp": 1458702548786000,\n      "value": "cs"\n    },\n    {\n      "endpoint": {\n        "serviceName": "zipkin-query",\n        "ipv4": "192.168.1.2",\n        "port": 9411\n      },\n      "timestamp": 1458702548799000,\n      "value": "cr"\n    }\n  ],\n  "binaryAnnotations": [\n    {\n      "key": "jdbc.query",\n      "value": "select distinct `zipkin_spans`.`trace_id` from `zipkin_spans` join `zipkin_annotations` on (`zipkin_spans`.`trace_id` = `zipkin_annotations`.`trace_id` and `zipkin_spans`.`id` = `zipkin_annotations`.`span_id`) where (`zipkin_annotations`.`endpoint_service_name` = ? and `zipkin_spans`.`start_ts` between ? and ?) order by `zipkin_spans`.`start_ts` desc limit ?",\n      "endpoint": {\n        "serviceName": "zipkin-query",\n        "ipv4": "192.168.1.2",\n        "port": 9411\n      }\n    },\n    {\n      "key": "sa",\n      "value": true,\n      "endpoint": {\n        "serviceName": "spanstore-jdbc",\n        "ipv4": "127.0.0.1",\n        "port": 3306\n      }\n    }\n  ]\n}\n```\n',image:vo.a},{id:"zookeeper",name:"Zookeeper",markdown:'# Zookeeper Input Plugin\n\nThe zookeeper plugin collects variables outputted from the \'mntr\' command\n[Zookeeper Admin](https://zookeeper.apache.org/doc/current/zookeeperAdmin.html).\n\n### Configuration\n\n```toml\n# Reads \'mntr\' stats from one or many zookeeper servers\n[[inputs.zookeeper]]\n  ## An array of address to gather stats about. Specify an ip or hostname\n  ## with port. ie localhost:2181, 10.0.0.1:2181, etc.\n\n  ## If no servers are specified, then localhost is used as the host.\n  ## If no port is specified, 2181 is used\n  servers = [":2181"]\n\n  ## Timeout for metric collections from all servers.  Minimum timeout is "1s".\n  # timeout = "5s"\n\n  ## Optional TLS Config\n  # enable_tls = true\n  # tls_ca = "/etc/telegraf/ca.pem"\n  # tls_cert = "/etc/telegraf/cert.pem"\n  # tls_key = "/etc/telegraf/key.pem"\n  ## If false, skip chain & host verification\n  # insecure_skip_verify = true\n```\n\n### Metrics:\n\nExact field names are based on Zookeeper response and may vary between\nconfiguration, platform, and version.\n\n- zookeeper\n  - tags:\n    - server\n    - port\n    - state\n  - fields:\n    - approximate_data_size (integer)\n    - avg_latency (integer)\n    - ephemerals_count (integer)\n    - max_file_descriptor_count (integer)\n    - max_latency (integer)\n    - min_latency (integer)\n    - num_alive_connections (integer)\n    - open_file_descriptor_count (integer)\n    - outstanding_requests (integer)\n    - packets_received (integer)\n    - packets_sent (integer)\n    - version (string)\n    - watch_count (integer)\n    - znode_count (integer)\n    - followers (integer, leader only)\n    - synced_followers (integer, leader only)\n    - pending_syncs (integer, leader only)\n\n### Debugging:\n\nIf you have any issues please check the direct Zookeeper output using netcat:\n```sh\n$ echo mntr | nc localhost 2181\nzk_version      3.4.9-3--1, built on Thu, 01 Jun 2017 16:26:44 -0700\nzk_avg_latency  0\nzk_max_latency  0\nzk_min_latency  0\nzk_packets_received     8\nzk_packets_sent 7\nzk_num_alive_connections        1\nzk_outstanding_requests 0\nzk_server_state standalone\nzk_znode_count  129\nzk_watch_count  0\nzk_ephemerals_count     0\nzk_approximate_data_size        10044\nzk_open_file_descriptor_count   44\nzk_max_file_descriptor_count    4096\n```\n\n### Example Output\n\n```\nzookeeper,server=localhost,port=2181,state=standalone ephemerals_count=0i,approximate_data_size=10044i,open_file_descriptor_count=44i,max_latency=0i,packets_received=7i,outstanding_requests=0i,znode_count=129i,max_file_descriptor_count=4096i,version="3.4.9-3--1",avg_latency=0i,packets_sent=6i,num_alive_connections=1i,watch_count=0i,min_latency=0i 1522351112000000000\n```\n',image:ko.a}],To=e=>xo.filter(t=>t.name.toLowerCase().includes(e.toLowerCase())).sort((e,t)=>e.name.toLowerCase().localeCompare(t.name.toLowerCase()))}}]);
//# sourceMappingURL=12.9a94465ff4.js.map